I1210 16:40:08.453299      20 e2e.go:132] Starting e2e run "5f7134a9-18ea-4167-acc5-c968fb1956b7" on Ginkgo node 1
{"msg":"Test Suite starting","total":346,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1639154408 - Will randomize all specs
Will run 346 of 7042 specs

Dec 10 16:40:17.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:40:17.609: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 10 16:40:17.653: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 10 16:40:17.690: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 10 16:40:17.691: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec 10 16:40:17.691: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 10 16:40:17.698: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'flannel' (0 seconds elapsed)
Dec 10 16:40:17.698: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 10 16:40:17.698: INFO: e2e test version: v1.23.0
Dec 10 16:40:17.701: INFO: kube-apiserver version: v1.23.0
Dec 10 16:40:17.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:40:17.719: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:17.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubelet-test
W1210 16:40:17.778966      20 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Dec 10 16:40:17.779: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:17.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7340" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":346,"completed":1,"skipped":42,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:17.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:17.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2302" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":346,"completed":2,"skipped":55,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:17.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 16:40:19.245: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 10 16:40:21.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 16:40:23.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 16:40:25.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 40, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 16:40:28.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:28.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2036" for this suite.
STEP: Destroying namespace "webhook-2036-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.709 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":346,"completed":3,"skipped":76,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:28.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-c7bc7cea-d2ed-415c-beb1-20d363b6e499
STEP: Creating a pod to test consume configMaps
Dec 10 16:40:28.670: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2" in namespace "projected-2407" to be "Succeeded or Failed"
Dec 10 16:40:28.673: INFO: Pod "pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.039116ms
Dec 10 16:40:30.680: INFO: Pod "pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009975135s
STEP: Saw pod success
Dec 10 16:40:30.680: INFO: Pod "pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2" satisfied condition "Succeeded or Failed"
Dec 10 16:40:30.683: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 16:40:30.738: INFO: Waiting for pod pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2 to disappear
Dec 10 16:40:30.746: INFO: Pod pod-projected-configmaps-31d2c663-b9b6-40cc-ab6f-548bfac3bef2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:30.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2407" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":4,"skipped":88,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:30.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6150
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6150
STEP: creating replication controller externalsvc in namespace services-6150
I1210 16:40:30.952232      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-6150, replica count: 2
I1210 16:40:34.003101      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 16:40:37.004154      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 10 16:40:37.020: INFO: Creating new exec pod
Dec 10 16:40:39.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6150 exec execpodsd726 -- /bin/sh -x -c nslookup clusterip-service.services-6150.svc.cluster.local'
Dec 10 16:40:39.517: INFO: stderr: "+ nslookup clusterip-service.services-6150.svc.cluster.local\n"
Dec 10 16:40:39.517: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-6150.svc.cluster.local\tcanonical name = externalsvc.services-6150.svc.cluster.local.\nName:\texternalsvc.services-6150.svc.cluster.local\nAddress: 10.3.246.181\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6150, will wait for the garbage collector to delete the pods
Dec 10 16:40:39.578: INFO: Deleting ReplicationController externalsvc took: 5.336464ms
Dec 10 16:40:39.681: INFO: Terminating ReplicationController externalsvc pods took: 103.200831ms
Dec 10 16:40:42.010: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:42.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6150" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:11.282 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":346,"completed":5,"skipped":119,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:42.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 16:40:42.535: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 16:40:45.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:40:45.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:48.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-284" for this suite.
STEP: Destroying namespace "webhook-284-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.805 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":346,"completed":6,"skipped":186,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:48.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override arguments
Dec 10 16:40:49.050: INFO: Waiting up to 5m0s for pod "client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa" in namespace "containers-3035" to be "Succeeded or Failed"
Dec 10 16:40:49.077: INFO: Pod "client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa": Phase="Pending", Reason="", readiness=false. Elapsed: 24.776835ms
Dec 10 16:40:51.084: INFO: Pod "client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032325477s
Dec 10 16:40:53.093: INFO: Pod "client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040765152s
STEP: Saw pod success
Dec 10 16:40:53.093: INFO: Pod "client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa" satisfied condition "Succeeded or Failed"
Dec 10 16:40:53.095: INFO: Trying to get logs from node ip-10-0-19-34 pod client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa container agnhost-container: <nil>
STEP: delete the pod
Dec 10 16:40:53.111: INFO: Waiting for pod client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa to disappear
Dec 10 16:40:53.114: INFO: Pod client-containers-dd65feb4-fb94-4463-8844-fd4d3e3e4efa no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:40:53.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3035" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":346,"completed":7,"skipped":205,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:40:53.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-projected-hshp
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 16:40:53.181: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hshp" in namespace "subpath-6301" to be "Succeeded or Failed"
Dec 10 16:40:53.188: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.389991ms
Dec 10 16:40:55.194: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 2.012687474s
Dec 10 16:40:57.199: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 4.017549999s
Dec 10 16:40:59.204: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 6.022515846s
Dec 10 16:41:01.211: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 8.029573644s
Dec 10 16:41:03.217: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 10.035040632s
Dec 10 16:41:05.223: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 12.041465971s
Dec 10 16:41:07.231: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 14.049589865s
Dec 10 16:41:09.239: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 16.057359082s
Dec 10 16:41:11.246: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 18.064317317s
Dec 10 16:41:13.253: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Running", Reason="", readiness=true. Elapsed: 20.071612234s
Dec 10 16:41:15.270: INFO: Pod "pod-subpath-test-projected-hshp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.088276737s
STEP: Saw pod success
Dec 10 16:41:15.270: INFO: Pod "pod-subpath-test-projected-hshp" satisfied condition "Succeeded or Failed"
Dec 10 16:41:15.281: INFO: Trying to get logs from node ip-10-0-0-54 pod pod-subpath-test-projected-hshp container test-container-subpath-projected-hshp: <nil>
STEP: delete the pod
Dec 10 16:41:15.335: INFO: Waiting for pod pod-subpath-test-projected-hshp to disappear
Dec 10 16:41:15.342: INFO: Pod pod-subpath-test-projected-hshp no longer exists
STEP: Deleting pod pod-subpath-test-projected-hshp
Dec 10 16:41:15.342: INFO: Deleting pod "pod-subpath-test-projected-hshp" in namespace "subpath-6301"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:41:15.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6301" for this suite.

• [SLOW TEST:22.241 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":8,"skipped":207,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:41:15.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:41:21.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8139" for this suite.
STEP: Destroying namespace "nsdeletetest-9016" for this suite.
Dec 10 16:41:21.652: INFO: Namespace nsdeletetest-9016 was already deleted
STEP: Destroying namespace "nsdeletetest-2764" for this suite.

• [SLOW TEST:6.293 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":346,"completed":9,"skipped":220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:41:21.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:41:21.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 10 16:41:24.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 create -f -'
Dec 10 16:41:24.876: INFO: stderr: ""
Dec 10 16:41:24.876: INFO: stdout: "e2e-test-crd-publish-openapi-5521-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 10 16:41:24.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 delete e2e-test-crd-publish-openapi-5521-crds test-foo'
Dec 10 16:41:24.935: INFO: stderr: ""
Dec 10 16:41:24.935: INFO: stdout: "e2e-test-crd-publish-openapi-5521-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 10 16:41:24.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 apply -f -'
Dec 10 16:41:25.100: INFO: stderr: ""
Dec 10 16:41:25.100: INFO: stdout: "e2e-test-crd-publish-openapi-5521-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 10 16:41:25.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 delete e2e-test-crd-publish-openapi-5521-crds test-foo'
Dec 10 16:41:25.164: INFO: stderr: ""
Dec 10 16:41:25.164: INFO: stdout: "e2e-test-crd-publish-openapi-5521-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with value outside defined enum values
Dec 10 16:41:25.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 create -f -'
Dec 10 16:41:25.318: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 10 16:41:25.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 create -f -'
Dec 10 16:41:25.457: INFO: rc: 1
Dec 10 16:41:25.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 apply -f -'
Dec 10 16:41:25.600: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 10 16:41:25.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 create -f -'
Dec 10 16:41:25.756: INFO: rc: 1
Dec 10 16:41:25.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 --namespace=crd-publish-openapi-8469 apply -f -'
Dec 10 16:41:25.921: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 10 16:41:25.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 explain e2e-test-crd-publish-openapi-5521-crds'
Dec 10 16:41:26.109: INFO: stderr: ""
Dec 10 16:41:26.109: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 10 16:41:26.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 explain e2e-test-crd-publish-openapi-5521-crds.metadata'
Dec 10 16:41:26.335: INFO: stderr: ""
Dec 10 16:41:26.335: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 10 16:41:26.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 explain e2e-test-crd-publish-openapi-5521-crds.spec'
Dec 10 16:41:26.508: INFO: stderr: ""
Dec 10 16:41:26.508: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 10 16:41:26.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 explain e2e-test-crd-publish-openapi-5521-crds.spec.bars'
Dec 10 16:41:26.680: INFO: stderr: ""
Dec 10 16:41:26.680: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 10 16:41:26.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-8469 explain e2e-test-crd-publish-openapi-5521-crds.spec.bars2'
Dec 10 16:41:26.854: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:41:29.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8469" for this suite.

• [SLOW TEST:7.632 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":346,"completed":10,"skipped":271,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:41:29.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9487
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9487
STEP: creating replication controller externalsvc in namespace services-9487
I1210 16:41:29.367843      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9487, replica count: 2
I1210 16:41:32.419761      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 10 16:41:32.456: INFO: Creating new exec pod
Dec 10 16:41:34.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-9487 exec execpodh9txp -- /bin/sh -x -c nslookup nodeport-service.services-9487.svc.cluster.local'
Dec 10 16:41:34.704: INFO: stderr: "+ nslookup nodeport-service.services-9487.svc.cluster.local\n"
Dec 10 16:41:34.704: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-9487.svc.cluster.local\tcanonical name = externalsvc.services-9487.svc.cluster.local.\nName:\texternalsvc.services-9487.svc.cluster.local\nAddress: 10.3.249.51\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9487, will wait for the garbage collector to delete the pods
Dec 10 16:41:34.763: INFO: Deleting ReplicationController externalsvc took: 5.271125ms
Dec 10 16:41:34.865: INFO: Terminating ReplicationController externalsvc pods took: 101.908053ms
Dec 10 16:41:36.782: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:41:36.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9487" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.521 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":346,"completed":11,"skipped":272,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:41:36.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Dec 10 16:41:36.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 create -f -'
Dec 10 16:41:37.588: INFO: stderr: ""
Dec 10 16:41:37.588: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 16:41:37.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:37.677: INFO: stderr: ""
Dec 10 16:41:37.677: INFO: stdout: "update-demo-nautilus-25kpq update-demo-nautilus-sq8ln "
Dec 10 16:41:37.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-25kpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:37.739: INFO: stderr: ""
Dec 10 16:41:37.739: INFO: stdout: ""
Dec 10 16:41:37.739: INFO: update-demo-nautilus-25kpq is created but not running
Dec 10 16:41:42.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:42.935: INFO: stderr: ""
Dec 10 16:41:42.935: INFO: stdout: "update-demo-nautilus-25kpq update-demo-nautilus-sq8ln "
Dec 10 16:41:42.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-25kpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:43.110: INFO: stderr: ""
Dec 10 16:41:43.110: INFO: stdout: "true"
Dec 10 16:41:43.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-25kpq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 16:41:43.165: INFO: stderr: ""
Dec 10 16:41:43.166: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 16:41:43.166: INFO: validating pod update-demo-nautilus-25kpq
Dec 10 16:41:43.173: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 16:41:43.173: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 16:41:43.173: INFO: update-demo-nautilus-25kpq is verified up and running
Dec 10 16:41:43.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:43.230: INFO: stderr: ""
Dec 10 16:41:43.230: INFO: stdout: "true"
Dec 10 16:41:43.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 16:41:43.286: INFO: stderr: ""
Dec 10 16:41:43.286: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 16:41:43.286: INFO: validating pod update-demo-nautilus-sq8ln
Dec 10 16:41:43.289: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 16:41:43.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 16:41:43.289: INFO: update-demo-nautilus-sq8ln is verified up and running
STEP: scaling down the replication controller
Dec 10 16:41:43.291: INFO: scanned /root for discovery docs: <nil>
Dec 10 16:41:43.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Dec 10 16:41:44.376: INFO: stderr: ""
Dec 10 16:41:44.376: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 16:41:44.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:44.441: INFO: stderr: ""
Dec 10 16:41:44.441: INFO: stdout: "update-demo-nautilus-25kpq update-demo-nautilus-sq8ln "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 10 16:41:49.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:49.515: INFO: stderr: ""
Dec 10 16:41:49.515: INFO: stdout: "update-demo-nautilus-sq8ln "
Dec 10 16:41:49.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:49.631: INFO: stderr: ""
Dec 10 16:41:49.631: INFO: stdout: "true"
Dec 10 16:41:49.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 16:41:49.752: INFO: stderr: ""
Dec 10 16:41:49.752: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 16:41:49.752: INFO: validating pod update-demo-nautilus-sq8ln
Dec 10 16:41:49.758: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 16:41:49.759: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 16:41:49.759: INFO: update-demo-nautilus-sq8ln is verified up and running
STEP: scaling up the replication controller
Dec 10 16:41:49.760: INFO: scanned /root for discovery docs: <nil>
Dec 10 16:41:49.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Dec 10 16:41:50.965: INFO: stderr: ""
Dec 10 16:41:50.965: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 16:41:50.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:51.036: INFO: stderr: ""
Dec 10 16:41:51.036: INFO: stdout: "update-demo-nautilus-b5vz9 update-demo-nautilus-sq8ln "
Dec 10 16:41:51.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-b5vz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:51.100: INFO: stderr: ""
Dec 10 16:41:51.100: INFO: stdout: ""
Dec 10 16:41:51.100: INFO: update-demo-nautilus-b5vz9 is created but not running
Dec 10 16:41:56.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 16:41:56.181: INFO: stderr: ""
Dec 10 16:41:56.181: INFO: stdout: "update-demo-nautilus-b5vz9 update-demo-nautilus-sq8ln "
Dec 10 16:41:56.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-b5vz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:56.283: INFO: stderr: ""
Dec 10 16:41:56.283: INFO: stdout: "true"
Dec 10 16:41:56.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-b5vz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 16:41:56.356: INFO: stderr: ""
Dec 10 16:41:56.356: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 16:41:56.356: INFO: validating pod update-demo-nautilus-b5vz9
Dec 10 16:41:56.364: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 16:41:56.364: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 16:41:56.364: INFO: update-demo-nautilus-b5vz9 is verified up and running
Dec 10 16:41:56.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 16:41:56.485: INFO: stderr: ""
Dec 10 16:41:56.485: INFO: stdout: "true"
Dec 10 16:41:56.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods update-demo-nautilus-sq8ln -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 16:41:56.557: INFO: stderr: ""
Dec 10 16:41:56.557: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 16:41:56.557: INFO: validating pod update-demo-nautilus-sq8ln
Dec 10 16:41:56.565: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 16:41:56.565: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 16:41:56.565: INFO: update-demo-nautilus-sq8ln is verified up and running
STEP: using delete to clean up resources
Dec 10 16:41:56.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 delete --grace-period=0 --force -f -'
Dec 10 16:41:56.650: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 16:41:56.650: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 16:41:56.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get rc,svc -l name=update-demo --no-headers'
Dec 10 16:41:56.844: INFO: stderr: "No resources found in kubectl-857 namespace.\n"
Dec 10 16:41:56.844: INFO: stdout: ""
Dec 10 16:41:56.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-857 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 16:41:57.421: INFO: stderr: ""
Dec 10 16:41:57.421: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:41:57.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-857" for this suite.

• [SLOW TEST:20.603 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should scale a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":346,"completed":12,"skipped":296,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:41:57.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Dec 10 16:42:08.236: INFO: 69 pods remaining
Dec 10 16:42:08.246: INFO: 69 pods has nil DeletionTimestamp
Dec 10 16:42:08.246: INFO: 
STEP: Gathering metrics
Dec 10 16:42:13.260: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 16:42:14.284: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 10 16:42:14.296: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bt7d" in namespace "gc-7345"
Dec 10 16:42:14.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gsnd" in namespace "gc-7345"
Dec 10 16:42:14.344: INFO: Deleting pod "simpletest-rc-to-be-deleted-2h9k6" in namespace "gc-7345"
Dec 10 16:42:14.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hwfz" in namespace "gc-7345"
Dec 10 16:42:14.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-2j5bf" in namespace "gc-7345"
Dec 10 16:42:14.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-47f6n" in namespace "gc-7345"
Dec 10 16:42:14.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-4c85m" in namespace "gc-7345"
Dec 10 16:42:14.396: INFO: Deleting pod "simpletest-rc-to-be-deleted-4hw46" in namespace "gc-7345"
Dec 10 16:42:14.409: INFO: Deleting pod "simpletest-rc-to-be-deleted-56jkq" in namespace "gc-7345"
Dec 10 16:42:14.420: INFO: Deleting pod "simpletest-rc-to-be-deleted-5lppn" in namespace "gc-7345"
Dec 10 16:42:14.430: INFO: Deleting pod "simpletest-rc-to-be-deleted-69l8s" in namespace "gc-7345"
Dec 10 16:42:14.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-6b6w8" in namespace "gc-7345"
Dec 10 16:42:14.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cxxz" in namespace "gc-7345"
Dec 10 16:42:14.472: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jmzh" in namespace "gc-7345"
Dec 10 16:42:14.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l7qj" in namespace "gc-7345"
Dec 10 16:42:14.519: INFO: Deleting pod "simpletest-rc-to-be-deleted-79j8v" in namespace "gc-7345"
Dec 10 16:42:14.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-7nstr" in namespace "gc-7345"
Dec 10 16:42:14.560: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pskg" in namespace "gc-7345"
Dec 10 16:42:14.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pw2n" in namespace "gc-7345"
Dec 10 16:42:14.608: INFO: Deleting pod "simpletest-rc-to-be-deleted-7spft" in namespace "gc-7345"
Dec 10 16:42:14.622: INFO: Deleting pod "simpletest-rc-to-be-deleted-86j92" in namespace "gc-7345"
Dec 10 16:42:14.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dmdh" in namespace "gc-7345"
Dec 10 16:42:14.665: INFO: Deleting pod "simpletest-rc-to-be-deleted-8j6bb" in namespace "gc-7345"
Dec 10 16:42:14.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-8kd6k" in namespace "gc-7345"
Dec 10 16:42:14.730: INFO: Deleting pod "simpletest-rc-to-be-deleted-8xchk" in namespace "gc-7345"
Dec 10 16:42:14.754: INFO: Deleting pod "simpletest-rc-to-be-deleted-92n7w" in namespace "gc-7345"
Dec 10 16:42:14.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dh68" in namespace "gc-7345"
Dec 10 16:42:14.781: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mjm8" in namespace "gc-7345"
Dec 10 16:42:14.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n99d" in namespace "gc-7345"
Dec 10 16:42:14.824: INFO: Deleting pod "simpletest-rc-to-be-deleted-9v4w7" in namespace "gc-7345"
Dec 10 16:42:14.841: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6hw9" in namespace "gc-7345"
Dec 10 16:42:14.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9hg4" in namespace "gc-7345"
Dec 10 16:42:14.861: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfzfh" in namespace "gc-7345"
Dec 10 16:42:14.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-bk4fb" in namespace "gc-7345"
Dec 10 16:42:14.874: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnfdf" in namespace "gc-7345"
Dec 10 16:42:14.882: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5vdt" in namespace "gc-7345"
Dec 10 16:42:14.889: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx7ht" in namespace "gc-7345"
Dec 10 16:42:14.897: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxstn" in namespace "gc-7345"
Dec 10 16:42:14.905: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4lvn" in namespace "gc-7345"
Dec 10 16:42:14.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbzxk" in namespace "gc-7345"
Dec 10 16:42:14.937: INFO: Deleting pod "simpletest-rc-to-be-deleted-fg6k4" in namespace "gc-7345"
Dec 10 16:42:14.951: INFO: Deleting pod "simpletest-rc-to-be-deleted-fl2fm" in namespace "gc-7345"
Dec 10 16:42:14.973: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmtsw" in namespace "gc-7345"
Dec 10 16:42:14.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqwd5" in namespace "gc-7345"
Dec 10 16:42:15.007: INFO: Deleting pod "simpletest-rc-to-be-deleted-fssch" in namespace "gc-7345"
Dec 10 16:42:15.023: INFO: Deleting pod "simpletest-rc-to-be-deleted-gg8vr" in namespace "gc-7345"
Dec 10 16:42:15.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-hmrgs" in namespace "gc-7345"
Dec 10 16:42:15.041: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8qxz" in namespace "gc-7345"
Dec 10 16:42:15.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-jjp89" in namespace "gc-7345"
Dec 10 16:42:15.076: INFO: Deleting pod "simpletest-rc-to-be-deleted-jzzj4" in namespace "gc-7345"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:42:15.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7345" for this suite.

• [SLOW TEST:17.688 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":346,"completed":13,"skipped":343,"failed":0}
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:42:15.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:42:15.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5935 version'
Dec 10 16:42:15.385: INFO: stderr: ""
Dec 10 16:42:15.385: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.0\", GitCommit:\"ab69524f795c42094a6630298ff53f3c3ebab7f4\", GitTreeState:\"clean\", BuildDate:\"2021-12-07T18:16:20Z\", GoVersion:\"go1.17.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.0\", GitCommit:\"ab69524f795c42094a6630298ff53f3c3ebab7f4\", GitTreeState:\"clean\", BuildDate:\"2021-12-07T18:09:57Z\", GoVersion:\"go1.17.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:42:15.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5935" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":346,"completed":14,"skipped":343,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:42:15.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Dec 10 16:42:15.426: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 16:43:15.445: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:43:15.448: INFO: Starting informer...
STEP: Starting pod...
Dec 10 16:43:15.662: INFO: Pod is running on ip-10-0-19-34. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 10 16:43:15.703: INFO: Pod wasn't evicted. Proceeding
Dec 10 16:43:15.703: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 10 16:44:30.790: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:44:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8733" for this suite.

• [SLOW TEST:135.409 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":346,"completed":15,"skipped":352,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:44:30.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 16:44:31.626: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 16:44:34.648: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:44:34.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8611-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:44:38.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5119" for this suite.
STEP: Destroying namespace "webhook-5119-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.292 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":346,"completed":16,"skipped":391,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:44:38.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:44:38.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 10 16:44:40.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-6322 --namespace=crd-publish-openapi-6322 create -f -'
Dec 10 16:44:41.445: INFO: stderr: ""
Dec 10 16:44:41.445: INFO: stdout: "e2e-test-crd-publish-openapi-8127-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 10 16:44:41.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-6322 --namespace=crd-publish-openapi-6322 delete e2e-test-crd-publish-openapi-8127-crds test-cr'
Dec 10 16:44:41.508: INFO: stderr: ""
Dec 10 16:44:41.508: INFO: stdout: "e2e-test-crd-publish-openapi-8127-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 10 16:44:41.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-6322 --namespace=crd-publish-openapi-6322 apply -f -'
Dec 10 16:44:41.677: INFO: stderr: ""
Dec 10 16:44:41.677: INFO: stdout: "e2e-test-crd-publish-openapi-8127-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 10 16:44:41.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-6322 --namespace=crd-publish-openapi-6322 delete e2e-test-crd-publish-openapi-8127-crds test-cr'
Dec 10 16:44:41.743: INFO: stderr: ""
Dec 10 16:44:41.744: INFO: stdout: "e2e-test-crd-publish-openapi-8127-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 10 16:44:41.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-6322 explain e2e-test-crd-publish-openapi-8127-crds'
Dec 10 16:44:41.910: INFO: stderr: ""
Dec 10 16:44:41.910: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8127-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:44:44.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6322" for this suite.

• [SLOW TEST:6.224 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":346,"completed":17,"skipped":396,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:44:44.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/hostport.go:47
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Dec 10 16:44:44.381: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:44:46.389: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.19.34 on the node which pod1 resides and expect scheduled
Dec 10 16:44:46.397: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:44:48.405: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.19.34 but use UDP protocol on the node which pod2 resides
Dec 10 16:44:48.415: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:44:50.422: INFO: The status of Pod pod3 is Running (Ready = true)
Dec 10 16:44:50.428: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:44:52.436: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Dec 10 16:44:52.439: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.19.34 http://127.0.0.1:54323/hostname] Namespace:hostport-2321 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:44:52.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:44:52.440: INFO: ExecWithOptions: Clientset creation
Dec 10 16:44:52.440: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-2321/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.19.34+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.19.34, port: 54323
Dec 10 16:44:52.524: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.19.34:54323/hostname] Namespace:hostport-2321 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:44:52.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:44:52.525: INFO: ExecWithOptions: Clientset creation
Dec 10 16:44:52.525: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-2321/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.19.34%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.19.34, port: 54323 UDP
Dec 10 16:44:52.624: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.0.19.34 54323] Namespace:hostport-2321 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:44:52.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:44:52.625: INFO: ExecWithOptions: Clientset creation
Dec 10 16:44:52.626: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-2321/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+10.0.19.34+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
[AfterEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:44:57.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2321" for this suite.

• [SLOW TEST:13.371 seconds]
[sig-network] HostPort
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":346,"completed":18,"skipped":410,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:44:57.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Dec 10 16:44:57.759: INFO: Pod name sample-pod: Found 0 pods out of 3
Dec 10 16:45:02.787: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Dec 10 16:45:08.818: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:08.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7799" for this suite.

• [SLOW TEST:11.173 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":346,"completed":19,"skipped":434,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:08.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:45:08.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:11.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5200" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":346,"completed":20,"skipped":445,"failed":0}
SSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:11.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Dec 10 16:45:11.761: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:11.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3680" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":346,"completed":21,"skipped":450,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:11.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override all
Dec 10 16:45:11.911: INFO: Waiting up to 5m0s for pod "client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403" in namespace "containers-1472" to be "Succeeded or Failed"
Dec 10 16:45:11.915: INFO: Pod "client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403": Phase="Pending", Reason="", readiness=false. Elapsed: 3.271656ms
Dec 10 16:45:13.931: INFO: Pod "client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019882981s
STEP: Saw pod success
Dec 10 16:45:13.932: INFO: Pod "client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403" satisfied condition "Succeeded or Failed"
Dec 10 16:45:13.939: INFO: Trying to get logs from node ip-10-0-19-34 pod client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 16:45:13.984: INFO: Waiting for pod client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403 to disappear
Dec 10 16:45:13.992: INFO: Pod client-containers-b8422ff5-a9dd-4e3f-983a-223284be8403 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:13.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1472" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":346,"completed":22,"skipped":498,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:14.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 10 16:45:14.092: INFO: Waiting up to 5m0s for pod "pod-525c52d6-38f5-4932-a8f7-c86fd6974141" in namespace "emptydir-139" to be "Succeeded or Failed"
Dec 10 16:45:14.103: INFO: Pod "pod-525c52d6-38f5-4932-a8f7-c86fd6974141": Phase="Pending", Reason="", readiness=false. Elapsed: 10.579664ms
Dec 10 16:45:16.116: INFO: Pod "pod-525c52d6-38f5-4932-a8f7-c86fd6974141": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023421819s
STEP: Saw pod success
Dec 10 16:45:16.117: INFO: Pod "pod-525c52d6-38f5-4932-a8f7-c86fd6974141" satisfied condition "Succeeded or Failed"
Dec 10 16:45:16.120: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-525c52d6-38f5-4932-a8f7-c86fd6974141 container test-container: <nil>
STEP: delete the pod
Dec 10 16:45:16.139: INFO: Waiting for pod pod-525c52d6-38f5-4932-a8f7-c86fd6974141 to disappear
Dec 10 16:45:16.144: INFO: Pod pod-525c52d6-38f5-4932-a8f7-c86fd6974141 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-139" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":23,"skipped":562,"failed":0}
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:16.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Dec 10 16:45:16.214: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:45:18.221: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Dec 10 16:45:18.231: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:45:20.238: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 16:45:20.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 16:45:20.282: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 16:45:22.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 16:45:22.289: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 16:45:24.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 16:45:24.290: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:24.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2163" for this suite.

• [SLOW TEST:8.142 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":346,"completed":24,"skipped":567,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:24.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 16:45:25.050: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 10 16:45:27.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 16, 45, 25, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 45, 25, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 16, 45, 25, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 45, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 16:45:30.124: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:30.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2039" for this suite.
STEP: Destroying namespace "webhook-2039-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.917 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":346,"completed":25,"skipped":574,"failed":0}
SSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:30.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Dec 10 16:45:30.316: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Dec 10 16:45:30.345: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:30.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2274" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":346,"completed":26,"skipped":581,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:30.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name secret-emptykey-test-049aacef-c15f-44a7-9263-45a371179356
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:30.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4430" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":346,"completed":27,"skipped":604,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:30.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-projected-all-test-volume-dc03c730-e00e-47b1-a294-06b36c09b943
STEP: Creating secret with name secret-projected-all-test-volume-6a84b6c9-fd3e-4fd1-b3bf-3bc6d65ce36b
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 10 16:45:30.470: INFO: Waiting up to 5m0s for pod "projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a" in namespace "projected-8710" to be "Succeeded or Failed"
Dec 10 16:45:30.472: INFO: Pod "projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.5655ms
Dec 10 16:45:32.481: INFO: Pod "projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010847054s
Dec 10 16:45:34.489: INFO: Pod "projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018412477s
STEP: Saw pod success
Dec 10 16:45:34.489: INFO: Pod "projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a" satisfied condition "Succeeded or Failed"
Dec 10 16:45:34.491: INFO: Trying to get logs from node ip-10-0-19-34 pod projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 10 16:45:34.510: INFO: Waiting for pod projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a to disappear
Dec 10 16:45:34.513: INFO: Pod projected-volume-4be1d939-ccf1-46bc-b19f-1f606e734a3a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:45:34.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8710" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":346,"completed":28,"skipped":671,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:45:34.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:00.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2570" for this suite.

• [SLOW TEST:326.250 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":346,"completed":29,"skipped":700,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-564
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 16:51:00.906: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 10 16:51:00.932: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:51:02.939: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:51:04.942: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:06.942: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:08.941: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:10.940: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:12.942: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:14.941: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:16.941: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:18.942: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:20.960: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 16:51:22.947: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 10 16:51:22.958: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Dec 10 16:51:24.983: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 10 16:51:24.983: INFO: Breadth first check of 10.2.2.62 on host 10.0.0.54...
Dec 10 16:51:24.985: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.71:9080/dial?request=hostname&protocol=udp&host=10.2.2.62&port=8081&tries=1'] Namespace:pod-network-test-564 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:51:24.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:51:24.985: INFO: ExecWithOptions: Clientset creation
Dec 10 16:51:24.986: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-564/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.1.71%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.2.62%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Dec 10 16:51:25.100: INFO: Waiting for responses: map[]
Dec 10 16:51:25.100: INFO: reached 10.2.2.62 after 0/1 tries
Dec 10 16:51:25.101: INFO: Breadth first check of 10.2.1.70 on host 10.0.19.34...
Dec 10 16:51:25.104: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.71:9080/dial?request=hostname&protocol=udp&host=10.2.1.70&port=8081&tries=1'] Namespace:pod-network-test-564 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:51:25.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:51:25.105: INFO: ExecWithOptions: Clientset creation
Dec 10 16:51:25.106: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-564/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.1.71%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.1.70%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Dec 10 16:51:25.203: INFO: Waiting for responses: map[]
Dec 10 16:51:25.204: INFO: reached 10.2.1.70 after 0/1 tries
Dec 10 16:51:25.204: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:25.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-564" for this suite.

• [SLOW TEST:24.444 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":346,"completed":30,"skipped":702,"failed":0}
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:25.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:51:25.273: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c85ef8b3-2717-4273-8826-aea9adc04d2a" in namespace "security-context-test-189" to be "Succeeded or Failed"
Dec 10 16:51:25.275: INFO: Pod "alpine-nnp-false-c85ef8b3-2717-4273-8826-aea9adc04d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107656ms
Dec 10 16:51:27.283: INFO: Pod "alpine-nnp-false-c85ef8b3-2717-4273-8826-aea9adc04d2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01005415s
Dec 10 16:51:29.291: INFO: Pod "alpine-nnp-false-c85ef8b3-2717-4273-8826-aea9adc04d2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017946952s
Dec 10 16:51:29.292: INFO: Pod "alpine-nnp-false-c85ef8b3-2717-4273-8826-aea9adc04d2a" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:29.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-189" for this suite.
•{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":31,"skipped":702,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:29.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 10 16:51:33.895: INFO: Successfully updated pod "adopt-release-6kb4v"
STEP: Checking that the Job readopts the Pod
Dec 10 16:51:33.895: INFO: Waiting up to 15m0s for pod "adopt-release-6kb4v" in namespace "job-3474" to be "adopted"
Dec 10 16:51:33.900: INFO: Pod "adopt-release-6kb4v": Phase="Running", Reason="", readiness=true. Elapsed: 4.735989ms
Dec 10 16:51:35.907: INFO: Pod "adopt-release-6kb4v": Phase="Running", Reason="", readiness=true. Elapsed: 2.011151034s
Dec 10 16:51:35.907: INFO: Pod "adopt-release-6kb4v" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 10 16:51:36.417: INFO: Successfully updated pod "adopt-release-6kb4v"
STEP: Checking that the Job releases the Pod
Dec 10 16:51:36.417: INFO: Waiting up to 15m0s for pod "adopt-release-6kb4v" in namespace "job-3474" to be "released"
Dec 10 16:51:36.419: INFO: Pod "adopt-release-6kb4v": Phase="Running", Reason="", readiness=true. Elapsed: 2.264296ms
Dec 10 16:51:38.429: INFO: Pod "adopt-release-6kb4v": Phase="Running", Reason="", readiness=true. Elapsed: 2.012614475s
Dec 10 16:51:38.430: INFO: Pod "adopt-release-6kb4v" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:38.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3474" for this suite.

• [SLOW TEST:9.116 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":346,"completed":32,"skipped":711,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:38.442: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 16:51:38.541: INFO: Waiting up to 5m0s for pod "pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc" in namespace "emptydir-3545" to be "Succeeded or Failed"
Dec 10 16:51:38.573: INFO: Pod "pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc": Phase="Pending", Reason="", readiness=false. Elapsed: 31.246708ms
Dec 10 16:51:40.582: INFO: Pod "pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041042027s
STEP: Saw pod success
Dec 10 16:51:40.583: INFO: Pod "pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc" satisfied condition "Succeeded or Failed"
Dec 10 16:51:40.592: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc container test-container: <nil>
STEP: delete the pod
Dec 10 16:51:40.608: INFO: Waiting for pod pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc to disappear
Dec 10 16:51:40.611: INFO: Pod pod-674b07ac-cc56-4a8e-a2bd-5f71b80b09bc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:40.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3545" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":33,"skipped":747,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:51:40.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: creating the pod
STEP: submitting the pod to kubernetes
Dec 10 16:51:40.671: INFO: The status of Pod pod-logs-websocket-89112b87-7287-4bba-9b04-9102473f0ec5 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:51:42.679: INFO: The status of Pod pod-logs-websocket-89112b87-7287-4bba-9b04-9102473f0ec5 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:42.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-477" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":346,"completed":34,"skipped":779,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:42.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Dec 10 16:51:42.756: INFO: Waiting up to 5m0s for pod "security-context-b8c9ea59-7e98-464c-a913-38255087f42f" in namespace "security-context-5315" to be "Succeeded or Failed"
Dec 10 16:51:42.759: INFO: Pod "security-context-b8c9ea59-7e98-464c-a913-38255087f42f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735274ms
Dec 10 16:51:44.768: INFO: Pod "security-context-b8c9ea59-7e98-464c-a913-38255087f42f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011457564s
STEP: Saw pod success
Dec 10 16:51:44.768: INFO: Pod "security-context-b8c9ea59-7e98-464c-a913-38255087f42f" satisfied condition "Succeeded or Failed"
Dec 10 16:51:44.771: INFO: Trying to get logs from node ip-10-0-19-34 pod security-context-b8c9ea59-7e98-464c-a913-38255087f42f container test-container: <nil>
STEP: delete the pod
Dec 10 16:51:44.795: INFO: Waiting for pod security-context-b8c9ea59-7e98-464c-a913-38255087f42f to disappear
Dec 10 16:51:44.797: INFO: Pod security-context-b8c9ea59-7e98-464c-a913-38255087f42f no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:44.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5315" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":35,"skipped":789,"failed":0}
SSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:44.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:44.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9341" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":346,"completed":36,"skipped":793,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:44.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-23ac726d-c6c7-42bc-9d6b-9e13f6bd7e95
STEP: Creating secret with name s-test-opt-upd-44ef8e03-b700-44a1-9d97-5c24a4f12160
STEP: Creating the pod
Dec 10 16:51:45.164: INFO: The status of Pod pod-secrets-674a119d-a41b-424c-b6ef-cad4753bb498 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:51:47.176: INFO: The status of Pod pod-secrets-674a119d-a41b-424c-b6ef-cad4753bb498 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-23ac726d-c6c7-42bc-9d6b-9e13f6bd7e95
STEP: Updating secret s-test-opt-upd-44ef8e03-b700-44a1-9d97-5c24a4f12160
STEP: Creating secret with name s-test-opt-create-de9f2ee2-9c6f-421c-956e-d3d5ac92440b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:49.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9151" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":37,"skipped":801,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:49.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 10 16:51:49.289: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 10 16:51:54.294: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:55.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3616" for this suite.

• [SLOW TEST:6.074 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":346,"completed":38,"skipped":827,"failed":0}
SSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:55.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:39
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: mirroring a new custom Endpoint
STEP: mirroring an update to a custom Endpoint
STEP: mirroring deletion of a custom Endpoint
Dec 10 16:51:55.529: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:57.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-5651" for this suite.
•{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":346,"completed":39,"skipped":832,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:57.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-67d0c1cf-3fd6-45b1-ad9e-a9b2b83645d4
STEP: Creating a pod to test consume configMaps
Dec 10 16:51:57.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce" in namespace "projected-4327" to be "Succeeded or Failed"
Dec 10 16:51:57.637: INFO: Pod "pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.741174ms
Dec 10 16:51:59.650: INFO: Pod "pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016715164s
STEP: Saw pod success
Dec 10 16:51:59.651: INFO: Pod "pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce" satisfied condition "Succeeded or Failed"
Dec 10 16:51:59.659: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce container agnhost-container: <nil>
STEP: delete the pod
Dec 10 16:51:59.739: INFO: Waiting for pod pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce to disappear
Dec 10 16:51:59.742: INFO: Pod pod-projected-configmaps-0e66d1f2-7eed-4b1a-9ea1-7a60ab6d84ce no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:51:59.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4327" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":40,"skipped":861,"failed":0}
S
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:51:59.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:157
[It] should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating server pod server in namespace prestop-3545
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3545
STEP: Deleting pre-stop pod
Dec 10 16:52:10.851: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:10.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3545" for this suite.

• [SLOW TEST:11.125 seconds]
[sig-node] PreStop
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":346,"completed":41,"skipped":862,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:10.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service multi-endpoint-test in namespace services-2131
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2131 to expose endpoints map[]
Dec 10 16:52:10.951: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Dec 10 16:52:11.959: INFO: successfully validated that service multi-endpoint-test in namespace services-2131 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2131
Dec 10 16:52:11.967: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:52:13.974: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2131 to expose endpoints map[pod1:[100]]
Dec 10 16:52:13.984: INFO: successfully validated that service multi-endpoint-test in namespace services-2131 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-2131
Dec 10 16:52:13.993: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:52:16.002: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2131 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 10 16:52:16.017: INFO: successfully validated that service multi-endpoint-test in namespace services-2131 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Dec 10 16:52:16.018: INFO: Creating new exec pod
Dec 10 16:52:19.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-2131 exec execpod5lrst -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Dec 10 16:52:19.284: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Dec 10 16:52:19.284: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:52:19.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-2131 exec execpod5lrst -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.216.32 80'
Dec 10 16:52:19.451: INFO: stderr: "+ nc -v -t -w 2 10.3.216.32 80\nConnection to 10.3.216.32 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 16:52:19.451: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:52:19.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-2131 exec execpod5lrst -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Dec 10 16:52:19.689: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Dec 10 16:52:19.689: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:52:19.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-2131 exec execpod5lrst -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.216.32 81'
Dec 10 16:52:19.842: INFO: stderr: "+ nc -v -t -w 2 10.3.216.32 81\n+ echo hostName\nConnection to 10.3.216.32 81 port [tcp/*] succeeded!\n"
Dec 10 16:52:19.842: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2131
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2131 to expose endpoints map[pod2:[101]]
Dec 10 16:52:20.897: INFO: successfully validated that service multi-endpoint-test in namespace services-2131 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-2131
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2131 to expose endpoints map[]
Dec 10 16:52:20.960: INFO: successfully validated that service multi-endpoint-test in namespace services-2131 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:20.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2131" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:10.116 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":346,"completed":42,"skipped":949,"failed":0}
SSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:21.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in volume subpath
Dec 10 16:52:21.112: INFO: Waiting up to 5m0s for pod "var-expansion-ac58db11-1028-4949-9e02-16dc974e0402" in namespace "var-expansion-5244" to be "Succeeded or Failed"
Dec 10 16:52:21.126: INFO: Pod "var-expansion-ac58db11-1028-4949-9e02-16dc974e0402": Phase="Pending", Reason="", readiness=false. Elapsed: 14.110935ms
Dec 10 16:52:23.134: INFO: Pod "var-expansion-ac58db11-1028-4949-9e02-16dc974e0402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02205239s
STEP: Saw pod success
Dec 10 16:52:23.135: INFO: Pod "var-expansion-ac58db11-1028-4949-9e02-16dc974e0402" satisfied condition "Succeeded or Failed"
Dec 10 16:52:23.136: INFO: Trying to get logs from node ip-10-0-19-34 pod var-expansion-ac58db11-1028-4949-9e02-16dc974e0402 container dapi-container: <nil>
STEP: delete the pod
Dec 10 16:52:23.152: INFO: Waiting for pod var-expansion-ac58db11-1028-4949-9e02-16dc974e0402 to disappear
Dec 10 16:52:23.155: INFO: Pod var-expansion-ac58db11-1028-4949-9e02-16dc974e0402 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:23.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5244" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":346,"completed":43,"skipped":955,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:23.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Dec 10 16:52:23.220: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:25.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6570" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":346,"completed":44,"skipped":1030,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:25.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 10 16:52:25.696: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:30.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-383" for this suite.

• [SLOW TEST:5.119 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":346,"completed":45,"skipped":1035,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:30.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:52:30.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-529" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":346,"completed":46,"skipped":1058,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:52:30.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Dec 10 16:52:32.965: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-76 PodName:var-expansion-912dceac-b848-4613-8e86-19165192d756 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:52:32.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:52:32.966: INFO: ExecWithOptions: Clientset creation
Dec 10 16:52:32.967: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-76/pods/var-expansion-912dceac-b848-4613-8e86-19165192d756/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: test for file in mounted path
Dec 10 16:52:33.087: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-76 PodName:var-expansion-912dceac-b848-4613-8e86-19165192d756 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 16:52:33.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 16:52:33.088: INFO: ExecWithOptions: Clientset creation
Dec 10 16:52:33.088: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-76/pods/var-expansion-912dceac-b848-4613-8e86-19165192d756/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: updating the annotation value
Dec 10 16:52:33.677: INFO: Successfully updated pod "var-expansion-912dceac-b848-4613-8e86-19165192d756"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Dec 10 16:52:33.681: INFO: Deleting pod "var-expansion-912dceac-b848-4613-8e86-19165192d756" in namespace "var-expansion-76"
Dec 10 16:52:33.685: INFO: Wait up to 5m0s for pod "var-expansion-912dceac-b848-4613-8e86-19165192d756" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:53:07.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-76" for this suite.

• [SLOW TEST:36.805 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":346,"completed":47,"skipped":1068,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:53:07.721: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:53:09.784: INFO: Deleting pod "var-expansion-21e1e40a-d847-4c03-a739-9e3b5059c4d7" in namespace "var-expansion-6652"
Dec 10 16:53:09.790: INFO: Wait up to 5m0s for pod "var-expansion-21e1e40a-d847-4c03-a739-9e3b5059c4d7" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:53:13.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6652" for this suite.

• [SLOW TEST:6.110 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":346,"completed":48,"skipped":1168,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:53:13.841: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Dec 10 16:53:13.918: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 16:54:13.959: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Dec 10 16:54:13.979: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 10 16:54:13.985: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 10 16:54:14.030: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 10 16:54:14.054: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:54:30.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-9412" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:76.309 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":346,"completed":49,"skipped":1175,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:54:30.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:54:46.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8164" for this suite.

• [SLOW TEST:16.229 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":346,"completed":50,"skipped":1180,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:54:46.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:54:46.433: INFO: Creating simple deployment test-new-deployment
Dec 10 16:54:46.442: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
Dec 10 16:54:48.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 16, 54, 46, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 54, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 16, 54, 46, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 16, 54, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-5d9fdcc779\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 16:54:50.562: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-1981  94ef2ce6-ebce-43cd-9fe8-ae63479e601d 5846 3 2021-12-10 16:54:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2021-12-10 16:54:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 16:54:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00444d0c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-5d9fdcc779" has successfully progressed.,LastUpdateTime:2021-12-10 16:54:48 +0000 UTC,LastTransitionTime:2021-12-10 16:54:46 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2021-12-10 16:54:50 +0000 UTC,LastTransitionTime:2021-12-10 16:54:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 16:54:50.579: INFO: New ReplicaSet "test-new-deployment-5d9fdcc779" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-5d9fdcc779  deployment-1981  09906a89-538b-4986-bb1b-003db14b3574 5849 3 2021-12-10 16:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 94ef2ce6-ebce-43cd-9fe8-ae63479e601d 0xc00444d4e0 0xc00444d4e1}] []  [{kube-controller-manager Update apps/v1 2021-12-10 16:54:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"94ef2ce6-ebce-43cd-9fe8-ae63479e601d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 16:54:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00444d568 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 10 16:54:50.594: INFO: Pod "test-new-deployment-5d9fdcc779-blsj8" is not available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-blsj8 test-new-deployment-5d9fdcc779- deployment-1981  dc2a4996-313e-444a-80a7-41722a11beb6 5852 0 2021-12-10 16:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 09906a89-538b-4986-bb1b-003db14b3574 0xc00444d930 0xc00444d931}] []  [{kube-controller-manager Update v1 2021-12-10 16:54:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"09906a89-538b-4986-bb1b-003db14b3574\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b7shc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b7shc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 16:54:50.595: INFO: Pod "test-new-deployment-5d9fdcc779-xsqhh" is not available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-xsqhh test-new-deployment-5d9fdcc779- deployment-1981  d809d40b-c180-48d9-8d41-754ccceb9c38 5851 0 2021-12-10 16:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 09906a89-538b-4986-bb1b-003db14b3574 0xc00444da67 0xc00444da68}] []  [{Go-http-client Update v1 2021-12-10 16:54:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 16:54:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"09906a89-538b-4986-bb1b-003db14b3574\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v8dpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v8dpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:,StartTime:2021-12-10 16:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 16:54:50.596: INFO: Pod "test-new-deployment-5d9fdcc779-z296v" is available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-z296v test-new-deployment-5d9fdcc779- deployment-1981  5fbcff72-49a6-43c1-b6da-f33051147281 5832 0 2021-12-10 16:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 09906a89-538b-4986-bb1b-003db14b3574 0xc00444dc30 0xc00444dc31}] []  [{kube-controller-manager Update v1 2021-12-10 16:54:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"09906a89-538b-4986-bb1b-003db14b3574\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 16:54:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.91\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vtrwt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vtrwt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 16:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.91,StartTime:2021-12-10 16:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 16:54:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://c116ddf85f18d5d7ac8cb1124c9f111b000c52e4ea07d09194d3f883ba9d7c88,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.91,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:54:50.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1981" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":346,"completed":51,"skipped":1216,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:54:50.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-7206
STEP: creating service affinity-nodeport-transition in namespace services-7206
STEP: creating replication controller affinity-nodeport-transition in namespace services-7206
I1210 16:54:50.806546      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-7206, replica count: 3
I1210 16:54:53.960781      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 16:54:56.995374      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 16:54:59.995560      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 16:55:00.026: INFO: Creating new exec pod
Dec 10 16:55:05.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Dec 10 16:55:05.526: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Dec 10 16:55:05.526: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:55:05.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.112.215 80'
Dec 10 16:55:05.740: INFO: stderr: "+ nc -v -t -w 2 10.3.112.215 80\n+ echo hostNameConnection to 10.3.112.215 80 port [tcp/http] succeeded!\n\n"
Dec 10 16:55:05.740: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:55:05.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.54 31450'
Dec 10 16:55:05.942: INFO: stderr: "+ nc -v -t -w 2 10.0.0.54 31450\n+ echo hostName\nConnection to 10.0.0.54 31450 port [tcp/*] succeeded!\n"
Dec 10 16:55:05.942: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:55:05.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 31450'
Dec 10 16:55:06.136: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 31450\n+ echo hostName\nConnection to 10.0.19.34 31450 port [tcp/*] succeeded!\n"
Dec 10 16:55:06.136: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 16:55:06.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.54:31450/ ; done'
Dec 10 16:55:06.853: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n"
Dec 10 16:55:06.853: INFO: stdout: "\naffinity-nodeport-transition-hlhsw\naffinity-nodeport-transition-dgv6x\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-hlhsw\naffinity-nodeport-transition-dgv6x\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-hlhsw\naffinity-nodeport-transition-dgv6x\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-hlhsw\naffinity-nodeport-transition-dgv6x\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-hlhsw\naffinity-nodeport-transition-dgv6x\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-hlhsw"
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-dgv6x
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-dgv6x
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-dgv6x
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-dgv6x
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-dgv6x
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:06.853: INFO: Received response from host: affinity-nodeport-transition-hlhsw
Dec 10 16:55:06.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7206 exec execpod-affinity9hqfw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.54:31450/ ; done'
Dec 10 16:55:07.230: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31450/\n"
Dec 10 16:55:07.230: INFO: stdout: "\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg\naffinity-nodeport-transition-zhdjg"
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.230: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.231: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.231: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.231: INFO: Received response from host: affinity-nodeport-transition-zhdjg
Dec 10 16:55:07.231: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7206, will wait for the garbage collector to delete the pods
Dec 10 16:55:07.298: INFO: Deleting ReplicationController affinity-nodeport-transition took: 3.957388ms
Dec 10 16:55:07.401: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 102.222589ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:55:10.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7206" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:19.400 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":52,"skipped":1273,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:55:10.068: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 16:55:10.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59" in namespace "downward-api-2001" to be "Succeeded or Failed"
Dec 10 16:55:10.165: INFO: Pod "downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59": Phase="Pending", Reason="", readiness=false. Elapsed: 3.375522ms
Dec 10 16:55:12.172: INFO: Pod "downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009608455s
STEP: Saw pod success
Dec 10 16:55:12.172: INFO: Pod "downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59" satisfied condition "Succeeded or Failed"
Dec 10 16:55:12.175: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59 container client-container: <nil>
STEP: delete the pod
Dec 10 16:55:12.206: INFO: Waiting for pod downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59 to disappear
Dec 10 16:55:12.211: INFO: Pod downwardapi-volume-b47a679c-14a3-4bec-a415-c0208664bc59 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:55:12.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2001" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":346,"completed":53,"skipped":1294,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:55:12.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:55:14.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-42" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":346,"completed":54,"skipped":1295,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:55:15.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-5064
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Dec 10 16:55:15.186: INFO: Found 0 stateful pods, waiting for 3
Dec 10 16:55:25.199: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 16:55:25.201: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 16:55:25.201: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 16:55:25.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-5064 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 16:55:25.393: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 16:55:25.393: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 16:55:25.393: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Dec 10 16:55:35.430: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 10 16:55:45.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-5064 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 16:55:45.601: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 16:55:45.601: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 16:55:45.601: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Dec 10 16:56:05.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-5064 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 16:56:05.773: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 16:56:05.773: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 16:56:05.773: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 16:56:15.817: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 10 16:56:25.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-5064 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 16:56:26.032: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 16:56:26.032: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 16:56:26.032: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 16:56:36.049: INFO: Deleting all statefulset in ns statefulset-5064
Dec 10 16:56:36.051: INFO: Scaling statefulset ss2 to 0
Dec 10 16:56:46.076: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 16:56:46.078: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:56:46.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5064" for this suite.

• [SLOW TEST:91.014 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":346,"completed":55,"skipped":1349,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:56:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:56:46.174: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 16:56:46.180: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:46.182: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:56:46.182: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:56:47.188: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:47.191: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:56:47.191: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:56:48.188: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:48.190: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 16:56:48.191: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 16:56:49.188: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:49.191: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 16:56:49.192: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 10 16:56:49.216: INFO: Wrong image for pod: daemon-set-d2rqx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:49.217: INFO: Wrong image for pod: daemon-set-xjvq2. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:49.221: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:50.236: INFO: Wrong image for pod: daemon-set-d2rqx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:50.243: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:51.233: INFO: Wrong image for pod: daemon-set-d2rqx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:51.236: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:52.227: INFO: Wrong image for pod: daemon-set-d2rqx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:52.227: INFO: Pod daemon-set-wszbm is not available
Dec 10 16:56:52.230: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:53.227: INFO: Wrong image for pod: daemon-set-d2rqx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Dec 10 16:56:53.227: INFO: Pod daemon-set-wszbm is not available
Dec 10 16:56:53.230: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:54.232: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:55.227: INFO: Pod daemon-set-6sx55 is not available
Dec 10 16:56:55.231: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 10 16:56:55.236: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:55.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 16:56:55.240: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:56:56.245: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:56.249: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 16:56:56.249: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:56:57.245: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:56:57.248: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 16:56:57.249: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2794, will wait for the garbage collector to delete the pods
Dec 10 16:56:57.318: INFO: Deleting DaemonSet.extensions daemon-set took: 4.60406ms
Dec 10 16:56:57.525: INFO: Terminating DaemonSet.extensions daemon-set pods took: 207.209346ms
Dec 10 16:56:59.934: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:56:59.934: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 16:56:59.937: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"6855"},"items":null}

Dec 10 16:56:59.939: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"6855"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:56:59.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2794" for this suite.

• [SLOW TEST:13.831 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":346,"completed":56,"skipped":1367,"failed":0}
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:56:59.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replication controller my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55
Dec 10 16:57:00.075: INFO: Pod name my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55: Found 0 pods out of 1
Dec 10 16:57:05.097: INFO: Pod name my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55: Found 1 pods out of 1
Dec 10 16:57:05.097: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55" are running
Dec 10 16:57:05.099: INFO: Pod "my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55-lcz7q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 16:57:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 16:57:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 16:57:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 16:57:00 +0000 UTC Reason: Message:}])
Dec 10 16:57:05.099: INFO: Trying to dial the pod
Dec 10 16:57:10.145: INFO: Controller my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55: Got expected result from replica 1 [my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55-lcz7q]: "my-hostname-basic-8a3373e3-c34c-488b-af8d-bb7fec4bfe55-lcz7q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9157" for this suite.

• [SLOW TEST:10.212 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":57,"skipped":1367,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:10.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-7d5cd494-3eb8-448f-b39b-c9254fc3c81e
STEP: Creating a pod to test consume secrets
Dec 10 16:57:10.304: INFO: Waiting up to 5m0s for pod "pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b" in namespace "secrets-3091" to be "Succeeded or Failed"
Dec 10 16:57:10.307: INFO: Pod "pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.874577ms
Dec 10 16:57:12.311: INFO: Pod "pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006304192s
Dec 10 16:57:14.320: INFO: Pod "pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014768925s
STEP: Saw pod success
Dec 10 16:57:14.321: INFO: Pod "pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b" satisfied condition "Succeeded or Failed"
Dec 10 16:57:14.323: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 16:57:14.354: INFO: Waiting for pod pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b to disappear
Dec 10 16:57:14.362: INFO: Pod pod-secrets-4dd53778-6cd0-4bfe-aba9-d8f8d4fdcf1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:14.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3091" for this suite.
STEP: Destroying namespace "secret-namespace-6822" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":346,"completed":58,"skipped":1376,"failed":0}
SSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 16:57:14.442: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Pending, waiting for it to be Running (with Ready = true)
Dec 10 16:57:16.448: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:18.449: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:20.450: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:22.448: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:24.446: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:26.454: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:28.452: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:30.448: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:32.449: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:34.472: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = false)
Dec 10 16:57:36.450: INFO: The status of Pod test-webserver-6f701828-1998-40af-bc4b-bfee8046d0da is Running (Ready = true)
Dec 10 16:57:36.451: INFO: Container started at 2021-12-10 16:57:15 +0000 UTC, pod became ready at 2021-12-10 16:57:34 +0000 UTC
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:36.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6500" for this suite.

• [SLOW TEST:22.079 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":346,"completed":59,"skipped":1382,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:36.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 16:57:36.523: INFO: Waiting up to 5m0s for pod "downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce" in namespace "downward-api-3595" to be "Succeeded or Failed"
Dec 10 16:57:36.526: INFO: Pod "downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.817197ms
Dec 10 16:57:38.531: INFO: Pod "downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007943134s
Dec 10 16:57:40.540: INFO: Pod "downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016473224s
STEP: Saw pod success
Dec 10 16:57:40.540: INFO: Pod "downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce" satisfied condition "Succeeded or Failed"
Dec 10 16:57:40.542: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce container client-container: <nil>
STEP: delete the pod
Dec 10 16:57:40.554: INFO: Waiting for pod downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce to disappear
Dec 10 16:57:40.556: INFO: Pod downwardapi-volume-964dc2a5-56c9-4c6a-9044-b6458b21cdce no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:40.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3595" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":60,"skipped":1398,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:40.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-6a091ee6-74a2-4978-83a0-bf4de60f8679
STEP: Creating a pod to test consume secrets
Dec 10 16:57:40.630: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf" in namespace "projected-792" to be "Succeeded or Failed"
Dec 10 16:57:40.640: INFO: Pod "pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.725147ms
Dec 10 16:57:42.646: INFO: Pod "pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014633656s
Dec 10 16:57:44.653: INFO: Pod "pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02205725s
STEP: Saw pod success
Dec 10 16:57:44.655: INFO: Pod "pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf" satisfied condition "Succeeded or Failed"
Dec 10 16:57:44.658: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 16:57:44.671: INFO: Waiting for pod pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf to disappear
Dec 10 16:57:44.674: INFO: Pod pod-projected-secrets-7bafe2bf-cbdb-41a7-9f4e-6b7e392f98bf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:44.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-792" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":61,"skipped":1416,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:44.684: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:55.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4613" for this suite.

• [SLOW TEST:11.118 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":346,"completed":62,"skipped":1429,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:55.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-40e1729c-bf5a-4b9f-96cb-ab711b10e344
STEP: Creating a pod to test consume configMaps
Dec 10 16:57:55.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f" in namespace "configmap-8020" to be "Succeeded or Failed"
Dec 10 16:57:55.872: INFO: Pod "pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.087289ms
Dec 10 16:57:57.880: INFO: Pod "pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015255138s
STEP: Saw pod success
Dec 10 16:57:57.881: INFO: Pod "pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f" satisfied condition "Succeeded or Failed"
Dec 10 16:57:57.882: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f container agnhost-container: <nil>
STEP: delete the pod
Dec 10 16:57:57.896: INFO: Waiting for pod pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f to disappear
Dec 10 16:57:57.899: INFO: Pod pod-configmaps-1cf19747-15fd-492c-aa30-7703e6af317f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:57:57.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8020" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":63,"skipped":1488,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:57:57.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 16:57:57.984: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:57:57.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:57:57.989: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:57:58.995: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:57:58.998: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:57:58.998: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 16:57:59.995: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:57:59.998: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 16:57:59.999: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 16:58:00.996: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:58:01.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 16:58:01.000: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 10 16:58:01.017: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 16:58:01.028: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 16:58:01.028: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5283, will wait for the garbage collector to delete the pods
Dec 10 16:58:02.154: INFO: Deleting DaemonSet.extensions daemon-set took: 15.89789ms
Dec 10 16:58:02.357: INFO: Terminating DaemonSet.extensions daemon-set pods took: 203.053356ms
Dec 10 16:58:04.167: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 16:58:04.167: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 16:58:04.172: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7266"},"items":null}

Dec 10 16:58:04.174: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7266"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:58:04.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5283" for this suite.

• [SLOW TEST:6.290 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":346,"completed":64,"skipped":1618,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:58:04.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1537
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Dec 10 16:58:04.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3929 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Dec 10 16:58:04.400: INFO: stderr: ""
Dec 10 16:58:04.400: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1541
Dec 10 16:58:04.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3929 delete pods e2e-test-httpd-pod'
Dec 10 16:58:07.322: INFO: stderr: ""
Dec 10 16:58:07.322: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 16:58:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3929" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":346,"completed":65,"skipped":1628,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 16:58:07.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Dec 10 16:58:07.380: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 16:58:07.385: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 16:58:07.387: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-0-54 before test
Dec 10 16:58:07.391: INFO: coredns-77c7788bfd-wgnt8 from kube-system started at 2021-12-10 16:43:15 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.392: INFO: 	Container coredns ready: true, restart count 0
Dec 10 16:58:07.392: INFO: flannel-v6cj5 from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.392: INFO: 	Container flannel ready: true, restart count 0
Dec 10 16:58:07.392: INFO: kube-proxy-n8zvk from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.392: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 16:58:07.393: INFO: sonobuoy from sonobuoy started at 2021-12-10 16:39:55 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.393: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 16:58:07.393: INFO: sonobuoy-e2e-job-8d0bd5401ee442a1 from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 16:58:07.393: INFO: 	Container e2e ready: true, restart count 0
Dec 10 16:58:07.393: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 16:58:07.393: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 16:58:07.394: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 16:58:07.394: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 10 16:58:07.394: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-19-34 before test
Dec 10 16:58:07.398: INFO: flannel-rjcp9 from kube-system started at 2021-12-10 16:43:16 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.398: INFO: 	Container flannel ready: true, restart count 0
Dec 10 16:58:07.398: INFO: kube-proxy-p6vhv from kube-system started at 2021-12-10 16:43:17 +0000 UTC (1 container statuses recorded)
Dec 10 16:58:07.398: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 16:58:07.398: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-x75pd from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 16:58:07.398: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 16:58:07.398: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e2a5bce6-949c-4ec4-b0f9-1db749477695 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.19.34 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-e2a5bce6-949c-4ec4-b0f9-1db749477695 off the node ip-10-0-19-34
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e2a5bce6-949c-4ec4-b0f9-1db749477695
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:11.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2582" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:304.164 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":346,"completed":66,"skipped":1650,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:11.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:22.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4788" for this suite.

• [SLOW TEST:11.202 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":346,"completed":67,"skipped":1652,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:22.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
Dec 10 17:03:22.745: INFO: Creating simple deployment test-deployment-j8jw8
Dec 10 17:03:22.751: INFO: new replicaset for deployment "test-deployment-j8jw8" is yet to be created
Dec 10 17:03:24.761: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 17, 3, 22, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 3, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 3, 22, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 3, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-j8jw8-764bc7c4b7\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status
Dec 10 17:03:26.778: INFO: Deployment test-deployment-j8jw8 has Conditions: [{Available True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-j8jw8-764bc7c4b7" has successfully progressed.}]
STEP: updating Deployment Status
Dec 10 17:03:26.791: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 3, 24, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 3, 24, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 3, 24, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 3, 22, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-j8jw8-764bc7c4b7\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Dec 10 17:03:26.796: INFO: Observed &Deployment event: ADDED
Dec 10 17:03:26.797: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-j8jw8-764bc7c4b7"}
Dec 10 17:03:26.797: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.797: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-j8jw8-764bc7c4b7"}
Dec 10 17:03:26.798: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 10 17:03:26.798: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.798: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 10 17:03:26.798: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-j8jw8-764bc7c4b7" is progressing.}
Dec 10 17:03:26.799: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.799: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 10 17:03:26.799: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-j8jw8-764bc7c4b7" has successfully progressed.}
Dec 10 17:03:26.800: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.800: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 10 17:03:26.801: INFO: Observed Deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-j8jw8-764bc7c4b7" has successfully progressed.}
Dec 10 17:03:26.801: INFO: Found Deployment test-deployment-j8jw8 in namespace deployment-5311 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 10 17:03:26.801: INFO: Deployment test-deployment-j8jw8 has an updated status
STEP: patching the Statefulset Status
Dec 10 17:03:26.801: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 10 17:03:26.831: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Dec 10 17:03:26.852: INFO: Observed &Deployment event: ADDED
Dec 10 17:03:26.852: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-j8jw8-764bc7c4b7"}
Dec 10 17:03:26.853: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.853: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-j8jw8-764bc7c4b7"}
Dec 10 17:03:26.853: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 10 17:03:26.854: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.854: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 10 17:03:26.854: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:22 +0000 UTC 2021-12-10 17:03:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-j8jw8-764bc7c4b7" is progressing.}
Dec 10 17:03:26.855: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.855: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 10 17:03:26.855: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-j8jw8-764bc7c4b7" has successfully progressed.}
Dec 10 17:03:26.856: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.856: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 10 17:03:26.856: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2021-12-10 17:03:24 +0000 UTC 2021-12-10 17:03:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-j8jw8-764bc7c4b7" has successfully progressed.}
Dec 10 17:03:26.856: INFO: Observed deployment test-deployment-j8jw8 in namespace deployment-5311 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 10 17:03:26.857: INFO: Observed &Deployment event: MODIFIED
Dec 10 17:03:26.857: INFO: Found deployment test-deployment-j8jw8 in namespace deployment-5311 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Dec 10 17:03:26.857: INFO: Deployment test-deployment-j8jw8 has a patched status
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:03:26.867: INFO: Deployment "test-deployment-j8jw8":
&Deployment{ObjectMeta:{test-deployment-j8jw8  deployment-5311  e88a36af-934c-4037-b0f5-79e666db787d 7885 1 2021-12-10 17:03:22 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2021-12-10 17:03:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2021-12-10 17:03:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2021-12-10 17:03:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b1f1e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-j8jw8-764bc7c4b7",LastUpdateTime:2021-12-10 17:03:26 +0000 UTC,LastTransitionTime:2021-12-10 17:03:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 17:03:26.874: INFO: New ReplicaSet "test-deployment-j8jw8-764bc7c4b7" of Deployment "test-deployment-j8jw8":
&ReplicaSet{ObjectMeta:{test-deployment-j8jw8-764bc7c4b7  deployment-5311  e27a86dd-565b-4986-8927-5df6bc78f1c0 7879 1 2021-12-10 17:03:22 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-j8jw8 e88a36af-934c-4037-b0f5-79e666db787d 0xc002b1f5c7 0xc002b1f5c8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:03:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e88a36af-934c-4037-b0f5-79e666db787d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:03:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 764bc7c4b7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b1f678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:03:26.879: INFO: Pod "test-deployment-j8jw8-764bc7c4b7-nkrnf" is available:
&Pod{ObjectMeta:{test-deployment-j8jw8-764bc7c4b7-nkrnf test-deployment-j8jw8-764bc7c4b7- deployment-5311  e4e34df1-cc4b-4e24-a37c-35147768a88d 7878 0 2021-12-10 17:03:22 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [{apps/v1 ReplicaSet test-deployment-j8jw8-764bc7c4b7 e27a86dd-565b-4986-8927-5df6bc78f1c0 0xc002b1fa17 0xc002b1fa18}] []  [{kube-controller-manager Update v1 2021-12-10 17:03:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e27a86dd-565b-4986-8927-5df6bc78f1c0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:03:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cx6m6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cx6m6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:03:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:03:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:03:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.114,StartTime:2021-12-10 17:03:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:03:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e4b149905364156bb98d2ace4bea70bbe4342818cd53d8a80a72f322523669e3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:26.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5311" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":346,"completed":68,"skipped":1657,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:26.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Dec 10 17:03:26.932: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:30.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9225" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":346,"completed":69,"skipped":1729,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:30.983: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating pod
Dec 10 17:03:31.045: INFO: The status of Pod pod-hostip-8c6fff77-c80d-44e3-84e2-2cb244ff0456 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:03:33.050: INFO: The status of Pod pod-hostip-8c6fff77-c80d-44e3-84e2-2cb244ff0456 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:03:35.054: INFO: The status of Pod pod-hostip-8c6fff77-c80d-44e3-84e2-2cb244ff0456 is Running (Ready = true)
Dec 10 17:03:35.057: INFO: Pod pod-hostip-8c6fff77-c80d-44e3-84e2-2cb244ff0456 has hostIP: 10.0.19.34
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:35.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-379" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":346,"completed":70,"skipped":1745,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:35.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:03:35.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64" in namespace "projected-8507" to be "Succeeded or Failed"
Dec 10 17:03:35.114: INFO: Pod "downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64": Phase="Pending", Reason="", readiness=false. Elapsed: 3.16121ms
Dec 10 17:03:37.120: INFO: Pod "downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009482934s
Dec 10 17:03:39.127: INFO: Pod "downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015991159s
STEP: Saw pod success
Dec 10 17:03:39.127: INFO: Pod "downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64" satisfied condition "Succeeded or Failed"
Dec 10 17:03:39.139: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64 container client-container: <nil>
STEP: delete the pod
Dec 10 17:03:39.211: INFO: Waiting for pod downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64 to disappear
Dec 10 17:03:39.219: INFO: Pod downwardapi-volume-fff6e6e4-1a4e-438c-b9bb-f68574da1e64 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:39.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8507" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":71,"skipped":1757,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:39.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:52.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3295" for this suite.

• [SLOW TEST:13.126 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":346,"completed":72,"skipped":1772,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:52.362: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-55a7933b-6031-40a7-9381-a1b1979fdee1
STEP: Creating a pod to test consume configMaps
Dec 10 17:03:52.412: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372" in namespace "configmap-8419" to be "Succeeded or Failed"
Dec 10 17:03:52.414: INFO: Pod "pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798809ms
Dec 10 17:03:54.420: INFO: Pod "pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00772779s
Dec 10 17:03:56.426: INFO: Pod "pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014134572s
STEP: Saw pod success
Dec 10 17:03:56.427: INFO: Pod "pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372" satisfied condition "Succeeded or Failed"
Dec 10 17:03:56.429: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:03:56.442: INFO: Waiting for pod pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372 to disappear
Dec 10 17:03:56.446: INFO: Pod pod-configmaps-e3294705-4e09-4a46-974b-ec470702c372 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:03:56.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8419" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":73,"skipped":1792,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:03:56.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Dec 10 17:03:56.500: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.500: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.513: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.514: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.532: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.532: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.600: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:56.600: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 10 17:03:58.502: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 10 17:03:58.502: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 10 17:04:00.633: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Dec 10 17:04:00.648: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Dec 10 17:04:00.653: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.654: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.654: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.654: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.654: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.654: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.655: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.655: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 0
Dec 10 17:04:00.656: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:00.656: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:00.656: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.656: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.656: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.657: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.661: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.662: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.821: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.821: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:00.877: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:00.878: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:00.906: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:00.906: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:02.766: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:02.766: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:02.810: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
STEP: listing Deployments
Dec 10 17:04:02.832: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Dec 10 17:04:02.845: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Dec 10 17:04:02.860: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:02.864: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:02.930: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:02.987: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:03.027: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:03.054: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:04.831: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:05.059: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:05.143: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:05.156: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 10 17:04:06.894: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 1
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 2
Dec 10 17:04:06.951: INFO: observed Deployment test-deployment in namespace deployment-9745 with ReadyReplicas 3
STEP: deleting the Deployment
Dec 10 17:04:06.984: INFO: observed event type MODIFIED
Dec 10 17:04:06.984: INFO: observed event type MODIFIED
Dec 10 17:04:06.984: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.985: INFO: observed event type MODIFIED
Dec 10 17:04:06.986: INFO: observed event type MODIFIED
Dec 10 17:04:06.986: INFO: observed event type MODIFIED
Dec 10 17:04:06.986: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:04:06.991: INFO: Log out all the ReplicaSets if there is no deployment created
Dec 10 17:04:06.993: INFO: ReplicaSet "test-deployment-5ddd8b47d8":
&ReplicaSet{ObjectMeta:{test-deployment-5ddd8b47d8  deployment-9745  ed9a504d-c625-429e-8122-29dd95732113 8262 4 2021-12-10 17:04:00 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 4361adfa-e648-42e7-9987-bd5899a341b2 0xc005767d07 0xc005767d08}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:04:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4361adfa-e648-42e7-9987-bd5899a341b2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:04:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5ddd8b47d8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.6 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005767d90 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Dec 10 17:04:07.022: INFO: pod: "test-deployment-5ddd8b47d8-72m57":
&Pod{ObjectMeta:{test-deployment-5ddd8b47d8-72m57 test-deployment-5ddd8b47d8- deployment-9745  1ba5e40b-a8cd-4c7c-aca1-4906515f1223 8234 0 2021-12-10 17:04:00 +0000 UTC 2021-12-10 17:04:06 +0000 UTC 0xc005790220 map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5ddd8b47d8 ed9a504d-c625-429e-8122-29dd95732113 0xc005790257 0xc005790258}] []  [{kube-controller-manager Update v1 2021-12-10 17:04:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ed9a504d-c625-429e-8122-29dd95732113\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:04:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.120\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wdszt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.6,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wdszt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.120,StartTime:2021-12-10 17:04:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:04:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.6,ImageID:docker-pullable://k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db,ContainerID:docker://d1f8d8d3c05a6430ded13907e94d53f35171437f7ec7ba57c0bdc78c755f9584,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.120,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec 10 17:04:07.022: INFO: pod: "test-deployment-5ddd8b47d8-vzr8b":
&Pod{ObjectMeta:{test-deployment-5ddd8b47d8-vzr8b test-deployment-5ddd8b47d8- deployment-9745  a910ddcc-6660-487d-bb7c-4a78ba46c5c6 8258 0 2021-12-10 17:04:02 +0000 UTC 2021-12-10 17:04:07 +0000 UTC 0xc005790440 map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5ddd8b47d8 ed9a504d-c625-429e-8122-29dd95732113 0xc005790477 0xc005790478}] []  [{kube-controller-manager Update v1 2021-12-10 17:04:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ed9a504d-c625-429e-8122-29dd95732113\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:04:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.79\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-srbsl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.6,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-srbsl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:10.2.2.79,StartTime:2021-12-10 17:04:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:04:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.6,ImageID:docker-pullable://k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db,ContainerID:docker://91b2ad5afee1463f0befedb6f513e84413556adb79f41bf7f823e956908edb95,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec 10 17:04:07.022: INFO: ReplicaSet "test-deployment-6cdc5bc678":
&ReplicaSet{ObjectMeta:{test-deployment-6cdc5bc678  deployment-9745  f9936849-cf18-4813-a40b-af56b1c03874 8184 3 2021-12-10 17:03:56 +0000 UTC <nil> <nil> map[pod-template-hash:6cdc5bc678 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 4361adfa-e648-42e7-9987-bd5899a341b2 0xc005767df7 0xc005767df8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:03:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4361adfa-e648-42e7-9987-bd5899a341b2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:04:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6cdc5bc678,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6cdc5bc678 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005767e80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Dec 10 17:04:07.029: INFO: ReplicaSet "test-deployment-854fdc678":
&ReplicaSet{ObjectMeta:{test-deployment-854fdc678  deployment-9745  6ebec2a2-bc5b-4b41-8d89-730fdaeb7103 8254 2 2021-12-10 17:04:02 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 4361adfa-e648-42e7-9987-bd5899a341b2 0xc005767ee7 0xc005767ee8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:04:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4361adfa-e648-42e7-9987-bd5899a341b2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:04:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 854fdc678,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005767f70 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Dec 10 17:04:07.035: INFO: pod: "test-deployment-854fdc678-nzs6p":
&Pod{ObjectMeta:{test-deployment-854fdc678-nzs6p test-deployment-854fdc678- deployment-9745  a775a775-082e-4865-b9d7-2371faa91289 8229 0 2021-12-10 17:04:02 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 6ebec2a2-bc5b-4b41-8d89-730fdaeb7103 0xc005791b17 0xc005791b18}] []  [{kube-controller-manager Update v1 2021-12-10 17:04:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6ebec2a2-bc5b-4b41-8d89-730fdaeb7103\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:04:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bwzbz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bwzbz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.121,StartTime:2021-12-10 17:04:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:04:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://8b86325cc6df5263a47fbe6fbc7b5203ce68a7bbe469ddbed746bbb8cfb4a81c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Dec 10 17:04:07.036: INFO: pod: "test-deployment-854fdc678-t9fjx":
&Pod{ObjectMeta:{test-deployment-854fdc678-t9fjx test-deployment-854fdc678- deployment-9745  ea1a05a3-586e-4441-8f24-61f0ea16bc34 8253 0 2021-12-10 17:04:05 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 6ebec2a2-bc5b-4b41-8d89-730fdaeb7103 0xc005791d17 0xc005791d18}] []  [{kube-controller-manager Update v1 2021-12-10 17:04:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6ebec2a2-bc5b-4b41-8d89-730fdaeb7103\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:04:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bg89p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bg89p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:04:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:10.2.2.80,StartTime:2021-12-10 17:04:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:04:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://825eb0bd600cb0ccb63c06d3253e8e1251b5181eab2b7a5850f946421b8c79d6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:04:07.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9745" for this suite.

• [SLOW TEST:10.605 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":346,"completed":74,"skipped":1827,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:04:07.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
STEP: creating an pod
Dec 10 17:04:07.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 10 17:04:07.238: INFO: stderr: ""
Dec 10 17:04:07.239: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for log generator to start.
Dec 10 17:04:07.239: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 10 17:04:07.239: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8593" to be "running and ready, or succeeded"
Dec 10 17:04:07.248: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 9.675859ms
Dec 10 17:04:09.270: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.031523249s
Dec 10 17:04:09.270: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 10 17:04:09.270: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 10 17:04:09.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator'
Dec 10 17:04:09.407: INFO: stderr: ""
Dec 10 17:04:09.407: INFO: stdout: "I1210 17:04:08.157170       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dn6 268\nI1210 17:04:08.357976       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/dmr 453\nI1210 17:04:08.557252       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/djqc 460\nI1210 17:04:08.757592       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/lcnf 383\nI1210 17:04:08.957951       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/2ls 387\nI1210 17:04:09.157242       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/4th 530\nI1210 17:04:09.357602       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/dmv 244\n"
STEP: limiting log lines
Dec 10 17:04:09.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator --tail=1'
Dec 10 17:04:09.510: INFO: stderr: ""
Dec 10 17:04:09.510: INFO: stdout: "I1210 17:04:09.357602       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/dmv 244\n"
Dec 10 17:04:09.510: INFO: got output "I1210 17:04:09.357602       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/dmv 244\n"
STEP: limiting log bytes
Dec 10 17:04:09.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator --limit-bytes=1'
Dec 10 17:04:09.595: INFO: stderr: ""
Dec 10 17:04:09.595: INFO: stdout: "I"
Dec 10 17:04:09.595: INFO: got output "I"
STEP: exposing timestamps
Dec 10 17:04:09.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator --tail=1 --timestamps'
Dec 10 17:04:09.677: INFO: stderr: ""
Dec 10 17:04:09.677: INFO: stdout: "2021-12-10T17:04:09.558120000Z I1210 17:04:09.557952       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm55 565\n"
Dec 10 17:04:09.677: INFO: got output "2021-12-10T17:04:09.558120000Z I1210 17:04:09.557952       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm55 565\n"
STEP: restricting to a time range
Dec 10 17:04:12.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator --since=1s'
Dec 10 17:04:12.288: INFO: stderr: ""
Dec 10 17:04:12.288: INFO: stdout: "I1210 17:04:11.157283       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/7jkh 557\nI1210 17:04:11.357657       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/z68m 294\nI1210 17:04:11.557682       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/7bgg 302\nI1210 17:04:11.757291       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/ggx 365\nI1210 17:04:11.958099       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/jvff 474\nI1210 17:04:12.157889       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/rnv6 526\n"
Dec 10 17:04:12.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 logs logs-generator logs-generator --since=24h'
Dec 10 17:04:12.372: INFO: stderr: ""
Dec 10 17:04:12.372: INFO: stdout: "I1210 17:04:08.157170       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dn6 268\nI1210 17:04:08.357976       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/dmr 453\nI1210 17:04:08.557252       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/djqc 460\nI1210 17:04:08.757592       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/lcnf 383\nI1210 17:04:08.957951       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/2ls 387\nI1210 17:04:09.157242       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/4th 530\nI1210 17:04:09.357602       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/dmv 244\nI1210 17:04:09.557952       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm55 565\nI1210 17:04:09.757273       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/gbqk 395\nI1210 17:04:09.957621       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/9md8 409\nI1210 17:04:10.157351       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/wdd 464\nI1210 17:04:10.357753       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/mcwq 466\nI1210 17:04:10.558125       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/wq5b 280\nI1210 17:04:10.757307       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/4ffr 451\nI1210 17:04:10.957926       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/kgl 402\nI1210 17:04:11.157283       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/7jkh 557\nI1210 17:04:11.357657       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/z68m 294\nI1210 17:04:11.557682       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/7bgg 302\nI1210 17:04:11.757291       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/ggx 365\nI1210 17:04:11.958099       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/jvff 474\nI1210 17:04:12.157889       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/rnv6 526\nI1210 17:04:12.357186       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/gll 531\n"
[AfterEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
Dec 10 17:04:12.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8593 delete pod logs-generator'
Dec 10 17:04:13.211: INFO: stderr: ""
Dec 10 17:04:13.211: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:04:13.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8593" for this suite.

• [SLOW TEST:6.162 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1406
    should be able to retrieve and filter logs  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":346,"completed":75,"skipped":1847,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:04:13.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-d91cbe07-888b-4c36-a934-91dc71b60bb1
STEP: Creating a pod to test consume secrets
Dec 10 17:04:13.270: INFO: Waiting up to 5m0s for pod "pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666" in namespace "secrets-8832" to be "Succeeded or Failed"
Dec 10 17:04:13.273: INFO: Pod "pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666": Phase="Pending", Reason="", readiness=false. Elapsed: 2.350191ms
Dec 10 17:04:15.278: INFO: Pod "pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008164011s
Dec 10 17:04:17.284: INFO: Pod "pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013806675s
STEP: Saw pod success
Dec 10 17:04:17.284: INFO: Pod "pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666" satisfied condition "Succeeded or Failed"
Dec 10 17:04:17.286: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:04:17.298: INFO: Waiting for pod pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666 to disappear
Dec 10 17:04:17.301: INFO: Pod pod-secrets-fdfc9af8-2596-4a8b-9d8c-13a4a8164666 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:04:17.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8832" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":76,"skipped":1871,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:04:17.310: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 17:04:20.370: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:04:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9667" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":77,"skipped":1881,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:04:20.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-downwardapi-q65r
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 17:04:20.487: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-q65r" in namespace "subpath-5494" to be "Succeeded or Failed"
Dec 10 17:04:20.492: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780632ms
Dec 10 17:04:22.497: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00955186s
Dec 10 17:04:24.512: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 4.024647706s
Dec 10 17:04:26.519: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 6.031553512s
Dec 10 17:04:28.525: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 8.036938556s
Dec 10 17:04:30.534: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 10.046557585s
Dec 10 17:04:32.539: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 12.051646338s
Dec 10 17:04:34.546: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 14.058498423s
Dec 10 17:04:36.552: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 16.064309962s
Dec 10 17:04:38.560: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 18.07218619s
Dec 10 17:04:40.589: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Running", Reason="", readiness=true. Elapsed: 20.101215118s
Dec 10 17:04:42.594: INFO: Pod "pod-subpath-test-downwardapi-q65r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.106166493s
STEP: Saw pod success
Dec 10 17:04:42.594: INFO: Pod "pod-subpath-test-downwardapi-q65r" satisfied condition "Succeeded or Failed"
Dec 10 17:04:42.596: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-subpath-test-downwardapi-q65r container test-container-subpath-downwardapi-q65r: <nil>
STEP: delete the pod
Dec 10 17:04:42.614: INFO: Waiting for pod pod-subpath-test-downwardapi-q65r to disappear
Dec 10 17:04:42.623: INFO: Pod pod-subpath-test-downwardapi-q65r no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-q65r
Dec 10 17:04:42.624: INFO: Deleting pod "pod-subpath-test-downwardapi-q65r" in namespace "subpath-5494"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:04:42.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5494" for this suite.

• [SLOW TEST:22.250 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":78,"skipped":1912,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:04:42.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:09:42.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1158" for this suite.

• [SLOW TEST:300.092 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":346,"completed":79,"skipped":1956,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:09:42.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 10 17:09:42.865: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8157  e86e48cc-e094-4dbb-a95f-f5034df0d64e 8950 0 2021-12-10 17:09:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2021-12-10 17:09:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:09:42.865: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8157  e86e48cc-e094-4dbb-a95f-f5034df0d64e 8951 0 2021-12-10 17:09:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2021-12-10 17:09:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:09:42.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8157" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":346,"completed":80,"skipped":1970,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:09:42.885: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:09:43.432: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 10 17:09:45.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 17, 9, 43, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 9, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 9, 43, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 9, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:09:48.459: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:09:48.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4242-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:09:51.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9886" for this suite.
STEP: Destroying namespace "webhook-9886-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.759 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":346,"completed":81,"skipped":1985,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:09:51.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:09:51.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f" in namespace "projected-814" to be "Succeeded or Failed"
Dec 10 17:09:51.932: INFO: Pod "downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.75354ms
Dec 10 17:09:53.939: INFO: Pod "downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020721919s
STEP: Saw pod success
Dec 10 17:09:53.939: INFO: Pod "downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f" satisfied condition "Succeeded or Failed"
Dec 10 17:09:53.941: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f container client-container: <nil>
STEP: delete the pod
Dec 10 17:09:53.969: INFO: Waiting for pod downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f to disappear
Dec 10 17:09:53.972: INFO: Pod downwardapi-volume-2f4f0745-5144-4f48-92c4-817cb8fc6d3f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:09:53.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-814" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":82,"skipped":2013,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:09:53.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:09:54.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1377" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":346,"completed":83,"skipped":2014,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:09:54.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8288.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8288.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8288.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8288.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 17:10:06.173: INFO: DNS probes using dns-8288/dns-test-9a5bb8f6-4866-427f-a111-e98bcf40af6f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:10:06.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8288" for this suite.

• [SLOW TEST:12.110 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":346,"completed":84,"skipped":2018,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:10:06.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Dec 10 17:10:06.267: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 17:11:06.296: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:06.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:488
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Dec 10 17:11:10.382: INFO: found a healthy node: ip-10-0-19-34
[It] runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:11:18.442: INFO: pods created so far: [1 1 1]
Dec 10 17:11:18.443: INFO: length of pods created so far: 3
Dec 10 17:11:22.459: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:29.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7024" for this suite.
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:462
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:29.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1159" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:83.344 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:451
    runs ReplicaSets to verify preemption running path [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":346,"completed":85,"skipped":2025,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:29.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service endpoint-test2 in namespace services-5490
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5490 to expose endpoints map[]
Dec 10 17:11:29.600: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Dec 10 17:11:30.608: INFO: successfully validated that service endpoint-test2 in namespace services-5490 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5490
Dec 10 17:11:30.616: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:11:32.626: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5490 to expose endpoints map[pod1:[80]]
Dec 10 17:11:32.641: INFO: successfully validated that service endpoint-test2 in namespace services-5490 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Dec 10 17:11:32.642: INFO: Creating new exec pod
Dec 10 17:11:35.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 10 17:11:35.991: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 10 17:11:35.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:11:35.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.31.117 80'
Dec 10 17:11:36.161: INFO: stderr: "+ nc -v -t -w 2 10.3.31.117 80\nConnection to 10.3.31.117 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:11:36.161: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-5490
Dec 10 17:11:36.168: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:11:38.220: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5490 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 10 17:11:38.308: INFO: successfully validated that service endpoint-test2 in namespace services-5490 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Dec 10 17:11:39.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 10 17:11:39.566: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 10 17:11:39.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:11:39.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.31.117 80'
Dec 10 17:11:39.765: INFO: stderr: "+ nc -v -t -w 2 10.3.31.117 80\nConnection to 10.3.31.117 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:11:39.765: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5490
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5490 to expose endpoints map[pod2:[80]]
Dec 10 17:11:40.847: INFO: successfully validated that service endpoint-test2 in namespace services-5490 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Dec 10 17:11:41.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 10 17:11:42.067: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 10 17:11:42.067: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:11:42.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5490 exec execpodkwndf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.31.117 80'
Dec 10 17:11:42.240: INFO: stderr: "+ nc -v -t -w 2 10.3.31.117 80\n+ echo hostName\nConnection to 10.3.31.117 80 port [tcp/http] succeeded!\n"
Dec 10 17:11:42.240: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-5490
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5490 to expose endpoints map[]
Dec 10 17:11:43.450: INFO: successfully validated that service endpoint-test2 in namespace services-5490 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:43.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5490" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:13.952 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":346,"completed":86,"skipped":2041,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:43.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:11:44.122: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:11:47.152: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:47.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9999" for this suite.
STEP: Destroying namespace "webhook-9999-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":346,"completed":87,"skipped":2041,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:47.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:11:47.423: INFO: The status of Pod pod-secrets-d87a7c30-f54d-4153-894b-8eb5fb22fbd8 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:11:49.428: INFO: The status of Pod pod-secrets-d87a7c30-f54d-4153-894b-8eb5fb22fbd8 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:49.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4184" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":346,"completed":88,"skipped":2045,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:49.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Dec 10 17:11:49.498: INFO: The status of Pod labelsupdate6683484b-3449-4052-b141-363cc27e15ef is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:11:51.505: INFO: The status of Pod labelsupdate6683484b-3449-4052-b141-363cc27e15ef is Running (Ready = true)
Dec 10 17:11:52.036: INFO: Successfully updated pod "labelsupdate6683484b-3449-4052-b141-363cc27e15ef"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:54.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7478" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":89,"skipped":2046,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:54.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's command
Dec 10 17:11:54.104: INFO: Waiting up to 5m0s for pod "var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983" in namespace "var-expansion-9565" to be "Succeeded or Failed"
Dec 10 17:11:54.107: INFO: Pod "var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.807933ms
Dec 10 17:11:56.113: INFO: Pod "var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008453716s
Dec 10 17:11:58.120: INFO: Pod "var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016352684s
STEP: Saw pod success
Dec 10 17:11:58.121: INFO: Pod "var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983" satisfied condition "Succeeded or Failed"
Dec 10 17:11:58.122: INFO: Trying to get logs from node ip-10-0-19-34 pod var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:11:58.135: INFO: Waiting for pod var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983 to disappear
Dec 10 17:11:58.137: INFO: Pod var-expansion-7090d140-8ec7-4130-888b-cf8c450d5983 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:11:58.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9565" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":346,"completed":90,"skipped":2066,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:11:58.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-a1b4635a-d6b6-4e60-8a36-9e145a28da28
STEP: Creating the pod
Dec 10 17:11:58.231: INFO: The status of Pod pod-configmaps-d51a8c3f-d97f-49c7-b988-784b245dd4bc is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:12:00.238: INFO: The status of Pod pod-configmaps-d51a8c3f-d97f-49c7-b988-784b245dd4bc is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-a1b4635a-d6b6-4e60-8a36-9e145a28da28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:02.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1127" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":91,"skipped":2068,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:02.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:12:02.816: INFO: Checking APIGroup: apiregistration.k8s.io
Dec 10 17:12:02.823: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Dec 10 17:12:02.824: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Dec 10 17:12:02.824: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Dec 10 17:12:02.824: INFO: Checking APIGroup: apps
Dec 10 17:12:02.829: INFO: PreferredVersion.GroupVersion: apps/v1
Dec 10 17:12:02.829: INFO: Versions found [{apps/v1 v1}]
Dec 10 17:12:02.830: INFO: apps/v1 matches apps/v1
Dec 10 17:12:02.830: INFO: Checking APIGroup: events.k8s.io
Dec 10 17:12:02.838: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Dec 10 17:12:02.839: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Dec 10 17:12:02.839: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Dec 10 17:12:02.839: INFO: Checking APIGroup: authentication.k8s.io
Dec 10 17:12:02.842: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Dec 10 17:12:02.843: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Dec 10 17:12:02.843: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Dec 10 17:12:02.843: INFO: Checking APIGroup: authorization.k8s.io
Dec 10 17:12:02.867: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Dec 10 17:12:02.867: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Dec 10 17:12:02.867: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Dec 10 17:12:02.867: INFO: Checking APIGroup: autoscaling
Dec 10 17:12:02.876: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Dec 10 17:12:02.876: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Dec 10 17:12:02.876: INFO: autoscaling/v2 matches autoscaling/v2
Dec 10 17:12:02.876: INFO: Checking APIGroup: batch
Dec 10 17:12:02.878: INFO: PreferredVersion.GroupVersion: batch/v1
Dec 10 17:12:02.878: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Dec 10 17:12:02.878: INFO: batch/v1 matches batch/v1
Dec 10 17:12:02.878: INFO: Checking APIGroup: certificates.k8s.io
Dec 10 17:12:02.880: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Dec 10 17:12:02.880: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Dec 10 17:12:02.880: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Dec 10 17:12:02.880: INFO: Checking APIGroup: networking.k8s.io
Dec 10 17:12:02.885: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Dec 10 17:12:02.885: INFO: Versions found [{networking.k8s.io/v1 v1}]
Dec 10 17:12:02.885: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Dec 10 17:12:02.886: INFO: Checking APIGroup: policy
Dec 10 17:12:02.887: INFO: PreferredVersion.GroupVersion: policy/v1
Dec 10 17:12:02.887: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Dec 10 17:12:02.888: INFO: policy/v1 matches policy/v1
Dec 10 17:12:02.888: INFO: Checking APIGroup: rbac.authorization.k8s.io
Dec 10 17:12:02.889: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Dec 10 17:12:02.889: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Dec 10 17:12:02.889: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Dec 10 17:12:02.890: INFO: Checking APIGroup: storage.k8s.io
Dec 10 17:12:02.890: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Dec 10 17:12:02.891: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Dec 10 17:12:02.891: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Dec 10 17:12:02.891: INFO: Checking APIGroup: admissionregistration.k8s.io
Dec 10 17:12:02.896: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Dec 10 17:12:02.897: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Dec 10 17:12:02.897: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Dec 10 17:12:02.897: INFO: Checking APIGroup: apiextensions.k8s.io
Dec 10 17:12:02.899: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Dec 10 17:12:02.900: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Dec 10 17:12:02.900: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Dec 10 17:12:02.900: INFO: Checking APIGroup: scheduling.k8s.io
Dec 10 17:12:02.902: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Dec 10 17:12:02.902: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Dec 10 17:12:02.902: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Dec 10 17:12:02.902: INFO: Checking APIGroup: coordination.k8s.io
Dec 10 17:12:02.903: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Dec 10 17:12:02.903: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Dec 10 17:12:02.903: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Dec 10 17:12:02.903: INFO: Checking APIGroup: node.k8s.io
Dec 10 17:12:02.906: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Dec 10 17:12:02.906: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Dec 10 17:12:02.906: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Dec 10 17:12:02.906: INFO: Checking APIGroup: discovery.k8s.io
Dec 10 17:12:02.907: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Dec 10 17:12:02.907: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Dec 10 17:12:02.907: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Dec 10 17:12:02.907: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Dec 10 17:12:02.909: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Dec 10 17:12:02.909: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Dec 10 17:12:02.909: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
[AfterEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:02.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-2236" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":346,"completed":92,"skipped":2101,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:02.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:05.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5801" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":93,"skipped":2113,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:05.063: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:05.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1744" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":346,"completed":94,"skipped":2114,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:05.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-e7183536-51f1-4097-a2bc-9931c5dd7249
STEP: Creating secret with name s-test-opt-upd-2a45f3e0-471c-479c-be9f-8878ba92ac72
STEP: Creating the pod
Dec 10 17:12:05.346: INFO: The status of Pod pod-projected-secrets-6663093b-c870-4db9-ae06-afd0554f843a is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:12:07.359: INFO: The status of Pod pod-projected-secrets-6663093b-c870-4db9-ae06-afd0554f843a is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:12:09.351: INFO: The status of Pod pod-projected-secrets-6663093b-c870-4db9-ae06-afd0554f843a is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-e7183536-51f1-4097-a2bc-9931c5dd7249
STEP: Updating secret s-test-opt-upd-2a45f3e0-471c-479c-be9f-8878ba92ac72
STEP: Creating secret with name s-test-opt-create-cff3d37c-2388-4def-874e-a2f996d063fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:11.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6346" for this suite.

• [SLOW TEST:6.196 seconds]
[sig-storage] Projected secret
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":95,"skipped":2123,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:11.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-5273
STEP: creating service affinity-clusterip in namespace services-5273
STEP: creating replication controller affinity-clusterip in namespace services-5273
I1210 17:12:11.504775      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-5273, replica count: 3
I1210 17:12:14.566639      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:12:14.574: INFO: Creating new exec pod
Dec 10 17:12:17.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5273 exec execpod-affinity8vcjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Dec 10 17:12:17.839: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Dec 10 17:12:17.839: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:12:17.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5273 exec execpod-affinity8vcjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.192.176 80'
Dec 10 17:12:18.062: INFO: stderr: "+ nc -v -t -w 2 10.3.192.176 80\n+ echo hostName\nConnection to 10.3.192.176 80 port [tcp/http] succeeded!\n"
Dec 10 17:12:18.062: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:12:18.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5273 exec execpod-affinity8vcjn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.192.176:80/ ; done'
Dec 10 17:12:18.358: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.192.176:80/\n"
Dec 10 17:12:18.358: INFO: stdout: "\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg\naffinity-clusterip-dzkmg"
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Received response from host: affinity-clusterip-dzkmg
Dec 10 17:12:18.358: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-5273, will wait for the garbage collector to delete the pods
Dec 10 17:12:18.428: INFO: Deleting ReplicationController affinity-clusterip took: 3.951102ms
Dec 10 17:12:18.530: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.822137ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:21.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5273" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.729 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":96,"skipped":2145,"failed":0}
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:21.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:12:21.228: INFO: The status of Pod busybox-host-aliases4e158c88-cc55-41ab-bbf9-be9d0a018aa0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:12:23.235: INFO: The status of Pod busybox-host-aliases4e158c88-cc55-41ab-bbf9-be9d0a018aa0 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:23.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6379" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":97,"skipped":2145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:23.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Dec 10 17:12:43.439: INFO: EndpointSlice for Service endpointslice-3209/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:12:53.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3209" for this suite.

• [SLOW TEST:30.204 seconds]
[sig-network] EndpointSlice
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":346,"completed":98,"skipped":2192,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:12:53.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Dec 10 17:12:53.534: INFO: The status of Pod annotationupdate63189203-fdea-4153-803f-e4025cd34d7e is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:12:55.543: INFO: The status of Pod annotationupdate63189203-fdea-4153-803f-e4025cd34d7e is Running (Ready = true)
Dec 10 17:12:56.065: INFO: Successfully updated pod "annotationupdate63189203-fdea-4153-803f-e4025cd34d7e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:13:00.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2148" for this suite.

• [SLOW TEST:6.621 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":99,"skipped":2220,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:13:00.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:13:01.341: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:13:04.365: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:13:16.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1795" for this suite.
STEP: Destroying namespace "webhook-1795-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.544 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":346,"completed":100,"skipped":2231,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:13:16.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption is created
Dec 10 17:13:16.794: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:13:18.802: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:13:19.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9068" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":346,"completed":101,"skipped":2243,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:13:19.845: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Dec 10 17:13:19.888: INFO: PodSpec: initContainers in spec.initContainers
Dec 10 17:14:09.595: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5762dceb-ac54-49f9-b1aa-7d732c70dd71", GenerateName:"", Namespace:"init-container-6320", SelfLink:"", UID:"f2a05b78-6aca-4e26-bdab-1f26d052f98f", ResourceVersion:"10465", Generation:0, CreationTimestamp:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"888868297"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005a64c00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2021, time.December, 10, 17, 13, 21, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005a64c30), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xmssh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00493c2c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xmssh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xmssh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.6", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xmssh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b1ee50), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-19-34", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0048f8ee0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b1eee0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002b1ef00)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002b1ef08), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002b1ef0c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc002cc6490), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.19.34", PodIP:"10.2.1.152", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.1.152"}}, StartTime:time.Date(2021, time.December, 10, 17, 13, 19, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0048f8fc0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0048f9030)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://6a7d4f72f38a195c5ac7753cd44d87656932ecd369dce8c129b15793de88e333", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00493c340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00493c320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.6", ImageID:"", ContainerID:"", Started:(*bool)(0xc002b1ef8f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:14:09.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6320" for this suite.

• [SLOW TEST:49.759 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":346,"completed":102,"skipped":2244,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:14:09.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create deployment with httpd image
Dec 10 17:14:09.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3603 create -f -'
Dec 10 17:14:10.793: INFO: stderr: ""
Dec 10 17:14:10.793: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Dec 10 17:14:10.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3603 diff -f -'
Dec 10 17:14:11.003: INFO: rc: 1
Dec 10 17:14:11.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3603 delete -f -'
Dec 10 17:14:11.059: INFO: stderr: ""
Dec 10 17:14:11.059: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:14:11.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3603" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":346,"completed":103,"skipped":2246,"failed":0}

------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:14:11.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-7047
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Dec 10 17:14:11.138: INFO: Found 0 stateful pods, waiting for 3
Dec 10 17:14:21.154: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:14:21.154: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:14:21.154: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Dec 10 17:14:21.194: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 10 17:14:31.270: INFO: Updating stateful set ss2
Dec 10 17:14:31.285: INFO: Waiting for Pod statefulset-7047/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Dec 10 17:14:41.367: INFO: Found 1 stateful pods, waiting for 3
Dec 10 17:14:51.371: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:14:51.371: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:14:51.371: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 10 17:14:51.393: INFO: Updating stateful set ss2
Dec 10 17:14:51.418: INFO: Waiting for Pod statefulset-7047/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Dec 10 17:15:01.477: INFO: Updating stateful set ss2
Dec 10 17:15:01.512: INFO: Waiting for StatefulSet statefulset-7047/ss2 to complete update
Dec 10 17:15:01.512: INFO: Waiting for Pod statefulset-7047/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:15:11.522: INFO: Deleting all statefulset in ns statefulset-7047
Dec 10 17:15:11.524: INFO: Scaling statefulset ss2 to 0
Dec 10 17:15:21.543: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:15:21.544: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:21.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7047" for this suite.

• [SLOW TEST:70.516 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":346,"completed":104,"skipped":2246,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:21.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:15:21.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379" in namespace "downward-api-1183" to be "Succeeded or Failed"
Dec 10 17:15:21.633: INFO: Pod "downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379": Phase="Pending", Reason="", readiness=false. Elapsed: 1.912639ms
Dec 10 17:15:23.638: INFO: Pod "downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007023121s
STEP: Saw pod success
Dec 10 17:15:23.638: INFO: Pod "downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379" satisfied condition "Succeeded or Failed"
Dec 10 17:15:23.640: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379 container client-container: <nil>
STEP: delete the pod
Dec 10 17:15:23.666: INFO: Waiting for pod downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379 to disappear
Dec 10 17:15:23.668: INFO: Pod downwardapi-volume-c9fd1f34-fc15-4607-97d8-624447d08379 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:23.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1183" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":105,"skipped":2247,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:23.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:40.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1946" for this suite.

• [SLOW TEST:17.091 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":346,"completed":106,"skipped":2255,"failed":0}
SSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:40.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:40.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5423" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":107,"skipped":2258,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:40.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Dec 10 17:15:40.926: INFO: The status of Pod annotationupdate4362d728-4434-4a10-96f4-c0699692032c is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:15:42.944: INFO: The status of Pod annotationupdate4362d728-4434-4a10-96f4-c0699692032c is Running (Ready = true)
Dec 10 17:15:43.471: INFO: Successfully updated pod "annotationupdate4362d728-4434-4a10-96f4-c0699692032c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:45.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4159" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":108,"skipped":2273,"failed":0}
SSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:45.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:15:45.537: INFO: Creating pod...
Dec 10 17:15:45.545: INFO: Pod Quantity: 1 Status: Pending
Dec 10 17:15:46.551: INFO: Pod Quantity: 1 Status: Pending
Dec 10 17:15:47.596: INFO: Pod Quantity: 1 Status: Pending
Dec 10 17:15:48.550: INFO: Pod Status: Running
Dec 10 17:15:48.550: INFO: Creating service...
Dec 10 17:15:48.558: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/DELETE
Dec 10 17:15:48.575: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 10 17:15:48.576: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/GET
Dec 10 17:15:48.581: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 10 17:15:48.581: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/HEAD
Dec 10 17:15:48.589: INFO: http.Client request:HEAD | StatusCode:200
Dec 10 17:15:48.589: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/OPTIONS
Dec 10 17:15:48.595: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 10 17:15:48.595: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/PATCH
Dec 10 17:15:48.602: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 10 17:15:48.602: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/POST
Dec 10 17:15:48.612: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 10 17:15:48.612: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/pods/agnhost/proxy/some/path/with/PUT
Dec 10 17:15:48.619: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 10 17:15:48.620: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/DELETE
Dec 10 17:15:48.629: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 10 17:15:48.630: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/GET
Dec 10 17:15:48.641: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 10 17:15:48.641: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/HEAD
Dec 10 17:15:48.660: INFO: http.Client request:HEAD | StatusCode:200
Dec 10 17:15:48.661: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/OPTIONS
Dec 10 17:15:48.721: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 10 17:15:48.722: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/PATCH
Dec 10 17:15:48.745: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 10 17:15:48.745: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/POST
Dec 10 17:15:48.764: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 10 17:15:48.765: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-7334/services/test-service/proxy/some/path/with/PUT
Dec 10 17:15:48.770: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:48.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7334" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":346,"completed":109,"skipped":2277,"failed":0}
SSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:48.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4440" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":346,"completed":110,"skipped":2280,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:49.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 10 17:15:50.139: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 17:15:50.334: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:50.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7918" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":346,"completed":111,"skipped":2282,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:50.349: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-f634c09c-2309-44a9-89bd-5af4856db66c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:52.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5760" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":112,"skipped":2294,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 10 17:15:57.034: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1225 pod-service-account-839210e8-87ba-4b28-9d64-753fae1c8031 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 10 17:15:57.227: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1225 pod-service-account-839210e8-87ba-4b28-9d64-753fae1c8031 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 10 17:15:57.448: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1225 pod-service-account-839210e8-87ba-4b28-9d64-753fae1c8031 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:57.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1225" for this suite.

• [SLOW TEST:5.347 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":346,"completed":113,"skipped":2322,"failed":0}
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:57.778: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:15:57.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3131" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":346,"completed":114,"skipped":2323,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:15:57.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1284.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1284.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1284.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1284.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 17:15:59.924: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.927: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.930: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.932: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.935: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.938: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.941: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.944: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:15:59.945: INFO: Lookups using dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1284.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1284.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local jessie_udp@dns-test-service-2.dns-1284.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1284.svc.cluster.local]

Dec 10 17:16:04.956: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:16:04.961: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:16:04.965: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1284.svc.cluster.local from pod dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae: the server could not find the requested resource (get pods dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae)
Dec 10 17:16:04.983: INFO: Lookups using dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1284.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1284.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1284.svc.cluster.local]

Dec 10 17:16:09.971: INFO: DNS probes using dns-1284/dns-test-34ea0af6-1e56-4674-8c3e-72e5936b9fae succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:16:10.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1284" for this suite.

• [SLOW TEST:12.216 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":346,"completed":115,"skipped":2325,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:16:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Dec 10 17:16:10.124: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Dec 10 17:16:10.128: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 10 17:16:10.128: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Dec 10 17:16:10.135: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 10 17:16:10.136: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Dec 10 17:16:10.153: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec 10 17:16:10.153: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Dec 10 17:16:17.239: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:16:17.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-7218" for this suite.

• [SLOW TEST:7.180 seconds]
[sig-scheduling] LimitRange
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":346,"completed":116,"skipped":2371,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:16:17.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:18:01.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4733" for this suite.

• [SLOW TEST:104.751 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":346,"completed":117,"skipped":2379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:18:02.015: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:18:02.234: INFO: Create a RollingUpdate DaemonSet
Dec 10 17:18:02.258: INFO: Check that daemon pods launch on every node of the cluster
Dec 10 17:18:02.268: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:02.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:18:02.285: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:18:03.293: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:03.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:18:03.299: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:18:04.292: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:04.294: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:18:04.295: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 17:18:05.291: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:05.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:18:05.295: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 17:18:06.291: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:06.293: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 17:18:06.293: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Dec 10 17:18:06.294: INFO: Update the DaemonSet to trigger a rollout
Dec 10 17:18:06.299: INFO: Updating DaemonSet daemon-set
Dec 10 17:18:07.318: INFO: Roll back the DaemonSet before rollout is complete
Dec 10 17:18:07.323: INFO: Updating DaemonSet daemon-set
Dec 10 17:18:07.323: INFO: Make sure DaemonSet rollback is complete
Dec 10 17:18:07.325: INFO: Wrong image for pod: daemon-set-xgs8p. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Dec 10 17:18:07.325: INFO: Pod daemon-set-xgs8p is not available
Dec 10 17:18:07.330: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:08.337: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:18:09.562: INFO: Pod daemon-set-24c79 is not available
Dec 10 17:18:09.564: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2731, will wait for the garbage collector to delete the pods
Dec 10 17:18:09.628: INFO: Deleting DaemonSet.extensions daemon-set took: 5.695854ms
Dec 10 17:18:09.738: INFO: Terminating DaemonSet.extensions daemon-set pods took: 109.3335ms
Dec 10 17:18:12.144: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:18:12.145: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 17:18:12.147: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11685"},"items":null}

Dec 10 17:18:12.149: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11685"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:18:12.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2731" for this suite.

• [SLOW TEST:10.145 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":346,"completed":118,"skipped":2406,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:18:12.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Dec 10 17:18:12.213: INFO: Waiting up to 5m0s for pod "downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c" in namespace "downward-api-8139" to be "Succeeded or Failed"
Dec 10 17:18:12.215: INFO: Pod "downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.612292ms
Dec 10 17:18:14.219: INFO: Pod "downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006070946s
STEP: Saw pod success
Dec 10 17:18:14.219: INFO: Pod "downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c" satisfied condition "Succeeded or Failed"
Dec 10 17:18:14.221: INFO: Trying to get logs from node ip-10-0-19-34 pod downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:18:14.244: INFO: Waiting for pod downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c to disappear
Dec 10 17:18:14.246: INFO: Pod downward-api-c402eb91-8bea-483f-9a44-f2e5d023437c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:18:14.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8139" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":346,"completed":119,"skipped":2419,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:18:14.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Dec 10 17:18:14.295: INFO: namespace kubectl-6430
Dec 10 17:18:14.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-6430 create -f -'
Dec 10 17:18:14.454: INFO: stderr: ""
Dec 10 17:18:14.455: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Dec 10 17:18:15.460: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:18:15.460: INFO: Found 0 / 1
Dec 10 17:18:16.459: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:18:16.459: INFO: Found 1 / 1
Dec 10 17:18:16.459: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 17:18:16.463: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:18:16.463: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 17:18:16.463: INFO: wait on agnhost-primary startup in kubectl-6430 
Dec 10 17:18:16.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-6430 logs agnhost-primary-dx72f agnhost-primary'
Dec 10 17:18:16.569: INFO: stderr: ""
Dec 10 17:18:16.569: INFO: stdout: "Paused\n"
STEP: exposing RC
Dec 10 17:18:16.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-6430 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Dec 10 17:18:16.676: INFO: stderr: ""
Dec 10 17:18:16.676: INFO: stdout: "service/rm2 exposed\n"
Dec 10 17:18:16.684: INFO: Service rm2 in namespace kubectl-6430 found.
STEP: exposing service
Dec 10 17:18:18.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-6430 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Dec 10 17:18:18.769: INFO: stderr: ""
Dec 10 17:18:18.770: INFO: stdout: "service/rm3 exposed\n"
Dec 10 17:18:18.788: INFO: Service rm3 in namespace kubectl-6430 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:18:20.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6430" for this suite.

• [SLOW TEST:6.545 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
    should create services for rc  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":346,"completed":120,"skipped":2425,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:18:20.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-05343fad-acd1-401b-9a7f-8ada3d334893
STEP: Creating a pod to test consume secrets
Dec 10 17:18:20.869: INFO: Waiting up to 5m0s for pod "pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc" in namespace "secrets-2884" to be "Succeeded or Failed"
Dec 10 17:18:20.870: INFO: Pod "pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769856ms
Dec 10 17:18:22.876: INFO: Pod "pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007679502s
STEP: Saw pod success
Dec 10 17:18:22.877: INFO: Pod "pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc" satisfied condition "Succeeded or Failed"
Dec 10 17:18:22.879: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:18:22.893: INFO: Waiting for pod pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc to disappear
Dec 10 17:18:22.895: INFO: Pod pod-secrets-7115835c-1b3d-4e91-a2f7-014f9f5b58dc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:18:22.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2884" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":121,"skipped":2426,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:18:22.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-9272
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9272
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9272
Dec 10 17:18:22.995: INFO: Found 0 stateful pods, waiting for 1
Dec 10 17:18:33.005: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 10 17:18:33.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 17:18:33.164: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 17:18:33.164: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 17:18:33.164: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 17:18:33.167: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 17:18:43.174: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 17:18:43.174: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:18:43.184: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999764s
Dec 10 17:18:44.189: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996186044s
Dec 10 17:18:45.203: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990898786s
Dec 10 17:18:46.209: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97564841s
Dec 10 17:18:47.250: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.971179185s
Dec 10 17:18:48.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.929313822s
Dec 10 17:18:49.265: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.919995506s
Dec 10 17:18:50.272: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.914815643s
Dec 10 17:18:51.278: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.907614705s
Dec 10 17:18:52.285: INFO: Verifying statefulset ss doesn't scale past 1 for another 901.329315ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9272
Dec 10 17:18:53.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:18:53.541: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 17:18:53.541: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 17:18:53.541: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 17:18:53.544: INFO: Found 1 stateful pods, waiting for 3
Dec 10 17:19:03.549: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:19:03.549: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:19:03.550: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 10 17:19:03.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 17:19:03.875: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 17:19:03.875: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 17:19:03.875: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 17:19:03.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 17:19:04.273: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 17:19:04.273: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 17:19:04.273: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 17:19:04.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 17:19:04.445: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 17:19:04.445: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 17:19:04.445: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 17:19:04.445: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:19:04.448: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 10 17:19:14.456: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 17:19:14.457: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 17:19:14.457: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 17:19:14.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999792s
Dec 10 17:19:15.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996024535s
Dec 10 17:19:16.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988957303s
Dec 10 17:19:17.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98180034s
Dec 10 17:19:18.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976775195s
Dec 10 17:19:19.498: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969713901s
Dec 10 17:19:20.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.961287608s
Dec 10 17:19:21.513: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954586185s
Dec 10 17:19:22.517: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949434942s
Dec 10 17:19:23.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.004574ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9272
Dec 10 17:19:24.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:24.673: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 17:19:24.673: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 17:19:24.673: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 17:19:24.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:25.026: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 17:19:25.026: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 17:19:25.027: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 17:19:25.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:25.286: INFO: rc: 1
Dec 10 17:19:25.286: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server: 

error:
exit status 1
Dec 10 17:19:35.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:35.420: INFO: rc: 1
Dec 10 17:19:35.420: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:19:45.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:45.558: INFO: rc: 1
Dec 10 17:19:45.558: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:19:55.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:19:55.632: INFO: rc: 1
Dec 10 17:19:55.632: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:05.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:05.700: INFO: rc: 1
Dec 10 17:20:05.701: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:15.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:15.771: INFO: rc: 1
Dec 10 17:20:15.772: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:25.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:25.838: INFO: rc: 1
Dec 10 17:20:25.838: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:35.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:35.905: INFO: rc: 1
Dec 10 17:20:35.905: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:45.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:46.047: INFO: rc: 1
Dec 10 17:20:46.047: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:20:56.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:20:56.172: INFO: rc: 1
Dec 10 17:20:56.172: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:06.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:06.375: INFO: rc: 1
Dec 10 17:21:06.375: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:16.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:16.447: INFO: rc: 1
Dec 10 17:21:16.447: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:26.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:26.533: INFO: rc: 1
Dec 10 17:21:26.533: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:36.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:36.825: INFO: rc: 1
Dec 10 17:21:36.825: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:46.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:46.944: INFO: rc: 1
Dec 10 17:21:46.944: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:21:56.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:21:57.096: INFO: rc: 1
Dec 10 17:21:57.096: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:07.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:07.183: INFO: rc: 1
Dec 10 17:22:07.183: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:17.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:17.260: INFO: rc: 1
Dec 10 17:22:17.260: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:27.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:27.384: INFO: rc: 1
Dec 10 17:22:27.384: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:37.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:37.579: INFO: rc: 1
Dec 10 17:22:37.579: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:47.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:47.784: INFO: rc: 1
Dec 10 17:22:47.784: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:22:57.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:22:57.914: INFO: rc: 1
Dec 10 17:22:57.915: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:07.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:08.104: INFO: rc: 1
Dec 10 17:23:08.104: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:18.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:18.242: INFO: rc: 1
Dec 10 17:23:18.242: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:28.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:28.396: INFO: rc: 1
Dec 10 17:23:28.396: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:38.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:38.477: INFO: rc: 1
Dec 10 17:23:38.477: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:48.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:48.751: INFO: rc: 1
Dec 10 17:23:48.751: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:23:58.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:23:58.938: INFO: rc: 1
Dec 10 17:23:58.938: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:24:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:24:09.061: INFO: rc: 1
Dec 10 17:24:09.061: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:24:19.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:24:19.457: INFO: rc: 1
Dec 10 17:24:19.457: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec 10 17:24:29.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-9272 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 17:24:29.546: INFO: rc: 1
Dec 10 17:24:29.546: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Dec 10 17:24:29.546: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:24:29.555: INFO: Deleting all statefulset in ns statefulset-9272
Dec 10 17:24:29.556: INFO: Scaling statefulset ss to 0
Dec 10 17:24:29.567: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:24:29.570: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:29.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9272" for this suite.

• [SLOW TEST:366.697 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":346,"completed":122,"skipped":2451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:29.613: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
Dec 10 17:24:30.200: INFO: created pod pod-service-account-defaultsa
Dec 10 17:24:30.201: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 10 17:24:30.208: INFO: created pod pod-service-account-mountsa
Dec 10 17:24:30.208: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 10 17:24:30.221: INFO: created pod pod-service-account-nomountsa
Dec 10 17:24:30.221: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 10 17:24:30.231: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 10 17:24:30.231: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 10 17:24:30.244: INFO: created pod pod-service-account-mountsa-mountspec
Dec 10 17:24:30.245: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 10 17:24:30.252: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 10 17:24:30.253: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 10 17:24:30.263: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 10 17:24:30.264: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 10 17:24:30.288: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 10 17:24:30.288: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 10 17:24:30.296: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 10 17:24:30.296: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:30.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-606" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":346,"completed":123,"skipped":2500,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:30.314: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:24:30.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: creating the pod
STEP: submitting the pod to kubernetes
Dec 10 17:24:30.383: INFO: The status of Pod pod-exec-websocket-c9c438e3-33ff-4e74-91d8-e7f4135824b0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:24:32.391: INFO: The status of Pod pod-exec-websocket-c9c438e3-33ff-4e74-91d8-e7f4135824b0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:24:34.388: INFO: The status of Pod pod-exec-websocket-c9c438e3-33ff-4e74-91d8-e7f4135824b0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:24:36.391: INFO: The status of Pod pod-exec-websocket-c9c438e3-33ff-4e74-91d8-e7f4135824b0 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5786" for this suite.

• [SLOW TEST:6.765 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":346,"completed":124,"skipped":2516,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:37.085: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:24:37.617: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:24:40.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:40.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8402" for this suite.
STEP: Destroying namespace "webhook-8402-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":346,"completed":125,"skipped":2521,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:40.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override command
Dec 10 17:24:41.008: INFO: Waiting up to 5m0s for pod "client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68" in namespace "containers-3974" to be "Succeeded or Failed"
Dec 10 17:24:41.012: INFO: Pod "client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.95018ms
Dec 10 17:24:43.023: INFO: Pod "client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014569802s
STEP: Saw pod success
Dec 10 17:24:43.023: INFO: Pod "client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68" satisfied condition "Succeeded or Failed"
Dec 10 17:24:43.027: INFO: Trying to get logs from node ip-10-0-19-34 pod client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:24:43.049: INFO: Waiting for pod client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68 to disappear
Dec 10 17:24:43.051: INFO: Pod client-containers-4833732a-076a-4a9d-9e33-bb65d34d0d68 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:43.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3974" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":346,"completed":126,"skipped":2556,"failed":0}

------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:43.059: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap that has name configmap-test-emptyKey-7483be01-17ae-4ccf-ab38-bdf1ac3ddc04
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:43.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6801" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":346,"completed":127,"skipped":2556,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:43.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:24:43.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 create -f -'
Dec 10 17:24:43.311: INFO: stderr: ""
Dec 10 17:24:43.311: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Dec 10 17:24:43.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 create -f -'
Dec 10 17:24:43.509: INFO: stderr: ""
Dec 10 17:24:43.510: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Dec 10 17:24:44.514: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:24:44.514: INFO: Found 1 / 1
Dec 10 17:24:44.514: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 17:24:44.515: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:24:44.516: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 17:24:44.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 describe pod agnhost-primary-bd2gh'
Dec 10 17:24:44.584: INFO: stderr: ""
Dec 10 17:24:44.584: INFO: stdout: "Name:         agnhost-primary-bd2gh\nNamespace:    kubectl-9056\nPriority:     0\nNode:         ip-10-0-19-34/10.0.19.34\nStart Time:   Fri, 10 Dec 2021 17:24:43 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nStatus:       Running\nIP:           10.2.1.179\nIPs:\n  IP:           10.2.1.179\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://a0d1643aec289de1d560c383e9dc7ed0f0f673a77ada5015766ee826f64f5efc\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.33\n    Image ID:       docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 10 Dec 2021 17:24:44 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-p5k6v (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-p5k6v:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-9056/agnhost-primary-bd2gh to ip-10-0-19-34\n  Normal  Pulled     0s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.33\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
Dec 10 17:24:44.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 describe rc agnhost-primary'
Dec 10 17:24:44.654: INFO: stderr: ""
Dec 10 17:24:44.654: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9056\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.33\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-bd2gh\n"
Dec 10 17:24:44.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 describe service agnhost-primary'
Dec 10 17:24:44.734: INFO: stderr: ""
Dec 10 17:24:44.734: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9056\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.3.105.99\nIPs:               10.3.105.99\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.1.179:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 10 17:24:44.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 describe node ip-10-0-0-54'
Dec 10 17:24:44.828: INFO: stderr: ""
Dec 10 17:24:44.828: INFO: stdout: "Name:               ip-10-0-0-54\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-0-54\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/node=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"9e:22:83:cf:e4:11\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.54\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 10 Dec 2021 16:33:20 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-0-0-54\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 10 Dec 2021 17:24:43 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 10 Dec 2021 16:34:17 +0000   Fri, 10 Dec 2021 16:34:17 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Fri, 10 Dec 2021 17:21:46 +0000   Fri, 10 Dec 2021 16:33:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 10 Dec 2021 17:21:46 +0000   Fri, 10 Dec 2021 16:33:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 10 Dec 2021 17:21:46 +0000   Fri, 10 Dec 2021 16:33:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 10 Dec 2021 17:21:46 +0000   Fri, 10 Dec 2021 16:34:22 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.54\n  Hostname:    ip-10-0-0-54\nCapacity:\n  cpu:                1\n  ephemeral-storage:  30921708Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3946604Ki\n  pods:               110\nAllocatable:\n  cpu:                1\n  ephemeral-storage:  28497446046\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3844204Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ad432f2cb0c28bbcd1f87a20199237f9\n  System UUID:                ec298d94-b0ae-5412-349b-6c53bb684f38\n  Boot ID:                    1f731d70-af0a-4c6d-b7cb-1d3467db1f5e\n  Kernel Version:             5.14.18-300.fc35.x86_64\n  OS Image:                   Fedora CoreOS 35.20211119.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.9\n  Kubelet Version:            v1.23.0\n  Kube-Proxy Version:         v1.23.0\nPodCIDR:                      10.2.2.0/24\nPodCIDRs:                     10.2.2.0/24\nProviderID:                   aws:///us-east-2a/i-05d0962e429f64db0\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-77c7788bfd-wgnt8                                   100m (10%)    0 (0%)      70Mi (1%)        170Mi (4%)     41m\n  kube-system                 flannel-v6cj5                                              100m (10%)    0 (0%)      0 (0%)           0 (0%)         51m\n  kube-system                 kube-proxy-n8zvk                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         51m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                    sonobuoy-e2e-job-8d0bd5401ee442a1                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  svcaccounts-606             pod-service-account-nomountsa-mountspec                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         14s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                200m (20%)  0 (0%)\n  memory             70Mi (1%)   170Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason     Age   From        Message\n  ----    ------     ----  ----        -------\n  Normal  Starting   50m   kube-proxy  \n  Normal  NodeReady  50m   kubelet     Node ip-10-0-0-54 status is now: NodeReady\n"
Dec 10 17:24:44.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-9056 describe namespace kubectl-9056'
Dec 10 17:24:44.897: INFO: stderr: ""
Dec 10 17:24:44.897: INFO: stdout: "Name:         kubectl-9056\nLabels:       e2e-framework=kubectl\n              e2e-run=5f7134a9-18ea-4167-acc5-c968fb1956b7\n              kubernetes.io/metadata.name=kubectl-9056\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:44.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9056" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":346,"completed":128,"skipped":2567,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:44.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:24:44.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 10 17:24:48.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-1420 --namespace=crd-publish-openapi-1420 create -f -'
Dec 10 17:24:49.578: INFO: stderr: ""
Dec 10 17:24:49.578: INFO: stdout: "e2e-test-crd-publish-openapi-8827-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 10 17:24:49.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-1420 --namespace=crd-publish-openapi-1420 delete e2e-test-crd-publish-openapi-8827-crds test-cr'
Dec 10 17:24:49.639: INFO: stderr: ""
Dec 10 17:24:49.639: INFO: stdout: "e2e-test-crd-publish-openapi-8827-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 10 17:24:49.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-1420 --namespace=crd-publish-openapi-1420 apply -f -'
Dec 10 17:24:49.805: INFO: stderr: ""
Dec 10 17:24:49.805: INFO: stdout: "e2e-test-crd-publish-openapi-8827-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 10 17:24:49.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-1420 --namespace=crd-publish-openapi-1420 delete e2e-test-crd-publish-openapi-8827-crds test-cr'
Dec 10 17:24:49.869: INFO: stderr: ""
Dec 10 17:24:49.869: INFO: stdout: "e2e-test-crd-publish-openapi-8827-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 10 17:24:49.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-1420 explain e2e-test-crd-publish-openapi-8827-crds'
Dec 10 17:24:50.031: INFO: stderr: ""
Dec 10 17:24:50.031: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8827-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:24:52.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1420" for this suite.

• [SLOW TEST:7.413 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":346,"completed":129,"skipped":2569,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:24:52.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8045.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8045.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 136.22.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.22.136_udp@PTR;check="$$(dig +tcp +noall +answer +search 136.22.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.22.136_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8045.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8045.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8045.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8045.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8045.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 136.22.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.22.136_udp@PTR;check="$$(dig +tcp +noall +answer +search 136.22.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.22.136_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 17:24:56.401: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.405: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.408: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.421: INFO: Unable to read jessie_udp@dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.425: INFO: Unable to read jessie_tcp@dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.427: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.430: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local from pod dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49: the server could not find the requested resource (get pods dns-test-465a1008-be69-49ae-b762-7b626e366c49)
Dec 10 17:24:56.442: INFO: Lookups using dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49 failed for: [wheezy_tcp@dns-test-service.dns-8045.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local jessie_udp@dns-test-service.dns-8045.svc.cluster.local jessie_tcp@dns-test-service.dns-8045.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8045.svc.cluster.local]

Dec 10 17:25:01.543: INFO: DNS probes using dns-8045/dns-test-465a1008-be69-49ae-b762-7b626e366c49 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8045" for this suite.

• [SLOW TEST:9.611 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":346,"completed":130,"skipped":2614,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:01.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:25:02.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416" in namespace "downward-api-1067" to be "Succeeded or Failed"
Dec 10 17:25:02.397: INFO: Pod "downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416": Phase="Pending", Reason="", readiness=false. Elapsed: 12.137326ms
Dec 10 17:25:04.400: INFO: Pod "downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015906437s
STEP: Saw pod success
Dec 10 17:25:04.401: INFO: Pod "downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416" satisfied condition "Succeeded or Failed"
Dec 10 17:25:04.403: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416 container client-container: <nil>
STEP: delete the pod
Dec 10 17:25:04.418: INFO: Waiting for pod downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416 to disappear
Dec 10 17:25:04.420: INFO: Pod downwardapi-volume-edcc7c3f-c793-4900-9a96-b547962ff416 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:04.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1067" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":131,"skipped":2660,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:04.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-a410991c-aaeb-4a38-a749-d6683eda4e7a
STEP: Creating a pod to test consume secrets
Dec 10 17:25:04.524: INFO: Waiting up to 5m0s for pod "pod-secrets-9e5873ea-6d73-43cd-b128-152437589614" in namespace "secrets-611" to be "Succeeded or Failed"
Dec 10 17:25:04.528: INFO: Pod "pod-secrets-9e5873ea-6d73-43cd-b128-152437589614": Phase="Pending", Reason="", readiness=false. Elapsed: 3.176158ms
Dec 10 17:25:06.532: INFO: Pod "pod-secrets-9e5873ea-6d73-43cd-b128-152437589614": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007460576s
STEP: Saw pod success
Dec 10 17:25:06.532: INFO: Pod "pod-secrets-9e5873ea-6d73-43cd-b128-152437589614" satisfied condition "Succeeded or Failed"
Dec 10 17:25:06.534: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-9e5873ea-6d73-43cd-b128-152437589614 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:25:06.548: INFO: Waiting for pod pod-secrets-9e5873ea-6d73-43cd-b128-152437589614 to disappear
Dec 10 17:25:06.550: INFO: Pod pod-secrets-9e5873ea-6d73-43cd-b128-152437589614 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:06.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-611" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":132,"skipped":2686,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:06.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:34.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7436" for this suite.

• [SLOW TEST:28.217 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":346,"completed":133,"skipped":2694,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:34.780: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 10 17:25:44.954: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 17:25:45.099: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:45.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7072" for this suite.

• [SLOW TEST:10.329 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":346,"completed":134,"skipped":2703,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:45.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:25:45.170: INFO: Waiting up to 5m0s for pod "busybox-user-65534-84e0120a-183d-4904-83a8-e06f4ecbf1ef" in namespace "security-context-test-1053" to be "Succeeded or Failed"
Dec 10 17:25:45.173: INFO: Pod "busybox-user-65534-84e0120a-183d-4904-83a8-e06f4ecbf1ef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.173788ms
Dec 10 17:25:47.181: INFO: Pod "busybox-user-65534-84e0120a-183d-4904-83a8-e06f4ecbf1ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011016377s
Dec 10 17:25:49.190: INFO: Pod "busybox-user-65534-84e0120a-183d-4904-83a8-e06f4ecbf1ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019580336s
Dec 10 17:25:49.190: INFO: Pod "busybox-user-65534-84e0120a-183d-4904-83a8-e06f4ecbf1ef" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:25:49.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1053" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":135,"skipped":2747,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:25:49.200: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:25:49.253: INFO: created pod
Dec 10 17:25:49.254: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4661" to be "Succeeded or Failed"
Dec 10 17:25:49.259: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.141001ms
Dec 10 17:25:51.276: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022024117s
STEP: Saw pod success
Dec 10 17:25:51.277: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Dec 10 17:26:21.277: INFO: polling logs
Dec 10 17:26:21.285: INFO: Pod logs: 
2021/12/10 17:25:50 OK: Got token
2021/12/10 17:25:50 validating with in-cluster discovery
2021/12/10 17:25:50 OK: got issuer https://kubernetes.default.svc.cluster.local
2021/12/10 17:25:50 Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4661:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1639157749, NotBefore:1639157149, IssuedAt:1639157149, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4661", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59211894-7d5a-4dd7-9f96-28fe148e2f4a"}}}
2021/12/10 17:25:50 OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
2021/12/10 17:25:50 OK: Validated signature on JWT
2021/12/10 17:25:50 OK: Got valid claims from token!
2021/12/10 17:25:50 Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4661:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1639157749, NotBefore:1639157149, IssuedAt:1639157149, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4661", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59211894-7d5a-4dd7-9f96-28fe148e2f4a"}}}

Dec 10 17:26:21.285: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:26:21.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4661" for this suite.

• [SLOW TEST:32.126 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":346,"completed":136,"skipped":2761,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:26:21.330: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Dec 10 17:26:21.414: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 17:26:21.418: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 17:26:21.422: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-0-54 before test
Dec 10 17:26:21.427: INFO: coredns-77c7788bfd-wgnt8 from kube-system started at 2021-12-10 16:43:15 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.427: INFO: 	Container coredns ready: true, restart count 0
Dec 10 17:26:21.427: INFO: flannel-v6cj5 from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.428: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:26:21.428: INFO: kube-proxy-n8zvk from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.428: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:26:21.428: INFO: sonobuoy from sonobuoy started at 2021-12-10 16:39:55 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.428: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 17:26:21.430: INFO: sonobuoy-e2e-job-8d0bd5401ee442a1 from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:26:21.430: INFO: 	Container e2e ready: true, restart count 0
Dec 10 17:26:21.430: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:26:21.431: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:26:21.431: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:26:21.431: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 10 17:26:21.432: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-606 started at 2021-12-10 17:24:30 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.432: INFO: 	Container token-test ready: false, restart count 0
Dec 10 17:26:21.432: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-19-34 before test
Dec 10 17:26:21.438: INFO: flannel-rjcp9 from kube-system started at 2021-12-10 16:43:16 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.439: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:26:21.439: INFO: kube-proxy-p6vhv from kube-system started at 2021-12-10 16:43:17 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.439: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:26:21.439: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-x75pd from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:26:21.440: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:26:21.440: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 10 17:26:21.440: INFO: oidc-discovery-validator from svcaccounts-4661 started at 2021-12-10 17:25:49 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.441: INFO: 	Container oidc-discovery-validator ready: false, restart count 0
Dec 10 17:26:21.441: INFO: pod-service-account-defaultsa from svcaccounts-606 started at 2021-12-10 17:24:30 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.441: INFO: 	Container token-test ready: false, restart count 0
Dec 10 17:26:21.441: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-606 started at 2021-12-10 17:24:30 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.441: INFO: 	Container token-test ready: false, restart count 0
Dec 10 17:26:21.442: INFO: pod-service-account-mountsa from svcaccounts-606 started at 2021-12-10 17:24:30 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.442: INFO: 	Container token-test ready: false, restart count 0
Dec 10 17:26:21.442: INFO: pod-service-account-mountsa-mountspec from svcaccounts-606 started at 2021-12-10 17:24:30 +0000 UTC (1 container statuses recorded)
Dec 10 17:26:21.442: INFO: 	Container token-test ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-19bd4e3d-b932-4343-bd98-6ab6979c4f51 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-19bd4e3d-b932-4343-bd98-6ab6979c4f51 off the node ip-10-0-19-34
STEP: verifying the node doesn't have the label kubernetes.io/e2e-19bd4e3d-b932-4343-bd98-6ab6979c4f51
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:26:25.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8256" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":346,"completed":137,"skipped":2769,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:26:25.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:26:25.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:26:26.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8425" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":346,"completed":138,"skipped":2781,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:26:26.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 10 17:26:26.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 10 17:26:38.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:26:40.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:26:51.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2167" for this suite.

• [SLOW TEST:24.681 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":346,"completed":139,"skipped":2799,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:26:51.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:26:51.342: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d" in namespace "security-context-test-1798" to be "Succeeded or Failed"
Dec 10 17:26:51.345: INFO: Pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.62787ms
Dec 10 17:26:53.358: INFO: Pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015088819s
Dec 10 17:26:55.363: INFO: Pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020431347s
Dec 10 17:26:55.363: INFO: Pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d" satisfied condition "Succeeded or Failed"
Dec 10 17:26:55.369: INFO: Got logs for pod "busybox-privileged-false-6059da56-155d-47f6-b0e8-768ebb15e54d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:26:55.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1798" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":140,"skipped":2819,"failed":0}
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:26:55.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:27:19.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2234" for this suite.

• [SLOW TEST:24.275 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    when starting a container that exits
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":346,"completed":141,"skipped":2820,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:27:19.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:27:20.108: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 10 17:27:22.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 17, 27, 20, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 27, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 27, 20, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 27, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78948c58f6\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:27:25.150: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:27:35.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5208" for this suite.
STEP: Destroying namespace "webhook-5208-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.911 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":346,"completed":142,"skipped":2821,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:27:35.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Dec 10 17:27:35.703: INFO: Waiting up to 5m0s for pod "downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0" in namespace "downward-api-5919" to be "Succeeded or Failed"
Dec 10 17:27:35.735: INFO: Pod "downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0": Phase="Pending", Reason="", readiness=false. Elapsed: 32.239946ms
Dec 10 17:27:37.754: INFO: Pod "downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050994432s
STEP: Saw pod success
Dec 10 17:27:37.754: INFO: Pod "downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0" satisfied condition "Succeeded or Failed"
Dec 10 17:27:37.758: INFO: Trying to get logs from node ip-10-0-19-34 pod downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:27:37.782: INFO: Waiting for pod downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0 to disappear
Dec 10 17:27:37.787: INFO: Pod downward-api-d9230982-b9af-4d03-9b5d-9effa91eb7a0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:27:37.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5919" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":346,"completed":143,"skipped":2850,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:27:37.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:27:37.897: INFO: The status of Pod busybox-scheduling-3b3654d5-2652-49c3-91c2-13ccb6d21863 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:27:39.905: INFO: The status of Pod busybox-scheduling-3b3654d5-2652-49c3-91c2-13ccb6d21863 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:27:39.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8334" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":346,"completed":144,"skipped":2863,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:27:39.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-732
Dec 10 17:27:40.007: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:27:42.014: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 10 17:27:42.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 10 17:27:42.252: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 10 17:27:42.252: INFO: stdout: "ipvs"
Dec 10 17:27:42.252: INFO: proxyMode: ipvs
Dec 10 17:27:42.260: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 10 17:27:42.262: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-732
STEP: creating replication controller affinity-nodeport-timeout in namespace services-732
I1210 17:27:42.283381      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-732, replica count: 3
I1210 17:27:45.335433      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:27:45.346: INFO: Creating new exec pod
Dec 10 17:27:48.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Dec 10 17:27:48.563: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-timeout 80\n+ echo hostName\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Dec 10 17:27:48.563: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:27:48.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.27.228 80'
Dec 10 17:27:48.897: INFO: stderr: "+ nc -v -t -w 2 10.3.27.228 80\nConnection to 10.3.27.228 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:27:48.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:27:48.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.54 30272'
Dec 10 17:27:49.082: INFO: stderr: "+ nc -v -t -w 2 10.0.0.54 30272\n+ echo hostName\nConnection to 10.0.0.54 30272 port [tcp/*] succeeded!\n"
Dec 10 17:27:49.082: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:27:49.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30272'
Dec 10 17:27:49.235: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30272\nConnection to 10.0.19.34 30272 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 17:27:49.235: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:27:49.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.54:30272/ ; done'
Dec 10 17:27:49.562: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n"
Dec 10 17:27:49.562: INFO: stdout: "\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f\naffinity-nodeport-timeout-9ps6f"
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Received response from host: affinity-nodeport-timeout-9ps6f
Dec 10 17:27:49.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.0.54:30272/'
Dec 10 17:27:49.728: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n"
Dec 10 17:27:49.728: INFO: stdout: "affinity-nodeport-timeout-9ps6f"
Dec 10 17:29:59.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-732 exec execpod-affinity5g9gd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.0.54:30272/'
Dec 10 17:29:59.924: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.0.54:30272/\n"
Dec 10 17:29:59.924: INFO: stdout: "affinity-nodeport-timeout-trtvr"
Dec 10 17:29:59.924: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-732, will wait for the garbage collector to delete the pods
Dec 10 17:30:00.025: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 23.386503ms
Dec 10 17:30:00.129: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 103.86872ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:30:02.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-732" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:143.119 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":145,"skipped":2876,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:30:03.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 17:30:05.278: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:30:05.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3766" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":146,"skipped":2923,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:30:05.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 10 17:30:45.449: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 17:30:45.602: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 10 17:30:45.608: INFO: Deleting pod "simpletest.rc-26nft" in namespace "gc-4799"
Dec 10 17:30:45.618: INFO: Deleting pod "simpletest.rc-27c4g" in namespace "gc-4799"
Dec 10 17:30:45.633: INFO: Deleting pod "simpletest.rc-2km44" in namespace "gc-4799"
Dec 10 17:30:45.677: INFO: Deleting pod "simpletest.rc-2s7n7" in namespace "gc-4799"
Dec 10 17:30:45.687: INFO: Deleting pod "simpletest.rc-49l6j" in namespace "gc-4799"
Dec 10 17:30:45.701: INFO: Deleting pod "simpletest.rc-4xb6d" in namespace "gc-4799"
Dec 10 17:30:45.716: INFO: Deleting pod "simpletest.rc-5f2vr" in namespace "gc-4799"
Dec 10 17:30:45.728: INFO: Deleting pod "simpletest.rc-5p6r7" in namespace "gc-4799"
Dec 10 17:30:45.746: INFO: Deleting pod "simpletest.rc-5r5xx" in namespace "gc-4799"
Dec 10 17:30:45.773: INFO: Deleting pod "simpletest.rc-5rtkk" in namespace "gc-4799"
Dec 10 17:30:45.781: INFO: Deleting pod "simpletest.rc-5zt7w" in namespace "gc-4799"
Dec 10 17:30:45.792: INFO: Deleting pod "simpletest.rc-627h8" in namespace "gc-4799"
Dec 10 17:30:45.801: INFO: Deleting pod "simpletest.rc-6j459" in namespace "gc-4799"
Dec 10 17:30:45.810: INFO: Deleting pod "simpletest.rc-6lf74" in namespace "gc-4799"
Dec 10 17:30:45.823: INFO: Deleting pod "simpletest.rc-6s6fj" in namespace "gc-4799"
Dec 10 17:30:45.830: INFO: Deleting pod "simpletest.rc-6z6lf" in namespace "gc-4799"
Dec 10 17:30:45.849: INFO: Deleting pod "simpletest.rc-798fx" in namespace "gc-4799"
Dec 10 17:30:45.858: INFO: Deleting pod "simpletest.rc-7nlnz" in namespace "gc-4799"
Dec 10 17:30:45.867: INFO: Deleting pod "simpletest.rc-82l6w" in namespace "gc-4799"
Dec 10 17:30:45.878: INFO: Deleting pod "simpletest.rc-8nxsk" in namespace "gc-4799"
Dec 10 17:30:45.888: INFO: Deleting pod "simpletest.rc-9d6w2" in namespace "gc-4799"
Dec 10 17:30:45.901: INFO: Deleting pod "simpletest.rc-9ld4j" in namespace "gc-4799"
Dec 10 17:30:45.908: INFO: Deleting pod "simpletest.rc-9njgl" in namespace "gc-4799"
Dec 10 17:30:45.918: INFO: Deleting pod "simpletest.rc-9zvb2" in namespace "gc-4799"
Dec 10 17:30:45.927: INFO: Deleting pod "simpletest.rc-bvzgp" in namespace "gc-4799"
Dec 10 17:30:45.956: INFO: Deleting pod "simpletest.rc-cc2mw" in namespace "gc-4799"
Dec 10 17:30:45.970: INFO: Deleting pod "simpletest.rc-db8g6" in namespace "gc-4799"
Dec 10 17:30:45.978: INFO: Deleting pod "simpletest.rc-dl5h2" in namespace "gc-4799"
Dec 10 17:30:45.988: INFO: Deleting pod "simpletest.rc-f299x" in namespace "gc-4799"
Dec 10 17:30:46.003: INFO: Deleting pod "simpletest.rc-fgx97" in namespace "gc-4799"
Dec 10 17:30:46.014: INFO: Deleting pod "simpletest.rc-fjq9p" in namespace "gc-4799"
Dec 10 17:30:46.023: INFO: Deleting pod "simpletest.rc-fq2mv" in namespace "gc-4799"
Dec 10 17:30:46.030: INFO: Deleting pod "simpletest.rc-fw662" in namespace "gc-4799"
Dec 10 17:30:46.046: INFO: Deleting pod "simpletest.rc-fwzvg" in namespace "gc-4799"
Dec 10 17:30:46.054: INFO: Deleting pod "simpletest.rc-fxdlf" in namespace "gc-4799"
Dec 10 17:30:46.073: INFO: Deleting pod "simpletest.rc-g2zqj" in namespace "gc-4799"
Dec 10 17:30:46.097: INFO: Deleting pod "simpletest.rc-gfsr7" in namespace "gc-4799"
Dec 10 17:30:46.120: INFO: Deleting pod "simpletest.rc-gm7sw" in namespace "gc-4799"
Dec 10 17:30:46.130: INFO: Deleting pod "simpletest.rc-gr76n" in namespace "gc-4799"
Dec 10 17:30:46.141: INFO: Deleting pod "simpletest.rc-gwq57" in namespace "gc-4799"
Dec 10 17:30:46.151: INFO: Deleting pod "simpletest.rc-h65vc" in namespace "gc-4799"
Dec 10 17:30:46.179: INFO: Deleting pod "simpletest.rc-hcg2g" in namespace "gc-4799"
Dec 10 17:30:46.190: INFO: Deleting pod "simpletest.rc-hvzcl" in namespace "gc-4799"
Dec 10 17:30:46.203: INFO: Deleting pod "simpletest.rc-hxjsm" in namespace "gc-4799"
Dec 10 17:30:46.215: INFO: Deleting pod "simpletest.rc-j956r" in namespace "gc-4799"
Dec 10 17:30:46.224: INFO: Deleting pod "simpletest.rc-jdrzv" in namespace "gc-4799"
Dec 10 17:30:46.232: INFO: Deleting pod "simpletest.rc-jr4pr" in namespace "gc-4799"
Dec 10 17:30:46.243: INFO: Deleting pod "simpletest.rc-kvg5f" in namespace "gc-4799"
Dec 10 17:30:46.252: INFO: Deleting pod "simpletest.rc-lr2qm" in namespace "gc-4799"
Dec 10 17:30:46.285: INFO: Deleting pod "simpletest.rc-m2q9w" in namespace "gc-4799"
Dec 10 17:30:46.313: INFO: Deleting pod "simpletest.rc-mb5xg" in namespace "gc-4799"
Dec 10 17:30:46.330: INFO: Deleting pod "simpletest.rc-mqq25" in namespace "gc-4799"
Dec 10 17:30:46.338: INFO: Deleting pod "simpletest.rc-mw687" in namespace "gc-4799"
Dec 10 17:30:46.352: INFO: Deleting pod "simpletest.rc-mxvrv" in namespace "gc-4799"
Dec 10 17:30:46.360: INFO: Deleting pod "simpletest.rc-n2vk8" in namespace "gc-4799"
Dec 10 17:30:46.369: INFO: Deleting pod "simpletest.rc-n6db5" in namespace "gc-4799"
Dec 10 17:30:46.378: INFO: Deleting pod "simpletest.rc-n7fs9" in namespace "gc-4799"
Dec 10 17:30:46.388: INFO: Deleting pod "simpletest.rc-nlh6j" in namespace "gc-4799"
Dec 10 17:30:46.398: INFO: Deleting pod "simpletest.rc-npgbc" in namespace "gc-4799"
Dec 10 17:30:46.455: INFO: Deleting pod "simpletest.rc-nttvq" in namespace "gc-4799"
Dec 10 17:30:46.493: INFO: Deleting pod "simpletest.rc-nw628" in namespace "gc-4799"
Dec 10 17:30:46.506: INFO: Deleting pod "simpletest.rc-nwhbj" in namespace "gc-4799"
Dec 10 17:30:46.512: INFO: Deleting pod "simpletest.rc-pf7gc" in namespace "gc-4799"
Dec 10 17:30:46.519: INFO: Deleting pod "simpletest.rc-pfcpq" in namespace "gc-4799"
Dec 10 17:30:46.526: INFO: Deleting pod "simpletest.rc-ph6gm" in namespace "gc-4799"
Dec 10 17:30:46.535: INFO: Deleting pod "simpletest.rc-phnnk" in namespace "gc-4799"
Dec 10 17:30:46.582: INFO: Deleting pod "simpletest.rc-prb54" in namespace "gc-4799"
Dec 10 17:30:46.589: INFO: Deleting pod "simpletest.rc-pt86w" in namespace "gc-4799"
Dec 10 17:30:46.596: INFO: Deleting pod "simpletest.rc-pwlj6" in namespace "gc-4799"
Dec 10 17:30:46.602: INFO: Deleting pod "simpletest.rc-q2znz" in namespace "gc-4799"
Dec 10 17:30:46.616: INFO: Deleting pod "simpletest.rc-qqpdw" in namespace "gc-4799"
Dec 10 17:30:46.666: INFO: Deleting pod "simpletest.rc-qw245" in namespace "gc-4799"
Dec 10 17:30:46.739: INFO: Deleting pod "simpletest.rc-r4s4m" in namespace "gc-4799"
Dec 10 17:30:46.768: INFO: Deleting pod "simpletest.rc-r5hgn" in namespace "gc-4799"
Dec 10 17:30:46.835: INFO: Deleting pod "simpletest.rc-r6cf4" in namespace "gc-4799"
Dec 10 17:30:46.867: INFO: Deleting pod "simpletest.rc-rbp8n" in namespace "gc-4799"
Dec 10 17:30:46.925: INFO: Deleting pod "simpletest.rc-rgrjh" in namespace "gc-4799"
Dec 10 17:30:46.987: INFO: Deleting pod "simpletest.rc-rhv4d" in namespace "gc-4799"
Dec 10 17:30:47.018: INFO: Deleting pod "simpletest.rc-rj47g" in namespace "gc-4799"
Dec 10 17:30:47.075: INFO: Deleting pod "simpletest.rc-rvcdn" in namespace "gc-4799"
Dec 10 17:30:47.116: INFO: Deleting pod "simpletest.rc-sdb8p" in namespace "gc-4799"
Dec 10 17:30:47.167: INFO: Deleting pod "simpletest.rc-sql6w" in namespace "gc-4799"
Dec 10 17:30:47.218: INFO: Deleting pod "simpletest.rc-t5vv2" in namespace "gc-4799"
Dec 10 17:30:47.266: INFO: Deleting pod "simpletest.rc-t7jhh" in namespace "gc-4799"
Dec 10 17:30:47.317: INFO: Deleting pod "simpletest.rc-tcqqc" in namespace "gc-4799"
Dec 10 17:30:47.366: INFO: Deleting pod "simpletest.rc-tfjlg" in namespace "gc-4799"
Dec 10 17:30:47.416: INFO: Deleting pod "simpletest.rc-trxpj" in namespace "gc-4799"
Dec 10 17:30:47.470: INFO: Deleting pod "simpletest.rc-v4lh2" in namespace "gc-4799"
Dec 10 17:30:47.516: INFO: Deleting pod "simpletest.rc-v79vb" in namespace "gc-4799"
Dec 10 17:30:47.566: INFO: Deleting pod "simpletest.rc-vbs9c" in namespace "gc-4799"
Dec 10 17:30:47.617: INFO: Deleting pod "simpletest.rc-vh5kh" in namespace "gc-4799"
Dec 10 17:30:47.665: INFO: Deleting pod "simpletest.rc-vh5np" in namespace "gc-4799"
Dec 10 17:30:47.719: INFO: Deleting pod "simpletest.rc-vpdbg" in namespace "gc-4799"
Dec 10 17:30:47.771: INFO: Deleting pod "simpletest.rc-wgcm9" in namespace "gc-4799"
Dec 10 17:30:47.819: INFO: Deleting pod "simpletest.rc-wl8rg" in namespace "gc-4799"
Dec 10 17:30:47.866: INFO: Deleting pod "simpletest.rc-ww4p9" in namespace "gc-4799"
Dec 10 17:30:47.916: INFO: Deleting pod "simpletest.rc-wz5st" in namespace "gc-4799"
Dec 10 17:30:47.966: INFO: Deleting pod "simpletest.rc-xvg4b" in namespace "gc-4799"
Dec 10 17:30:48.019: INFO: Deleting pod "simpletest.rc-z7jkx" in namespace "gc-4799"
Dec 10 17:30:48.069: INFO: Deleting pod "simpletest.rc-zxlxr" in namespace "gc-4799"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:30:48.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4799" for this suite.

• [SLOW TEST:42.914 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":346,"completed":147,"skipped":2938,"failed":0}
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:30:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:30:48.267: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 10 17:30:53.273: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 17:31:09.282: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:31:09.309: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5813  7c7c91bd-a4f4-499b-9ebb-cb5b7780c067 15914 1 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005447b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 10 17:31:09.320: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 10 17:31:09.320: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 10 17:31:09.321: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5813  0b1582f8-d571-4694-af00-ad00895794d9 15915 1 2021-12-10 17:30:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 7c7c91bd-a4f4-499b-9ebb-cb5b7780c067 0xc005447e77 0xc005447e78}] []  [{e2e.test Update apps/v1 2021-12-10 17:30:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:31:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"7c7c91bd-a4f4-499b-9ebb-cb5b7780c067\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005447f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:31:09.325: INFO: Pod "test-cleanup-controller-7w2sf" is available:
&Pod{ObjectMeta:{test-cleanup-controller-7w2sf test-cleanup-controller- deployment-5813  4e980b23-423f-4417-a7d4-9fd7781ab6b0 15909 0 2021-12-10 17:30:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 0b1582f8-d571-4694-af00-ad00895794d9 0xc00549a247 0xc00549a248}] []  [{kube-controller-manager Update v1 2021-12-10 17:30:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0b1582f8-d571-4694-af00-ad00895794d9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.249\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqrbh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqrbh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:30:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:30:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:30:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.249,StartTime:2021-12-10 17:30:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:30:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://16dd8b75f0a6c2b4d19718c6e9fcceb1882cf23d2cd618af5ca33ddb323b05c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:31:09.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5813" for this suite.

• [SLOW TEST:21.192 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":346,"completed":148,"skipped":2938,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:31:09.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 10 17:31:09.573: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15931 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:09.574: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15931 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 10 17:31:09.579: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15932 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:09.580: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15932 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 10 17:31:09.587: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15933 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:09.587: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15933 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 10 17:31:09.592: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15934 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:09.593: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2571  a25dbb50-5912-4b67-9373-8f3ff4ac2149 15934 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 10 17:31:09.602: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2571  f5ce28f9-d009-44f8-8e0d-1392d314be82 15935 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:09.603: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2571  f5ce28f9-d009-44f8-8e0d-1392d314be82 15935 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 10 17:31:19.618: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2571  f5ce28f9-d009-44f8-8e0d-1392d314be82 15969 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:31:19.619: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2571  f5ce28f9-d009-44f8-8e0d-1392d314be82 15969 0 2021-12-10 17:31:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-12-10 17:31:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:31:29.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2571" for this suite.

• [SLOW TEST:20.219 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":346,"completed":149,"skipped":2939,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:31:29.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:31:29.697: INFO: Creating deployment "webserver-deployment"
Dec 10 17:31:29.704: INFO: Waiting for observed generation 1
Dec 10 17:31:31.723: INFO: Waiting for all required pods to come up
Dec 10 17:31:31.734: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 10 17:31:35.769: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 10 17:31:35.773: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 10 17:31:35.778: INFO: Updating deployment webserver-deployment
Dec 10 17:31:35.778: INFO: Waiting for observed generation 2
Dec 10 17:31:37.788: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 10 17:31:37.792: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 10 17:31:37.795: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 10 17:31:37.801: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 10 17:31:37.802: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 10 17:31:37.804: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 10 17:31:37.807: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 10 17:31:37.807: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 10 17:31:37.813: INFO: Updating deployment webserver-deployment
Dec 10 17:31:37.813: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 10 17:31:37.821: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 10 17:31:37.841: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:31:37.916: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6290  b2bf57af-ec78-4d63-a146-d95996732e26 16190 3 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00370caa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-566f96c878" is progressing.,LastUpdateTime:2021-12-10 17:31:36 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2021-12-10 17:31:37 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 10 17:31:37.984: INFO: New ReplicaSet "webserver-deployment-566f96c878" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-566f96c878  deployment-6290  471de14d-af71-4692-97ed-44fe14c39825 16183 3 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment b2bf57af-ec78-4d63-a146-d95996732e26 0xc00370cec7 0xc00370cec8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2bf57af-ec78-4d63-a146-d95996732e26\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 566f96c878,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00370cf68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:31:37.984: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 10 17:31:37.984: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-5d9fdcc779  deployment-6290  3be335db-c738-4d42-9fa1-1bbeb3723393 16182 3 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment b2bf57af-ec78-4d63-a146-d95996732e26 0xc00370cfc7 0xc00370cfc8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2bf57af-ec78-4d63-a146-d95996732e26\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00370d058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:31:38.045: INFO: Pod "webserver-deployment-566f96c878-25j48" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-25j48 webserver-deployment-566f96c878- deployment-6290  ff0b68de-ed86-486f-9198-46d3436a23a7 16169 0 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00370d537 0xc00370d538}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qjf5k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qjf5k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:,StartTime:2021-12-10 17:31:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.046: INFO: Pod "webserver-deployment-566f96c878-2gqf9" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-2gqf9 webserver-deployment-566f96c878- deployment-6290  bde3991f-b654-4fb3-8ced-6d9b5674c656 16211 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00370d950 0xc00370d951}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6bdd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6bdd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.047: INFO: Pod "webserver-deployment-566f96c878-6m78c" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-6m78c webserver-deployment-566f96c878- deployment-6290  8aee5216-b40b-4aae-93b0-ca6fbefe4b2d 16168 0 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00444c7b7 0xc00444c7b8}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7bd5l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7bd5l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:,StartTime:2021-12-10 17:31:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.048: INFO: Pod "webserver-deployment-566f96c878-7w86q" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-7w86q webserver-deployment-566f96c878- deployment-6290  104cb4ad-d8a2-4d66-8c54-73d73cc8cd2b 16212 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00444d020 0xc00444d021}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6pglj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6pglj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.049: INFO: Pod "webserver-deployment-566f96c878-85zlt" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-85zlt webserver-deployment-566f96c878- deployment-6290  34014382-08d8-4356-9c7b-4c99a58e77e0 16225 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00444d4e7 0xc00444d4e8}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4t6m4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4t6m4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.060: INFO: Pod "webserver-deployment-566f96c878-9gmp2" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-9gmp2 webserver-deployment-566f96c878- deployment-6290  b61a39c8-07ca-4ca8-85cf-1f78d8b74ead 16143 0 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00444da67 0xc00444da68}] []  [{Go-http-client Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2sql,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2sql,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:,StartTime:2021-12-10 17:31:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.060: INFO: Pod "webserver-deployment-566f96c878-ckszw" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-ckszw webserver-deployment-566f96c878- deployment-6290  70b82b24-449e-4e00-8668-d551cb7d08ce 16152 0 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c080 0xc00420c081}] []  [{Go-http-client Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-st92g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-st92g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:,StartTime:2021-12-10 17:31:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.060: INFO: Pod "webserver-deployment-566f96c878-dqb6c" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-dqb6c webserver-deployment-566f96c878- deployment-6290  5e426159-974d-4bf5-9535-9c450199dea4 16209 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c280 0xc00420c281}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vdpvn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vdpvn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.060: INFO: Pod "webserver-deployment-566f96c878-krjl5" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-krjl5 webserver-deployment-566f96c878- deployment-6290  bc0cdde1-495e-4073-9478-a07662ee0c0f 16147 0 2021-12-10 17:31:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c3d7 0xc00420c3d8}] []  [{Go-http-client Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ws9t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ws9t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:,StartTime:2021-12-10 17:31:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.065: INFO: Pod "webserver-deployment-566f96c878-l8gq2" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-l8gq2 webserver-deployment-566f96c878- deployment-6290  79541b05-50b1-479c-8a2b-42581aca41a6 16221 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c5d0 0xc00420c5d1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8n76h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8n76h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.070: INFO: Pod "webserver-deployment-566f96c878-lfztv" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-lfztv webserver-deployment-566f96c878- deployment-6290  6f8d814c-3145-4fc3-b6f2-4a144d6f7fb8 16202 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c740 0xc00420c741}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bmmgr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bmmgr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.074: INFO: Pod "webserver-deployment-566f96c878-w8ln9" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-w8ln9 webserver-deployment-566f96c878- deployment-6290  a0e48fdd-3151-4e1e-8613-ad1b212a0fe1 16208 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c8b0 0xc00420c8b1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gqp76,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gqp76,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.074: INFO: Pod "webserver-deployment-566f96c878-xrrt4" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-xrrt4 webserver-deployment-566f96c878- deployment-6290  80e2215b-b372-4d1a-b455-95d89ab6c045 16218 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 471de14d-af71-4692-97ed-44fe14c39825 0xc00420c9f7 0xc00420c9f8}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471de14d-af71-4692-97ed-44fe14c39825\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-85zkj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-85zkj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.075: INFO: Pod "webserver-deployment-5d9fdcc779-22dbx" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-22dbx webserver-deployment-5d9fdcc779- deployment-6290  bbbb2f23-c6cd-4eb9-8a03-bca34d29bc72 16206 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420cb80 0xc00420cb81}] []  [{Go-http-client Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pw5p2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pw5p2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:,StartTime:2021-12-10 17:31:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.077: INFO: Pod "webserver-deployment-5d9fdcc779-4rhl2" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4rhl2 webserver-deployment-5d9fdcc779- deployment-6290  cc43e8bf-0424-49fc-84cd-f5562987446c 16226 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420cd40 0xc00420cd41}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lmf4w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lmf4w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.077: INFO: Pod "webserver-deployment-5d9fdcc779-4v5wt" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4v5wt webserver-deployment-5d9fdcc779- deployment-6290  3334f8db-14af-4048-b8dd-fbecf16f6a72 16210 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420ceb0 0xc00420ceb1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cb6vp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cb6vp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.077: INFO: Pod "webserver-deployment-5d9fdcc779-787xz" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-787xz webserver-deployment-5d9fdcc779- deployment-6290  320786cb-d7d5-43f1-bff9-d91069846dfd 16203 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d007 0xc00420d008}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q2t52,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q2t52,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.079: INFO: Pod "webserver-deployment-5d9fdcc779-8jmgw" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-8jmgw webserver-deployment-5d9fdcc779- deployment-6290  0d018a6f-7693-4871-9ce5-f2d4fbea3b6c 16217 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d170 0xc00420d171}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l9ck9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l9ck9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.080: INFO: Pod "webserver-deployment-5d9fdcc779-8k6qk" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-8k6qk webserver-deployment-5d9fdcc779- deployment-6290  4e96e869-4cbb-4575-9e92-53670eaa1d4e 16220 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d2d0 0xc00420d2d1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjvdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjvdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.080: INFO: Pod "webserver-deployment-5d9fdcc779-bq78v" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-bq78v webserver-deployment-5d9fdcc779- deployment-6290  14c51cad-4b42-45cc-b3e9-78c7c7e55828 16215 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d430 0xc00420d431}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j45z5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j45z5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.081: INFO: Pod "webserver-deployment-5d9fdcc779-bxgps" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-bxgps webserver-deployment-5d9fdcc779- deployment-6290  14827dcc-0706-4af2-bd13-ff5cc55d97ec 16227 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d567 0xc00420d568}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7jxdf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7jxdf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:,StartTime:2021-12-10 17:31:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.092: INFO: Pod "webserver-deployment-5d9fdcc779-cr8jq" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-cr8jq webserver-deployment-5d9fdcc779- deployment-6290  b19e61b6-bf99-47ae-bd70-95c1395c8b4c 16094 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d730 0xc00420d731}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.250\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ft6gv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ft6gv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.250,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://a0fa5ec2fe4abba4e7f50b298e166a79b93bddb31d5587493525e894e77923f3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.250,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.093: INFO: Pod "webserver-deployment-5d9fdcc779-cw5lk" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-cw5lk webserver-deployment-5d9fdcc779- deployment-6290  72a0c77e-8f0d-40ec-a26b-9a79f235b89d 16104 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420d920 0xc00420d921}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5jwkg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5jwkg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:10.2.2.145,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://4bdc725a5cb888d13557dbff4073ac19523fd3beab88445eb94cdb7e071bbdc9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.093: INFO: Pod "webserver-deployment-5d9fdcc779-d5m8r" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-d5m8r webserver-deployment-5d9fdcc779- deployment-6290  40950c13-7140-4255-9ae4-6dd3e6a030d8 16102 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420db10 0xc00420db11}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5rw88,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5rw88,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:10.2.2.144,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://2e944b29dc6f8888b7c03227eb1ee60dd899c1637076e76ec39671b941add2b3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.099: INFO: Pod "webserver-deployment-5d9fdcc779-d7gsx" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-d7gsx webserver-deployment-5d9fdcc779- deployment-6290  f2f1ad03-0afc-44a4-8141-9b4cd4672903 16087 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420dd00 0xc00420dd01}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.254\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q2hc9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q2hc9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.254,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://3482da5a94116c41f4600bc8107c309dc25241ed4365f5c7e8c3d0f22c2af341,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.254,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.100: INFO: Pod "webserver-deployment-5d9fdcc779-j627x" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-j627x webserver-deployment-5d9fdcc779- deployment-6290  68c676b5-34f9-4f4e-9f1b-8a0b63a16430 16229 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00420def0 0xc00420def1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgbq5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgbq5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.105: INFO: Pod "webserver-deployment-5d9fdcc779-pptc2" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-pptc2 webserver-deployment-5d9fdcc779- deployment-6290  343d1849-ac79-4374-bcf4-35ca7b372345 16228 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e060 0xc00521e061}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-64kqh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-64kqh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.106: INFO: Pod "webserver-deployment-5d9fdcc779-prgks" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-prgks webserver-deployment-5d9fdcc779- deployment-6290  075e5b51-2abb-42a2-8b0f-f0a92847f3d0 16085 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e1c0 0xc00521e1c1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.252\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k9qxc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k9qxc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.252,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://06ad5fb3d0d189d3cde5f8e9c220e1c610e9a140f0ab2fb8328d230ce519094d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.252,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.107: INFO: Pod "webserver-deployment-5d9fdcc779-ptjqh" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-ptjqh webserver-deployment-5d9fdcc779- deployment-6290  614150ea-8a2e-423b-b3d2-6256fcb538ac 16099 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e3b0 0xc00521e3b1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.146\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9m7ql,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9m7ql,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-0-54,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.54,PodIP:10.2.2.146,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://9411436a1b0286088378e04b8e969a5f06c59d8afaa83caa09c1f63292f79f5d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.2.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.107: INFO: Pod "webserver-deployment-5d9fdcc779-qf5k4" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-qf5k4 webserver-deployment-5d9fdcc779- deployment-6290  781199b6-fa58-498b-bf4d-15c370ed97c1 16090 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e5b0 0xc00521e5b1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.251\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pqvvz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pqvvz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.251,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://cb9022064806754c2b7725d70bc15951bff3ecf7072fb94355d1bc7af5e9e0d6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.251,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.107: INFO: Pod "webserver-deployment-5d9fdcc779-trcqf" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-trcqf webserver-deployment-5d9fdcc779- deployment-6290  a10704b2-9af2-491b-928f-fbe36258ebc0 16219 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e7b0 0xc00521e7b1}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m7np2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m7np2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.124: INFO: Pod "webserver-deployment-5d9fdcc779-vpmwx" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-vpmwx webserver-deployment-5d9fdcc779- deployment-6290  005a4591-5602-4464-9526-d2313d8f4aea 16222 0 2021-12-10 17:31:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521e920 0xc00521e921}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lw2mz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lw2mz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:31:38.124: INFO: Pod "webserver-deployment-5d9fdcc779-wt7cr" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-wt7cr webserver-deployment-5d9fdcc779- deployment-6290  38519034-79cb-421f-bacc-1cc67d042e6d 16114 0 2021-12-10 17:31:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 3be335db-c738-4d42-9fa1-1bbeb3723393 0xc00521ea90 0xc00521ea91}] []  [{kube-controller-manager Update v1 2021-12-10 17:31:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3be335db-c738-4d42-9fa1-1bbeb3723393\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:31:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7xsz7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7xsz7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:31:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.253,StartTime:2021-12-10 17:31:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:31:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://25452452ef5d992bfb43139299f8c242911fa33927ed87741420b29f04395fea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.253,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:31:38.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6290" for this suite.

• [SLOW TEST:8.551 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":346,"completed":150,"skipped":2972,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:31:38.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1542 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1542;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1542 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1542;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1542.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1542.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1542.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1542.svc;check="$$(dig +notcp +noall +answer +search 102.234.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.234.102_udp@PTR;check="$$(dig +tcp +noall +answer +search 102.234.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.234.102_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1542 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1542;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1542 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1542;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1542.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1542.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1542.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1542.svc;check="$$(dig +notcp +noall +answer +search 102.234.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.234.102_udp@PTR;check="$$(dig +tcp +noall +answer +search 102.234.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.234.102_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 17:31:48.348: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.352: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.355: INFO: Unable to read wheezy_udp@dns-test-service.dns-1542 from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.358: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1542 from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.361: INFO: Unable to read wheezy_udp@dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.365: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.369: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.372: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.398: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.403: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.408: INFO: Unable to read jessie_udp@dns-test-service.dns-1542 from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.411: INFO: Unable to read jessie_tcp@dns-test-service.dns-1542 from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.415: INFO: Unable to read jessie_udp@dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.420: INFO: Unable to read jessie_tcp@dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.423: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.425: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1542.svc from pod dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02: the server could not find the requested resource (get pods dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02)
Dec 10 17:31:48.451: INFO: Lookups using dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1542 wheezy_tcp@dns-test-service.dns-1542 wheezy_udp@dns-test-service.dns-1542.svc wheezy_tcp@dns-test-service.dns-1542.svc wheezy_udp@_http._tcp.dns-test-service.dns-1542.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1542.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1542 jessie_tcp@dns-test-service.dns-1542 jessie_udp@dns-test-service.dns-1542.svc jessie_tcp@dns-test-service.dns-1542.svc jessie_udp@_http._tcp.dns-test-service.dns-1542.svc jessie_tcp@_http._tcp.dns-test-service.dns-1542.svc]

Dec 10 17:31:53.549: INFO: DNS probes using dns-1542/dns-test-02b8a314-d8e8-4529-86a7-d56d6f452b02 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:31:53.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1542" for this suite.

• [SLOW TEST:15.463 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":346,"completed":151,"skipped":2989,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:31:53.658: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:31:53.745: INFO: The status of Pod server-envvars-24fe9081-f543-407a-80e9-e27bdb0d2020 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:31:55.749: INFO: The status of Pod server-envvars-24fe9081-f543-407a-80e9-e27bdb0d2020 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:31:57.752: INFO: The status of Pod server-envvars-24fe9081-f543-407a-80e9-e27bdb0d2020 is Running (Ready = true)
Dec 10 17:31:57.775: INFO: Waiting up to 5m0s for pod "client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd" in namespace "pods-224" to be "Succeeded or Failed"
Dec 10 17:31:57.785: INFO: Pod "client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.6161ms
Dec 10 17:31:59.792: INFO: Pod "client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017112535s
STEP: Saw pod success
Dec 10 17:31:59.792: INFO: Pod "client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd" satisfied condition "Succeeded or Failed"
Dec 10 17:31:59.796: INFO: Trying to get logs from node ip-10-0-19-34 pod client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd container env3cont: <nil>
STEP: delete the pod
Dec 10 17:31:59.824: INFO: Waiting for pod client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd to disappear
Dec 10 17:31:59.828: INFO: Pod client-envvars-b511bf3f-e1a2-43bc-a3d5-b4688c6068fd no longer exists
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:31:59.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-224" for this suite.

• [SLOW TEST:6.177 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":346,"completed":152,"skipped":3015,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:31:59.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:32:59.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-341" for this suite.

• [SLOW TEST:60.081 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":346,"completed":153,"skipped":3034,"failed":0}
SSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:32:59.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Dec 10 17:33:02.038: INFO: running pods: 0 < 1
Dec 10 17:33:04.044: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:06.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2837" for this suite.

• [SLOW TEST:6.149 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":346,"completed":154,"skipped":3041,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:06.085: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a collection of services
Dec 10 17:33:06.129: INFO: Creating e2e-svc-a-wfjhk
Dec 10 17:33:06.135: INFO: Creating e2e-svc-b-j6v7f
Dec 10 17:33:06.143: INFO: Creating e2e-svc-c-7fvwl
STEP: deleting service collection
Dec 10 17:33:06.175: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:06.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6877" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":346,"completed":155,"skipped":3144,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:06.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-6ec1e289-75bc-400f-8f6f-1155c0e4b10b
STEP: Creating a pod to test consume configMaps
Dec 10 17:33:06.237: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e" in namespace "projected-1381" to be "Succeeded or Failed"
Dec 10 17:33:06.257: INFO: Pod "pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002668ms
Dec 10 17:33:08.262: INFO: Pod "pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024611655s
Dec 10 17:33:10.270: INFO: Pod "pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032329567s
STEP: Saw pod success
Dec 10 17:33:10.270: INFO: Pod "pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e" satisfied condition "Succeeded or Failed"
Dec 10 17:33:10.272: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:33:10.288: INFO: Waiting for pod pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e to disappear
Dec 10 17:33:10.292: INFO: Pod pod-projected-configmaps-55bd81e3-4919-42d0-8f59-09ff1c91dd3e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1381" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":156,"skipped":3150,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:10.329: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Dec 10 17:33:10.382: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 10 17:33:15.387: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:15.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-896" for this suite.

• [SLOW TEST:5.126 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":346,"completed":157,"skipped":3159,"failed":0}
SSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:15.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:15.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5650" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":346,"completed":158,"skipped":3165,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:15.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:15.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-5220
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:21.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-495" for this suite.
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:21.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5220" for this suite.

• [SLOW TEST:6.157 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:75
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":346,"completed":159,"skipped":3190,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:21.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Service
STEP: watching for the Service to be added
Dec 10 17:33:21.789: INFO: Found Service test-service-7dkxd in namespace services-1443 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Dec 10 17:33:21.790: INFO: Service test-service-7dkxd created
STEP: Getting /status
Dec 10 17:33:21.799: INFO: Service test-service-7dkxd has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Dec 10 17:33:21.807: INFO: observed Service test-service-7dkxd in namespace services-1443 with annotations: map[] & LoadBalancer: {[]}
Dec 10 17:33:21.810: INFO: Found Service test-service-7dkxd in namespace services-1443 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Dec 10 17:33:21.810: INFO: Service test-service-7dkxd has service status patched
STEP: updating the ServiceStatus
Dec 10 17:33:21.823: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Dec 10 17:33:21.830: INFO: Observed Service test-service-7dkxd in namespace services-1443 with annotations: map[] & Conditions: {[]}
Dec 10 17:33:21.831: INFO: Observed event: &Service{ObjectMeta:{test-service-7dkxd  services-1443  1193e8a6-6b64-415f-8644-e14a353bac87 16930 0 2021-12-10 17:33:21 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2021-12-10 17:33:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2021-12-10 17:33:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.3.55.91,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.3.55.91],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Dec 10 17:33:21.831: INFO: Found Service test-service-7dkxd in namespace services-1443 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 10 17:33:21.832: INFO: Service test-service-7dkxd has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Dec 10 17:33:21.845: INFO: observed Service test-service-7dkxd in namespace services-1443 with labels: map[test-service-static:true]
Dec 10 17:33:21.846: INFO: observed Service test-service-7dkxd in namespace services-1443 with labels: map[test-service-static:true]
Dec 10 17:33:21.848: INFO: observed Service test-service-7dkxd in namespace services-1443 with labels: map[test-service-static:true]
Dec 10 17:33:21.848: INFO: Found Service test-service-7dkxd in namespace services-1443 with labels: map[test-service:patched test-service-static:true]
Dec 10 17:33:21.849: INFO: Service test-service-7dkxd patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Dec 10 17:33:21.863: INFO: Observed event: ADDED
Dec 10 17:33:21.864: INFO: Observed event: MODIFIED
Dec 10 17:33:21.864: INFO: Observed event: MODIFIED
Dec 10 17:33:21.865: INFO: Observed event: MODIFIED
Dec 10 17:33:21.865: INFO: Found Service test-service-7dkxd in namespace services-1443 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Dec 10 17:33:21.866: INFO: Service test-service-7dkxd deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:21.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1443" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":346,"completed":160,"skipped":3213,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:21.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:33:21.928: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623" in namespace "projected-31" to be "Succeeded or Failed"
Dec 10 17:33:21.933: INFO: Pod "downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623": Phase="Pending", Reason="", readiness=false. Elapsed: 4.188699ms
Dec 10 17:33:23.940: INFO: Pod "downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011475477s
STEP: Saw pod success
Dec 10 17:33:23.941: INFO: Pod "downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623" satisfied condition "Succeeded or Failed"
Dec 10 17:33:23.948: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623 container client-container: <nil>
STEP: delete the pod
Dec 10 17:33:23.970: INFO: Waiting for pod downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623 to disappear
Dec 10 17:33:23.973: INFO: Pod downwardapi-volume-e2c1fc51-462d-4878-8f76-fb8b7b75d623 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:23.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-31" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":161,"skipped":3238,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:23.988: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-e19ade66-a36e-43e4-9ff8-2ce4bd5ddd0e
STEP: Creating configMap with name cm-test-opt-upd-f63786b0-89a8-437a-aa7a-22ca23a82e46
STEP: Creating the pod
Dec 10 17:33:24.053: INFO: The status of Pod pod-projected-configmaps-f28bbb97-5394-4365-94e7-d37c3cfbbb13 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:33:26.064: INFO: The status of Pod pod-projected-configmaps-f28bbb97-5394-4365-94e7-d37c3cfbbb13 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:33:28.059: INFO: The status of Pod pod-projected-configmaps-f28bbb97-5394-4365-94e7-d37c3cfbbb13 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-e19ade66-a36e-43e4-9ff8-2ce4bd5ddd0e
STEP: Updating configmap cm-test-opt-upd-f63786b0-89a8-437a-aa7a-22ca23a82e46
STEP: Creating configMap with name cm-test-opt-create-34999c5d-0fee-4dd2-85cb-e5be83ea4dc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:30.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3010" for this suite.

• [SLOW TEST:6.175 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":162,"skipped":3238,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:30.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:33:30.206: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 10 17:33:30.217: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 10 17:33:35.232: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 17:33:35.233: INFO: Creating deployment "test-rolling-update-deployment"
Dec 10 17:33:35.238: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 10 17:33:35.274: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 10 17:33:37.283: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 10 17:33:37.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 33, 35, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 33, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 33, 35, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 33, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-796dbc4547\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:33:39.292: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:33:39.299: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-616  c557951d-cd84-468b-98b3-bc3e8230c69b 17103 1 2021-12-10 17:33:35 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2021-12-10 17:33:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:33:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005534858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2021-12-10 17:33:35 +0000 UTC,LastTransitionTime:2021-12-10 17:33:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-796dbc4547" has successfully progressed.,LastUpdateTime:2021-12-10 17:33:37 +0000 UTC,LastTransitionTime:2021-12-10 17:33:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 17:33:39.302: INFO: New ReplicaSet "test-rolling-update-deployment-796dbc4547" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-796dbc4547  deployment-616  439a6837-7195-433e-b507-bfb51e252640 17093 1 2021-12-10 17:33:35 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c557951d-cd84-468b-98b3-bc3e8230c69b 0xc005534d37 0xc005534d38}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:33:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c557951d-cd84-468b-98b3-bc3e8230c69b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:33:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 796dbc4547,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005534de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:33:39.303: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 10 17:33:39.303: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-616  e57dce80-8e07-4d11-b407-9737347561ed 17102 2 2021-12-10 17:33:30 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c557951d-cd84-468b-98b3-bc3e8230c69b 0xc005534c07 0xc005534c08}] []  [{e2e.test Update apps/v1 2021-12-10 17:33:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:33:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c557951d-cd84-468b-98b3-bc3e8230c69b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:33:37 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005534cc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:33:39.306: INFO: Pod "test-rolling-update-deployment-796dbc4547-5l8lk" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-796dbc4547-5l8lk test-rolling-update-deployment-796dbc4547- deployment-616  87701708-8713-429f-938c-afb7ac1cae60 17092 0 2021-12-10 17:33:35 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-796dbc4547 439a6837-7195-433e-b507-bfb51e252640 0xc005535247 0xc005535248}] []  [{kube-controller-manager Update v1 2021-12-10 17:33:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"439a6837-7195-433e-b507-bfb51e252640\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:33:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kqrpd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kqrpd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:33:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:33:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:33:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:33:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.16,StartTime:2021-12-10 17:33:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:33:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43,ContainerID:docker://0b3be45fd22170a07132774727d182ab77e5c18289e1e3d374eda4fdcf92b197,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:33:39.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-616" for this suite.

• [SLOW TEST:9.153 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":163,"skipped":3254,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:33:39.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-6933acdf-136d-4969-89c5-da9245b5725e in namespace container-probe-3105
Dec 10 17:33:41.396: INFO: Started pod liveness-6933acdf-136d-4969-89c5-da9245b5725e in namespace container-probe-3105
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 17:33:41.398: INFO: Initial restart count of pod liveness-6933acdf-136d-4969-89c5-da9245b5725e is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:37:42.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3105" for this suite.

• [SLOW TEST:243.219 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":346,"completed":164,"skipped":3263,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:37:42.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Request ServerVersion
STEP: Confirm major version
Dec 10 17:37:42.578: INFO: Major version: 1
STEP: Confirm minor version
Dec 10 17:37:42.579: INFO: cleanMinorVersion: 23
Dec 10 17:37:42.579: INFO: Minor version: 23
[AfterEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:37:42.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7562" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":346,"completed":165,"skipped":3291,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:37:42.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2c24a456-1c8f-4ea4-a4a8-9792abd4f994
STEP: Creating the pod
Dec 10 17:37:42.636: INFO: The status of Pod pod-projected-configmaps-584c74a3-ae4c-4782-bd77-b0dc29139969 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:37:44.644: INFO: The status of Pod pod-projected-configmaps-584c74a3-ae4c-4782-bd77-b0dc29139969 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-2c24a456-1c8f-4ea4-a4a8-9792abd4f994
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:37:46.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5671" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":166,"skipped":3300,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:37:46.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-bac8acef-0efa-4333-91a2-58be97709548
STEP: Creating a pod to test consume secrets
Dec 10 17:37:46.767: INFO: Waiting up to 5m0s for pod "pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513" in namespace "secrets-130" to be "Succeeded or Failed"
Dec 10 17:37:46.770: INFO: Pod "pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513": Phase="Pending", Reason="", readiness=false. Elapsed: 2.540459ms
Dec 10 17:37:48.781: INFO: Pod "pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012942632s
STEP: Saw pod success
Dec 10 17:37:48.781: INFO: Pod "pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513" satisfied condition "Succeeded or Failed"
Dec 10 17:37:48.782: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:37:48.794: INFO: Waiting for pod pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513 to disappear
Dec 10 17:37:48.796: INFO: Pod pod-secrets-b30c957a-06d6-4d4f-9108-59f19f081513 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:37:48.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-130" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":167,"skipped":3339,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:37:48.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 17:37:48.903: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:37:48.912: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:37:48.912: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:37:49.919: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:37:49.921: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:37:49.921: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:37:50.919: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:37:50.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 17:37:50.923: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
Dec 10 17:37:50.938: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17598"},"items":null}

Dec 10 17:37:50.941: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17598"},"items":[{"metadata":{"name":"daemon-set-h9d5w","generateName":"daemon-set-","namespace":"daemonsets-1305","uid":"d68101e9-7b71-4128-99f0-3ab3c7114812","resourceVersion":"17596","creationTimestamp":"2021-12-10T17:37:48Z","labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3d6a2084-d466-4a74-86c0-31d2313bca64","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2021-12-10T17:37:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d6a2084-d466-4a74-86c0-31d2313bca64\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2021-12-10T17:37:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.2.152\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-8tctj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-8tctj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-0-54","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-0-54"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:48Z"}],"hostIP":"10.0.0.54","podIP":"10.2.2.152","podIPs":[{"ip":"10.2.2.152"}],"startTime":"2021-12-10T17:37:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2021-12-10T17:37:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://8124573a1bc659485020e3fb38bea2bb94e413bf26227786b593d0466fed7323","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-htddh","generateName":"daemon-set-","namespace":"daemonsets-1305","uid":"80d6e148-6860-45f9-bcc1-55ddfecf90bc","resourceVersion":"17593","creationTimestamp":"2021-12-10T17:37:48Z","labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"3d6a2084-d466-4a74-86c0-31d2313bca64","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2021-12-10T17:37:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d6a2084-d466-4a74-86c0-31d2313bca64\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2021-12-10T17:37:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hjddw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hjddw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-19-34","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-19-34"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2021-12-10T17:37:48Z"}],"hostIP":"10.0.19.34","podIP":"10.2.1.20","podIPs":[{"ip":"10.2.1.20"}],"startTime":"2021-12-10T17:37:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2021-12-10T17:37:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://6a79f8f013e9b8e4e159c79afb446457f6f03b4bf19b77fd3ad7e350aafc3bcb","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:37:50.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1305" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":346,"completed":168,"skipped":3352,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:37:50.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Dec 10 17:37:57.052: INFO: 80 pods remaining
Dec 10 17:37:57.052: INFO: 80 pods has nil DeletionTimestamp
Dec 10 17:37:57.052: INFO: 
Dec 10 17:37:58.134: INFO: 70 pods remaining
Dec 10 17:37:58.135: INFO: 70 pods has nil DeletionTimestamp
Dec 10 17:37:58.135: INFO: 
Dec 10 17:37:59.069: INFO: 60 pods remaining
Dec 10 17:37:59.088: INFO: 60 pods has nil DeletionTimestamp
Dec 10 17:37:59.088: INFO: 
Dec 10 17:38:00.057: INFO: 40 pods remaining
Dec 10 17:38:00.057: INFO: 40 pods has nil DeletionTimestamp
Dec 10 17:38:00.057: INFO: 
Dec 10 17:38:01.087: INFO: 30 pods remaining
Dec 10 17:38:01.088: INFO: 30 pods has nil DeletionTimestamp
Dec 10 17:38:01.088: INFO: 
Dec 10 17:38:02.066: INFO: 20 pods remaining
Dec 10 17:38:02.066: INFO: 20 pods has nil DeletionTimestamp
Dec 10 17:38:02.066: INFO: 
STEP: Gathering metrics
Dec 10 17:38:03.134: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 17:38:03.619: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:38:03.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-927" for this suite.

• [SLOW TEST:12.657 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":346,"completed":169,"skipped":3363,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:38:03.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:38:03.697: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba" in namespace "downward-api-270" to be "Succeeded or Failed"
Dec 10 17:38:03.699: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.869516ms
Dec 10 17:38:05.732: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03461356s
Dec 10 17:38:07.739: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041705127s
Dec 10 17:38:09.756: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058765717s
Dec 10 17:38:11.768: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 8.070371892s
Dec 10 17:38:13.778: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 10.081215563s
Dec 10 17:38:15.900: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 12.203212604s
Dec 10 17:38:17.947: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 14.249386242s
Dec 10 17:38:19.966: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 16.268659545s
Dec 10 17:38:21.975: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 18.278262611s
Dec 10 17:38:24.009: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 20.311811181s
Dec 10 17:38:26.021: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 22.323361155s
Dec 10 17:38:28.028: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 24.330993699s
Dec 10 17:38:30.043: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 26.345855996s
Dec 10 17:38:32.050: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Pending", Reason="", readiness=false. Elapsed: 28.353292349s
Dec 10 17:38:34.056: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.35929905s
STEP: Saw pod success
Dec 10 17:38:34.057: INFO: Pod "downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba" satisfied condition "Succeeded or Failed"
Dec 10 17:38:34.058: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba container client-container: <nil>
STEP: delete the pod
Dec 10 17:38:34.145: INFO: Waiting for pod downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba to disappear
Dec 10 17:38:34.147: INFO: Pod downwardapi-volume-5196c8a2-4f14-4eb3-8dba-eb1cf4909dba no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:38:34.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-270" for this suite.

• [SLOW TEST:30.513 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":170,"skipped":3397,"failed":0}
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:38:34.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:38:34.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b" in namespace "projected-544" to be "Succeeded or Failed"
Dec 10 17:38:34.223: INFO: Pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392042ms
Dec 10 17:38:36.226: INFO: Pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007815857s
Dec 10 17:38:38.236: INFO: Pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018170427s
Dec 10 17:38:40.241: INFO: Pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022811976s
STEP: Saw pod success
Dec 10 17:38:40.241: INFO: Pod "downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b" satisfied condition "Succeeded or Failed"
Dec 10 17:38:40.243: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b container client-container: <nil>
STEP: delete the pod
Dec 10 17:38:40.256: INFO: Waiting for pod downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b to disappear
Dec 10 17:38:40.258: INFO: Pod downwardapi-volume-e36837e9-d271-409d-b6fc-28a79db7e19b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:38:40.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-544" for this suite.

• [SLOW TEST:6.106 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":171,"skipped":3397,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:38:40.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Dec 10 17:38:40.322: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:38:42.331: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:38:44.330: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Dec 10 17:38:44.337: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:38:46.343: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 10 17:38:46.346: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.351: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.351: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.464: INFO: Exec stderr: ""
Dec 10 17:38:46.464: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.465: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.466: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.549: INFO: Exec stderr: ""
Dec 10 17:38:46.549: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.550: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.551: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.638: INFO: Exec stderr: ""
Dec 10 17:38:46.639: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.640: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.640: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.763: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 10 17:38:46.764: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.765: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.766: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.845: INFO: Exec stderr: ""
Dec 10 17:38:46.845: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.845: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.851: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.851: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:46.987: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 10 17:38:46.988: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:46.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:46.989: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:46.990: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:47.229: INFO: Exec stderr: ""
Dec 10 17:38:47.229: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:47.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:47.230: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:47.230: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:47.304: INFO: Exec stderr: ""
Dec 10 17:38:47.305: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:47.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:47.305: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:47.305: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:47.374: INFO: Exec stderr: ""
Dec 10 17:38:47.375: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2110 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:38:47.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:38:47.376: INFO: ExecWithOptions: Clientset creation
Dec 10 17:38:47.376: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2110/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:38:47.433: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:38:47.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2110" for this suite.

• [SLOW TEST:7.169 seconds]
[sig-node] KubeletManagedEtcHosts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":172,"skipped":3480,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:38:47.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:38:47.500: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 10 17:38:52.512: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 17:38:52.513: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 10 17:38:54.523: INFO: Creating deployment "test-rollover-deployment"
Dec 10 17:38:54.537: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 10 17:38:56.546: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 10 17:38:56.549: INFO: Ensure that both replica sets have 1 created replica
Dec 10 17:38:56.553: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 10 17:38:56.559: INFO: Updating deployment test-rollover-deployment
Dec 10 17:38:56.560: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 10 17:38:58.569: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 10 17:38:58.573: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 10 17:38:58.584: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:38:58.584: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 56, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:00.592: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:39:00.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 58, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:02.596: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:39:02.597: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 58, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:04.594: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:39:04.594: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 58, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:06.593: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:39:06.594: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 58, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:08.596: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 17:39:08.597: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 17, 38, 58, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 17, 38, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 17:39:10.600: INFO: 
Dec 10 17:39:10.600: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 17:39:10.615: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3366  a55181fd-c86c-483e-9cf3-108cadee6384 18812 2 2021-12-10 17:38:54 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-12-10 17:38:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:39:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005584818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2021-12-10 17:38:54 +0000 UTC,LastTransitionTime:2021-12-10 17:38:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-668b7f667d" has successfully progressed.,LastUpdateTime:2021-12-10 17:39:08 +0000 UTC,LastTransitionTime:2021-12-10 17:38:54 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 17:39:10.620: INFO: New ReplicaSet "test-rollover-deployment-668b7f667d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-668b7f667d  deployment-3366  c0d20c54-be87-4f57-bb34-d7b1505cf54f 18802 2 2021-12-10 17:38:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment a55181fd-c86c-483e-9cf3-108cadee6384 0xc005584cf7 0xc005584cf8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:38:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a55181fd-c86c-483e-9cf3-108cadee6384\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:39:08 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 668b7f667d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005584da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:39:10.622: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 10 17:39:10.623: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3366  3a39bcc5-6539-4a70-92ea-3a40c9aabfd8 18811 2 2021-12-10 17:38:47 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment a55181fd-c86c-483e-9cf3-108cadee6384 0xc005584bb7 0xc005584bb8}] []  [{e2e.test Update apps/v1 2021-12-10 17:38:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:39:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a55181fd-c86c-483e-9cf3-108cadee6384\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:39:08 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005584c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:39:10.623: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-784bc44b77  deployment-3366  689253bd-26de-43bc-a531-f065271ad241 18763 2 2021-12-10 17:38:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment a55181fd-c86c-483e-9cf3-108cadee6384 0xc005584e17 0xc005584e18}] []  [{kube-controller-manager Update apps/v1 2021-12-10 17:38:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a55181fd-c86c-483e-9cf3-108cadee6384\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 17:38:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 784bc44b77,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005584ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 17:39:10.626: INFO: Pod "test-rollover-deployment-668b7f667d-r8xfc" is available:
&Pod{ObjectMeta:{test-rollover-deployment-668b7f667d-r8xfc test-rollover-deployment-668b7f667d- deployment-3366  de81def1-5d23-4e4c-b140-d3ff76b1828e 18776 0 2021-12-10 17:38:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[] [{apps/v1 ReplicaSet test-rollover-deployment-668b7f667d c0d20c54-be87-4f57-bb34-d7b1505cf54f 0xc005585427 0xc005585428}] []  [{kube-controller-manager Update v1 2021-12-10 17:38:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0d20c54-be87-4f57-bb34-d7b1505cf54f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2021-12-10 17:38:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.1.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rnpqh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rnpqh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:38:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:38:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:38:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 17:38:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:10.2.1.66,StartTime:2021-12-10 17:38:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-12-10 17:38:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43,ContainerID:docker://c12643507dda60bacf9b60445275b4cdd59a07949307fe9515cde8454ee111b8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.1.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:10.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3366" for this suite.

• [SLOW TEST:23.183 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":346,"completed":173,"skipped":3541,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:10.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:14.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5646" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":346,"completed":174,"skipped":3574,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:14.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Dec 10 17:39:14.506: INFO: The status of Pod pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:39:16.509: INFO: The status of Pod pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 17:39:17.026: INFO: Successfully updated pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37"
Dec 10 17:39:17.026: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37" in namespace "pods-6084" to be "terminated due to deadline exceeded"
Dec 10 17:39:17.033: INFO: Pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37": Phase="Running", Reason="", readiness=true. Elapsed: 5.837884ms
Dec 10 17:39:19.041: INFO: Pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37": Phase="Running", Reason="", readiness=true. Elapsed: 2.014237157s
Dec 10 17:39:21.047: INFO: Pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37": Phase="Failed", Reason="DeadlineExceeded", readiness=true. Elapsed: 4.020351218s
Dec 10 17:39:21.048: INFO: Pod "pod-update-activedeadlineseconds-63a9a72d-341d-4317-9438-3bb8809f1d37" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:21.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6084" for this suite.

• [SLOW TEST:6.595 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":346,"completed":175,"skipped":3587,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:21.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-6652
[It] Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6652
STEP: Waiting until pod test-pod will start running in namespace statefulset-6652
STEP: Creating statefulset with conflicting port in namespace statefulset-6652
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6652
Dec 10 17:39:23.191: INFO: Observed stateful pod in namespace: statefulset-6652, name: ss-0, uid: 53a0aceb-a18c-413a-a315-a6e09c89e461, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 17:39:23.220: INFO: Observed stateful pod in namespace: statefulset-6652, name: ss-0, uid: 53a0aceb-a18c-413a-a315-a6e09c89e461, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 17:39:23.224: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6652
STEP: Removing pod with conflicting port in namespace statefulset-6652
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6652 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:39:25.280: INFO: Deleting all statefulset in ns statefulset-6652
Dec 10 17:39:25.283: INFO: Scaling statefulset ss to 0
Dec 10 17:39:35.301: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:39:35.304: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:35.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6652" for this suite.

• [SLOW TEST:14.272 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Should recreate evicted statefulset [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":346,"completed":176,"skipped":3590,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:35.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:39:35.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5517
I1210 17:39:35.399995      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5517, replica count: 1
I1210 17:39:36.450610      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 17:39:37.451000      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:39:37.563: INFO: Created: latency-svc-fp9ps
Dec 10 17:39:37.573: INFO: Got endpoints: latency-svc-fp9ps [20.765786ms]
Dec 10 17:39:37.590: INFO: Created: latency-svc-z6hhz
Dec 10 17:39:37.598: INFO: Created: latency-svc-zrgp7
Dec 10 17:39:37.608: INFO: Got endpoints: latency-svc-z6hhz [35.111808ms]
Dec 10 17:39:37.612: INFO: Created: latency-svc-j7z85
Dec 10 17:39:37.614: INFO: Got endpoints: latency-svc-zrgp7 [40.914154ms]
Dec 10 17:39:37.628: INFO: Got endpoints: latency-svc-j7z85 [51.400009ms]
Dec 10 17:39:37.629: INFO: Created: latency-svc-mr6hj
Dec 10 17:39:37.642: INFO: Created: latency-svc-lhkqm
Dec 10 17:39:37.649: INFO: Created: latency-svc-xlk6c
Dec 10 17:39:37.652: INFO: Got endpoints: latency-svc-mr6hj [76.354105ms]
Dec 10 17:39:37.678: INFO: Created: latency-svc-5jvhx
Dec 10 17:39:37.679: INFO: Created: latency-svc-f98km
Dec 10 17:39:37.679: INFO: Got endpoints: latency-svc-xlk6c [103.083948ms]
Dec 10 17:39:37.679: INFO: Got endpoints: latency-svc-lhkqm [103.391514ms]
Dec 10 17:39:37.714: INFO: Created: latency-svc-2prgc
Dec 10 17:39:37.714: INFO: Created: latency-svc-rcgzs
Dec 10 17:39:37.715: INFO: Created: latency-svc-4zrdf
Dec 10 17:39:37.718: INFO: Got endpoints: latency-svc-4zrdf [141.558085ms]
Dec 10 17:39:37.717: INFO: Got endpoints: latency-svc-rcgzs [141.285902ms]
Dec 10 17:39:37.717: INFO: Got endpoints: latency-svc-f98km [141.43487ms]
Dec 10 17:39:37.717: INFO: Got endpoints: latency-svc-5jvhx [141.357979ms]
Dec 10 17:39:37.744: INFO: Got endpoints: latency-svc-2prgc [167.915282ms]
Dec 10 17:39:37.745: INFO: Created: latency-svc-sn2t5
Dec 10 17:39:37.745: INFO: Created: latency-svc-wvmqc
Dec 10 17:39:37.769: INFO: Created: latency-svc-f2dmz
Dec 10 17:39:37.770: INFO: Created: latency-svc-m2bvb
Dec 10 17:39:37.770: INFO: Got endpoints: latency-svc-wvmqc [193.844583ms]
Dec 10 17:39:37.770: INFO: Got endpoints: latency-svc-sn2t5 [193.89894ms]
Dec 10 17:39:37.801: INFO: Created: latency-svc-gqkx4
Dec 10 17:39:37.802: INFO: Got endpoints: latency-svc-gqkx4 [192.997989ms]
Dec 10 17:39:37.802: INFO: Got endpoints: latency-svc-m2bvb [225.84344ms]
Dec 10 17:39:37.803: INFO: Got endpoints: latency-svc-f2dmz [226.264729ms]
Dec 10 17:39:37.805: INFO: Created: latency-svc-ksl9p
Dec 10 17:39:37.823: INFO: Got endpoints: latency-svc-ksl9p [208.053502ms]
Dec 10 17:39:37.824: INFO: Created: latency-svc-2hqzz
Dec 10 17:39:37.824: INFO: Created: latency-svc-bkt2z
Dec 10 17:39:37.831: INFO: Got endpoints: latency-svc-2hqzz [201.61996ms]
Dec 10 17:39:37.837: INFO: Created: latency-svc-d72nl
Dec 10 17:39:37.845: INFO: Got endpoints: latency-svc-bkt2z [192.417929ms]
Dec 10 17:39:37.851: INFO: Created: latency-svc-d5tj8
Dec 10 17:39:37.854: INFO: Got endpoints: latency-svc-d72nl [175.003035ms]
Dec 10 17:39:37.864: INFO: Got endpoints: latency-svc-d5tj8 [183.680331ms]
Dec 10 17:39:37.928: INFO: Created: latency-svc-zr69f
Dec 10 17:39:37.929: INFO: Created: latency-svc-pmzcm
Dec 10 17:39:37.929: INFO: Created: latency-svc-hl54s
Dec 10 17:39:37.957: INFO: Created: latency-svc-cjkbb
Dec 10 17:39:37.958: INFO: Created: latency-svc-hb2pc
Dec 10 17:39:37.958: INFO: Created: latency-svc-vd99t
Dec 10 17:39:37.958: INFO: Created: latency-svc-kmkk7
Dec 10 17:39:37.958: INFO: Created: latency-svc-7wf95
Dec 10 17:39:37.958: INFO: Created: latency-svc-hsb5d
Dec 10 17:39:37.958: INFO: Created: latency-svc-lw72m
Dec 10 17:39:37.958: INFO: Created: latency-svc-677dm
Dec 10 17:39:37.958: INFO: Created: latency-svc-5z7qn
Dec 10 17:39:37.958: INFO: Created: latency-svc-gbmq2
Dec 10 17:39:37.958: INFO: Created: latency-svc-m2cpf
Dec 10 17:39:37.958: INFO: Created: latency-svc-fznms
Dec 10 17:39:37.969: INFO: Got endpoints: latency-svc-cjkbb [104.762747ms]
Dec 10 17:39:37.969: INFO: Got endpoints: latency-svc-pmzcm [251.437679ms]
Dec 10 17:39:37.969: INFO: Got endpoints: latency-svc-hb2pc [249.436242ms]
Dec 10 17:39:37.969: INFO: Got endpoints: latency-svc-vd99t [250.759617ms]
Dec 10 17:39:37.969: INFO: Got endpoints: latency-svc-hl54s [138.257562ms]
Dec 10 17:39:37.986: INFO: Got endpoints: latency-svc-hsb5d [215.172458ms]
Dec 10 17:39:37.986: INFO: Got endpoints: latency-svc-kmkk7 [266.390626ms]
Dec 10 17:39:37.986: INFO: Got endpoints: latency-svc-lw72m [214.683648ms]
Dec 10 17:39:37.986: INFO: Got endpoints: latency-svc-677dm [181.051564ms]
Dec 10 17:39:37.986: INFO: Got endpoints: latency-svc-7wf95 [241.223648ms]
Dec 10 17:39:38.023: INFO: Got endpoints: latency-svc-fznms [177.678972ms]
Dec 10 17:39:38.024: INFO: Got endpoints: latency-svc-5z7qn [221.687402ms]
Dec 10 17:39:38.025: INFO: Got endpoints: latency-svc-m2cpf [201.790838ms]
Dec 10 17:39:38.031: INFO: Got endpoints: latency-svc-zr69f [176.056035ms]
Dec 10 17:39:38.031: INFO: Got endpoints: latency-svc-gbmq2 [228.756144ms]
Dec 10 17:39:38.046: INFO: Created: latency-svc-7qnj9
Dec 10 17:39:38.059: INFO: Got endpoints: latency-svc-7qnj9 [68.332267ms]
Dec 10 17:39:38.124: INFO: Created: latency-svc-v9v5w
Dec 10 17:39:38.127: INFO: Created: latency-svc-775ff
Dec 10 17:39:38.127: INFO: Created: latency-svc-hhd4s
Dec 10 17:39:38.127: INFO: Created: latency-svc-xzwzr
Dec 10 17:39:38.127: INFO: Created: latency-svc-t6rcx
Dec 10 17:39:38.137: INFO: Created: latency-svc-hn2cf
Dec 10 17:39:38.150: INFO: Created: latency-svc-h27wt
Dec 10 17:39:38.155: INFO: Created: latency-svc-frqs6
Dec 10 17:39:38.157: INFO: Created: latency-svc-sfkjk
Dec 10 17:39:38.162: INFO: Created: latency-svc-s7qrh
Dec 10 17:39:38.165: INFO: Created: latency-svc-kltw4
Dec 10 17:39:38.165: INFO: Created: latency-svc-rdz9j
Dec 10 17:39:38.165: INFO: Created: latency-svc-dpgm4
Dec 10 17:39:38.165: INFO: Created: latency-svc-gbz6r
Dec 10 17:39:38.165: INFO: Got endpoints: latency-svc-t6rcx [104.738379ms]
Dec 10 17:39:38.149: INFO: Created: latency-svc-v6j9f
Dec 10 17:39:38.165: INFO: Got endpoints: latency-svc-hhd4s [170.930826ms]
Dec 10 17:39:38.165: INFO: Got endpoints: latency-svc-xzwzr [171.550695ms]
Dec 10 17:39:38.167: INFO: Got endpoints: latency-svc-hn2cf [149.027677ms]
Dec 10 17:39:38.185: INFO: Created: latency-svc-ds5zz
Dec 10 17:39:38.188: INFO: Created: latency-svc-8t659
Dec 10 17:39:38.206: INFO: Created: latency-svc-ngn27
Dec 10 17:39:38.206: INFO: Created: latency-svc-hcwdl
Dec 10 17:39:38.231: INFO: Got endpoints: latency-svc-v6j9f [206.845667ms]
Dec 10 17:39:38.242: INFO: Created: latency-svc-75n7p
Dec 10 17:39:38.292: INFO: Got endpoints: latency-svc-h27wt [273.329055ms]
Dec 10 17:39:38.313: INFO: Created: latency-svc-smrqj
Dec 10 17:39:38.332: INFO: Got endpoints: latency-svc-sfkjk [312.053351ms]
Dec 10 17:39:38.365: INFO: Created: latency-svc-tp2gb
Dec 10 17:39:38.385: INFO: Got endpoints: latency-svc-frqs6 [364.661342ms]
Dec 10 17:39:38.398: INFO: Created: latency-svc-mgxjv
Dec 10 17:39:38.422: INFO: Got endpoints: latency-svc-s7qrh [399.467381ms]
Dec 10 17:39:38.431: INFO: Created: latency-svc-ngg7p
Dec 10 17:39:38.475: INFO: Got endpoints: latency-svc-kltw4 [452.318956ms]
Dec 10 17:39:38.487: INFO: Created: latency-svc-p6t6h
Dec 10 17:39:38.532: INFO: Got endpoints: latency-svc-rdz9j [508.760315ms]
Dec 10 17:39:38.545: INFO: Created: latency-svc-sgtlb
Dec 10 17:39:38.571: INFO: Got endpoints: latency-svc-dpgm4 [539.77074ms]
Dec 10 17:39:38.580: INFO: Created: latency-svc-b48rs
Dec 10 17:39:38.622: INFO: Got endpoints: latency-svc-gbz6r [589.951127ms]
Dec 10 17:39:38.633: INFO: Created: latency-svc-j8hcm
Dec 10 17:39:38.672: INFO: Got endpoints: latency-svc-v9v5w [642.121975ms]
Dec 10 17:39:38.686: INFO: Created: latency-svc-jrjm8
Dec 10 17:39:38.739: INFO: Got endpoints: latency-svc-775ff [744.517862ms]
Dec 10 17:39:38.763: INFO: Created: latency-svc-5n5zm
Dec 10 17:39:38.795: INFO: Got endpoints: latency-svc-ds5zz [623.67066ms]
Dec 10 17:39:38.860: INFO: Created: latency-svc-jmf5k
Dec 10 17:39:38.860: INFO: Got endpoints: latency-svc-8t659 [685.585942ms]
Dec 10 17:39:38.871: INFO: Created: latency-svc-2qzr6
Dec 10 17:39:38.875: INFO: Got endpoints: latency-svc-hcwdl [697.374601ms]
Dec 10 17:39:38.886: INFO: Created: latency-svc-lcvr9
Dec 10 17:39:38.923: INFO: Got endpoints: latency-svc-ngn27 [745.307527ms]
Dec 10 17:39:38.932: INFO: Created: latency-svc-ljqgq
Dec 10 17:39:38.972: INFO: Got endpoints: latency-svc-75n7p [740.672565ms]
Dec 10 17:39:38.980: INFO: Created: latency-svc-xhgbq
Dec 10 17:39:39.020: INFO: Got endpoints: latency-svc-smrqj [726.888847ms]
Dec 10 17:39:39.028: INFO: Created: latency-svc-82l87
Dec 10 17:39:39.073: INFO: Got endpoints: latency-svc-tp2gb [741.336427ms]
Dec 10 17:39:39.082: INFO: Created: latency-svc-qj9mg
Dec 10 17:39:39.122: INFO: Got endpoints: latency-svc-mgxjv [737.304368ms]
Dec 10 17:39:39.133: INFO: Created: latency-svc-kxm9n
Dec 10 17:39:39.173: INFO: Got endpoints: latency-svc-ngg7p [750.571333ms]
Dec 10 17:39:39.181: INFO: Created: latency-svc-k72c4
Dec 10 17:39:39.226: INFO: Got endpoints: latency-svc-p6t6h [750.463531ms]
Dec 10 17:39:39.239: INFO: Created: latency-svc-jtbhr
Dec 10 17:39:39.271: INFO: Got endpoints: latency-svc-sgtlb [738.338246ms]
Dec 10 17:39:39.280: INFO: Created: latency-svc-xsnnx
Dec 10 17:39:39.321: INFO: Got endpoints: latency-svc-b48rs [749.603463ms]
Dec 10 17:39:39.329: INFO: Created: latency-svc-fxs2k
Dec 10 17:39:39.372: INFO: Got endpoints: latency-svc-j8hcm [750.485189ms]
Dec 10 17:39:39.381: INFO: Created: latency-svc-lpzdr
Dec 10 17:39:39.421: INFO: Got endpoints: latency-svc-jrjm8 [748.020023ms]
Dec 10 17:39:39.430: INFO: Created: latency-svc-xgxrg
Dec 10 17:39:39.472: INFO: Got endpoints: latency-svc-5n5zm [732.16645ms]
Dec 10 17:39:39.481: INFO: Created: latency-svc-mc55b
Dec 10 17:39:39.522: INFO: Got endpoints: latency-svc-jmf5k [727.013735ms]
Dec 10 17:39:39.531: INFO: Created: latency-svc-q95nr
Dec 10 17:39:39.571: INFO: Got endpoints: latency-svc-2qzr6 [711.050023ms]
Dec 10 17:39:39.580: INFO: Created: latency-svc-dztnz
Dec 10 17:39:39.624: INFO: Got endpoints: latency-svc-lcvr9 [748.637207ms]
Dec 10 17:39:39.633: INFO: Created: latency-svc-qcg4g
Dec 10 17:39:39.672: INFO: Got endpoints: latency-svc-ljqgq [748.201864ms]
Dec 10 17:39:39.681: INFO: Created: latency-svc-k9djv
Dec 10 17:39:39.731: INFO: Got endpoints: latency-svc-xhgbq [759.061312ms]
Dec 10 17:39:39.739: INFO: Created: latency-svc-bbzs5
Dec 10 17:39:39.772: INFO: Got endpoints: latency-svc-82l87 [751.718232ms]
Dec 10 17:39:39.781: INFO: Created: latency-svc-hw4jt
Dec 10 17:39:39.824: INFO: Got endpoints: latency-svc-qj9mg [750.366217ms]
Dec 10 17:39:39.834: INFO: Created: latency-svc-m9nhm
Dec 10 17:39:39.914: INFO: Got endpoints: latency-svc-kxm9n [790.673729ms]
Dec 10 17:39:39.919: INFO: Got endpoints: latency-svc-k72c4 [746.464683ms]
Dec 10 17:39:39.930: INFO: Created: latency-svc-b55mx
Dec 10 17:39:39.932: INFO: Created: latency-svc-995nb
Dec 10 17:39:39.973: INFO: Got endpoints: latency-svc-jtbhr [747.160169ms]
Dec 10 17:39:39.982: INFO: Created: latency-svc-znhdb
Dec 10 17:39:40.019: INFO: Got endpoints: latency-svc-xsnnx [748.050942ms]
Dec 10 17:39:40.031: INFO: Created: latency-svc-4hkr7
Dec 10 17:39:40.069: INFO: Got endpoints: latency-svc-fxs2k [747.150694ms]
Dec 10 17:39:40.097: INFO: Created: latency-svc-7wvp9
Dec 10 17:39:40.144: INFO: Got endpoints: latency-svc-lpzdr [771.376303ms]
Dec 10 17:39:40.171: INFO: Created: latency-svc-5fn5m
Dec 10 17:39:40.182: INFO: Got endpoints: latency-svc-xgxrg [760.155393ms]
Dec 10 17:39:40.207: INFO: Created: latency-svc-8hx7l
Dec 10 17:39:40.223: INFO: Got endpoints: latency-svc-mc55b [751.094047ms]
Dec 10 17:39:40.236: INFO: Created: latency-svc-ntrpv
Dec 10 17:39:40.271: INFO: Got endpoints: latency-svc-q95nr [748.244676ms]
Dec 10 17:39:40.281: INFO: Created: latency-svc-p4nc2
Dec 10 17:39:40.323: INFO: Got endpoints: latency-svc-dztnz [751.2516ms]
Dec 10 17:39:40.334: INFO: Created: latency-svc-7nf65
Dec 10 17:39:40.371: INFO: Got endpoints: latency-svc-qcg4g [746.695862ms]
Dec 10 17:39:40.381: INFO: Created: latency-svc-x9qmf
Dec 10 17:39:40.421: INFO: Got endpoints: latency-svc-k9djv [748.119514ms]
Dec 10 17:39:40.432: INFO: Created: latency-svc-tmlhp
Dec 10 17:39:40.475: INFO: Got endpoints: latency-svc-bbzs5 [742.939683ms]
Dec 10 17:39:40.486: INFO: Created: latency-svc-gprjm
Dec 10 17:39:40.522: INFO: Got endpoints: latency-svc-hw4jt [749.120492ms]
Dec 10 17:39:40.531: INFO: Created: latency-svc-dgf6p
Dec 10 17:39:40.577: INFO: Got endpoints: latency-svc-m9nhm [752.376155ms]
Dec 10 17:39:40.588: INFO: Created: latency-svc-2c7c4
Dec 10 17:39:40.624: INFO: Got endpoints: latency-svc-b55mx [709.581747ms]
Dec 10 17:39:40.632: INFO: Created: latency-svc-r8vjv
Dec 10 17:39:40.675: INFO: Got endpoints: latency-svc-995nb [754.542984ms]
Dec 10 17:39:40.685: INFO: Created: latency-svc-7cdb9
Dec 10 17:39:40.722: INFO: Got endpoints: latency-svc-znhdb [748.666012ms]
Dec 10 17:39:40.734: INFO: Created: latency-svc-nsdf6
Dec 10 17:39:40.770: INFO: Got endpoints: latency-svc-4hkr7 [750.903462ms]
Dec 10 17:39:40.784: INFO: Created: latency-svc-btrrq
Dec 10 17:39:40.831: INFO: Got endpoints: latency-svc-7wvp9 [762.161911ms]
Dec 10 17:39:40.843: INFO: Created: latency-svc-4ncst
Dec 10 17:39:40.874: INFO: Got endpoints: latency-svc-5fn5m [728.790485ms]
Dec 10 17:39:40.881: INFO: Created: latency-svc-44chr
Dec 10 17:39:40.922: INFO: Got endpoints: latency-svc-8hx7l [740.386705ms]
Dec 10 17:39:40.932: INFO: Created: latency-svc-kcrtn
Dec 10 17:39:40.974: INFO: Got endpoints: latency-svc-ntrpv [750.170036ms]
Dec 10 17:39:40.984: INFO: Created: latency-svc-8d7sx
Dec 10 17:39:41.019: INFO: Got endpoints: latency-svc-p4nc2 [747.671219ms]
Dec 10 17:39:41.031: INFO: Created: latency-svc-chtvd
Dec 10 17:39:41.072: INFO: Got endpoints: latency-svc-7nf65 [748.285274ms]
Dec 10 17:39:41.081: INFO: Created: latency-svc-9vnts
Dec 10 17:39:41.125: INFO: Got endpoints: latency-svc-x9qmf [753.984076ms]
Dec 10 17:39:41.140: INFO: Created: latency-svc-mpchf
Dec 10 17:39:41.173: INFO: Got endpoints: latency-svc-tmlhp [752.115928ms]
Dec 10 17:39:41.182: INFO: Created: latency-svc-6b9wz
Dec 10 17:39:41.274: INFO: Got endpoints: latency-svc-gprjm [799.093104ms]
Dec 10 17:39:41.283: INFO: Created: latency-svc-k4bg5
Dec 10 17:39:41.319: INFO: Got endpoints: latency-svc-dgf6p [796.839512ms]
Dec 10 17:39:41.332: INFO: Created: latency-svc-c679b
Dec 10 17:39:41.384: INFO: Got endpoints: latency-svc-2c7c4 [806.650968ms]
Dec 10 17:39:41.395: INFO: Created: latency-svc-rtbxx
Dec 10 17:39:41.418: INFO: Got endpoints: latency-svc-r8vjv [794.320503ms]
Dec 10 17:39:41.433: INFO: Created: latency-svc-smw8v
Dec 10 17:39:41.473: INFO: Got endpoints: latency-svc-7cdb9 [798.315383ms]
Dec 10 17:39:41.483: INFO: Created: latency-svc-8ksvg
Dec 10 17:39:41.523: INFO: Got endpoints: latency-svc-nsdf6 [800.736425ms]
Dec 10 17:39:41.534: INFO: Created: latency-svc-cvqcz
Dec 10 17:39:41.571: INFO: Got endpoints: latency-svc-btrrq [800.768138ms]
Dec 10 17:39:41.581: INFO: Created: latency-svc-47vbd
Dec 10 17:39:41.626: INFO: Got endpoints: latency-svc-4ncst [794.2772ms]
Dec 10 17:39:41.636: INFO: Created: latency-svc-gt88p
Dec 10 17:39:41.672: INFO: Got endpoints: latency-svc-44chr [798.88959ms]
Dec 10 17:39:41.681: INFO: Created: latency-svc-cxrpr
Dec 10 17:39:41.724: INFO: Got endpoints: latency-svc-kcrtn [801.201756ms]
Dec 10 17:39:41.736: INFO: Created: latency-svc-lq255
Dec 10 17:39:41.769: INFO: Got endpoints: latency-svc-8d7sx [794.127639ms]
Dec 10 17:39:41.780: INFO: Created: latency-svc-jfvff
Dec 10 17:39:41.821: INFO: Got endpoints: latency-svc-chtvd [801.77193ms]
Dec 10 17:39:41.832: INFO: Created: latency-svc-l8r9p
Dec 10 17:39:41.872: INFO: Got endpoints: latency-svc-9vnts [799.369908ms]
Dec 10 17:39:41.880: INFO: Created: latency-svc-9frmh
Dec 10 17:39:41.922: INFO: Got endpoints: latency-svc-mpchf [795.830912ms]
Dec 10 17:39:41.930: INFO: Created: latency-svc-dt85z
Dec 10 17:39:41.973: INFO: Got endpoints: latency-svc-6b9wz [798.905117ms]
Dec 10 17:39:41.984: INFO: Created: latency-svc-jdxpr
Dec 10 17:39:42.038: INFO: Got endpoints: latency-svc-k4bg5 [764.231542ms]
Dec 10 17:39:42.052: INFO: Created: latency-svc-vbwxw
Dec 10 17:39:42.073: INFO: Got endpoints: latency-svc-c679b [754.292096ms]
Dec 10 17:39:42.082: INFO: Created: latency-svc-9znxt
Dec 10 17:39:42.122: INFO: Got endpoints: latency-svc-rtbxx [737.983781ms]
Dec 10 17:39:42.130: INFO: Created: latency-svc-jqvpv
Dec 10 17:39:42.170: INFO: Got endpoints: latency-svc-smw8v [751.528199ms]
Dec 10 17:39:42.179: INFO: Created: latency-svc-ql2bb
Dec 10 17:39:42.223: INFO: Got endpoints: latency-svc-8ksvg [749.657952ms]
Dec 10 17:39:42.232: INFO: Created: latency-svc-w7bjq
Dec 10 17:39:42.277: INFO: Got endpoints: latency-svc-cvqcz [752.907558ms]
Dec 10 17:39:42.300: INFO: Created: latency-svc-df65l
Dec 10 17:39:42.322: INFO: Got endpoints: latency-svc-47vbd [750.074566ms]
Dec 10 17:39:42.332: INFO: Created: latency-svc-jvrvf
Dec 10 17:39:42.370: INFO: Got endpoints: latency-svc-gt88p [743.865359ms]
Dec 10 17:39:42.378: INFO: Created: latency-svc-zj9rl
Dec 10 17:39:42.422: INFO: Got endpoints: latency-svc-cxrpr [749.672071ms]
Dec 10 17:39:42.430: INFO: Created: latency-svc-dq2jr
Dec 10 17:39:42.471: INFO: Got endpoints: latency-svc-lq255 [746.394819ms]
Dec 10 17:39:42.479: INFO: Created: latency-svc-gtth4
Dec 10 17:39:42.523: INFO: Got endpoints: latency-svc-jfvff [753.586244ms]
Dec 10 17:39:42.530: INFO: Created: latency-svc-np88b
Dec 10 17:39:42.582: INFO: Got endpoints: latency-svc-l8r9p [760.216227ms]
Dec 10 17:39:42.591: INFO: Created: latency-svc-wb8lm
Dec 10 17:39:42.622: INFO: Got endpoints: latency-svc-9frmh [749.427584ms]
Dec 10 17:39:42.630: INFO: Created: latency-svc-5dcqf
Dec 10 17:39:42.670: INFO: Got endpoints: latency-svc-dt85z [747.996288ms]
Dec 10 17:39:42.684: INFO: Created: latency-svc-cggs5
Dec 10 17:39:42.723: INFO: Got endpoints: latency-svc-jdxpr [749.761861ms]
Dec 10 17:39:42.732: INFO: Created: latency-svc-8848k
Dec 10 17:39:42.783: INFO: Got endpoints: latency-svc-vbwxw [743.638195ms]
Dec 10 17:39:42.815: INFO: Created: latency-svc-kp2rx
Dec 10 17:39:42.835: INFO: Got endpoints: latency-svc-9znxt [761.048952ms]
Dec 10 17:39:42.854: INFO: Created: latency-svc-4gfsg
Dec 10 17:39:42.906: INFO: Got endpoints: latency-svc-jqvpv [783.503461ms]
Dec 10 17:39:42.933: INFO: Got endpoints: latency-svc-ql2bb [762.071621ms]
Dec 10 17:39:42.934: INFO: Created: latency-svc-5zbmz
Dec 10 17:39:42.941: INFO: Created: latency-svc-znmjb
Dec 10 17:39:42.976: INFO: Got endpoints: latency-svc-w7bjq [751.693797ms]
Dec 10 17:39:42.987: INFO: Created: latency-svc-r9r6f
Dec 10 17:39:43.027: INFO: Got endpoints: latency-svc-df65l [750.422494ms]
Dec 10 17:39:43.051: INFO: Created: latency-svc-bn4q6
Dec 10 17:39:43.083: INFO: Got endpoints: latency-svc-jvrvf [761.119528ms]
Dec 10 17:39:43.108: INFO: Created: latency-svc-wnz9b
Dec 10 17:39:43.132: INFO: Got endpoints: latency-svc-zj9rl [761.522446ms]
Dec 10 17:39:43.146: INFO: Created: latency-svc-5kk5g
Dec 10 17:39:43.178: INFO: Got endpoints: latency-svc-dq2jr [754.614931ms]
Dec 10 17:39:43.195: INFO: Created: latency-svc-pnjzr
Dec 10 17:39:43.227: INFO: Got endpoints: latency-svc-gtth4 [755.398404ms]
Dec 10 17:39:43.237: INFO: Created: latency-svc-fsm7c
Dec 10 17:39:43.273: INFO: Got endpoints: latency-svc-np88b [749.671088ms]
Dec 10 17:39:43.287: INFO: Created: latency-svc-xghz7
Dec 10 17:39:43.322: INFO: Got endpoints: latency-svc-wb8lm [738.932675ms]
Dec 10 17:39:43.330: INFO: Created: latency-svc-h78z6
Dec 10 17:39:43.373: INFO: Got endpoints: latency-svc-5dcqf [751.170377ms]
Dec 10 17:39:43.382: INFO: Created: latency-svc-gj5fz
Dec 10 17:39:43.431: INFO: Got endpoints: latency-svc-cggs5 [760.134773ms]
Dec 10 17:39:43.485: INFO: Created: latency-svc-vfzrf
Dec 10 17:39:43.520: INFO: Got endpoints: latency-svc-8848k [796.347609ms]
Dec 10 17:39:43.544: INFO: Got endpoints: latency-svc-kp2rx [760.669067ms]
Dec 10 17:39:43.549: INFO: Created: latency-svc-fsrrm
Dec 10 17:39:43.554: INFO: Created: latency-svc-9dtnw
Dec 10 17:39:43.570: INFO: Got endpoints: latency-svc-4gfsg [734.871978ms]
Dec 10 17:39:43.584: INFO: Created: latency-svc-ftpql
Dec 10 17:39:43.625: INFO: Got endpoints: latency-svc-5zbmz [717.79331ms]
Dec 10 17:39:43.637: INFO: Created: latency-svc-thb9z
Dec 10 17:39:43.673: INFO: Got endpoints: latency-svc-znmjb [739.281807ms]
Dec 10 17:39:43.686: INFO: Created: latency-svc-59x4x
Dec 10 17:39:43.725: INFO: Got endpoints: latency-svc-r9r6f [748.533292ms]
Dec 10 17:39:43.744: INFO: Created: latency-svc-hmnjt
Dec 10 17:39:43.802: INFO: Got endpoints: latency-svc-bn4q6 [774.279459ms]
Dec 10 17:39:43.824: INFO: Created: latency-svc-mh6qs
Dec 10 17:39:43.844: INFO: Got endpoints: latency-svc-wnz9b [760.721511ms]
Dec 10 17:39:43.855: INFO: Created: latency-svc-2vfc7
Dec 10 17:39:43.872: INFO: Got endpoints: latency-svc-5kk5g [738.695326ms]
Dec 10 17:39:43.883: INFO: Created: latency-svc-4ztqn
Dec 10 17:39:43.921: INFO: Got endpoints: latency-svc-pnjzr [743.325093ms]
Dec 10 17:39:43.930: INFO: Created: latency-svc-hf8zm
Dec 10 17:39:43.973: INFO: Got endpoints: latency-svc-fsm7c [745.23457ms]
Dec 10 17:39:43.987: INFO: Created: latency-svc-ftw8v
Dec 10 17:39:44.022: INFO: Got endpoints: latency-svc-xghz7 [748.91874ms]
Dec 10 17:39:44.032: INFO: Created: latency-svc-k5bsn
Dec 10 17:39:44.074: INFO: Got endpoints: latency-svc-h78z6 [751.950412ms]
Dec 10 17:39:44.086: INFO: Created: latency-svc-tdtdw
Dec 10 17:39:44.123: INFO: Got endpoints: latency-svc-gj5fz [749.759804ms]
Dec 10 17:39:44.130: INFO: Created: latency-svc-hpxqp
Dec 10 17:39:44.173: INFO: Got endpoints: latency-svc-vfzrf [741.722401ms]
Dec 10 17:39:44.188: INFO: Created: latency-svc-7sdfs
Dec 10 17:39:44.224: INFO: Got endpoints: latency-svc-fsrrm [704.301239ms]
Dec 10 17:39:44.235: INFO: Created: latency-svc-2jn47
Dec 10 17:39:44.272: INFO: Got endpoints: latency-svc-9dtnw [727.851282ms]
Dec 10 17:39:44.283: INFO: Created: latency-svc-chs6c
Dec 10 17:39:44.320: INFO: Got endpoints: latency-svc-ftpql [748.988269ms]
Dec 10 17:39:44.332: INFO: Created: latency-svc-fcghg
Dec 10 17:39:44.372: INFO: Got endpoints: latency-svc-thb9z [746.285235ms]
Dec 10 17:39:44.381: INFO: Created: latency-svc-dcfgg
Dec 10 17:39:44.423: INFO: Got endpoints: latency-svc-59x4x [749.511334ms]
Dec 10 17:39:44.438: INFO: Created: latency-svc-zgwxc
Dec 10 17:39:44.473: INFO: Got endpoints: latency-svc-hmnjt [747.906303ms]
Dec 10 17:39:44.482: INFO: Created: latency-svc-xmdxs
Dec 10 17:39:44.527: INFO: Got endpoints: latency-svc-mh6qs [723.850778ms]
Dec 10 17:39:44.538: INFO: Created: latency-svc-pn482
Dec 10 17:39:44.571: INFO: Got endpoints: latency-svc-2vfc7 [726.254152ms]
Dec 10 17:39:44.581: INFO: Created: latency-svc-2gf2t
Dec 10 17:39:44.619: INFO: Got endpoints: latency-svc-4ztqn [745.746545ms]
Dec 10 17:39:44.630: INFO: Created: latency-svc-7qh5f
Dec 10 17:39:44.673: INFO: Got endpoints: latency-svc-hf8zm [750.77922ms]
Dec 10 17:39:44.685: INFO: Created: latency-svc-znn84
Dec 10 17:39:44.723: INFO: Got endpoints: latency-svc-ftw8v [749.998947ms]
Dec 10 17:39:44.737: INFO: Created: latency-svc-qf5fj
Dec 10 17:39:44.773: INFO: Got endpoints: latency-svc-k5bsn [750.212415ms]
Dec 10 17:39:44.783: INFO: Created: latency-svc-mdg88
Dec 10 17:39:44.829: INFO: Got endpoints: latency-svc-tdtdw [754.916536ms]
Dec 10 17:39:44.839: INFO: Created: latency-svc-rkm45
Dec 10 17:39:44.875: INFO: Got endpoints: latency-svc-hpxqp [752.033761ms]
Dec 10 17:39:44.902: INFO: Created: latency-svc-c6q86
Dec 10 17:39:44.926: INFO: Got endpoints: latency-svc-7sdfs [752.802851ms]
Dec 10 17:39:44.951: INFO: Created: latency-svc-h62wk
Dec 10 17:39:44.976: INFO: Got endpoints: latency-svc-2jn47 [751.558368ms]
Dec 10 17:39:44.998: INFO: Created: latency-svc-v5264
Dec 10 17:39:45.037: INFO: Got endpoints: latency-svc-chs6c [763.913468ms]
Dec 10 17:39:45.059: INFO: Created: latency-svc-td4hs
Dec 10 17:39:45.083: INFO: Got endpoints: latency-svc-fcghg [762.638652ms]
Dec 10 17:39:45.103: INFO: Created: latency-svc-ns8h5
Dec 10 17:39:45.126: INFO: Got endpoints: latency-svc-dcfgg [753.569186ms]
Dec 10 17:39:45.145: INFO: Created: latency-svc-gx5qk
Dec 10 17:39:45.171: INFO: Got endpoints: latency-svc-zgwxc [747.929666ms]
Dec 10 17:39:45.183: INFO: Created: latency-svc-9wgpv
Dec 10 17:39:45.236: INFO: Got endpoints: latency-svc-xmdxs [763.508452ms]
Dec 10 17:39:45.254: INFO: Created: latency-svc-snrlc
Dec 10 17:39:45.272: INFO: Got endpoints: latency-svc-pn482 [744.927874ms]
Dec 10 17:39:45.281: INFO: Created: latency-svc-ff289
Dec 10 17:39:45.323: INFO: Got endpoints: latency-svc-2gf2t [750.920578ms]
Dec 10 17:39:45.338: INFO: Created: latency-svc-jlnfs
Dec 10 17:39:45.370: INFO: Got endpoints: latency-svc-7qh5f [750.778664ms]
Dec 10 17:39:45.380: INFO: Created: latency-svc-hcw4r
Dec 10 17:39:45.421: INFO: Got endpoints: latency-svc-znn84 [747.655405ms]
Dec 10 17:39:45.434: INFO: Created: latency-svc-62tcb
Dec 10 17:39:45.478: INFO: Got endpoints: latency-svc-qf5fj [753.997782ms]
Dec 10 17:39:45.523: INFO: Got endpoints: latency-svc-mdg88 [749.673944ms]
Dec 10 17:39:45.581: INFO: Got endpoints: latency-svc-rkm45 [751.187288ms]
Dec 10 17:39:45.624: INFO: Got endpoints: latency-svc-c6q86 [748.432831ms]
Dec 10 17:39:45.673: INFO: Got endpoints: latency-svc-h62wk [746.50064ms]
Dec 10 17:39:45.721: INFO: Got endpoints: latency-svc-v5264 [744.641043ms]
Dec 10 17:39:45.770: INFO: Got endpoints: latency-svc-td4hs [733.454338ms]
Dec 10 17:39:45.823: INFO: Got endpoints: latency-svc-ns8h5 [740.18175ms]
Dec 10 17:39:45.869: INFO: Got endpoints: latency-svc-gx5qk [741.93991ms]
Dec 10 17:39:45.922: INFO: Got endpoints: latency-svc-9wgpv [750.069095ms]
Dec 10 17:39:45.970: INFO: Got endpoints: latency-svc-snrlc [730.568903ms]
Dec 10 17:39:46.021: INFO: Got endpoints: latency-svc-ff289 [748.534967ms]
Dec 10 17:39:46.072: INFO: Got endpoints: latency-svc-jlnfs [748.211702ms]
Dec 10 17:39:46.123: INFO: Got endpoints: latency-svc-hcw4r [752.954744ms]
Dec 10 17:39:46.171: INFO: Got endpoints: latency-svc-62tcb [750.148239ms]
Dec 10 17:39:46.171: INFO: Latencies: [35.111808ms 40.914154ms 51.400009ms 68.332267ms 76.354105ms 103.083948ms 103.391514ms 104.738379ms 104.762747ms 138.257562ms 141.285902ms 141.357979ms 141.43487ms 141.558085ms 149.027677ms 167.915282ms 170.930826ms 171.550695ms 175.003035ms 176.056035ms 177.678972ms 181.051564ms 183.680331ms 192.417929ms 192.997989ms 193.844583ms 193.89894ms 201.61996ms 201.790838ms 206.845667ms 208.053502ms 214.683648ms 215.172458ms 221.687402ms 225.84344ms 226.264729ms 228.756144ms 241.223648ms 249.436242ms 250.759617ms 251.437679ms 266.390626ms 273.329055ms 312.053351ms 364.661342ms 399.467381ms 452.318956ms 508.760315ms 539.77074ms 589.951127ms 623.67066ms 642.121975ms 685.585942ms 697.374601ms 704.301239ms 709.581747ms 711.050023ms 717.79331ms 723.850778ms 726.254152ms 726.888847ms 727.013735ms 727.851282ms 728.790485ms 730.568903ms 732.16645ms 733.454338ms 734.871978ms 737.304368ms 737.983781ms 738.338246ms 738.695326ms 738.932675ms 739.281807ms 740.18175ms 740.386705ms 740.672565ms 741.336427ms 741.722401ms 741.93991ms 742.939683ms 743.325093ms 743.638195ms 743.865359ms 744.517862ms 744.641043ms 744.927874ms 745.23457ms 745.307527ms 745.746545ms 746.285235ms 746.394819ms 746.464683ms 746.50064ms 746.695862ms 747.150694ms 747.160169ms 747.655405ms 747.671219ms 747.906303ms 747.929666ms 747.996288ms 748.020023ms 748.050942ms 748.119514ms 748.201864ms 748.211702ms 748.244676ms 748.285274ms 748.432831ms 748.533292ms 748.534967ms 748.637207ms 748.666012ms 748.91874ms 748.988269ms 749.120492ms 749.427584ms 749.511334ms 749.603463ms 749.657952ms 749.671088ms 749.672071ms 749.673944ms 749.759804ms 749.761861ms 749.998947ms 750.069095ms 750.074566ms 750.148239ms 750.170036ms 750.212415ms 750.366217ms 750.422494ms 750.463531ms 750.485189ms 750.571333ms 750.778664ms 750.77922ms 750.903462ms 750.920578ms 751.094047ms 751.170377ms 751.187288ms 751.2516ms 751.528199ms 751.558368ms 751.693797ms 751.718232ms 751.950412ms 752.033761ms 752.115928ms 752.376155ms 752.802851ms 752.907558ms 752.954744ms 753.569186ms 753.586244ms 753.984076ms 753.997782ms 754.292096ms 754.542984ms 754.614931ms 754.916536ms 755.398404ms 759.061312ms 760.134773ms 760.155393ms 760.216227ms 760.669067ms 760.721511ms 761.048952ms 761.119528ms 761.522446ms 762.071621ms 762.161911ms 762.638652ms 763.508452ms 763.913468ms 764.231542ms 771.376303ms 774.279459ms 783.503461ms 790.673729ms 794.127639ms 794.2772ms 794.320503ms 795.830912ms 796.347609ms 796.839512ms 798.315383ms 798.88959ms 798.905117ms 799.093104ms 799.369908ms 800.736425ms 800.768138ms 801.201756ms 801.77193ms 806.650968ms]
Dec 10 17:39:46.172: INFO: 50 %ile: 747.929666ms
Dec 10 17:39:46.172: INFO: 90 %ile: 771.376303ms
Dec 10 17:39:46.172: INFO: 99 %ile: 801.77193ms
Dec 10 17:39:46.172: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:46.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5517" for this suite.

• [SLOW TEST:10.844 seconds]
[sig-network] Service endpoints latency
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":346,"completed":177,"skipped":3598,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:46.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:39:46.731: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:39:49.758: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 10 17:39:51.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=webhook-7964 attach --namespace=webhook-7964 to-be-attached-pod -i -c=container1'
Dec 10 17:39:52.514: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:52.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7964" for this suite.
STEP: Destroying namespace "webhook-7964-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.407 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":346,"completed":178,"skipped":3626,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:52.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:39:52.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c" in namespace "projected-7929" to be "Succeeded or Failed"
Dec 10 17:39:52.696: INFO: Pod "downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.216115ms
Dec 10 17:39:54.708: INFO: Pod "downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026346316s
STEP: Saw pod success
Dec 10 17:39:54.708: INFO: Pod "downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c" satisfied condition "Succeeded or Failed"
Dec 10 17:39:54.711: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c container client-container: <nil>
STEP: delete the pod
Dec 10 17:39:54.724: INFO: Waiting for pod downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c to disappear
Dec 10 17:39:54.727: INFO: Pod downwardapi-volume-fc46252d-2fab-4319-9264-5e975ef7326c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:39:54.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7929" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":179,"skipped":3632,"failed":0}
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:39:54.740: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-9367
[It] should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-9367
Dec 10 17:39:54.889: INFO: Found 0 stateful pods, waiting for 1
Dec 10 17:40:04.909: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Dec 10 17:40:04.960: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Dec 10 17:40:04.976: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Dec 10 17:40:04.979: INFO: Observed &StatefulSet event: ADDED
Dec 10 17:40:04.979: INFO: Found Statefulset ss in namespace statefulset-9367 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 10 17:40:04.980: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Dec 10 17:40:04.980: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 10 17:40:04.994: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Dec 10 17:40:05.004: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:40:05.005: INFO: Deleting all statefulset in ns statefulset-9367
Dec 10 17:40:05.008: INFO: Scaling statefulset ss to 0
Dec 10 17:40:15.070: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:40:15.071: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:15.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9367" for this suite.

• [SLOW TEST:20.352 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should validate Statefulset Status endpoints [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":346,"completed":180,"skipped":3637,"failed":0}
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:15.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:15.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8351" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":181,"skipped":3642,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:15.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 17:40:15.202: INFO: Waiting up to 5m0s for pod "pod-fed35785-c99e-4044-8c46-55c789de253f" in namespace "emptydir-5605" to be "Succeeded or Failed"
Dec 10 17:40:15.208: INFO: Pod "pod-fed35785-c99e-4044-8c46-55c789de253f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.223137ms
Dec 10 17:40:17.215: INFO: Pod "pod-fed35785-c99e-4044-8c46-55c789de253f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012162896s
Dec 10 17:40:19.223: INFO: Pod "pod-fed35785-c99e-4044-8c46-55c789de253f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019945677s
STEP: Saw pod success
Dec 10 17:40:19.223: INFO: Pod "pod-fed35785-c99e-4044-8c46-55c789de253f" satisfied condition "Succeeded or Failed"
Dec 10 17:40:19.225: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-fed35785-c99e-4044-8c46-55c789de253f container test-container: <nil>
STEP: delete the pod
Dec 10 17:40:19.238: INFO: Waiting for pod pod-fed35785-c99e-4044-8c46-55c789de253f to disappear
Dec 10 17:40:19.242: INFO: Pod pod-fed35785-c99e-4044-8c46-55c789de253f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:19.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5605" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":182,"skipped":3661,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:19.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-18b7fd91-e794-4d7c-9844-1b59ae0d9f8c
STEP: Creating a pod to test consume configMaps
Dec 10 17:40:19.304: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378" in namespace "projected-2155" to be "Succeeded or Failed"
Dec 10 17:40:19.316: INFO: Pod "pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378": Phase="Pending", Reason="", readiness=false. Elapsed: 11.289587ms
Dec 10 17:40:21.327: INFO: Pod "pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022806034s
STEP: Saw pod success
Dec 10 17:40:21.328: INFO: Pod "pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378" satisfied condition "Succeeded or Failed"
Dec 10 17:40:21.330: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:40:21.344: INFO: Waiting for pod pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378 to disappear
Dec 10 17:40:21.347: INFO: Pod pod-projected-configmaps-4519e78c-082d-47f2-804f-4fb5f78d8378 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:21.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2155" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":183,"skipped":3689,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3344, will wait for the garbage collector to delete the pods
Dec 10 17:40:25.486: INFO: Deleting Job.batch foo took: 6.864669ms
Dec 10 17:40:25.590: INFO: Terminating Job.batch foo pods took: 104.237029ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:57.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3344" for this suite.

• [SLOW TEST:36.343 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":346,"completed":184,"skipped":3711,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:57.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 10 17:40:58.858: INFO: The status of Pod kube-controller-manager-ip-10-0-4-83 is Running (Ready = true)
Dec 10 17:40:59.151: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:59.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5296" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":346,"completed":185,"skipped":3723,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:59.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 10 17:40:59.232: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3476  857639f5-edc5-4e0a-bdc3-d67884792b98 21183 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:40:59.232: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3476  857639f5-edc5-4e0a-bdc3-d67884792b98 21184 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 10 17:40:59.243: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3476  857639f5-edc5-4e0a-bdc3-d67884792b98 21185 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:40:59.243: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3476  857639f5-edc5-4e0a-bdc3-d67884792b98 21186 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:40:59.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3476" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":346,"completed":186,"skipped":3729,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:40:59.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 10 17:40:59.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21193 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:40:59.295: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21194 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:40:59.296: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21195 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 10 17:41:09.333: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21260 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:41:09.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21261 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 10 17:41:09.335: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2861  fe13a878-7279-4533-a843-433d7136e308 21262 0 2021-12-10 17:40:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-12-10 17:40:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:09.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2861" for this suite.

• [SLOW TEST:10.100 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":346,"completed":187,"skipped":3739,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:09.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-5f8f66ac-0d68-4726-b428-a0559edac2a8
STEP: Creating a pod to test consume configMaps
Dec 10 17:41:09.439: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae" in namespace "projected-3117" to be "Succeeded or Failed"
Dec 10 17:41:09.440: INFO: Pod "pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae": Phase="Pending", Reason="", readiness=false. Elapsed: 1.823461ms
Dec 10 17:41:11.446: INFO: Pod "pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00707229s
STEP: Saw pod success
Dec 10 17:41:11.446: INFO: Pod "pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae" satisfied condition "Succeeded or Failed"
Dec 10 17:41:11.449: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:41:11.463: INFO: Waiting for pod pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae to disappear
Dec 10 17:41:11.466: INFO: Pod pod-projected-configmaps-212cdcb2-85bb-46b0-9043-f042af6267ae no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:11.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3117" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":188,"skipped":3779,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:11.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's args
Dec 10 17:41:11.528: INFO: Waiting up to 5m0s for pod "var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0" in namespace "var-expansion-4326" to be "Succeeded or Failed"
Dec 10 17:41:11.532: INFO: Pod "var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.259405ms
Dec 10 17:41:13.537: INFO: Pod "var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008387288s
STEP: Saw pod success
Dec 10 17:41:13.537: INFO: Pod "var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0" satisfied condition "Succeeded or Failed"
Dec 10 17:41:13.541: INFO: Trying to get logs from node ip-10-0-19-34 pod var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:41:13.559: INFO: Waiting for pod var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0 to disappear
Dec 10 17:41:13.562: INFO: Pod var-expansion-e24c3ed0-778e-452d-82eb-caf90e7c75a0 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:13.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4326" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":346,"completed":189,"skipped":3795,"failed":0}
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:13.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 17:41:15.647: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:15.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9272" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":190,"skipped":3800,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:15.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:41:16.199: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:41:19.240: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:19.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8954" for this suite.
STEP: Destroying namespace "webhook-8954-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":346,"completed":191,"skipped":3800,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:19.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:41:19.843: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:41:22.861: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:22.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5773" for this suite.
STEP: Destroying namespace "webhook-5773-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":346,"completed":192,"skipped":3822,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:22.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:41:23.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691" in namespace "projected-4608" to be "Succeeded or Failed"
Dec 10 17:41:23.050: INFO: Pod "downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691": Phase="Pending", Reason="", readiness=false. Elapsed: 8.349219ms
Dec 10 17:41:25.059: INFO: Pod "downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016662115s
STEP: Saw pod success
Dec 10 17:41:25.059: INFO: Pod "downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691" satisfied condition "Succeeded or Failed"
Dec 10 17:41:25.061: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691 container client-container: <nil>
STEP: delete the pod
Dec 10 17:41:25.078: INFO: Waiting for pod downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691 to disappear
Dec 10 17:41:25.081: INFO: Pod downwardapi-volume-1ffbf07e-b6d8-47e5-bc9e-7529aae02691 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:25.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4608" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":193,"skipped":3833,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:25.092: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Starting the proxy
Dec 10 17:41:25.128: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8136 proxy --unix-socket=/tmp/kubectl-proxy-unix3040536124/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:25.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8136" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":346,"completed":194,"skipped":3843,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:25.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test service account token: 
Dec 10 17:41:25.229: INFO: Waiting up to 5m0s for pod "test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862" in namespace "svcaccounts-2626" to be "Succeeded or Failed"
Dec 10 17:41:25.231: INFO: Pod "test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074017ms
Dec 10 17:41:27.236: INFO: Pod "test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007231985s
STEP: Saw pod success
Dec 10 17:41:27.236: INFO: Pod "test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862" satisfied condition "Succeeded or Failed"
Dec 10 17:41:27.238: INFO: Trying to get logs from node ip-10-0-19-34 pod test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:41:27.254: INFO: Waiting for pod test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862 to disappear
Dec 10 17:41:27.258: INFO: Pod test-pod-c8797823-79d5-498b-a0c1-d5d7f4181862 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:27.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2626" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":346,"completed":195,"skipped":3854,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:27.269: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Dec 10 17:41:27.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:42.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6281" for this suite.

• [SLOW TEST:15.105 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":346,"completed":196,"skipped":3854,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:42.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:42.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4090" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":346,"completed":197,"skipped":3864,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:42.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Dec 10 17:41:42.478: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 17:41:42.491: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 17:41:42.493: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-0-54 before test
Dec 10 17:41:42.497: INFO: coredns-77c7788bfd-wgnt8 from kube-system started at 2021-12-10 16:43:15 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.498: INFO: 	Container coredns ready: true, restart count 0
Dec 10 17:41:42.498: INFO: flannel-v6cj5 from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.498: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:41:42.498: INFO: kube-proxy-n8zvk from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.499: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:41:42.499: INFO: sonobuoy from sonobuoy started at 2021-12-10 16:39:55 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.499: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 17:41:42.499: INFO: sonobuoy-e2e-job-8d0bd5401ee442a1 from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:41:42.499: INFO: 	Container e2e ready: true, restart count 0
Dec 10 17:41:42.499: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:41:42.499: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:41:42.500: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:41:42.500: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 10 17:41:42.500: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-19-34 before test
Dec 10 17:41:42.504: INFO: flannel-rjcp9 from kube-system started at 2021-12-10 16:43:16 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.504: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:41:42.504: INFO: kube-proxy-p6vhv from kube-system started at 2021-12-10 16:43:17 +0000 UTC (1 container statuses recorded)
Dec 10 17:41:42.505: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:41:42.505: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-x75pd from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:41:42.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:41:42.505: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16bf759c0f6faf54], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/controller: }, that the pod didn't tolerate, 2 node(s) didn't match Pod's node affinity/selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:43.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-14" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":346,"completed":198,"skipped":3891,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:43.532: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:41:43.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d" in namespace "projected-2240" to be "Succeeded or Failed"
Dec 10 17:41:43.578: INFO: Pod "downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.932878ms
Dec 10 17:41:45.588: INFO: Pod "downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012479574s
Dec 10 17:41:47.600: INFO: Pod "downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024656522s
STEP: Saw pod success
Dec 10 17:41:47.600: INFO: Pod "downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d" satisfied condition "Succeeded or Failed"
Dec 10 17:41:47.607: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d container client-container: <nil>
STEP: delete the pod
Dec 10 17:41:47.630: INFO: Waiting for pod downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d to disappear
Dec 10 17:41:47.635: INFO: Pod downwardapi-volume-af6a82c8-597c-4f8e-a7d6-0ee192e2cb0d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:47.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2240" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":199,"skipped":3906,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:47.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pods
Dec 10 17:41:47.711: INFO: created test-pod-1
Dec 10 17:41:49.723: INFO: running and ready test-pod-1
Dec 10 17:41:49.730: INFO: created test-pod-2
Dec 10 17:41:53.740: INFO: running and ready test-pod-2
Dec 10 17:41:53.745: INFO: created test-pod-3
Dec 10 17:41:57.754: INFO: running and ready test-pod-3
STEP: waiting for all 3 pods to be located
STEP: waiting for all pods to be deleted
Dec 10 17:41:57.782: INFO: Pod quantity 3 is different from expected quantity 0
Dec 10 17:41:58.787: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:41:59.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-936" for this suite.

• [SLOW TEST:12.148 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":346,"completed":200,"skipped":3909,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:41:59.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:41:59.845: INFO: Waiting up to 5m0s for pod "downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3" in namespace "downward-api-462" to be "Succeeded or Failed"
Dec 10 17:41:59.848: INFO: Pod "downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404217ms
Dec 10 17:42:01.857: INFO: Pod "downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011159227s
Dec 10 17:42:03.865: INFO: Pod "downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0195205s
STEP: Saw pod success
Dec 10 17:42:03.865: INFO: Pod "downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3" satisfied condition "Succeeded or Failed"
Dec 10 17:42:03.868: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3 container client-container: <nil>
STEP: delete the pod
Dec 10 17:42:03.884: INFO: Waiting for pod downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3 to disappear
Dec 10 17:42:03.886: INFO: Pod downwardapi-volume-573b6899-76fa-4c15-8b5d-2115909e25b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:42:03.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-462" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":201,"skipped":3931,"failed":0}
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:42:03.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Dec 10 17:42:03.972: INFO: Waiting up to 5m0s for pod "downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433" in namespace "downward-api-4104" to be "Succeeded or Failed"
Dec 10 17:42:04.001: INFO: Pod "downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433": Phase="Pending", Reason="", readiness=false. Elapsed: 28.684042ms
Dec 10 17:42:06.008: INFO: Pod "downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035754634s
STEP: Saw pod success
Dec 10 17:42:06.009: INFO: Pod "downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433" satisfied condition "Succeeded or Failed"
Dec 10 17:42:06.011: INFO: Trying to get logs from node ip-10-0-19-34 pod downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:42:06.029: INFO: Waiting for pod downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433 to disappear
Dec 10 17:42:06.032: INFO: Pod downward-api-77950da4-6809-42f2-8ed9-ca4e9c3ee433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:42:06.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4104" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":346,"completed":202,"skipped":3936,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:42:06.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 10 17:42:06.086: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:42:08.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:42:18.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4722" for this suite.

• [SLOW TEST:12.197 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":346,"completed":203,"skipped":3940,"failed":0}
SSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:42:18.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:42:18.282: INFO: Endpoints addresses: [10.0.4.83] , ports: [6443]
Dec 10 17:42:18.283: INFO: EndpointSlices addresses: [10.0.4.83] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:42:18.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7005" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":346,"completed":204,"skipped":3946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:42:18.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5633
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-5633
I1210 17:42:18.349274      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5633, replica count: 2
I1210 17:42:21.401033      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:42:21.402: INFO: Creating new exec pod
Dec 10 17:42:26.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 17:42:26.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:26.721: INFO: stdout: ""
Dec 10 17:42:27.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 17:42:27.873: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:27.873: INFO: stdout: ""
Dec 10 17:42:28.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 17:42:28.969: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:28.969: INFO: stdout: ""
Dec 10 17:42:29.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 17:42:30.124: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:30.125: INFO: stdout: "externalname-service-xjvp7"
Dec 10 17:42:30.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:30.432: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\n+ echo hostName\nConnection to 10.3.3.51 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:30.432: INFO: stdout: ""
Dec 10 17:42:31.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:31.609: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\n+ echo hostName\nConnection to 10.3.3.51 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:31.609: INFO: stdout: ""
Dec 10 17:42:32.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:32.703: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\nConnection to 10.3.3.51 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:42:32.703: INFO: stdout: ""
Dec 10 17:42:33.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:33.616: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\n+ echo hostName\nConnection to 10.3.3.51 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:33.616: INFO: stdout: ""
Dec 10 17:42:34.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:34.628: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\nConnection to 10.3.3.51 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:42:34.628: INFO: stdout: ""
Dec 10 17:42:35.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5633 exec execpodxkqz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.3.51 80'
Dec 10 17:42:35.605: INFO: stderr: "+ nc -v -t -w 2 10.3.3.51 80\n+ Connection to 10.3.3.51 80 port [tcp/http] succeeded!\necho hostName\n"
Dec 10 17:42:35.606: INFO: stdout: "externalname-service-xjvp7"
Dec 10 17:42:35.606: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:42:35.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5633" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:17.386 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":346,"completed":205,"skipped":3987,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:42:35.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-7468
Dec 10 17:42:35.767: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:42:37.778: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 10 17:42:37.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 10 17:42:37.961: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 10 17:42:37.961: INFO: stdout: "ipvs"
Dec 10 17:42:37.961: INFO: proxyMode: ipvs
Dec 10 17:42:37.970: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 10 17:42:37.972: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-7468
STEP: creating replication controller affinity-clusterip-timeout in namespace services-7468
I1210 17:42:37.994570      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-7468, replica count: 3
I1210 17:42:41.049529      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:42:41.055: INFO: Creating new exec pod
Dec 10 17:42:44.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec execpod-affinity4kpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Dec 10 17:42:44.338: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:44.338: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:42:44.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec execpod-affinity4kpl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.176.156 80'
Dec 10 17:42:44.492: INFO: stderr: "+ nc -v -t -w 2 10.3.176.156 80\n+ echo hostName\nConnection to 10.3.176.156 80 port [tcp/http] succeeded!\n"
Dec 10 17:42:44.492: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:42:44.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec execpod-affinity4kpl9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.176.156:80/ ; done'
Dec 10 17:42:44.749: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n"
Dec 10 17:42:44.750: INFO: stdout: "\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd\naffinity-clusterip-timeout-tqhkd"
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Received response from host: affinity-clusterip-timeout-tqhkd
Dec 10 17:42:44.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec execpod-affinity4kpl9 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.176.156:80/'
Dec 10 17:42:44.906: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n"
Dec 10 17:42:44.906: INFO: stdout: "affinity-clusterip-timeout-tqhkd"
Dec 10 17:44:54.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-7468 exec execpod-affinity4kpl9 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.176.156:80/'
Dec 10 17:44:55.157: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.176.156:80/\n"
Dec 10 17:44:55.157: INFO: stdout: "affinity-clusterip-timeout-9dsxt"
Dec 10 17:44:55.157: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-7468, will wait for the garbage collector to delete the pods
Dec 10 17:44:55.230: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.455039ms
Dec 10 17:44:55.330: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.503187ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:44:57.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7468" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:142.240 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":206,"skipped":4015,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:44:57.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1571
[It] should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Dec 10 17:44:57.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3505 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 10 17:44:58.100: INFO: stderr: ""
Dec 10 17:44:58.100: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 10 17:45:03.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3505 get pod e2e-test-httpd-pod -o json'
Dec 10 17:45:03.213: INFO: stderr: ""
Dec 10 17:45:03.213: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2021-12-10T17:44:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3505\",\n        \"resourceVersion\": \"22360\",\n        \"uid\": \"6641e497-5027-465c-a37e-6f6466131bd8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-mk7m5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-19-34\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-mk7m5\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-12-10T17:44:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-12-10T17:44:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-12-10T17:44:59Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-12-10T17:44:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0dd6742796113dfd0a56c18c684628d4fad2d343499a23b0edc13316a4fb3644\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2021-12-10T17:44:58Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.19.34\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.1.99\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.1.99\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2021-12-10T17:44:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 10 17:45:03.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3505 replace -f -'
Dec 10 17:45:04.515: INFO: stderr: ""
Dec 10 17:45:04.515: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1575
Dec 10 17:45:04.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3505 delete pods e2e-test-httpd-pod'
Dec 10 17:45:07.140: INFO: stderr: ""
Dec 10 17:45:07.140: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:07.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3505" for this suite.

• [SLOW TEST:9.229 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
    should update a single-container pod's image  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":346,"completed":207,"skipped":4019,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:07.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:45:07.200: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 10 17:45:09.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-4213 --namespace=crd-publish-openapi-4213 create -f -'
Dec 10 17:45:10.733: INFO: stderr: ""
Dec 10 17:45:10.733: INFO: stdout: "e2e-test-crd-publish-openapi-1931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 10 17:45:10.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-4213 --namespace=crd-publish-openapi-4213 delete e2e-test-crd-publish-openapi-1931-crds test-cr'
Dec 10 17:45:10.850: INFO: stderr: ""
Dec 10 17:45:10.850: INFO: stdout: "e2e-test-crd-publish-openapi-1931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 10 17:45:10.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-4213 --namespace=crd-publish-openapi-4213 apply -f -'
Dec 10 17:45:11.056: INFO: stderr: ""
Dec 10 17:45:11.056: INFO: stdout: "e2e-test-crd-publish-openapi-1931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 10 17:45:11.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-4213 --namespace=crd-publish-openapi-4213 delete e2e-test-crd-publish-openapi-1931-crds test-cr'
Dec 10 17:45:11.128: INFO: stderr: ""
Dec 10 17:45:11.128: INFO: stdout: "e2e-test-crd-publish-openapi-1931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 10 17:45:11.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=crd-publish-openapi-4213 explain e2e-test-crd-publish-openapi-1931-crds'
Dec 10 17:45:11.317: INFO: stderr: ""
Dec 10 17:45:11.317: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1931-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:13.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4213" for this suite.

• [SLOW TEST:6.318 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":346,"completed":208,"skipped":4024,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:13.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service nodeport-test with type=NodePort in namespace services-8265
STEP: creating replication controller nodeport-test in namespace services-8265
I1210 17:45:13.536189      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8265, replica count: 2
I1210 17:45:16.590928      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:45:16.591: INFO: Creating new exec pod
Dec 10 17:45:19.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 10 17:45:19.851: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 10 17:45:19.851: INFO: stdout: "nodeport-test-bwvsj"
Dec 10 17:45:19.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.172.23 80'
Dec 10 17:45:20.055: INFO: stderr: "+ nc -v -t -w 2 10.3.172.23 80\n+ echo hostName\nConnection to 10.3.172.23 80 port [tcp/http] succeeded!\n"
Dec 10 17:45:20.055: INFO: stdout: "nodeport-test-c8pf8"
Dec 10 17:45:20.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.54 30611'
Dec 10 17:45:20.223: INFO: stderr: "+ nc -v -t -w 2 10.0.0.54 30611\n+ echo hostName\nConnection to 10.0.0.54 30611 port [tcp/*] succeeded!\n"
Dec 10 17:45:20.223: INFO: stdout: "nodeport-test-bwvsj"
Dec 10 17:45:20.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:20.359: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 17:45:20.359: INFO: stdout: ""
Dec 10 17:45:21.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:21.551: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\n+ echo hostName\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n"
Dec 10 17:45:21.551: INFO: stdout: ""
Dec 10 17:45:22.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:22.570: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 17:45:22.570: INFO: stdout: ""
Dec 10 17:45:23.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:23.517: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\n+ echo hostName\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n"
Dec 10 17:45:23.517: INFO: stdout: ""
Dec 10 17:45:24.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:24.680: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 17:45:24.680: INFO: stdout: ""
Dec 10 17:45:25.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-8265 exec execpod7rcvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30611'
Dec 10 17:45:25.500: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30611\n+ echo hostName\nConnection to 10.0.19.34 30611 port [tcp/*] succeeded!\n"
Dec 10 17:45:25.500: INFO: stdout: "nodeport-test-c8pf8"
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:25.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8265" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:12.040 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":346,"completed":209,"skipped":4045,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:25.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 10 17:45:25.599: INFO: Waiting up to 5m0s for pod "pod-2b80bd34-5705-4eba-8345-42a8c812057d" in namespace "emptydir-1338" to be "Succeeded or Failed"
Dec 10 17:45:25.605: INFO: Pod "pod-2b80bd34-5705-4eba-8345-42a8c812057d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.526578ms
Dec 10 17:45:27.611: INFO: Pod "pod-2b80bd34-5705-4eba-8345-42a8c812057d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011967549s
Dec 10 17:45:29.619: INFO: Pod "pod-2b80bd34-5705-4eba-8345-42a8c812057d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019244492s
STEP: Saw pod success
Dec 10 17:45:29.619: INFO: Pod "pod-2b80bd34-5705-4eba-8345-42a8c812057d" satisfied condition "Succeeded or Failed"
Dec 10 17:45:29.621: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-2b80bd34-5705-4eba-8345-42a8c812057d container test-container: <nil>
STEP: delete the pod
Dec 10 17:45:29.658: INFO: Waiting for pod pod-2b80bd34-5705-4eba-8345-42a8c812057d to disappear
Dec 10 17:45:29.661: INFO: Pod pod-2b80bd34-5705-4eba-8345-42a8c812057d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:29.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1338" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":210,"skipped":4061,"failed":0}
SS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:29.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Dec 10 17:45:29.743: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Dec 10 17:45:29.750: INFO: starting watch
STEP: patching
STEP: updating
Dec 10 17:45:29.771: INFO: waiting for watch events with expected annotations
Dec 10 17:45:29.772: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9785" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":346,"completed":211,"skipped":4063,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:29.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-9512/configmap-test-d592a5cf-dbe9-44d4-b18c-141c7922bfa9
STEP: Creating a pod to test consume configMaps
Dec 10 17:45:29.875: INFO: Waiting up to 5m0s for pod "pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545" in namespace "configmap-9512" to be "Succeeded or Failed"
Dec 10 17:45:29.879: INFO: Pod "pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946766ms
Dec 10 17:45:31.884: INFO: Pod "pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008697654s
Dec 10 17:45:33.890: INFO: Pod "pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014360101s
STEP: Saw pod success
Dec 10 17:45:33.890: INFO: Pod "pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545" satisfied condition "Succeeded or Failed"
Dec 10 17:45:33.892: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545 container env-test: <nil>
STEP: delete the pod
Dec 10 17:45:33.904: INFO: Waiting for pod pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545 to disappear
Dec 10 17:45:33.907: INFO: Pod pod-configmaps-e2543d42-7f74-429f-83fa-da61f2cd8545 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:33.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9512" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":212,"skipped":4074,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:33.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating cluster-info
Dec 10 17:45:33.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-6072 cluster-info'
Dec 10 17:45:34.105: INFO: stderr: ""
Dec 10 17:45:34.105: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:34.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6072" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":346,"completed":213,"skipped":4078,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:34.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:34.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6126" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":346,"completed":214,"skipped":4087,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:34.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Dec 10 17:45:34.220: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:45:36.226: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Dec 10 17:45:36.235: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:45:38.243: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Dec 10 17:45:38.250: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 17:45:38.252: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 17:45:40.253: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 17:45:40.261: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 17:45:42.253: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 17:45:42.261: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:42.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3105" for this suite.

• [SLOW TEST:8.132 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":346,"completed":215,"skipped":4094,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:42.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Dec 10 17:45:42.393: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 17:45:42.397: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 17:45:42.399: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-0-54 before test
Dec 10 17:45:42.404: INFO: pod-handle-http-request from container-lifecycle-hook-3105 started at 2021-12-10 17:45:34 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.405: INFO: 	Container agnhost-container ready: true, restart count 0
Dec 10 17:45:42.405: INFO: coredns-77c7788bfd-wgnt8 from kube-system started at 2021-12-10 16:43:15 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.406: INFO: 	Container coredns ready: true, restart count 0
Dec 10 17:45:42.406: INFO: flannel-v6cj5 from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.406: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:45:42.408: INFO: kube-proxy-n8zvk from kube-system started at 2021-12-10 16:33:51 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.408: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:45:42.408: INFO: sonobuoy from sonobuoy started at 2021-12-10 16:39:55 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.409: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 17:45:42.409: INFO: sonobuoy-e2e-job-8d0bd5401ee442a1 from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:45:42.421: INFO: 	Container e2e ready: true, restart count 0
Dec 10 17:45:42.421: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:45:42.421: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:45:42.421: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:45:42.421: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 10 17:45:42.421: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-19-34 before test
Dec 10 17:45:42.432: INFO: flannel-rjcp9 from kube-system started at 2021-12-10 16:43:16 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.432: INFO: 	Container flannel ready: true, restart count 0
Dec 10 17:45:42.432: INFO: kube-proxy-p6vhv from kube-system started at 2021-12-10 16:43:17 +0000 UTC (1 container statuses recorded)
Dec 10 17:45:42.432: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 17:45:42.432: INFO: sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-x75pd from sonobuoy started at 2021-12-10 16:39:58 +0000 UTC (2 container statuses recorded)
Dec 10 17:45:42.432: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 17:45:42.432: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: verifying the node has the label node ip-10-0-0-54
STEP: verifying the node has the label node ip-10-0-19-34
Dec 10 17:45:42.480: INFO: Pod pod-handle-http-request requesting resource cpu=0m on Node ip-10-0-0-54
Dec 10 17:45:42.480: INFO: Pod coredns-77c7788bfd-wgnt8 requesting resource cpu=100m on Node ip-10-0-0-54
Dec 10 17:45:42.481: INFO: Pod flannel-rjcp9 requesting resource cpu=100m on Node ip-10-0-19-34
Dec 10 17:45:42.481: INFO: Pod flannel-v6cj5 requesting resource cpu=100m on Node ip-10-0-0-54
Dec 10 17:45:42.481: INFO: Pod kube-proxy-n8zvk requesting resource cpu=0m on Node ip-10-0-0-54
Dec 10 17:45:42.481: INFO: Pod kube-proxy-p6vhv requesting resource cpu=0m on Node ip-10-0-19-34
Dec 10 17:45:42.481: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-0-54
Dec 10 17:45:42.481: INFO: Pod sonobuoy-e2e-job-8d0bd5401ee442a1 requesting resource cpu=0m on Node ip-10-0-0-54
Dec 10 17:45:42.482: INFO: Pod sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-qcmrl requesting resource cpu=0m on Node ip-10-0-0-54
Dec 10 17:45:42.482: INFO: Pod sonobuoy-systemd-logs-daemon-set-0b5cc4503c0e4a72-x75pd requesting resource cpu=0m on Node ip-10-0-19-34
STEP: Starting Pods to consume most of the cluster CPU.
Dec 10 17:45:42.482: INFO: Creating a pod which consumes cpu=560m on Node ip-10-0-0-54
Dec 10 17:45:42.489: INFO: Creating a pod which consumes cpu=630m on Node ip-10-0-19-34
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b.16bf75d3efa54079], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4286/filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b to ip-10-0-19-34]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b.16bf75d42814337e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b.16bf75d42afc2100], Reason = [Created], Message = [Created container filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b.16bf75d4305fafd5], Reason = [Started], Message = [Started container filler-pod-14e5a46d-1e0d-4408-bdd9-4495b085ed6b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f.16bf75d3ef1661df], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4286/filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f to ip-10-0-0-54]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f.16bf75d4315f4435], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f.16bf75d43459cb02], Reason = [Created], Message = [Created container filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f.16bf75d43b62b0bc], Reason = [Started], Message = [Started container filler-pod-a63bce61-9ba3-41fb-b6bb-86c283c67e8f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16bf75d4e0cdedcb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/controller: }, that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-0-54
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-19-34
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:47.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4286" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:5.307 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":346,"completed":216,"skipped":4141,"failed":0}
S
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:47.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pod templates
Dec 10 17:45:47.648: INFO: created test-podtemplate-1
Dec 10 17:45:47.652: INFO: created test-podtemplate-2
Dec 10 17:45:47.657: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Dec 10 17:45:47.661: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Dec 10 17:45:47.670: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:45:47.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2687" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":346,"completed":217,"skipped":4142,"failed":0}

------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:45:47.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-secret-f4m8
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 17:45:47.727: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-f4m8" in namespace "subpath-1847" to be "Succeeded or Failed"
Dec 10 17:45:47.729: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.974308ms
Dec 10 17:45:49.737: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 2.009730403s
Dec 10 17:45:51.747: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 4.019719877s
Dec 10 17:45:53.755: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 6.027897151s
Dec 10 17:45:55.763: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 8.035876705s
Dec 10 17:45:57.772: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 10.045051553s
Dec 10 17:45:59.778: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 12.051091882s
Dec 10 17:46:01.881: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 14.153636911s
Dec 10 17:46:03.890: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 16.162803052s
Dec 10 17:46:05.901: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 18.173524531s
Dec 10 17:46:07.906: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 20.178338427s
Dec 10 17:46:09.909: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Running", Reason="", readiness=true. Elapsed: 22.182068693s
Dec 10 17:46:11.920: INFO: Pod "pod-subpath-test-secret-f4m8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.192401496s
STEP: Saw pod success
Dec 10 17:46:11.921: INFO: Pod "pod-subpath-test-secret-f4m8" satisfied condition "Succeeded or Failed"
Dec 10 17:46:11.926: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-subpath-test-secret-f4m8 container test-container-subpath-secret-f4m8: <nil>
STEP: delete the pod
Dec 10 17:46:11.940: INFO: Waiting for pod pod-subpath-test-secret-f4m8 to disappear
Dec 10 17:46:11.942: INFO: Pod pod-subpath-test-secret-f4m8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-f4m8
Dec 10 17:46:11.942: INFO: Deleting pod "pod-subpath-test-secret-f4m8" in namespace "subpath-1847"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:11.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1847" for this suite.

• [SLOW TEST:24.265 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":218,"skipped":4142,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:11.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:46:12.066: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5e1bf473-70ae-4e42-b3ce-a1994fd2a734", Controller:(*bool)(0xc00554ad86), BlockOwnerDeletion:(*bool)(0xc00554ad87)}}
Dec 10 17:46:12.073: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"aa534b22-f41e-43e9-9ef9-4c34d24e01e3", Controller:(*bool)(0xc00554b106), BlockOwnerDeletion:(*bool)(0xc00554b107)}}
Dec 10 17:46:12.082: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bf8143fd-aea7-4ec5-bd51-2958e295c2a3", Controller:(*bool)(0xc00554b3de), BlockOwnerDeletion:(*bool)(0xc00554b3df)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:17.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1463" for this suite.

• [SLOW TEST:5.145 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":346,"completed":219,"skipped":4160,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:17.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name projected-secret-test-d2b0a3a2-612e-43b0-8426-cba403f15ffe
STEP: Creating a pod to test consume secrets
Dec 10 17:46:17.163: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f" in namespace "projected-268" to be "Succeeded or Failed"
Dec 10 17:46:17.168: INFO: Pod "pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705456ms
Dec 10 17:46:19.181: INFO: Pod "pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017517768s
Dec 10 17:46:21.186: INFO: Pod "pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022254138s
STEP: Saw pod success
Dec 10 17:46:21.186: INFO: Pod "pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f" satisfied condition "Succeeded or Failed"
Dec 10 17:46:21.189: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:46:21.204: INFO: Waiting for pod pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f to disappear
Dec 10 17:46:21.205: INFO: Pod pod-projected-secrets-4f5205a7-e0fc-4e22-8feb-20dbc2f0261f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:21.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-268" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":220,"skipped":4169,"failed":0}
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:21.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-gw4c7 in namespace proxy-2448
I1210 17:46:21.283205      20 runners.go:193] Created replication controller with name: proxy-service-gw4c7, namespace: proxy-2448, replica count: 1
I1210 17:46:22.339553      20 runners.go:193] proxy-service-gw4c7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 17:46:23.340723      20 runners.go:193] proxy-service-gw4c7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 17:46:24.340898      20 runners.go:193] proxy-service-gw4c7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:46:24.348: INFO: setup took 3.091821048s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 10 17:46:24.365: INFO: (0) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 16.204793ms)
Dec 10 17:46:24.365: INFO: (0) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 16.467348ms)
Dec 10 17:46:24.372: INFO: (0) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 23.245096ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 23.432276ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 23.70381ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 23.545701ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 23.400688ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 23.669132ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 23.416212ms)
Dec 10 17:46:24.373: INFO: (0) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 23.899553ms)
Dec 10 17:46:24.375: INFO: (0) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 26.485939ms)
Dec 10 17:46:24.382: INFO: (0) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 32.484805ms)
Dec 10 17:46:24.382: INFO: (0) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 32.435561ms)
Dec 10 17:46:24.383: INFO: (0) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 33.851445ms)
Dec 10 17:46:24.383: INFO: (0) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 33.565353ms)
Dec 10 17:46:24.383: INFO: (0) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 33.77976ms)
Dec 10 17:46:24.394: INFO: (1) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 10.872012ms)
Dec 10 17:46:24.402: INFO: (1) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 18.601299ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 18.581773ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 18.916414ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 19.447802ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 19.744719ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 19.548178ms)
Dec 10 17:46:24.403: INFO: (1) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 19.384822ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 19.991559ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 19.812321ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 19.973402ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 19.902406ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 19.621551ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 19.967807ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 20.867282ms)
Dec 10 17:46:24.404: INFO: (1) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 19.702122ms)
Dec 10 17:46:24.418: INFO: (2) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 11.790231ms)
Dec 10 17:46:24.419: INFO: (2) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.179721ms)
Dec 10 17:46:24.420: INFO: (2) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 12.794433ms)
Dec 10 17:46:24.421: INFO: (2) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 14.149863ms)
Dec 10 17:46:24.421: INFO: (2) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.577954ms)
Dec 10 17:46:24.422: INFO: (2) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 14.700221ms)
Dec 10 17:46:24.422: INFO: (2) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 14.918709ms)
Dec 10 17:46:24.422: INFO: (2) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 15.007815ms)
Dec 10 17:46:24.422: INFO: (2) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 15.706747ms)
Dec 10 17:46:24.423: INFO: (2) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 15.913426ms)
Dec 10 17:46:24.423: INFO: (2) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 16.428125ms)
Dec 10 17:46:24.423: INFO: (2) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 15.977125ms)
Dec 10 17:46:24.423: INFO: (2) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 16.311474ms)
Dec 10 17:46:24.424: INFO: (2) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 17.047977ms)
Dec 10 17:46:24.424: INFO: (2) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 16.926334ms)
Dec 10 17:46:24.424: INFO: (2) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 16.644448ms)
Dec 10 17:46:24.436: INFO: (3) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 11.327055ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 11.481041ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 12.033763ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.95774ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 11.914769ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.791985ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 12.301402ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 12.251185ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 12.538388ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.191832ms)
Dec 10 17:46:24.437: INFO: (3) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 12.571566ms)
Dec 10 17:46:24.438: INFO: (3) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 12.867813ms)
Dec 10 17:46:24.438: INFO: (3) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 12.552308ms)
Dec 10 17:46:24.438: INFO: (3) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 13.255885ms)
Dec 10 17:46:24.438: INFO: (3) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 12.548745ms)
Dec 10 17:46:24.438: INFO: (3) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.964719ms)
Dec 10 17:46:24.449: INFO: (4) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 9.162315ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.104056ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 11.789951ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 11.619887ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 11.567761ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 11.403539ms)
Dec 10 17:46:24.453: INFO: (4) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.293965ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 13.289103ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 13.647315ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 12.654107ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.16963ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 13.29087ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.240558ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 12.846343ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 13.578266ms)
Dec 10 17:46:24.454: INFO: (4) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 12.804351ms)
Dec 10 17:46:24.468: INFO: (5) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.702677ms)
Dec 10 17:46:24.468: INFO: (5) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.531154ms)
Dec 10 17:46:24.469: INFO: (5) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.883706ms)
Dec 10 17:46:24.469: INFO: (5) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 13.186281ms)
Dec 10 17:46:24.469: INFO: (5) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.936167ms)
Dec 10 17:46:24.469: INFO: (5) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 13.846031ms)
Dec 10 17:46:24.469: INFO: (5) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.83553ms)
Dec 10 17:46:24.470: INFO: (5) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 14.527698ms)
Dec 10 17:46:24.471: INFO: (5) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 14.985155ms)
Dec 10 17:46:24.471: INFO: (5) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 15.276376ms)
Dec 10 17:46:24.471: INFO: (5) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 15.72409ms)
Dec 10 17:46:24.471: INFO: (5) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 15.721315ms)
Dec 10 17:46:24.472: INFO: (5) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 16.061974ms)
Dec 10 17:46:24.472: INFO: (5) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 16.209003ms)
Dec 10 17:46:24.472: INFO: (5) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 16.903513ms)
Dec 10 17:46:24.472: INFO: (5) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 16.96679ms)
Dec 10 17:46:24.483: INFO: (6) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 9.939773ms)
Dec 10 17:46:24.484: INFO: (6) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 11.393248ms)
Dec 10 17:46:24.484: INFO: (6) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 11.197285ms)
Dec 10 17:46:24.484: INFO: (6) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.310165ms)
Dec 10 17:46:24.484: INFO: (6) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 11.124506ms)
Dec 10 17:46:24.486: INFO: (6) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.072887ms)
Dec 10 17:46:24.487: INFO: (6) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 14.233304ms)
Dec 10 17:46:24.487: INFO: (6) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 14.126922ms)
Dec 10 17:46:24.487: INFO: (6) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 14.079256ms)
Dec 10 17:46:24.487: INFO: (6) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 14.044376ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.64315ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 14.832494ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 15.117418ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 15.29132ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 15.098249ms)
Dec 10 17:46:24.488: INFO: (6) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 15.057835ms)
Dec 10 17:46:24.502: INFO: (7) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.285672ms)
Dec 10 17:46:24.503: INFO: (7) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 11.959584ms)
Dec 10 17:46:24.503: INFO: (7) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 12.625215ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.837619ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 13.034014ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.091407ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 13.512801ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.585235ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 13.979446ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 13.236955ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.057877ms)
Dec 10 17:46:24.504: INFO: (7) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 13.433765ms)
Dec 10 17:46:24.505: INFO: (7) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 13.805119ms)
Dec 10 17:46:24.505: INFO: (7) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 14.352466ms)
Dec 10 17:46:24.505: INFO: (7) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.460624ms)
Dec 10 17:46:24.505: INFO: (7) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 14.098313ms)
Dec 10 17:46:24.517: INFO: (8) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 10.059656ms)
Dec 10 17:46:24.522: INFO: (8) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 14.391283ms)
Dec 10 17:46:24.522: INFO: (8) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 14.819225ms)
Dec 10 17:46:24.522: INFO: (8) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 15.419576ms)
Dec 10 17:46:24.523: INFO: (8) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 15.187679ms)
Dec 10 17:46:24.523: INFO: (8) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 15.249434ms)
Dec 10 17:46:24.523: INFO: (8) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 15.730425ms)
Dec 10 17:46:24.523: INFO: (8) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 16.253815ms)
Dec 10 17:46:24.524: INFO: (8) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 16.721693ms)
Dec 10 17:46:24.524: INFO: (8) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 16.304098ms)
Dec 10 17:46:24.542: INFO: (8) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 34.832085ms)
Dec 10 17:46:24.543: INFO: (8) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 35.271138ms)
Dec 10 17:46:24.543: INFO: (8) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 35.762852ms)
Dec 10 17:46:24.543: INFO: (8) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 36.177385ms)
Dec 10 17:46:24.543: INFO: (8) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 36.176086ms)
Dec 10 17:46:24.544: INFO: (8) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 35.998024ms)
Dec 10 17:46:24.554: INFO: (9) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 10.346649ms)
Dec 10 17:46:24.557: INFO: (9) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.417358ms)
Dec 10 17:46:24.558: INFO: (9) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 13.267747ms)
Dec 10 17:46:24.559: INFO: (9) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 14.951436ms)
Dec 10 17:46:24.560: INFO: (9) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 15.275447ms)
Dec 10 17:46:24.560: INFO: (9) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 15.544197ms)
Dec 10 17:46:24.560: INFO: (9) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 16.195866ms)
Dec 10 17:46:24.561: INFO: (9) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 16.119196ms)
Dec 10 17:46:24.561: INFO: (9) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 17.200144ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 17.211582ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 17.749993ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 17.716999ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 17.520271ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 17.859909ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 17.601969ms)
Dec 10 17:46:24.562: INFO: (9) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 17.16445ms)
Dec 10 17:46:24.574: INFO: (10) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 9.878456ms)
Dec 10 17:46:24.574: INFO: (10) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 10.454956ms)
Dec 10 17:46:24.574: INFO: (10) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 9.977112ms)
Dec 10 17:46:24.575: INFO: (10) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 10.608894ms)
Dec 10 17:46:24.575: INFO: (10) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 10.81762ms)
Dec 10 17:46:24.575: INFO: (10) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 11.181005ms)
Dec 10 17:46:24.575: INFO: (10) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 11.050258ms)
Dec 10 17:46:24.576: INFO: (10) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 12.118748ms)
Dec 10 17:46:24.577: INFO: (10) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.202481ms)
Dec 10 17:46:24.577: INFO: (10) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 13.313035ms)
Dec 10 17:46:24.577: INFO: (10) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.277059ms)
Dec 10 17:46:24.578: INFO: (10) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.151991ms)
Dec 10 17:46:24.579: INFO: (10) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 14.733615ms)
Dec 10 17:46:24.579: INFO: (10) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 15.057911ms)
Dec 10 17:46:24.579: INFO: (10) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 15.105307ms)
Dec 10 17:46:24.579: INFO: (10) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 15.271375ms)
Dec 10 17:46:24.590: INFO: (11) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 10.622727ms)
Dec 10 17:46:24.591: INFO: (11) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 11.138825ms)
Dec 10 17:46:24.591: INFO: (11) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.41872ms)
Dec 10 17:46:24.591: INFO: (11) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.123073ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 11.988767ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 12.07661ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.967789ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 12.18286ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.109364ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 12.301605ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.243936ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 12.124343ms)
Dec 10 17:46:24.592: INFO: (11) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.155579ms)
Dec 10 17:46:24.593: INFO: (11) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 13.174217ms)
Dec 10 17:46:24.593: INFO: (11) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 12.990466ms)
Dec 10 17:46:24.593: INFO: (11) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 13.127751ms)
Dec 10 17:46:24.608: INFO: (12) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.868306ms)
Dec 10 17:46:24.608: INFO: (12) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 11.756062ms)
Dec 10 17:46:24.609: INFO: (12) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 12.560381ms)
Dec 10 17:46:24.609: INFO: (12) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 12.631864ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.200818ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.968425ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.296562ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 13.621662ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.801025ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.413736ms)
Dec 10 17:46:24.610: INFO: (12) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.94692ms)
Dec 10 17:46:24.611: INFO: (12) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.170999ms)
Dec 10 17:46:24.611: INFO: (12) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 14.397827ms)
Dec 10 17:46:24.611: INFO: (12) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 14.848694ms)
Dec 10 17:46:24.611: INFO: (12) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 14.456999ms)
Dec 10 17:46:24.611: INFO: (12) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.823906ms)
Dec 10 17:46:24.620: INFO: (13) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 9.138476ms)
Dec 10 17:46:24.623: INFO: (13) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 11.308133ms)
Dec 10 17:46:24.623: INFO: (13) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 11.673254ms)
Dec 10 17:46:24.624: INFO: (13) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.87396ms)
Dec 10 17:46:24.624: INFO: (13) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 12.14821ms)
Dec 10 17:46:24.624: INFO: (13) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 12.634637ms)
Dec 10 17:46:24.625: INFO: (13) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.837032ms)
Dec 10 17:46:24.625: INFO: (13) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.121406ms)
Dec 10 17:46:24.625: INFO: (13) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.429855ms)
Dec 10 17:46:24.625: INFO: (13) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 14.323583ms)
Dec 10 17:46:24.626: INFO: (13) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.827736ms)
Dec 10 17:46:24.626: INFO: (13) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 14.768279ms)
Dec 10 17:46:24.626: INFO: (13) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 14.326571ms)
Dec 10 17:46:24.626: INFO: (13) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 15.278268ms)
Dec 10 17:46:24.627: INFO: (13) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 15.530121ms)
Dec 10 17:46:24.627: INFO: (13) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.963457ms)
Dec 10 17:46:24.637: INFO: (14) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 9.674926ms)
Dec 10 17:46:24.639: INFO: (14) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.901116ms)
Dec 10 17:46:24.639: INFO: (14) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 11.810869ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.23472ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.681883ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 12.197184ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 11.967907ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.481664ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 12.809674ms)
Dec 10 17:46:24.640: INFO: (14) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.694013ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 13.133855ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 13.601463ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 13.294651ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.830419ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 13.360264ms)
Dec 10 17:46:24.641: INFO: (14) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 13.692888ms)
Dec 10 17:46:24.646: INFO: (15) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 4.990598ms)
Dec 10 17:46:24.654: INFO: (15) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.112748ms)
Dec 10 17:46:24.654: INFO: (15) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.360415ms)
Dec 10 17:46:24.656: INFO: (15) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 13.623411ms)
Dec 10 17:46:24.657: INFO: (15) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 14.036916ms)
Dec 10 17:46:24.657: INFO: (15) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 14.64811ms)
Dec 10 17:46:24.658: INFO: (15) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 15.707096ms)
Dec 10 17:46:24.658: INFO: (15) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 16.021759ms)
Dec 10 17:46:24.658: INFO: (15) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 16.569379ms)
Dec 10 17:46:24.659: INFO: (15) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 16.294313ms)
Dec 10 17:46:24.659: INFO: (15) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 16.847838ms)
Dec 10 17:46:24.659: INFO: (15) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 17.135773ms)
Dec 10 17:46:24.659: INFO: (15) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 16.98791ms)
Dec 10 17:46:24.660: INFO: (15) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 17.110939ms)
Dec 10 17:46:24.660: INFO: (15) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 17.632263ms)
Dec 10 17:46:24.660: INFO: (15) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 18.241469ms)
Dec 10 17:46:24.673: INFO: (16) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 12.389326ms)
Dec 10 17:46:24.674: INFO: (16) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 12.809051ms)
Dec 10 17:46:24.674: INFO: (16) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 12.732014ms)
Dec 10 17:46:24.674: INFO: (16) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 12.841829ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.606177ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.387387ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 14.087128ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 14.32086ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.977572ms)
Dec 10 17:46:24.675: INFO: (16) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.475074ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.894607ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 14.728735ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 14.932896ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 15.194223ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 14.805285ms)
Dec 10 17:46:24.676: INFO: (16) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 15.116876ms)
Dec 10 17:46:24.686: INFO: (17) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 9.333347ms)
Dec 10 17:46:24.688: INFO: (17) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.582405ms)
Dec 10 17:46:24.689: INFO: (17) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 12.117406ms)
Dec 10 17:46:24.689: INFO: (17) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.321278ms)
Dec 10 17:46:24.689: INFO: (17) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 12.611778ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.851555ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 13.457781ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 13.415545ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 13.542861ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.994734ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 13.409948ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 13.732322ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 13.235559ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 13.279507ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 13.829057ms)
Dec 10 17:46:24.690: INFO: (17) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.200921ms)
Dec 10 17:46:24.702: INFO: (18) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 9.921183ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.11606ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 11.778781ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 12.333841ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 12.156794ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.957166ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.643416ms)
Dec 10 17:46:24.705: INFO: (18) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.057638ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 13.25976ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 12.757223ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 12.9367ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 13.738405ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 13.435949ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.684443ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.004094ms)
Dec 10 17:46:24.706: INFO: (18) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 13.415659ms)
Dec 10 17:46:24.718: INFO: (19) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 11.527817ms)
Dec 10 17:46:24.719: INFO: (19) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 11.573465ms)
Dec 10 17:46:24.719: INFO: (19) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">... (200; 11.884855ms)
Dec 10 17:46:24.719: INFO: (19) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz/proxy/rewriteme">test</a> (200; 12.634336ms)
Dec 10 17:46:24.719: INFO: (19) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:460/proxy/: tls baz (200; 12.117186ms)
Dec 10 17:46:24.720: INFO: (19) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname2/proxy/: bar (200; 13.156331ms)
Dec 10 17:46:24.720: INFO: (19) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:462/proxy/: tls qux (200; 13.03447ms)
Dec 10 17:46:24.720: INFO: (19) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:162/proxy/: bar (200; 13.776198ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname1/proxy/: tls baz (200; 14.339226ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname1/proxy/: foo (200; 14.002265ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/pods/http:proxy-service-gw4c7-w96jz:160/proxy/: foo (200; 14.078568ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/https:proxy-service-gw4c7-w96jz:443/proxy/tlsrewritem... (200; 14.058525ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2448/pods/proxy-service-gw4c7-w96jz:1080/proxy/rewriteme">test<... (200; 13.964307ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/services/proxy-service-gw4c7:portname2/proxy/: bar (200; 13.741726ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/services/https:proxy-service-gw4c7:tlsportname2/proxy/: tls qux (200; 14.263157ms)
Dec 10 17:46:24.721: INFO: (19) /api/v1/namespaces/proxy-2448/services/http:proxy-service-gw4c7:portname1/proxy/: foo (200; 14.120504ms)
STEP: deleting ReplicationController proxy-service-gw4c7 in namespace proxy-2448, will wait for the garbage collector to delete the pods
Dec 10 17:46:24.781: INFO: Deleting ReplicationController proxy-service-gw4c7 took: 4.822356ms
Dec 10 17:46:24.882: INFO: Terminating ReplicationController proxy-service-gw4c7 pods took: 100.820852ms
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:27.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2448" for this suite.

• [SLOW TEST:6.391 seconds]
[sig-network] Proxy
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":346,"completed":221,"skipped":4170,"failed":0}
SSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:27.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Dec 10 17:46:29.845: INFO: running pods: 0 < 3
Dec 10 17:46:31.859: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:33.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2626" for this suite.

• [SLOW TEST:6.241 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":346,"completed":222,"skipped":4174,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:33.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-8290
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 17:46:33.901: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 10 17:46:33.928: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:46:35.935: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:46:37.933: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:39.935: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:41.945: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:43.935: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:45.936: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:47.936: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:49.937: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:51.939: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:53.960: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:46:55.940: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 10 17:46:55.944: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Dec 10 17:46:57.969: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 10 17:46:57.969: INFO: Breadth first check of 10.2.2.199 on host 10.0.0.54...
Dec 10 17:46:57.972: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.112:9080/dial?request=hostname&protocol=http&host=10.2.2.199&port=8083&tries=1'] Namespace:pod-network-test-8290 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:46:57.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:46:57.973: INFO: ExecWithOptions: Clientset creation
Dec 10 17:46:57.973: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-8290/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.1.112%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.2.199%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:46:58.045: INFO: Waiting for responses: map[]
Dec 10 17:46:58.045: INFO: reached 10.2.2.199 after 0/1 tries
Dec 10 17:46:58.046: INFO: Breadth first check of 10.2.1.111 on host 10.0.19.34...
Dec 10 17:46:58.049: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.112:9080/dial?request=hostname&protocol=http&host=10.2.1.111&port=8083&tries=1'] Namespace:pod-network-test-8290 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:46:58.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:46:58.050: INFO: ExecWithOptions: Clientset creation
Dec 10 17:46:58.050: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-8290/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.1.112%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.1.111%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:46:58.168: INFO: Waiting for responses: map[]
Dec 10 17:46:58.168: INFO: reached 10.2.1.111 after 0/1 tries
Dec 10 17:46:58.168: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:46:58.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8290" for this suite.

• [SLOW TEST:24.313 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":346,"completed":223,"skipped":4189,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:46:58.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:46:58.872: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:47:01.896: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Dec 10 17:47:01.915: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:02.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1898" for this suite.
STEP: Destroying namespace "webhook-1898-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":346,"completed":224,"skipped":4206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:02.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 17:47:02.269: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:02.274: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:47:02.275: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:03.287: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:03.294: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:47:03.295: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:04.281: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:04.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:04.286: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:05.281: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:05.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:05.285: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:06.282: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:06.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:06.285: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:07.286: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:07.290: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:07.290: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:08.280: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:08.283: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:08.283: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:09.280: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:09.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:09.289: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 17:47:10.281: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:10.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 17:47:10.284: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 10 17:47:10.294: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:10.298: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:10.298: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 17:47:11.304: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:11.308: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:11.308: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 17:47:12.304: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:12.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 17:47:12.307: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 17:47:13.304: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 17:47:13.307: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 17:47:13.308: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7742, will wait for the garbage collector to delete the pods
Dec 10 17:47:13.369: INFO: Deleting DaemonSet.extensions daemon-set took: 4.521085ms
Dec 10 17:47:13.472: INFO: Terminating DaemonSet.extensions daemon-set pods took: 103.359023ms
Dec 10 17:47:17.775: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 17:47:17.776: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 17:47:17.779: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23385"},"items":null}

Dec 10 17:47:17.781: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23385"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:17.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7742" for this suite.

• [SLOW TEST:15.613 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":346,"completed":225,"skipped":4228,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:17.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-4dd019e5-1e11-4df9-9c7d-f8d903110023 in namespace container-probe-5836
Dec 10 17:47:19.883: INFO: Started pod liveness-4dd019e5-1e11-4df9-9c7d-f8d903110023 in namespace container-probe-5836
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 17:47:19.886: INFO: Initial restart count of pod liveness-4dd019e5-1e11-4df9-9c7d-f8d903110023 is 0
Dec 10 17:47:39.997: INFO: Restart count of pod container-probe-5836/liveness-4dd019e5-1e11-4df9-9c7d-f8d903110023 is now 1 (20.110980379s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:40.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5836" for this suite.

• [SLOW TEST:22.219 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":226,"skipped":4242,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:40.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating api versions
Dec 10 17:47:40.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-8383 api-versions'
Dec 10 17:47:40.405: INFO: stderr: ""
Dec 10 17:47:40.405: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:40.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8383" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":346,"completed":227,"skipped":4251,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:40.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-64e4e43d-9220-49a3-97b7-e8f32ab3d592
STEP: Creating a pod to test consume secrets
Dec 10 17:47:40.487: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e" in namespace "projected-317" to be "Succeeded or Failed"
Dec 10 17:47:40.489: INFO: Pod "pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.454291ms
Dec 10 17:47:42.496: INFO: Pod "pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009093187s
STEP: Saw pod success
Dec 10 17:47:42.497: INFO: Pod "pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e" satisfied condition "Succeeded or Failed"
Dec 10 17:47:42.499: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:47:42.514: INFO: Waiting for pod pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e to disappear
Dec 10 17:47:42.516: INFO: Pod pod-projected-secrets-b3e4ceeb-716f-43aa-b578-58674b4ec06e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:42.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-317" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":228,"skipped":4256,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:42.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Dec 10 17:47:43.524: INFO: starting watch
STEP: patching
STEP: updating
Dec 10 17:47:43.536: INFO: waiting for watch events with expected annotations
Dec 10 17:47:43.537: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:43.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-5197" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":346,"completed":229,"skipped":4264,"failed":0}
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:43.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-a6c65d6e-ead6-4590-8ae5-8620b0dd5d2a
STEP: Creating a pod to test consume secrets
Dec 10 17:47:43.691: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a" in namespace "projected-2033" to be "Succeeded or Failed"
Dec 10 17:47:43.694: INFO: Pod "pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.923476ms
Dec 10 17:47:45.703: INFO: Pod "pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011704579s
Dec 10 17:47:47.708: INFO: Pod "pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016641407s
STEP: Saw pod success
Dec 10 17:47:47.708: INFO: Pod "pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a" satisfied condition "Succeeded or Failed"
Dec 10 17:47:47.713: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:47:47.729: INFO: Waiting for pod pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a to disappear
Dec 10 17:47:47.734: INFO: Pod pod-projected-secrets-ee45be3e-063d-4ef7-9d00-d79e5a6bce0a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:47:47.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2033" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":230,"skipped":4267,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:47:47.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-bbea83d8-5811-4137-87c0-a2c7badaeaaa in namespace container-probe-2781
Dec 10 17:47:49.804: INFO: Started pod busybox-bbea83d8-5811-4137-87c0-a2c7badaeaaa in namespace container-probe-2781
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 17:47:49.807: INFO: Initial restart count of pod busybox-bbea83d8-5811-4137-87c0-a2c7badaeaaa is 0
Dec 10 17:48:39.977: INFO: Restart count of pod container-probe-2781/busybox-bbea83d8-5811-4137-87c0-a2c7badaeaaa is now 1 (50.170655189s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:39.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2781" for this suite.

• [SLOW TEST:52.258 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":231,"skipped":4317,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:40.002: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Dec 10 17:48:40.065: INFO: Waiting up to 5m0s for pod "downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2" in namespace "downward-api-4586" to be "Succeeded or Failed"
Dec 10 17:48:40.071: INFO: Pod "downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.463307ms
Dec 10 17:48:42.077: INFO: Pod "downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012111854s
STEP: Saw pod success
Dec 10 17:48:42.078: INFO: Pod "downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2" satisfied condition "Succeeded or Failed"
Dec 10 17:48:42.079: INFO: Trying to get logs from node ip-10-0-19-34 pod downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:48:42.093: INFO: Waiting for pod downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2 to disappear
Dec 10 17:48:42.095: INFO: Pod downward-api-b5cb4344-dc0b-4ff2-84f7-3bb61eccf3b2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:42.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4586" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":346,"completed":232,"skipped":4326,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:42.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-7be1f626-8c50-481e-8ee2-891dc76f7010
STEP: Creating a pod to test consume secrets
Dec 10 17:48:42.155: INFO: Waiting up to 5m0s for pod "pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9" in namespace "secrets-270" to be "Succeeded or Failed"
Dec 10 17:48:42.157: INFO: Pod "pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.747994ms
Dec 10 17:48:44.162: INFO: Pod "pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006467197s
STEP: Saw pod success
Dec 10 17:48:44.162: INFO: Pod "pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9" satisfied condition "Succeeded or Failed"
Dec 10 17:48:44.165: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 17:48:44.203: INFO: Waiting for pod pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9 to disappear
Dec 10 17:48:44.207: INFO: Pod pod-secrets-5f009f70-223e-4e86-905c-a7c35a4919b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:44.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-270" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":233,"skipped":4331,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:44.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Dec 10 17:48:44.308: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:48:46.314: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:48:48.315: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Dec 10 17:48:48.324: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:48:50.331: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:48:52.332: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 17:48:52.358: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 17:48:52.362: INFO: Pod pod-with-poststart-http-hook still exists
Dec 10 17:48:54.362: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 17:48:54.368: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:54.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8161" for this suite.

• [SLOW TEST:10.160 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":346,"completed":234,"skipped":4345,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:54.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:48:54.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345" in namespace "downward-api-4869" to be "Succeeded or Failed"
Dec 10 17:48:54.432: INFO: Pod "downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096151ms
Dec 10 17:48:56.439: INFO: Pod "downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011023186s
STEP: Saw pod success
Dec 10 17:48:56.440: INFO: Pod "downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345" satisfied condition "Succeeded or Failed"
Dec 10 17:48:56.443: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345 container client-container: <nil>
STEP: delete the pod
Dec 10 17:48:56.465: INFO: Waiting for pod downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345 to disappear
Dec 10 17:48:56.474: INFO: Pod downwardapi-volume-be9c6d47-c93b-4a78-af62-e1df5d368345 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:56.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4869" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":235,"skipped":4348,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:56.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:56.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-690" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":236,"skipped":4361,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:56.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 17:48:56.770: INFO: Waiting up to 5m0s for pod "pod-50970323-21b0-415b-a980-83f917b699a3" in namespace "emptydir-3206" to be "Succeeded or Failed"
Dec 10 17:48:56.774: INFO: Pod "pod-50970323-21b0-415b-a980-83f917b699a3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738017ms
Dec 10 17:48:58.780: INFO: Pod "pod-50970323-21b0-415b-a980-83f917b699a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009641378s
STEP: Saw pod success
Dec 10 17:48:58.780: INFO: Pod "pod-50970323-21b0-415b-a980-83f917b699a3" satisfied condition "Succeeded or Failed"
Dec 10 17:48:58.782: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-50970323-21b0-415b-a980-83f917b699a3 container test-container: <nil>
STEP: delete the pod
Dec 10 17:48:58.794: INFO: Waiting for pod pod-50970323-21b0-415b-a980-83f917b699a3 to disappear
Dec 10 17:48:58.796: INFO: Pod pod-50970323-21b0-415b-a980-83f917b699a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:48:58.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3206" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":237,"skipped":4362,"failed":0}
SS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:48:58.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:48:58.906: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 10 17:49:03.917: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Dec 10 17:49:03.924: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Dec 10 17:49:03.939: INFO: observed ReplicaSet test-rs in namespace replicaset-2437 with ReadyReplicas 1, AvailableReplicas 1
Dec 10 17:49:03.976: INFO: observed ReplicaSet test-rs in namespace replicaset-2437 with ReadyReplicas 1, AvailableReplicas 1
Dec 10 17:49:04.001: INFO: observed ReplicaSet test-rs in namespace replicaset-2437 with ReadyReplicas 1, AvailableReplicas 1
Dec 10 17:49:04.008: INFO: observed ReplicaSet test-rs in namespace replicaset-2437 with ReadyReplicas 1, AvailableReplicas 1
Dec 10 17:49:05.785: INFO: observed ReplicaSet test-rs in namespace replicaset-2437 with ReadyReplicas 2, AvailableReplicas 2
Dec 10 17:49:06.013: INFO: observed Replicaset test-rs in namespace replicaset-2437 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:06.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2437" for this suite.

• [SLOW TEST:7.216 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":346,"completed":238,"skipped":4364,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:06.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-1934
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 17:49:06.078: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 10 17:49:06.101: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:49:08.106: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:10.109: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:12.105: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:14.105: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:16.107: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:18.108: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:20.108: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:22.108: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:24.105: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:26.129: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:49:28.106: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 10 17:49:28.115: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Dec 10 17:49:32.159: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 10 17:49:32.160: INFO: Going to poll 10.2.2.204 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 10 17:49:32.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.2.204:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1934 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:49:32.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:49:32.164: INFO: ExecWithOptions: Clientset creation
Dec 10 17:49:32.165: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1934/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.2.204%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:49:32.308: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 10 17:49:32.309: INFO: Going to poll 10.2.1.126 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 10 17:49:32.317: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.1.126:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1934 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:49:32.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:49:32.318: INFO: ExecWithOptions: Clientset creation
Dec 10 17:49:32.318: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1934/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.1.126%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:49:32.448: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:32.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1934" for this suite.

• [SLOW TEST:26.429 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":239,"skipped":4396,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:32.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:49:33.122: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:49:36.147: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:49:36.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7891-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:39.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1053" for this suite.
STEP: Destroying namespace "webhook-1053-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.857 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":346,"completed":240,"skipped":4412,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:39.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-8748/configmap-test-b3d2da8b-c9b4-48ca-a21f-83410d2c6ff0
STEP: Creating a pod to test consume configMaps
Dec 10 17:49:39.594: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7" in namespace "configmap-8748" to be "Succeeded or Failed"
Dec 10 17:49:39.642: INFO: Pod "pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7": Phase="Pending", Reason="", readiness=false. Elapsed: 47.212035ms
Dec 10 17:49:41.652: INFO: Pod "pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058030858s
Dec 10 17:49:43.699: INFO: Pod "pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.104108777s
STEP: Saw pod success
Dec 10 17:49:43.699: INFO: Pod "pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7" satisfied condition "Succeeded or Failed"
Dec 10 17:49:43.701: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7 container env-test: <nil>
STEP: delete the pod
Dec 10 17:49:43.715: INFO: Waiting for pod pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7 to disappear
Dec 10 17:49:43.717: INFO: Pod pod-configmaps-aa7a0058-22b8-41f5-967a-c05edbfbe7a7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:43.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8748" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":346,"completed":241,"skipped":4513,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:43.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-6415
STEP: creating service affinity-clusterip-transition in namespace services-6415
STEP: creating replication controller affinity-clusterip-transition in namespace services-6415
I1210 17:49:43.792267      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6415, replica count: 3
I1210 17:49:46.878786      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 17:49:46.884: INFO: Creating new exec pod
Dec 10 17:49:49.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6415 exec execpod-affinity7xdlr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Dec 10 17:49:50.097: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Dec 10 17:49:50.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:49:50.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6415 exec execpod-affinity7xdlr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.132.68 80'
Dec 10 17:49:50.247: INFO: stderr: "+ nc -v -t -w 2 10.3.132.68 80\nConnection to 10.3.132.68 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 17:49:50.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 17:49:50.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6415 exec execpod-affinity7xdlr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.132.68:80/ ; done'
Dec 10 17:49:50.787: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n"
Dec 10 17:49:50.787: INFO: stdout: "\naffinity-clusterip-transition-wt847\naffinity-clusterip-transition-55d68\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-wt847\naffinity-clusterip-transition-55d68\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-wt847\naffinity-clusterip-transition-55d68\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-wt847\naffinity-clusterip-transition-55d68\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-wt847\naffinity-clusterip-transition-55d68\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-wt847"
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-55d68
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-55d68
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-55d68
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-55d68
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-55d68
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:50.787: INFO: Received response from host: affinity-clusterip-transition-wt847
Dec 10 17:49:50.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6415 exec execpod-affinity7xdlr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.132.68:80/ ; done'
Dec 10 17:49:51.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.132.68:80/\n"
Dec 10 17:49:51.189: INFO: stdout: "\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx\naffinity-clusterip-transition-tngnx"
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Received response from host: affinity-clusterip-transition-tngnx
Dec 10 17:49:51.189: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6415, will wait for the garbage collector to delete the pods
Dec 10 17:49:51.272: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.0912ms
Dec 10 17:49:51.374: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.623153ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:53.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6415" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.790 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":242,"skipped":4548,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:53.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:49:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6689" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":346,"completed":243,"skipped":4586,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:49:53.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Dec 10 17:49:53.649: INFO: The status of Pod labelsupdate2f106daf-1faf-4ba2-8a2b-f9683a1f692c is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:49:55.656: INFO: The status of Pod labelsupdate2f106daf-1faf-4ba2-8a2b-f9683a1f692c is Running (Ready = true)
Dec 10 17:49:56.180: INFO: Successfully updated pod "labelsupdate2f106daf-1faf-4ba2-8a2b-f9683a1f692c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:00.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-224" for this suite.

• [SLOW TEST:6.626 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":244,"skipped":4597,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:00.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:50:00.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:07.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6076" for this suite.

• [SLOW TEST:6.798 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":346,"completed":245,"skipped":4621,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:07.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-0fff6a79-529f-4de5-b303-23cc420dd0e8
STEP: Creating a pod to test consume configMaps
Dec 10 17:50:07.095: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88" in namespace "projected-2522" to be "Succeeded or Failed"
Dec 10 17:50:07.098: INFO: Pod "pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88": Phase="Pending", Reason="", readiness=false. Elapsed: 3.465416ms
Dec 10 17:50:09.107: INFO: Pod "pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011829386s
STEP: Saw pod success
Dec 10 17:50:09.107: INFO: Pod "pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88" satisfied condition "Succeeded or Failed"
Dec 10 17:50:09.109: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:50:09.131: INFO: Waiting for pod pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88 to disappear
Dec 10 17:50:09.134: INFO: Pod pod-projected-configmaps-ca3fdc16-9a53-4a43-921b-becf09491c88 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:09.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2522" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":246,"skipped":4623,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:09.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Dec 10 17:50:09.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3299 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 10 17:50:09.270: INFO: stderr: ""
Dec 10 17:50:09.270: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Dec 10 17:50:09.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3299 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Dec 10 17:50:10.386: INFO: stderr: ""
Dec 10 17:50:10.386: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Dec 10 17:50:10.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-3299 delete pods e2e-test-httpd-pod'
Dec 10 17:50:12.251: INFO: stderr: ""
Dec 10 17:50:12.251: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:12.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3299" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":346,"completed":247,"skipped":4693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:12.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:50:12.325: INFO: Creating ReplicaSet my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301
Dec 10 17:50:12.338: INFO: Pod name my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301: Found 0 pods out of 1
Dec 10 17:50:17.343: INFO: Pod name my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301: Found 1 pods out of 1
Dec 10 17:50:17.343: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301" is running
Dec 10 17:50:17.345: INFO: Pod "my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301-2rr65" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 17:50:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 17:50:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 17:50:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-12-10 17:50:12 +0000 UTC Reason: Message:}])
Dec 10 17:50:17.345: INFO: Trying to dial the pod
Dec 10 17:50:22.367: INFO: Controller my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301: Got expected result from replica 1 [my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301-2rr65]: "my-hostname-basic-d12f7ced-9b73-495b-9783-4e711efef301-2rr65", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:22.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5902" for this suite.

• [SLOW TEST:10.118 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":248,"skipped":4716,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:22.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:30.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6957" for this suite.

• [SLOW TEST:8.108 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":346,"completed":249,"skipped":4727,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:30.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1331
STEP: creating the pod
Dec 10 17:50:30.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 create -f -'
Dec 10 17:50:30.721: INFO: stderr: ""
Dec 10 17:50:30.721: INFO: stdout: "pod/pause created\n"
Dec 10 17:50:30.721: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 10 17:50:30.721: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5002" to be "running and ready"
Dec 10 17:50:30.725: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126684ms
Dec 10 17:50:32.733: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011525806s
Dec 10 17:50:32.733: INFO: Pod "pause" satisfied condition "running and ready"
Dec 10 17:50:32.733: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 10 17:50:32.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 label pods pause testing-label=testing-label-value'
Dec 10 17:50:32.881: INFO: stderr: ""
Dec 10 17:50:32.881: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 10 17:50:32.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 get pod pause -L testing-label'
Dec 10 17:50:32.995: INFO: stderr: ""
Dec 10 17:50:32.996: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 10 17:50:32.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 label pods pause testing-label-'
Dec 10 17:50:33.090: INFO: stderr: ""
Dec 10 17:50:33.090: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 10 17:50:33.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 get pod pause -L testing-label'
Dec 10 17:50:33.222: INFO: stderr: ""
Dec 10 17:50:33.222: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1337
STEP: using delete to clean up resources
Dec 10 17:50:33.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 delete --grace-period=0 --force -f -'
Dec 10 17:50:33.344: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:50:33.344: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 10 17:50:33.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 get rc,svc -l name=pause --no-headers'
Dec 10 17:50:33.436: INFO: stderr: "No resources found in kubectl-5002 namespace.\n"
Dec 10 17:50:33.436: INFO: stdout: ""
Dec 10 17:50:33.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-5002 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 17:50:33.624: INFO: stderr: ""
Dec 10 17:50:33.624: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:33.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5002" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":346,"completed":250,"skipped":4729,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:33.634: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Dec 10 17:50:33.702: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2565  08301c34-03d0-4371-b8ad-ef8b187892a2 24720 0 2021-12-10 17:50:33 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2021-12-10 17:50:33 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ml9kh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ml9kh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 10 17:50:33.705: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:50:35.713: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:50:37.711: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Dec 10 17:50:37.711: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2565 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:50:37.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:50:37.711: INFO: ExecWithOptions: Clientset creation
Dec 10 17:50:37.711: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2565/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
STEP: Verifying customized DNS server is configured on pod...
Dec 10 17:50:37.846: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2565 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:50:37.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:50:37.847: INFO: ExecWithOptions: Clientset creation
Dec 10 17:50:37.847: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2565/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:50:37.961: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:37.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2565" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":346,"completed":251,"skipped":4732,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:37.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:50:38.636: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:50:41.655: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 10 17:50:41.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:41.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-499" for this suite.
STEP: Destroying namespace "webhook-499-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":346,"completed":252,"skipped":4743,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:41.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-a2b4af49-f1a4-4e8f-95b3-5db942192237
STEP: Creating a pod to test consume secrets
Dec 10 17:50:41.815: INFO: Waiting up to 5m0s for pod "pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1" in namespace "secrets-6611" to be "Succeeded or Failed"
Dec 10 17:50:41.819: INFO: Pod "pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.461865ms
Dec 10 17:50:43.828: INFO: Pod "pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012017719s
STEP: Saw pod success
Dec 10 17:50:43.829: INFO: Pod "pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1" satisfied condition "Succeeded or Failed"
Dec 10 17:50:43.831: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1 container secret-env-test: <nil>
STEP: delete the pod
Dec 10 17:50:43.860: INFO: Waiting for pod pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1 to disappear
Dec 10 17:50:43.866: INFO: Pod pod-secrets-8d719254-b8f5-4a0b-b104-e4b14928d4b1 no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:43.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6611" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":346,"completed":253,"skipped":4801,"failed":0}
SSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:43.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Dec 10 17:50:43.936: INFO: observed Pod pod-test in namespace pods-911 in phase Pending with labels: map[test-pod-static:true] & conditions []
Dec 10 17:50:43.940: INFO: observed Pod pod-test in namespace pods-911 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC  }]
Dec 10 17:50:43.955: INFO: observed Pod pod-test in namespace pods-911 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC  }]
Dec 10 17:50:45.567: INFO: Found Pod pod-test in namespace pods-911 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 17:50:43 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
Dec 10 17:50:45.575: INFO: observed event type ADDED
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Dec 10 17:50:45.592: INFO: observed event type ADDED
Dec 10 17:50:45.593: INFO: observed event type MODIFIED
Dec 10 17:50:45.593: INFO: observed event type MODIFIED
Dec 10 17:50:45.593: INFO: observed event type MODIFIED
Dec 10 17:50:45.594: INFO: observed event type MODIFIED
Dec 10 17:50:45.594: INFO: observed event type MODIFIED
Dec 10 17:50:45.594: INFO: observed event type MODIFIED
Dec 10 17:50:47.018: INFO: observed event type MODIFIED
Dec 10 17:50:48.647: INFO: observed event type MODIFIED
Dec 10 17:50:48.654: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:50:48.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-911" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":346,"completed":254,"skipped":4805,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:50:48.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-4857
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:50:48.780: INFO: Found 0 stateful pods, waiting for 1
Dec 10 17:50:58.798: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Dec 10 17:50:58.861: INFO: Found 1 stateful pods, waiting for 2
Dec 10 17:51:08.872: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 17:51:08.873: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:51:08.902: INFO: Deleting all statefulset in ns statefulset-4857
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:08.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4857" for this suite.

• [SLOW TEST:20.263 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should list, patch and delete a collection of StatefulSets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":346,"completed":255,"skipped":4811,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:08.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:20.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7472" for this suite.

• [SLOW TEST:11.168 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":346,"completed":256,"skipped":4836,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:20.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting the proxy server
Dec 10 17:51:20.149: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-4256 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:20.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4256" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":346,"completed":257,"skipped":4844,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:20.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:36.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-574" for this suite.

• [SLOW TEST:16.169 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":346,"completed":258,"skipped":4875,"failed":0}
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:36.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Dec 10 17:51:36.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-4141 create -f -'
Dec 10 17:51:36.730: INFO: stderr: ""
Dec 10 17:51:36.730: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Dec 10 17:51:37.734: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:51:37.734: INFO: Found 0 / 1
Dec 10 17:51:38.739: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:51:38.739: INFO: Found 1 / 1
Dec 10 17:51:38.739: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 10 17:51:38.742: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:51:38.742: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 17:51:38.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-4141 patch pod agnhost-primary-ls57t -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 10 17:51:38.837: INFO: stderr: ""
Dec 10 17:51:38.838: INFO: stdout: "pod/agnhost-primary-ls57t patched\n"
STEP: checking annotations
Dec 10 17:51:38.840: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 10 17:51:38.840: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:38.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4141" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":346,"completed":259,"skipped":4875,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:38.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:51:38.888: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 10 17:51:40.930: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:41.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9221" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":346,"completed":260,"skipped":4884,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:41.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 17:51:42.014: INFO: Waiting up to 5m0s for pod "pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1" in namespace "emptydir-7848" to be "Succeeded or Failed"
Dec 10 17:51:42.018: INFO: Pod "pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3178ms
Dec 10 17:51:44.023: INFO: Pod "pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008098517s
STEP: Saw pod success
Dec 10 17:51:44.023: INFO: Pod "pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1" satisfied condition "Succeeded or Failed"
Dec 10 17:51:44.026: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1 container test-container: <nil>
STEP: delete the pod
Dec 10 17:51:44.053: INFO: Waiting for pod pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1 to disappear
Dec 10 17:51:44.058: INFO: Pod pod-f0fd8ccf-a712-4d6e-bb3b-52544cb34fa1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:44.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7848" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":261,"skipped":4900,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:44.074: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
Dec 10 17:51:44.161: INFO: created test-event-1
Dec 10 17:51:44.164: INFO: created test-event-2
Dec 10 17:51:44.169: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Dec 10 17:51:44.172: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Dec 10 17:51:44.186: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:44.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9377" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":346,"completed":262,"skipped":4914,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:44.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:51:51.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2918" for this suite.

• [SLOW TEST:7.085 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":346,"completed":263,"skipped":4936,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:51:51.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Dec 10 17:51:51.360: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 17:52:51.388: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Dec 10 17:52:51.432: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 10 17:52:51.435: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 10 17:52:51.466: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 10 17:52:51.471: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:01.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7355" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:70.643 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":346,"completed":264,"skipped":4995,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:01.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:53:02.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28" in namespace "projected-3908" to be "Succeeded or Failed"
Dec 10 17:53:02.078: INFO: Pod "downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.356316ms
Dec 10 17:53:04.087: INFO: Pod "downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012543431s
Dec 10 17:53:06.096: INFO: Pod "downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021336171s
STEP: Saw pod success
Dec 10 17:53:06.096: INFO: Pod "downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28" satisfied condition "Succeeded or Failed"
Dec 10 17:53:06.099: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28 container client-container: <nil>
STEP: delete the pod
Dec 10 17:53:06.118: INFO: Waiting for pod downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28 to disappear
Dec 10 17:53:06.120: INFO: Pod downwardapi-volume-51d2b092-74b8-4c8a-b1b6-08182a7edf28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:06.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3908" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":265,"skipped":5014,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating all guestbook components
Dec 10 17:53:06.177: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Dec 10 17:53:06.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:06.485: INFO: stderr: ""
Dec 10 17:53:06.485: INFO: stdout: "service/agnhost-replica created\n"
Dec 10 17:53:06.486: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Dec 10 17:53:06.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:07.116: INFO: stderr: ""
Dec 10 17:53:07.117: INFO: stdout: "service/agnhost-primary created\n"
Dec 10 17:53:07.117: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 10 17:53:07.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:07.556: INFO: stderr: ""
Dec 10 17:53:07.556: INFO: stdout: "service/frontend created\n"
Dec 10 17:53:07.557: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec 10 17:53:07.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:07.886: INFO: stderr: ""
Dec 10 17:53:07.886: INFO: stdout: "deployment.apps/frontend created\n"
Dec 10 17:53:07.886: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 10 17:53:07.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:08.136: INFO: stderr: ""
Dec 10 17:53:08.136: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Dec 10 17:53:08.137: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 10 17:53:08.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 create -f -'
Dec 10 17:53:08.573: INFO: stderr: ""
Dec 10 17:53:08.573: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Dec 10 17:53:08.573: INFO: Waiting for all frontend pods to be Running.
Dec 10 17:53:13.624: INFO: Waiting for frontend to serve content.
Dec 10 17:53:13.638: INFO: Trying to add a new entry to the guestbook.
Dec 10 17:53:13.651: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 10 17:53:13.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:13.743: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:13.743: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 17:53:13.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:13.870: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:13.870: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 17:53:13.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:13.998: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:13.998: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 17:53:13.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:14.127: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:14.127: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 17:53:14.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:14.523: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:14.523: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 17:53:14.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-154 delete --grace-period=0 --force -f -'
Dec 10 17:53:14.700: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:53:14.700: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:14.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-154" for this suite.

• [SLOW TEST:8.570 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:339
    should create and stop a working application  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":346,"completed":266,"skipped":5091,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:14.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:18.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3422" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":346,"completed":267,"skipped":5108,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:18.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-8409
[It] should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-8409
Dec 10 17:53:18.879: INFO: Found 0 stateful pods, waiting for 1
Dec 10 17:53:28.888: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 17:53:28.925: INFO: Deleting all statefulset in ns statefulset-8409
Dec 10 17:53:28.942: INFO: Scaling statefulset ss to 0
Dec 10 17:53:39.005: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 17:53:39.008: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:39.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8409" for this suite.

• [SLOW TEST:20.235 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should have a working scale subresource [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":346,"completed":268,"skipped":5116,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:39.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Dec 10 17:53:39.124: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Dec 10 17:53:39.131: INFO: starting watch
STEP: patching
STEP: updating
Dec 10 17:53:39.172: INFO: waiting for watch events with expected annotations
Dec 10 17:53:39.172: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:39.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-827" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":346,"completed":269,"skipped":5133,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:39.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 10 17:53:39.269: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:53:41.635: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:53:52.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4162" for this suite.

• [SLOW TEST:12.857 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":346,"completed":270,"skipped":5168,"failed":0}
SS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:53:52.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod test-webserver-364e007f-2162-471c-860e-80210fefff9d in namespace container-probe-7876
Dec 10 17:53:56.144: INFO: Started pod test-webserver-364e007f-2162-471c-860e-80210fefff9d in namespace container-probe-7876
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 17:53:56.146: INFO: Initial restart count of pod test-webserver-364e007f-2162-471c-860e-80210fefff9d is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:57:57.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7876" for this suite.

• [SLOW TEST:245.017 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":271,"skipped":5170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:57:57.124: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Dec 10 17:57:57.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 create -f -'
Dec 10 17:57:57.864: INFO: stderr: ""
Dec 10 17:57:57.864: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 17:57:57.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 17:57:57.951: INFO: stderr: ""
Dec 10 17:57:57.952: INFO: stdout: "update-demo-nautilus-62mpk update-demo-nautilus-bb78c "
Dec 10 17:57:57.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods update-demo-nautilus-62mpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 17:57:58.015: INFO: stderr: ""
Dec 10 17:57:58.015: INFO: stdout: ""
Dec 10 17:57:58.016: INFO: update-demo-nautilus-62mpk is created but not running
Dec 10 17:58:03.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 10 17:58:03.173: INFO: stderr: ""
Dec 10 17:58:03.173: INFO: stdout: "update-demo-nautilus-62mpk update-demo-nautilus-bb78c "
Dec 10 17:58:03.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods update-demo-nautilus-62mpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 17:58:03.292: INFO: stderr: ""
Dec 10 17:58:03.292: INFO: stdout: "true"
Dec 10 17:58:03.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods update-demo-nautilus-62mpk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 17:58:03.380: INFO: stderr: ""
Dec 10 17:58:03.380: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 17:58:03.380: INFO: validating pod update-demo-nautilus-62mpk
Dec 10 17:58:03.385: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 17:58:03.386: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 17:58:03.386: INFO: update-demo-nautilus-62mpk is verified up and running
Dec 10 17:58:03.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods update-demo-nautilus-bb78c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 10 17:58:03.458: INFO: stderr: ""
Dec 10 17:58:03.458: INFO: stdout: "true"
Dec 10 17:58:03.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods update-demo-nautilus-bb78c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 10 17:58:03.574: INFO: stderr: ""
Dec 10 17:58:03.574: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Dec 10 17:58:03.574: INFO: validating pod update-demo-nautilus-bb78c
Dec 10 17:58:03.578: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 17:58:03.578: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 17:58:03.578: INFO: update-demo-nautilus-bb78c is verified up and running
STEP: using delete to clean up resources
Dec 10 17:58:03.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 delete --grace-period=0 --force -f -'
Dec 10 17:58:03.752: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 17:58:03.752: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 17:58:03.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get rc,svc -l name=update-demo --no-headers'
Dec 10 17:58:03.930: INFO: stderr: "No resources found in kubectl-1553 namespace.\n"
Dec 10 17:58:03.930: INFO: stdout: ""
Dec 10 17:58:03.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=kubectl-1553 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 17:58:04.353: INFO: stderr: ""
Dec 10 17:58:04.353: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:04.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1553" for this suite.

• [SLOW TEST:7.236 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should create and stop a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":346,"completed":272,"skipped":5233,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:04.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:04.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5532" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":346,"completed":273,"skipped":5233,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:04.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:17.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9323" for this suite.
STEP: Destroying namespace "nsdeletetest-9407" for this suite.
Dec 10 17:58:17.571: INFO: Namespace nsdeletetest-9407 was already deleted
STEP: Destroying namespace "nsdeletetest-6301" for this suite.

• [SLOW TEST:13.161 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":346,"completed":274,"skipped":5241,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:17.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test env composition
Dec 10 17:58:17.619: INFO: Waiting up to 5m0s for pod "var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80" in namespace "var-expansion-1321" to be "Succeeded or Failed"
Dec 10 17:58:17.621: INFO: Pod "var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.368506ms
Dec 10 17:58:19.629: INFO: Pod "var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009617085s
Dec 10 17:58:21.633: INFO: Pod "var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013528292s
STEP: Saw pod success
Dec 10 17:58:21.633: INFO: Pod "var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80" satisfied condition "Succeeded or Failed"
Dec 10 17:58:21.635: INFO: Trying to get logs from node ip-10-0-19-34 pod var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:58:21.659: INFO: Waiting for pod var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80 to disappear
Dec 10 17:58:21.662: INFO: Pod var-expansion-8232ae83-9da6-4609-9dce-62ec43e81a80 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:21.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1321" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":346,"completed":275,"skipped":5260,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:21.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Dec 10 17:58:21.705: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:24.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7985" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":346,"completed":276,"skipped":5269,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:24.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-00dad4a7-bce4-4e13-bab3-f59096556f30
STEP: Creating a pod to test consume configMaps
Dec 10 17:58:25.024: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b" in namespace "projected-9242" to be "Succeeded or Failed"
Dec 10 17:58:25.027: INFO: Pod "pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318003ms
Dec 10 17:58:27.031: INFO: Pod "pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006914165s
STEP: Saw pod success
Dec 10 17:58:27.032: INFO: Pod "pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b" satisfied condition "Succeeded or Failed"
Dec 10 17:58:27.035: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 17:58:27.058: INFO: Waiting for pod pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b to disappear
Dec 10 17:58:27.060: INFO: Pod pod-projected-configmaps-b3365baa-d3fe-4e10-9fe4-ca8d889dc74b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:27.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9242" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":277,"skipped":5283,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:27.074: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 17:58:27.118: INFO: Waiting up to 5m0s for pod "pod-471d9cc9-6222-4776-be83-cdf8bf73aef5" in namespace "emptydir-7510" to be "Succeeded or Failed"
Dec 10 17:58:27.122: INFO: Pod "pod-471d9cc9-6222-4776-be83-cdf8bf73aef5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.012481ms
Dec 10 17:58:29.129: INFO: Pod "pod-471d9cc9-6222-4776-be83-cdf8bf73aef5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010510455s
STEP: Saw pod success
Dec 10 17:58:29.130: INFO: Pod "pod-471d9cc9-6222-4776-be83-cdf8bf73aef5" satisfied condition "Succeeded or Failed"
Dec 10 17:58:29.132: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-471d9cc9-6222-4776-be83-cdf8bf73aef5 container test-container: <nil>
STEP: delete the pod
Dec 10 17:58:29.157: INFO: Waiting for pod pod-471d9cc9-6222-4776-be83-cdf8bf73aef5 to disappear
Dec 10 17:58:29.162: INFO: Pod pod-471d9cc9-6222-4776-be83-cdf8bf73aef5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:29.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7510" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":278,"skipped":5323,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:29.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 17:58:29.217: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487" in namespace "downward-api-2145" to be "Succeeded or Failed"
Dec 10 17:58:29.220: INFO: Pod "downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487": Phase="Pending", Reason="", readiness=false. Elapsed: 2.511888ms
Dec 10 17:58:31.231: INFO: Pod "downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012924673s
Dec 10 17:58:33.238: INFO: Pod "downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020460321s
STEP: Saw pod success
Dec 10 17:58:33.239: INFO: Pod "downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487" satisfied condition "Succeeded or Failed"
Dec 10 17:58:33.242: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487 container client-container: <nil>
STEP: delete the pod
Dec 10 17:58:33.254: INFO: Waiting for pod downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487 to disappear
Dec 10 17:58:33.256: INFO: Pod downwardapi-volume-a79f8ae0-5995-48fc-adc4-eb0e7aac5487 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:33.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2145" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":279,"skipped":5361,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:33.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Dec 10 17:58:33.307: INFO: Waiting up to 5m0s for pod "downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725" in namespace "downward-api-5909" to be "Succeeded or Failed"
Dec 10 17:58:33.310: INFO: Pod "downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725": Phase="Pending", Reason="", readiness=false. Elapsed: 3.131006ms
Dec 10 17:58:35.318: INFO: Pod "downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010554588s
STEP: Saw pod success
Dec 10 17:58:35.319: INFO: Pod "downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725" satisfied condition "Succeeded or Failed"
Dec 10 17:58:35.321: INFO: Trying to get logs from node ip-10-0-19-34 pod downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725 container dapi-container: <nil>
STEP: delete the pod
Dec 10 17:58:35.336: INFO: Waiting for pod downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725 to disappear
Dec 10 17:58:35.337: INFO: Pod downward-api-ef2d12d5-d2e7-4e00-8592-48d870a78725 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:35.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5909" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":346,"completed":280,"skipped":5375,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:35.347: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:35.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3059" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":346,"completed":281,"skipped":5380,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:35.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Dec 10 17:58:35.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:52.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8201" for this suite.

• [SLOW TEST:17.216 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":346,"completed":282,"skipped":5382,"failed":0}
SSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:52.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:149
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:52.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3608" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":346,"completed":283,"skipped":5387,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:52.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-01028e31-f8a2-4dcd-8cc6-faa1e2cca9d3
STEP: Creating a pod to test consume configMaps
Dec 10 17:58:52.849: INFO: Waiting up to 5m0s for pod "pod-configmaps-15899249-8734-4aa9-b026-d2820be28114" in namespace "configmap-9396" to be "Succeeded or Failed"
Dec 10 17:58:52.852: INFO: Pod "pod-configmaps-15899249-8734-4aa9-b026-d2820be28114": Phase="Pending", Reason="", readiness=false. Elapsed: 3.003861ms
Dec 10 17:58:54.860: INFO: Pod "pod-configmaps-15899249-8734-4aa9-b026-d2820be28114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01108245s
STEP: Saw pod success
Dec 10 17:58:54.860: INFO: Pod "pod-configmaps-15899249-8734-4aa9-b026-d2820be28114" satisfied condition "Succeeded or Failed"
Dec 10 17:58:54.862: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-15899249-8734-4aa9-b026-d2820be28114 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 17:58:54.879: INFO: Waiting for pod pod-configmaps-15899249-8734-4aa9-b026-d2820be28114 to disappear
Dec 10 17:58:54.880: INFO: Pod pod-configmaps-15899249-8734-4aa9-b026-d2820be28114 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:54.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9396" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":284,"skipped":5393,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:54.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 17:58:54.955: INFO: Waiting up to 5m0s for pod "pod-f877e462-85dd-4e75-a929-141148854c78" in namespace "emptydir-6920" to be "Succeeded or Failed"
Dec 10 17:58:54.958: INFO: Pod "pod-f877e462-85dd-4e75-a929-141148854c78": Phase="Pending", Reason="", readiness=false. Elapsed: 3.168085ms
Dec 10 17:58:56.970: INFO: Pod "pod-f877e462-85dd-4e75-a929-141148854c78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01510146s
Dec 10 17:58:58.978: INFO: Pod "pod-f877e462-85dd-4e75-a929-141148854c78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023146537s
STEP: Saw pod success
Dec 10 17:58:58.979: INFO: Pod "pod-f877e462-85dd-4e75-a929-141148854c78" satisfied condition "Succeeded or Failed"
Dec 10 17:58:58.980: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-f877e462-85dd-4e75-a929-141148854c78 container test-container: <nil>
STEP: delete the pod
Dec 10 17:58:58.993: INFO: Waiting for pod pod-f877e462-85dd-4e75-a929-141148854c78 to disappear
Dec 10 17:58:58.995: INFO: Pod pod-f877e462-85dd-4e75-a929-141148854c78 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:58:58.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6920" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":285,"skipped":5404,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:58:59.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-5189
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 17:58:59.063: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 10 17:58:59.100: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:59:01.154: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:03.114: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:05.119: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:07.168: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:09.112: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:11.110: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:13.116: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:15.116: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:17.108: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 10 17:59:19.114: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 10 17:59:19.118: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Dec 10 17:59:23.138: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 10 17:59:23.139: INFO: Going to poll 10.2.2.215 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 10 17:59:23.141: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.2.215 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:59:23.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:59:23.142: INFO: ExecWithOptions: Clientset creation
Dec 10 17:59:23.143: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-5189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.2.215+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:59:24.236: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 10 17:59:24.236: INFO: Going to poll 10.2.1.171 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 10 17:59:24.260: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.1.171 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 17:59:24.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 17:59:24.261: INFO: ExecWithOptions: Clientset creation
Dec 10 17:59:24.261: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-5189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.1.171+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 17:59:25.381: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:25.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5189" for this suite.

• [SLOW TEST:26.369 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":286,"skipped":5415,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:25.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 10 17:59:25.936: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 17:59:28.960: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:59:28.966: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:32.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9906" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.748 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":346,"completed":287,"skipped":5442,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:32.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 17:59:32.230: INFO: Waiting up to 5m0s for pod "pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d" in namespace "emptydir-4759" to be "Succeeded or Failed"
Dec 10 17:59:32.234: INFO: Pod "pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606328ms
Dec 10 17:59:34.242: INFO: Pod "pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011295746s
STEP: Saw pod success
Dec 10 17:59:34.242: INFO: Pod "pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d" satisfied condition "Succeeded or Failed"
Dec 10 17:59:34.244: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d container test-container: <nil>
STEP: delete the pod
Dec 10 17:59:34.256: INFO: Waiting for pod pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d to disappear
Dec 10 17:59:34.258: INFO: Pod pod-681f53ea-bf21-4661-bd53-e7b2c4cf161d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:34.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4759" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":288,"skipped":5480,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:34.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:186
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Dec 10 17:59:34.328: INFO: starting watch
STEP: patching
STEP: updating
Dec 10 17:59:34.339: INFO: waiting for watch events with expected annotations
Dec 10 17:59:34.340: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:34.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5761" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":346,"completed":289,"skipped":5514,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:34.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 17:59:34.420: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-7dbcbca1-25f9-433f-9c92-04cdb91c52da" in namespace "security-context-test-9553" to be "Succeeded or Failed"
Dec 10 17:59:34.423: INFO: Pod "busybox-readonly-false-7dbcbca1-25f9-433f-9c92-04cdb91c52da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719342ms
Dec 10 17:59:36.429: INFO: Pod "busybox-readonly-false-7dbcbca1-25f9-433f-9c92-04cdb91c52da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009497629s
Dec 10 17:59:36.430: INFO: Pod "busybox-readonly-false-7dbcbca1-25f9-433f-9c92-04cdb91c52da" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:36.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9553" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":346,"completed":290,"skipped":5529,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:36.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Dec 10 17:59:36.488: INFO: The status of Pod pod-update-19acc739-4acf-441d-a7ce-4f874f914595 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:59:38.494: INFO: The status of Pod pod-update-19acc739-4acf-441d-a7ce-4f874f914595 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 17:59:39.007: INFO: Successfully updated pod "pod-update-19acc739-4acf-441d-a7ce-4f874f914595"
STEP: verifying the updated pod is in kubernetes
Dec 10 17:59:39.011: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:39.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8544" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":346,"completed":291,"skipped":5550,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:39.030: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 17:59:39.078: INFO: Waiting up to 5m0s for pod "pod-525f7d79-04f9-4d31-9516-317320e75897" in namespace "emptydir-8902" to be "Succeeded or Failed"
Dec 10 17:59:39.082: INFO: Pod "pod-525f7d79-04f9-4d31-9516-317320e75897": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083928ms
Dec 10 17:59:41.087: INFO: Pod "pod-525f7d79-04f9-4d31-9516-317320e75897": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007784633s
STEP: Saw pod success
Dec 10 17:59:41.087: INFO: Pod "pod-525f7d79-04f9-4d31-9516-317320e75897" satisfied condition "Succeeded or Failed"
Dec 10 17:59:41.088: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-525f7d79-04f9-4d31-9516-317320e75897 container test-container: <nil>
STEP: delete the pod
Dec 10 17:59:41.103: INFO: Waiting for pod pod-525f7d79-04f9-4d31-9516-317320e75897 to disappear
Dec 10 17:59:41.105: INFO: Pod pod-525f7d79-04f9-4d31-9516-317320e75897 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:41.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8902" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":292,"skipped":5602,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:41.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Dec 10 17:59:41.185: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:59:43.192: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Dec 10 17:59:43.200: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:59:45.207: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 10 17:59:47.213: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Dec 10 17:59:47.220: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 17:59:47.223: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 17:59:49.223: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 17:59:49.229: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 17:59:49.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7612" for this suite.

• [SLOW TEST:8.124 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":346,"completed":293,"skipped":5634,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 17:59:49.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-rl8d
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 17:59:49.372: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rl8d" in namespace "subpath-3065" to be "Succeeded or Failed"
Dec 10 17:59:49.376: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.072868ms
Dec 10 17:59:51.381: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008156426s
Dec 10 17:59:53.388: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 4.015622981s
Dec 10 17:59:55.398: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 6.025183943s
Dec 10 17:59:57.429: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 8.056903707s
Dec 10 17:59:59.435: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 10.063011988s
Dec 10 18:00:01.440: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 12.067348776s
Dec 10 18:00:03.458: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 14.085799698s
Dec 10 18:00:05.473: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 16.100308674s
Dec 10 18:00:07.539: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 18.166692663s
Dec 10 18:00:09.547: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Running", Reason="", readiness=true. Elapsed: 20.174612266s
Dec 10 18:00:11.559: INFO: Pod "pod-subpath-test-configmap-rl8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.186239261s
STEP: Saw pod success
Dec 10 18:00:11.559: INFO: Pod "pod-subpath-test-configmap-rl8d" satisfied condition "Succeeded or Failed"
Dec 10 18:00:11.562: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-subpath-test-configmap-rl8d container test-container-subpath-configmap-rl8d: <nil>
STEP: delete the pod
Dec 10 18:00:11.587: INFO: Waiting for pod pod-subpath-test-configmap-rl8d to disappear
Dec 10 18:00:11.594: INFO: Pod pod-subpath-test-configmap-rl8d no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rl8d
Dec 10 18:00:11.594: INFO: Deleting pod "pod-subpath-test-configmap-rl8d" in namespace "subpath-3065"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:00:11.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3065" for this suite.

• [SLOW TEST:22.372 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]","total":346,"completed":294,"skipped":5635,"failed":0}
SS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:00:11.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Dec 10 18:00:11.739: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Dec 10 18:00:11.743: INFO: starting watch
STEP: patching
STEP: updating
Dec 10 18:00:11.766: INFO: waiting for watch events with expected annotations
Dec 10 18:00:11.767: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:00:11.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-4158" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":346,"completed":295,"skipped":5637,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:00:11.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-08b26ae0-3ad7-4cce-a2f2-0b960826f547 in namespace container-probe-382
Dec 10 18:00:13.870: INFO: Started pod busybox-08b26ae0-3ad7-4cce-a2f2-0b960826f547 in namespace container-probe-382
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 18:00:13.873: INFO: Initial restart count of pod busybox-08b26ae0-3ad7-4cce-a2f2-0b960826f547 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:15.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-382" for this suite.

• [SLOW TEST:243.547 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":296,"skipped":5662,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:15.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:19.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2173" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":346,"completed":297,"skipped":5677,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:19.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-934b8cf9-506b-4761-a209-87b14ba6f3ac
STEP: Creating a pod to test consume secrets
Dec 10 18:04:19.471: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda" in namespace "projected-8990" to be "Succeeded or Failed"
Dec 10 18:04:19.475: INFO: Pod "pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.459851ms
Dec 10 18:04:21.482: INFO: Pod "pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011021115s
STEP: Saw pod success
Dec 10 18:04:21.483: INFO: Pod "pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda" satisfied condition "Succeeded or Failed"
Dec 10 18:04:21.486: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 18:04:21.510: INFO: Waiting for pod pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda to disappear
Dec 10 18:04:21.513: INFO: Pod pod-projected-secrets-f8ecc6f4-457b-4802-96c0-fdf34db31eda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:21.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8990" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":298,"skipped":5679,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:21.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:27.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-163" for this suite.

• [SLOW TEST:6.088 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":346,"completed":299,"skipped":5739,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:27.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 18:04:31.691: INFO: DNS probes using dns-7161/dns-test-ad804d52-571b-46e6-b405-a489ff709157 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:31.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7161" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":346,"completed":300,"skipped":5743,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:31.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 10 18:04:32.390: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 10 18:04:34.411: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 4, 32, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 4, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 4, 32, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 4, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-bb9577b7b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 18:04:37.429: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:04:37.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:04:40.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1898" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:8.994 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":346,"completed":301,"skipped":5753,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:04:40.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:04:40.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Creating first CR 
Dec 10 18:04:43.434: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:43Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:04:43Z]] name:name1 resourceVersion:28047 uid:6ff47af3-d895-49cf-bfdd-b69b34f3c20a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 10 18:04:53.448: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:53Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:04:53Z]] name:name2 resourceVersion:28074 uid:ec199e77-42b8-42e1-9a55-8b160038dd42] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 10 18:05:03.484: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:05:03Z]] name:name1 resourceVersion:28089 uid:6ff47af3-d895-49cf-bfdd-b69b34f3c20a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 10 18:05:13.515: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:53Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:05:13Z]] name:name2 resourceVersion:28104 uid:ec199e77-42b8-42e1-9a55-8b160038dd42] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 10 18:05:23.527: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:05:03Z]] name:name1 resourceVersion:28119 uid:6ff47af3-d895-49cf-bfdd-b69b34f3c20a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 10 18:05:33.542: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-12-10T18:04:53Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-12-10T18:05:13Z]] name:name2 resourceVersion:28132 uid:ec199e77-42b8-42e1-9a55-8b160038dd42] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:05:44.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5516" for this suite.

• [SLOW TEST:63.360 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":346,"completed":302,"skipped":5754,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:05:44.071: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 10 18:05:46.133: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:05:46.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1266" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":346,"completed":303,"skipped":5768,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:05:46.149: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating secret secrets-9257/secret-test-dd839c36-6f37-4196-b4ee-9b0515bc38f2
STEP: Creating a pod to test consume secrets
Dec 10 18:05:46.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f" in namespace "secrets-9257" to be "Succeeded or Failed"
Dec 10 18:05:46.217: INFO: Pod "pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893869ms
Dec 10 18:05:48.225: INFO: Pod "pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011084192s
Dec 10 18:05:50.234: INFO: Pod "pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019430415s
STEP: Saw pod success
Dec 10 18:05:50.234: INFO: Pod "pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f" satisfied condition "Succeeded or Failed"
Dec 10 18:05:50.238: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f container env-test: <nil>
STEP: delete the pod
Dec 10 18:05:50.254: INFO: Waiting for pod pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f to disappear
Dec 10 18:05:50.256: INFO: Pod pod-configmaps-3ba96165-af46-4018-8335-0314958ba03f no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:05:50.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9257" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":304,"skipped":5823,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:05:50.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-5062
STEP: creating service affinity-nodeport in namespace services-5062
STEP: creating replication controller affinity-nodeport in namespace services-5062
I1210 18:05:50.322726      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5062, replica count: 3
I1210 18:05:53.376358      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 18:05:53.386: INFO: Creating new exec pod
Dec 10 18:05:56.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5062 exec execpod-affinityrxmn9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Dec 10 18:05:56.617: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Dec 10 18:05:56.617: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 18:05:56.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5062 exec execpod-affinityrxmn9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.138.158 80'
Dec 10 18:05:56.774: INFO: stderr: "+ nc -v -t -w 2 10.3.138.158 80\nConnection to 10.3.138.158 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 10 18:05:56.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 18:05:56.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5062 exec execpod-affinityrxmn9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.54 31630'
Dec 10 18:05:56.986: INFO: stderr: "+ nc -v -t -w 2 10.0.0.54 31630\n+ echo hostName\nConnection to 10.0.0.54 31630 port [tcp/*] succeeded!\n"
Dec 10 18:05:56.986: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 18:05:56.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5062 exec execpod-affinityrxmn9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 31630'
Dec 10 18:05:57.234: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 31630\nConnection to 10.0.19.34 31630 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 18:05:57.234: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 10 18:05:57.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-5062 exec execpod-affinityrxmn9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.54:31630/ ; done'
Dec 10 18:05:57.570: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.54:31630/\n"
Dec 10 18:05:57.570: INFO: stdout: "\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7\naffinity-nodeport-8rcm7"
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Received response from host: affinity-nodeport-8rcm7
Dec 10 18:05:57.570: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5062, will wait for the garbage collector to delete the pods
Dec 10 18:05:57.642: INFO: Deleting ReplicationController affinity-nodeport took: 3.805388ms
Dec 10 18:05:57.744: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.524939ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:06:00.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5062" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:10.136 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":305,"skipped":5844,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:06:00.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 18:06:00.492: INFO: Waiting up to 5m0s for pod "pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28" in namespace "emptydir-6813" to be "Succeeded or Failed"
Dec 10 18:06:00.503: INFO: Pod "pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28": Phase="Pending", Reason="", readiness=false. Elapsed: 9.488757ms
Dec 10 18:06:02.520: INFO: Pod "pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026860091s
STEP: Saw pod success
Dec 10 18:06:02.520: INFO: Pod "pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28" satisfied condition "Succeeded or Failed"
Dec 10 18:06:02.535: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28 container test-container: <nil>
STEP: delete the pod
Dec 10 18:06:02.638: INFO: Waiting for pod pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28 to disappear
Dec 10 18:06:02.657: INFO: Pod pod-2b7fd5c1-183f-456e-bce0-d7c2cf1c7c28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:06:02.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6813" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":306,"skipped":5852,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:06:02.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:06:03.066: INFO: Creating deployment "test-recreate-deployment"
Dec 10 18:06:03.082: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 10 18:06:03.164: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 10 18:06:05.178: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 10 18:06:05.181: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 10 18:06:05.188: INFO: Updating deployment test-recreate-deployment
Dec 10 18:06:05.189: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Dec 10 18:06:05.422: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2625  68cecc56-c918-47a2-9093-d3426307f2fa 28408 2 2021-12-10 18:06:03 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0073848c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2021-12-10 18:06:05 +0000 UTC,LastTransitionTime:2021-12-10 18:06:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5b99bd5487" is progressing.,LastUpdateTime:2021-12-10 18:06:05 +0000 UTC,LastTransitionTime:2021-12-10 18:06:03 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 10 18:06:05.427: INFO: New ReplicaSet "test-recreate-deployment-5b99bd5487" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5b99bd5487  deployment-2625  b2832b76-eb0c-4d23-833d-a45766b750cd 28407 1 2021-12-10 18:06:05 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 68cecc56-c918-47a2-9093-d3426307f2fa 0xc007384ca7 0xc007384ca8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68cecc56-c918-47a2-9093-d3426307f2fa\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5b99bd5487,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007384d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 18:06:05.427: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 10 18:06:05.427: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d659f7dc9  deployment-2625  a1986aa7-90f2-4014-a311-2fde999850a8 28396 2 2021-12-10 18:06:03 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d659f7dc9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 68cecc56-c918-47a2-9093-d3426307f2fa 0xc007384dc7 0xc007384dc8}] []  [{kube-controller-manager Update apps/v1 2021-12-10 18:06:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68cecc56-c918-47a2-9093-d3426307f2fa\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d659f7dc9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d659f7dc9] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007384e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 10 18:06:05.433: INFO: Pod "test-recreate-deployment-5b99bd5487-6rw4z" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5b99bd5487-6rw4z test-recreate-deployment-5b99bd5487- deployment-2625  fb5abd6a-408c-43c1-86c3-3951e2c4e5ef 28406 0 2021-12-10 18:06:05 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5b99bd5487 b2832b76-eb0c-4d23-833d-a45766b750cd 0xc007385307 0xc007385308}] []  [{Go-http-client Update v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2021-12-10 18:06:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b2832b76-eb0c-4d23-833d-a45766b750cd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6r427,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6r427,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-19-34,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 18:06:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 18:06:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 18:06:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-12-10 18:06:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.19.34,PodIP:,StartTime:2021-12-10 18:06:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:06:05.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2625" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":307,"skipped":5873,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:06:05.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Dec 10 18:06:09.534: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3832 PodName:pod-sharedvolume-451e2e46-1fe7-445b-86cb-b0a66caa3217 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 10 18:06:09.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
Dec 10 18:06:09.535: INFO: ExecWithOptions: Clientset creation
Dec 10 18:06:09.535: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/emptydir-3832/pods/pod-sharedvolume-451e2e46-1fe7-445b-86cb-b0a66caa3217/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true %!s(MISSING))
Dec 10 18:06:09.618: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:06:09.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3832" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":346,"completed":308,"skipped":5874,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:06:09.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:06:09.700: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 10 18:06:09.712: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:09.712: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Dec 10 18:06:09.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:09.741: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:10.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:10.747: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:11.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:11.747: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:12.749: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 18:06:12.749: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 10 18:06:12.789: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 18:06:12.789: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Dec 10 18:06:13.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:13.796: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 10 18:06:13.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:13.803: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:14.858: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:14.858: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:15.808: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:15.808: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:16.822: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:16.823: INFO: Node ip-10-0-19-34 is running 0 daemon pod, expected 1
Dec 10 18:06:17.809: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 10 18:06:17.809: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4410, will wait for the garbage collector to delete the pods
Dec 10 18:06:17.872: INFO: Deleting DaemonSet.extensions daemon-set took: 6.26446ms
Dec 10 18:06:17.973: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.762816ms
Dec 10 18:06:20.477: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:06:20.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 18:06:20.480: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28578"},"items":null}

Dec 10 18:06:20.482: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28578"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:06:20.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4410" for this suite.

• [SLOW TEST:10.884 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":346,"completed":309,"skipped":5896,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:06:20.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-1516
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating stateful set ss in namespace statefulset-1516
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1516
Dec 10 18:06:20.591: INFO: Found 0 stateful pods, waiting for 1
Dec 10 18:06:30.599: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 10 18:06:30.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 18:06:31.054: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 18:06:31.054: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 18:06:31.054: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 18:06:31.057: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 18:06:41.064: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 18:06:41.064: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 18:06:41.073: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Dec 10 18:06:41.074: INFO: ss-0  ip-10-0-19-34  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  }]
Dec 10 18:06:41.074: INFO: 
Dec 10 18:06:41.074: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 10 18:06:42.088: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993916576s
Dec 10 18:06:43.095: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982251016s
Dec 10 18:06:44.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975180251s
Dec 10 18:06:45.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967974664s
Dec 10 18:06:46.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.961834148s
Dec 10 18:06:47.121: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955005079s
Dec 10 18:06:48.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949196746s
Dec 10 18:06:49.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944289341s
Dec 10 18:06:50.137: INFO: Verifying statefulset ss doesn't scale past 3 for another 938.492983ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1516
Dec 10 18:06:51.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 18:06:51.321: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 10 18:06:51.321: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 18:06:51.321: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 18:06:51.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 18:06:51.473: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 10 18:06:51.473: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 18:06:51.473: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 18:06:51.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 10 18:06:51.642: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 10 18:06:51.642: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 10 18:06:51.642: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 10 18:06:51.657: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 18:06:51.657: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 18:06:51.657: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 10 18:06:51.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 18:06:51.842: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 18:06:51.842: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 18:06:51.842: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 18:06:51.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 18:06:52.000: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 18:06:52.000: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 18:06:52.000: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 18:06:52.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=statefulset-1516 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 10 18:06:52.210: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 10 18:06:52.210: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 10 18:06:52.210: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 10 18:06:52.210: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 18:06:52.214: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 10 18:07:02.233: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 18:07:02.234: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 18:07:02.234: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 18:07:02.251: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Dec 10 18:07:02.251: INFO: ss-0  ip-10-0-19-34  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  }]
Dec 10 18:07:02.251: INFO: ss-1  ip-10-0-0-54   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  }]
Dec 10 18:07:02.251: INFO: ss-2  ip-10-0-19-34  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  }]
Dec 10 18:07:02.251: INFO: 
Dec 10 18:07:02.251: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 18:07:03.258: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Dec 10 18:07:03.258: INFO: ss-0  ip-10-0-19-34  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:20 +0000 UTC  }]
Dec 10 18:07:03.259: INFO: ss-1  ip-10-0-0-54   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-12-10 18:06:41 +0000 UTC  }]
Dec 10 18:07:03.260: INFO: 
Dec 10 18:07:03.260: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 10 18:07:04.265: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.986417208s
Dec 10 18:07:05.270: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.981134775s
Dec 10 18:07:06.276: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.975378052s
Dec 10 18:07:07.281: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.969611705s
Dec 10 18:07:08.287: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.964618793s
Dec 10 18:07:09.292: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.958456144s
Dec 10 18:07:10.297: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.953730297s
Dec 10 18:07:11.303: INFO: Verifying statefulset ss doesn't scale past 0 for another 948.392839ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1516
Dec 10 18:07:12.310: INFO: Scaling statefulset ss to 0
Dec 10 18:07:12.324: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Dec 10 18:07:12.327: INFO: Deleting all statefulset in ns statefulset-1516
Dec 10 18:07:12.330: INFO: Scaling statefulset ss to 0
Dec 10 18:07:12.341: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 18:07:12.343: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:07:12.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1516" for this suite.

• [SLOW TEST:51.868 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":346,"completed":310,"skipped":5905,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:07:12.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 10 18:07:12.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the sample API server.
Dec 10 18:07:13.147: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 10 18:07:15.273: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:17.278: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:19.278: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:21.280: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:23.280: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:25.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), LastTransitionTime:time.Date(2021, time.December, 10, 18, 7, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 18:07:27.406: INFO: Waited 123.38745ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Dec 10 18:07:27.475: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:07:27.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1965" for this suite.

• [SLOW TEST:15.546 seconds]
[sig-api-machinery] Aggregator
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":346,"completed":311,"skipped":5913,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:07:27.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:09:02.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9183" for this suite.

• [SLOW TEST:94.128 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":346,"completed":312,"skipped":5930,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:09:02.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Dec 10 18:09:02.227: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Dec 10 18:09:04.234: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 10 18:09:05.252: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:09:06.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8983" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":346,"completed":313,"skipped":5935,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:09:06.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 18:09:06.345: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 18:09:06.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:09:06.354: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 18:09:07.372: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 18:09:07.387: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:09:07.387: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 18:09:08.360: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 18:09:08.363: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:09:08.364: INFO: Node ip-10-0-0-54 is running 0 daemon pod, expected 1
Dec 10 18:09:09.359: INFO: DaemonSet pods can't tolerate node ip-10-0-4-83 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 18:09:09.362: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 10 18:09:09.363: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status
Dec 10 18:09:09.370: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Dec 10 18:09:09.384: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Dec 10 18:09:09.390: INFO: Observed &DaemonSet event: ADDED
Dec 10 18:09:09.392: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.394: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.395: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.400: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.401: INFO: Found daemon set daemon-set in namespace daemonsets-4123 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 10 18:09:09.401: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Dec 10 18:09:09.415: INFO: Observed &DaemonSet event: ADDED
Dec 10 18:09:09.415: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.418: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.419: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.420: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.420: INFO: Observed daemon set daemon-set in namespace daemonsets-4123 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 10 18:09:09.421: INFO: Observed &DaemonSet event: MODIFIED
Dec 10 18:09:09.421: INFO: Found daemon set daemon-set in namespace daemonsets-4123 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Dec 10 18:09:09.421: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4123, will wait for the garbage collector to delete the pods
Dec 10 18:09:09.482: INFO: Deleting DaemonSet.extensions daemon-set took: 4.636204ms
Dec 10 18:09:09.584: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.653067ms
Dec 10 18:09:11.789: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 10 18:09:11.789: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 10 18:09:11.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29274"},"items":null}

Dec 10 18:09:11.793: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29274"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:09:11.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4123" for this suite.

• [SLOW TEST:5.522 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":346,"completed":314,"skipped":5940,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:09:11.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-24e2cf3a-1cff-4437-834b-a9404b60fb57
STEP: Creating a pod to test consume configMaps
Dec 10 18:09:11.855: INFO: Waiting up to 5m0s for pod "pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91" in namespace "configmap-3474" to be "Succeeded or Failed"
Dec 10 18:09:11.858: INFO: Pod "pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.414271ms
Dec 10 18:09:13.878: INFO: Pod "pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022831704s
STEP: Saw pod success
Dec 10 18:09:13.878: INFO: Pod "pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91" satisfied condition "Succeeded or Failed"
Dec 10 18:09:13.887: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 18:09:13.911: INFO: Waiting for pod pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91 to disappear
Dec 10 18:09:13.923: INFO: Pod pod-configmaps-046d44ac-aaa2-4358-88ba-398171e9ed91 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:09:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3474" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":315,"skipped":5946,"failed":0}
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:09:13.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 10 18:09:14.267: INFO: Pod name wrapped-volume-race-6362bdcc-dbf3-4d36-acf9-8ecd8bd4bfca: Found 2 pods out of 5
Dec 10 18:09:19.273: INFO: Pod name wrapped-volume-race-6362bdcc-dbf3-4d36-acf9-8ecd8bd4bfca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6362bdcc-dbf3-4d36-acf9-8ecd8bd4bfca in namespace emptydir-wrapper-9418, will wait for the garbage collector to delete the pods
Dec 10 18:09:31.353: INFO: Deleting ReplicationController wrapped-volume-race-6362bdcc-dbf3-4d36-acf9-8ecd8bd4bfca took: 4.874969ms
Dec 10 18:09:31.454: INFO: Terminating ReplicationController wrapped-volume-race-6362bdcc-dbf3-4d36-acf9-8ecd8bd4bfca pods took: 101.21362ms
STEP: Creating RC which spawns configmap-volume pods
Dec 10 18:09:35.980: INFO: Pod name wrapped-volume-race-94084df5-05d5-4ecb-9808-1840d593efeb: Found 0 pods out of 5
Dec 10 18:09:40.990: INFO: Pod name wrapped-volume-race-94084df5-05d5-4ecb-9808-1840d593efeb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-94084df5-05d5-4ecb-9808-1840d593efeb in namespace emptydir-wrapper-9418, will wait for the garbage collector to delete the pods
Dec 10 18:09:53.069: INFO: Deleting ReplicationController wrapped-volume-race-94084df5-05d5-4ecb-9808-1840d593efeb took: 4.62671ms
Dec 10 18:09:53.170: INFO: Terminating ReplicationController wrapped-volume-race-94084df5-05d5-4ecb-9808-1840d593efeb pods took: 101.058844ms
STEP: Creating RC which spawns configmap-volume pods
Dec 10 18:09:57.295: INFO: Pod name wrapped-volume-race-a8c311dc-90e4-42be-8700-21731e65e097: Found 0 pods out of 5
Dec 10 18:10:02.302: INFO: Pod name wrapped-volume-race-a8c311dc-90e4-42be-8700-21731e65e097: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a8c311dc-90e4-42be-8700-21731e65e097 in namespace emptydir-wrapper-9418, will wait for the garbage collector to delete the pods
Dec 10 18:10:12.395: INFO: Deleting ReplicationController wrapped-volume-race-a8c311dc-90e4-42be-8700-21731e65e097 took: 4.949765ms
Dec 10 18:10:12.496: INFO: Terminating ReplicationController wrapped-volume-race-a8c311dc-90e4-42be-8700-21731e65e097 pods took: 101.231404ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:10:16.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9418" for this suite.

• [SLOW TEST:62.321 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":346,"completed":316,"skipped":5947,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:10:16.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-c1fd5424-0286-46f0-83ed-0ac64b1fd1ba
STEP: Creating a pod to test consume configMaps
Dec 10 18:10:16.318: INFO: Waiting up to 5m0s for pod "pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763" in namespace "configmap-102" to be "Succeeded or Failed"
Dec 10 18:10:16.321: INFO: Pod "pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763": Phase="Pending", Reason="", readiness=false. Elapsed: 2.644986ms
Dec 10 18:10:18.327: INFO: Pod "pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008712959s
Dec 10 18:10:20.336: INFO: Pod "pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01701365s
STEP: Saw pod success
Dec 10 18:10:20.336: INFO: Pod "pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763" satisfied condition "Succeeded or Failed"
Dec 10 18:10:20.338: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763 container agnhost-container: <nil>
STEP: delete the pod
Dec 10 18:10:20.354: INFO: Waiting for pod pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763 to disappear
Dec 10 18:10:20.357: INFO: Pod pod-configmaps-91e482ff-b264-44b5-91ea-38d95cd63763 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:10:20.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-102" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":317,"skipped":5985,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:10:20.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 18:10:20.427: INFO: Waiting up to 5m0s for pod "pod-4058034d-421d-484b-9a84-94ababeb2cfe" in namespace "emptydir-1003" to be "Succeeded or Failed"
Dec 10 18:10:20.431: INFO: Pod "pod-4058034d-421d-484b-9a84-94ababeb2cfe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.245281ms
Dec 10 18:10:22.436: INFO: Pod "pod-4058034d-421d-484b-9a84-94ababeb2cfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008786783s
Dec 10 18:10:24.444: INFO: Pod "pod-4058034d-421d-484b-9a84-94ababeb2cfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017110584s
STEP: Saw pod success
Dec 10 18:10:24.446: INFO: Pod "pod-4058034d-421d-484b-9a84-94ababeb2cfe" satisfied condition "Succeeded or Failed"
Dec 10 18:10:24.449: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-4058034d-421d-484b-9a84-94ababeb2cfe container test-container: <nil>
STEP: delete the pod
Dec 10 18:10:24.466: INFO: Waiting for pod pod-4058034d-421d-484b-9a84-94ababeb2cfe to disappear
Dec 10 18:10:24.468: INFO: Pod pod-4058034d-421d-484b-9a84-94ababeb2cfe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:10:24.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1003" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":318,"skipped":5999,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:10:24.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 18:10:28.587: INFO: DNS probes using dns-test-b660b07f-603d-4819-99ad-cc38bb75c5a3 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 18:10:30.653: INFO: File wheezy_udp@dns-test-service-3.dns-8183.svc.cluster.local from pod  dns-8183/dns-test-c79f6dc5-9960-4a06-bbfa-b975b01df02f contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 18:10:30.669: INFO: File jessie_udp@dns-test-service-3.dns-8183.svc.cluster.local from pod  dns-8183/dns-test-c79f6dc5-9960-4a06-bbfa-b975b01df02f contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 10 18:10:30.669: INFO: Lookups using dns-8183/dns-test-c79f6dc5-9960-4a06-bbfa-b975b01df02f failed for: [wheezy_udp@dns-test-service-3.dns-8183.svc.cluster.local jessie_udp@dns-test-service-3.dns-8183.svc.cluster.local]

Dec 10 18:10:35.676: INFO: DNS probes using dns-test-c79f6dc5-9960-4a06-bbfa-b975b01df02f succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8183.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8183.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 18:10:37.753: INFO: DNS probes using dns-test-2199500d-77fd-4275-b845-7297f5655486 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:10:37.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8183" for this suite.

• [SLOW TEST:13.309 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":346,"completed":319,"skipped":6004,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:10:37.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod with failed condition
STEP: updating the pod
Dec 10 18:12:38.672: INFO: Successfully updated pod "var-expansion-bed7b259-575e-4de5-be24-1bd2e706b983"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Dec 10 18:12:40.682: INFO: Deleting pod "var-expansion-bed7b259-575e-4de5-be24-1bd2e706b983" in namespace "var-expansion-9948"
Dec 10 18:12:40.686: INFO: Wait up to 5m0s for pod "var-expansion-bed7b259-575e-4de5-be24-1bd2e706b983" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:13:12.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9948" for this suite.

• [SLOW TEST:154.895 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":346,"completed":320,"skipped":6006,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:13:12.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 18:13:13.279: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 18:13:16.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:13:16.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-316" for this suite.
STEP: Destroying namespace "webhook-316-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":346,"completed":321,"skipped":6013,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:13:16.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 18:13:16.457: INFO: Waiting up to 5m0s for pod "pod-e6be53d7-56ad-4124-95e6-317720b4a6d9" in namespace "emptydir-5020" to be "Succeeded or Failed"
Dec 10 18:13:16.460: INFO: Pod "pod-e6be53d7-56ad-4124-95e6-317720b4a6d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038791ms
Dec 10 18:13:18.467: INFO: Pod "pod-e6be53d7-56ad-4124-95e6-317720b4a6d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009712703s
STEP: Saw pod success
Dec 10 18:13:18.467: INFO: Pod "pod-e6be53d7-56ad-4124-95e6-317720b4a6d9" satisfied condition "Succeeded or Failed"
Dec 10 18:13:18.469: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-e6be53d7-56ad-4124-95e6-317720b4a6d9 container test-container: <nil>
STEP: delete the pod
Dec 10 18:13:18.490: INFO: Waiting for pod pod-e6be53d7-56ad-4124-95e6-317720b4a6d9 to disappear
Dec 10 18:13:18.492: INFO: Pod pod-e6be53d7-56ad-4124-95e6-317720b4a6d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:13:18.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5020" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":322,"skipped":6025,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:13:18.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Dec 10 18:13:18.538: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 18:14:18.558: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:14:18.567: INFO: Starting informer...
STEP: Starting pods...
Dec 10 18:14:18.799: INFO: Pod1 is running on ip-10-0-19-34. Tainting Node
Dec 10 18:14:21.022: INFO: Pod2 is running on ip-10-0-19-34. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 10 18:14:26.928: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 10 18:14:47.449: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:14:47.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8233" for this suite.

• [SLOW TEST:88.993 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":346,"completed":323,"skipped":6062,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:14:47.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:14:51.680: INFO: Deleting pod "var-expansion-18f4c8dc-f260-4b53-a488-005134864a1f" in namespace "var-expansion-7994"
Dec 10 18:14:51.684: INFO: Wait up to 5m0s for pod "var-expansion-18f4c8dc-f260-4b53-a488-005134864a1f" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:14:53.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7994" for this suite.

• [SLOW TEST:6.194 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":346,"completed":324,"skipped":6093,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:14:53.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:14:53.733: INFO: Got root ca configmap in namespace "svcaccounts-1669"
Dec 10 18:14:53.736: INFO: Deleted root ca configmap in namespace "svcaccounts-1669"
STEP: waiting for a new root ca configmap created
Dec 10 18:14:54.241: INFO: Recreated root ca configmap in namespace "svcaccounts-1669"
Dec 10 18:14:54.248: INFO: Updated root ca configmap in namespace "svcaccounts-1669"
STEP: waiting for the root ca configmap reconciled
Dec 10 18:14:54.756: INFO: Reconciled root ca configmap in namespace "svcaccounts-1669"
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:14:54.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1669" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":346,"completed":325,"skipped":6100,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:14:54.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:14:54.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3114" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":346,"completed":326,"skipped":6122,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:14:54.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 18:14:54.944: INFO: Waiting up to 5m0s for pod "pod-feb72ed2-87e7-4239-ac22-f1457d580db0" in namespace "emptydir-6713" to be "Succeeded or Failed"
Dec 10 18:14:54.946: INFO: Pod "pod-feb72ed2-87e7-4239-ac22-f1457d580db0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769972ms
Dec 10 18:14:56.958: INFO: Pod "pod-feb72ed2-87e7-4239-ac22-f1457d580db0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013750064s
Dec 10 18:14:58.968: INFO: Pod "pod-feb72ed2-87e7-4239-ac22-f1457d580db0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024006516s
STEP: Saw pod success
Dec 10 18:14:58.969: INFO: Pod "pod-feb72ed2-87e7-4239-ac22-f1457d580db0" satisfied condition "Succeeded or Failed"
Dec 10 18:14:58.972: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-feb72ed2-87e7-4239-ac22-f1457d580db0 container test-container: <nil>
STEP: delete the pod
Dec 10 18:14:59.004: INFO: Waiting for pod pod-feb72ed2-87e7-4239-ac22-f1457d580db0 to disappear
Dec 10 18:14:59.007: INFO: Pod pod-feb72ed2-87e7-4239-ac22-f1457d580db0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:14:59.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6713" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":327,"skipped":6155,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:14:59.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-cd6ebffd-79bd-4af2-b981-72e6b69dc6bf
STEP: Creating configMap with name cm-test-opt-upd-e600af73-4c83-4c4d-98e6-4f5024ec84c0
STEP: Creating the pod
Dec 10 18:14:59.089: INFO: The status of Pod pod-configmaps-841a009d-d0de-49c7-b706-e4cd7f615243 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 18:15:01.110: INFO: The status of Pod pod-configmaps-841a009d-d0de-49c7-b706-e4cd7f615243 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 18:15:03.097: INFO: The status of Pod pod-configmaps-841a009d-d0de-49c7-b706-e4cd7f615243 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-cd6ebffd-79bd-4af2-b981-72e6b69dc6bf
STEP: Updating configmap cm-test-opt-upd-e600af73-4c83-4c4d-98e6-4f5024ec84c0
STEP: Creating configMap with name cm-test-opt-create-43996e38-1795-4997-9e9b-82d0e039312c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:09.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6537" for this suite.

• [SLOW TEST:70.461 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":328,"skipped":6172,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:09.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-67a335b3-bcb9-45ea-80a7-edb6d85dfc75
STEP: Creating a pod to test consume configMaps
Dec 10 18:16:09.551: INFO: Waiting up to 5m0s for pod "pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3" in namespace "configmap-4664" to be "Succeeded or Failed"
Dec 10 18:16:09.554: INFO: Pod "pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.373701ms
Dec 10 18:16:11.563: INFO: Pod "pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011792842s
Dec 10 18:16:13.568: INFO: Pod "pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017076736s
STEP: Saw pod success
Dec 10 18:16:13.569: INFO: Pod "pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3" satisfied condition "Succeeded or Failed"
Dec 10 18:16:13.572: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 18:16:13.586: INFO: Waiting for pod pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3 to disappear
Dec 10 18:16:13.589: INFO: Pod pod-configmaps-31f0e8e0-cbf4-4b8c-8b97-f22718249ed3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:13.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4664" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":329,"skipped":6195,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:13.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8341.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8341.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8341.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8341.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 18:16:17.758: INFO: DNS probes using dns-8341/dns-test-6e15b10d-9f16-4aee-a6d7-99b40bd0221e succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:17.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8341" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":346,"completed":330,"skipped":6205,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:17.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 18:16:17.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e" in namespace "projected-2753" to be "Succeeded or Failed"
Dec 10 18:16:17.897: INFO: Pod "downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.190241ms
Dec 10 18:16:19.905: INFO: Pod "downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012587464s
Dec 10 18:16:21.914: INFO: Pod "downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021081186s
STEP: Saw pod success
Dec 10 18:16:21.915: INFO: Pod "downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e" satisfied condition "Succeeded or Failed"
Dec 10 18:16:21.917: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e container client-container: <nil>
STEP: delete the pod
Dec 10 18:16:21.931: INFO: Waiting for pod downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e to disappear
Dec 10 18:16:21.936: INFO: Pod downwardapi-volume-d4ca5418-bcd5-423a-8781-d5cb32f36c8e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:21.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2753" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":346,"completed":331,"skipped":6218,"failed":0}
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:21.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:16:22.020: INFO: The status of Pod busybox-readonly-fs11a2e2a3-05a1-4b44-80d6-0741579146f2 is Pending, waiting for it to be Running (with Ready = true)
Dec 10 18:16:24.039: INFO: The status of Pod busybox-readonly-fs11a2e2a3-05a1-4b44-80d6-0741579146f2 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:24.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2712" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":332,"skipped":6223,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:24.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-4aab6060-7c09-46ae-b4d8-f32c9aa32e8b
STEP: Creating a pod to test consume secrets
Dec 10 18:16:24.105: INFO: Waiting up to 5m0s for pod "pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60" in namespace "secrets-3397" to be "Succeeded or Failed"
Dec 10 18:16:24.107: INFO: Pod "pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60": Phase="Pending", Reason="", readiness=false. Elapsed: 1.803112ms
Dec 10 18:16:26.121: INFO: Pod "pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015381096s
STEP: Saw pod success
Dec 10 18:16:26.122: INFO: Pod "pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60" satisfied condition "Succeeded or Failed"
Dec 10 18:16:26.124: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 18:16:26.143: INFO: Waiting for pod pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60 to disappear
Dec 10 18:16:26.146: INFO: Pod pod-secrets-dc2db4bf-09c2-46fa-9451-33893a91fa60 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:26.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3397" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":333,"skipped":6232,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:26.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 10 18:16:26.683: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 10 18:16:29.704: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:29.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8513" for this suite.
STEP: Destroying namespace "webhook-8513-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":346,"completed":334,"skipped":6304,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:16:29.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1525" for this suite.
STEP: Destroying namespace "nspatchtest-9fb1e5aa-3a29-4936-be89-cfd379bd814b-8009" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":346,"completed":335,"skipped":6352,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:16:29.995: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Dec 10 18:16:30.051: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 10 18:17:30.072: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:17:30.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:679
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:17:30.154: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Dec 10 18:17:30.161: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:17:30.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6970" for this suite.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:693
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:17:30.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1388" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:60.303 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:673
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":346,"completed":336,"skipped":6436,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:17:30.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Dec 10 18:17:30.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:17:30.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5817" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":346,"completed":337,"skipped":6439,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:17:30.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-2885
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 18:17:30.558: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2885" in namespace "subpath-8225" to be "Succeeded or Failed"
Dec 10 18:17:30.562: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4676ms
Dec 10 18:17:32.570: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 2.010955837s
Dec 10 18:17:34.575: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 4.016166761s
Dec 10 18:17:36.584: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 6.025678101s
Dec 10 18:17:38.590: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 8.030754815s
Dec 10 18:17:40.596: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 10.036854625s
Dec 10 18:17:42.605: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 12.045919277s
Dec 10 18:17:44.613: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 14.054450469s
Dec 10 18:17:46.619: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 16.06042134s
Dec 10 18:17:48.627: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 18.068691924s
Dec 10 18:17:50.633: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 20.074514676s
Dec 10 18:17:52.651: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Running", Reason="", readiness=true. Elapsed: 22.091719646s
Dec 10 18:17:54.654: INFO: Pod "pod-subpath-test-configmap-2885": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.095440786s
STEP: Saw pod success
Dec 10 18:17:54.654: INFO: Pod "pod-subpath-test-configmap-2885" satisfied condition "Succeeded or Failed"
Dec 10 18:17:54.656: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-subpath-test-configmap-2885 container test-container-subpath-configmap-2885: <nil>
STEP: delete the pod
Dec 10 18:17:54.670: INFO: Waiting for pod pod-subpath-test-configmap-2885 to disappear
Dec 10 18:17:54.673: INFO: Pod pod-subpath-test-configmap-2885 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2885
Dec 10 18:17:54.673: INFO: Deleting pod "pod-subpath-test-configmap-2885" in namespace "subpath-8225"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:17:54.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8225" for this suite.

• [SLOW TEST:24.166 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":338,"skipped":6470,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:17:54.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6260
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6260
I1210 18:17:54.769624      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6260, replica count: 2
I1210 18:17:57.821227      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 18:17:57.822: INFO: Creating new exec pod
Dec 10 18:18:00.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6260 exec execpodfc6rn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 18:18:01.253: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 18:18:01.253: INFO: stdout: ""
Dec 10 18:18:02.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6260 exec execpodfc6rn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 10 18:18:02.529: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 10 18:18:02.529: INFO: stdout: "externalname-service-wt9rc"
Dec 10 18:18:02.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6260 exec execpodfc6rn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.166.188 80'
Dec 10 18:18:02.782: INFO: stderr: "+ nc -v -t -w 2 10.3.166.188 80\n+ echo hostNameConnection to 10.3.166.188 80 port [tcp/http] succeeded!\n\n"
Dec 10 18:18:02.782: INFO: stdout: "externalname-service-gqdnt"
Dec 10 18:18:02.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6260 exec execpodfc6rn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.54 30901'
Dec 10 18:18:03.078: INFO: stderr: "+ nc -v -t -w 2 10.0.0.54 30901\n+ echo hostNameConnection to 10.0.0.54 30901 port [tcp/*] succeeded!\n\n"
Dec 10 18:18:03.078: INFO: stdout: "externalname-service-gqdnt"
Dec 10 18:18:03.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2692618226 --namespace=services-6260 exec execpodfc6rn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.19.34 30901'
Dec 10 18:18:03.295: INFO: stderr: "+ nc -v -t -w 2 10.0.19.34 30901\nConnection to 10.0.19.34 30901 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 10 18:18:03.295: INFO: stdout: "externalname-service-gqdnt"
Dec 10 18:18:03.295: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:18:03.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6260" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:8.671 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":346,"completed":339,"skipped":6483,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:18:03.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Dec 10 18:18:03.438: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7" in namespace "downward-api-3434" to be "Succeeded or Failed"
Dec 10 18:18:03.451: INFO: Pod "downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.914243ms
Dec 10 18:18:05.457: INFO: Pod "downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019177864s
STEP: Saw pod success
Dec 10 18:18:05.457: INFO: Pod "downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7" satisfied condition "Succeeded or Failed"
Dec 10 18:18:05.459: INFO: Trying to get logs from node ip-10-0-19-34 pod downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7 container client-container: <nil>
STEP: delete the pod
Dec 10 18:18:05.482: INFO: Waiting for pod downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7 to disappear
Dec 10 18:18:05.484: INFO: Pod downwardapi-volume-36ec22da-aaf3-44af-aec7-905a38e8e7f7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:18:05.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3434" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":340,"skipped":6510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:18:05.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-b5969146-c854-4d63-94de-43132938c0db in namespace container-probe-1354
Dec 10 18:18:07.611: INFO: Started pod liveness-b5969146-c854-4d63-94de-43132938c0db in namespace container-probe-1354
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 18:18:07.615: INFO: Initial restart count of pod liveness-b5969146-c854-4d63-94de-43132938c0db is 0
Dec 10 18:18:27.714: INFO: Restart count of pod container-probe-1354/liveness-b5969146-c854-4d63-94de-43132938c0db is now 1 (20.098757793s elapsed)
Dec 10 18:18:47.843: INFO: Restart count of pod container-probe-1354/liveness-b5969146-c854-4d63-94de-43132938c0db is now 2 (40.227443555s elapsed)
Dec 10 18:19:07.981: INFO: Restart count of pod container-probe-1354/liveness-b5969146-c854-4d63-94de-43132938c0db is now 3 (1m0.365163108s elapsed)
Dec 10 18:19:28.059: INFO: Restart count of pod container-probe-1354/liveness-b5969146-c854-4d63-94de-43132938c0db is now 4 (1m20.44400553s elapsed)
Dec 10 18:20:28.449: INFO: Restart count of pod container-probe-1354/liveness-b5969146-c854-4d63-94de-43132938c0db is now 5 (2m20.8333249s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:28.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1354" for this suite.

• [SLOW TEST:142.967 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":346,"completed":341,"skipped":6566,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:20:28.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Dec 10 18:20:30.533: INFO: pods: 0 < 3
Dec 10 18:20:32.542: INFO: running pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Dec 10 18:20:36.683: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:38.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8459" for this suite.

• [SLOW TEST:10.260 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":346,"completed":342,"skipped":6586,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:20:38.734: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Dec 10 18:20:38.798: INFO: Waiting up to 5m0s for pod "security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824" in namespace "security-context-3235" to be "Succeeded or Failed"
Dec 10 18:20:38.802: INFO: Pod "security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824": Phase="Pending", Reason="", readiness=false. Elapsed: 3.086616ms
Dec 10 18:20:40.827: INFO: Pod "security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028744176s
Dec 10 18:20:42.853: INFO: Pod "security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054612818s
STEP: Saw pod success
Dec 10 18:20:42.853: INFO: Pod "security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824" satisfied condition "Succeeded or Failed"
Dec 10 18:20:42.855: INFO: Trying to get logs from node ip-10-0-19-34 pod security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824 container test-container: <nil>
STEP: delete the pod
Dec 10 18:20:42.885: INFO: Waiting for pod security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824 to disappear
Dec 10 18:20:42.888: INFO: Pod security-context-81eac66b-ad9d-4fe1-8f53-b8ea71985824 no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:42.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3235" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":343,"skipped":6596,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:20:42.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-ba33e535-c1d7-4ad2-a52e-a412d94a7490
STEP: Creating a pod to test consume secrets
Dec 10 18:20:42.952: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0" in namespace "projected-1921" to be "Succeeded or Failed"
Dec 10 18:20:42.956: INFO: Pod "pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.307679ms
Dec 10 18:20:44.961: INFO: Pod "pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008074608s
STEP: Saw pod success
Dec 10 18:20:44.961: INFO: Pod "pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0" satisfied condition "Succeeded or Failed"
Dec 10 18:20:44.964: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 18:20:44.996: INFO: Waiting for pod pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0 to disappear
Dec 10 18:20:45.000: INFO: Pod pod-projected-secrets-4afcb573-71ca-4fbf-8040-4cbee44d17f0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:45.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1921" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":344,"skipped":6607,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:20:45.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Dec 10 18:20:45.089: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 10 18:20:50.095: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Dec 10 18:20:50.097: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Dec 10 18:20:50.111: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Dec 10 18:20:50.116: INFO: Observed &ReplicaSet event: ADDED
Dec 10 18:20:50.116: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.117: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.117: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.117: INFO: Found replicaset test-rs in namespace replicaset-6050 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 10 18:20:50.117: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Dec 10 18:20:50.118: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 10 18:20:50.125: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Dec 10 18:20:50.128: INFO: Observed &ReplicaSet event: ADDED
Dec 10 18:20:50.128: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.129: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.130: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.131: INFO: Observed replicaset test-rs in namespace replicaset-6050 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 10 18:20:50.131: INFO: Observed &ReplicaSet event: MODIFIED
Dec 10 18:20:50.131: INFO: Found replicaset test-rs in namespace replicaset-6050 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Dec 10 18:20:50.132: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:50.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6050" for this suite.

• [SLOW TEST:5.103 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":346,"completed":345,"skipped":6653,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Dec 10 18:20:50.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2692618226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-34d01883-df33-410e-be6c-f51fd4d35d8c
STEP: Creating a pod to test consume configMaps
Dec 10 18:20:50.246: INFO: Waiting up to 5m0s for pod "pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab" in namespace "configmap-3299" to be "Succeeded or Failed"
Dec 10 18:20:50.263: INFO: Pod "pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab": Phase="Pending", Reason="", readiness=false. Elapsed: 17.347124ms
Dec 10 18:20:52.270: INFO: Pod "pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024292328s
Dec 10 18:20:54.282: INFO: Pod "pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03643659s
STEP: Saw pod success
Dec 10 18:20:54.283: INFO: Pod "pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab" satisfied condition "Succeeded or Failed"
Dec 10 18:20:54.288: INFO: Trying to get logs from node ip-10-0-19-34 pod pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab container agnhost-container: <nil>
STEP: delete the pod
Dec 10 18:20:54.312: INFO: Waiting for pod pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab to disappear
Dec 10 18:20:54.315: INFO: Pod pod-configmaps-4b807fa5-4e81-43b1-bfc7-1d9d4c435bab no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Dec 10 18:20:54.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3299" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":346,"skipped":6665,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec 10 18:20:54.342: INFO: Running AfterSuite actions on all nodes
Dec 10 18:20:54.343: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func18.2
Dec 10 18:20:54.343: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Dec 10 18:20:54.343: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
Dec 10 18:20:54.343: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Dec 10 18:20:54.344: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Dec 10 18:20:54.351: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Dec 10 18:20:54.351: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Dec 10 18:20:54.352: INFO: Running AfterSuite actions on node 1
Dec 10 18:20:54.354: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":346,"completed":346,"skipped":6696,"failed":0}

Ran 346 of 7042 Specs in 6036.768 seconds
SUCCESS! -- 346 Passed | 0 Failed | 0 Pending | 6696 Skipped
PASS

Ginkgo ran 1 suite in 1h40m46.431147014s
Test Suite Passed
