I0407 06:29:16.249394      23 e2e.go:132] Starting e2e run "f7f4912d-3f9a-4bad-b707-d31154960389" on Ginkgo node 1
{"msg":"Test Suite starting","total":346,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1649312956 - Will randomize all specs
Will run 346 of 7042 specs

Apr  7 06:29:18.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:29:18.315: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  7 06:29:18.361: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  7 06:29:18.407: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  7 06:29:18.407: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Apr  7 06:29:18.407: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  7 06:29:18.425: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'azure-ip-masq-agent' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'cloud-node-manager' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'cloud-node-manager-windows' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-azuredisk-node' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-azuredisk-node-win' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-azurefile-node' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-azurefile-node-win' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr  7 06:29:18.425: INFO: e2e test version: v1.23.3
Apr  7 06:29:18.427: INFO: kube-apiserver version: v1.23.3
Apr  7 06:29:18.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:29:18.435: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:18.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replication-controller
Apr  7 06:29:18.535: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
W0407 06:29:18.535583      23 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  7 06:29:18.557: INFO: Pod name pod-release: Found 0 pods out of 1
Apr  7 06:29:23.572: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:24.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3010" for this suite.

• [SLOW TEST:6.210 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":346,"completed":1,"skipped":24,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:24.645: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:29:24.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1" in namespace "downward-api-6694" to be "Succeeded or Failed"
Apr  7 06:29:24.743: INFO: Pod "downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.51722ms
Apr  7 06:29:26.755: INFO: Pod "downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018698688s
Apr  7 06:29:28.772: INFO: Pod "downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035991908s
STEP: Saw pod success
Apr  7 06:29:28.772: INFO: Pod "downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1" satisfied condition "Succeeded or Failed"
Apr  7 06:29:28.779: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1 container client-container: <nil>
STEP: delete the pod
Apr  7 06:29:28.815: INFO: Waiting for pod downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1 to disappear
Apr  7 06:29:28.821: INFO: Pod downwardapi-volume-d51f8b47-0fe2-41c4-9524-0d340b0e93a1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:28.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6694" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":2,"skipped":26,"failed":0}
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:28.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
Apr  7 06:29:29.495: INFO: created pod pod-service-account-defaultsa
Apr  7 06:29:29.495: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  7 06:29:29.504: INFO: created pod pod-service-account-mountsa
Apr  7 06:29:29.504: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  7 06:29:29.512: INFO: created pod pod-service-account-nomountsa
Apr  7 06:29:29.512: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  7 06:29:29.522: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  7 06:29:29.522: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  7 06:29:29.536: INFO: created pod pod-service-account-mountsa-mountspec
Apr  7 06:29:29.536: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  7 06:29:29.545: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  7 06:29:29.545: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  7 06:29:29.559: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  7 06:29:29.559: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  7 06:29:29.576: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  7 06:29:29.576: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  7 06:29:29.588: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  7 06:29:29.588: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:29.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9632" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":346,"completed":3,"skipped":30,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:29.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:29:29.697: INFO: Creating pod...
Apr  7 06:29:29.718: INFO: Pod Quantity: 1 Status: Pending
Apr  7 06:29:30.729: INFO: Pod Quantity: 1 Status: Pending
Apr  7 06:29:31.726: INFO: Pod Quantity: 1 Status: Pending
Apr  7 06:29:32.729: INFO: Pod Quantity: 1 Status: Pending
Apr  7 06:29:33.734: INFO: Pod Status: Running
Apr  7 06:29:33.734: INFO: Creating service...
Apr  7 06:29:33.769: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/DELETE
Apr  7 06:29:33.782: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr  7 06:29:33.782: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/GET
Apr  7 06:29:33.799: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr  7 06:29:33.799: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/HEAD
Apr  7 06:29:33.806: INFO: http.Client request:HEAD | StatusCode:200
Apr  7 06:29:33.806: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/OPTIONS
Apr  7 06:29:33.814: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr  7 06:29:33.814: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/PATCH
Apr  7 06:29:33.822: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr  7 06:29:33.822: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/POST
Apr  7 06:29:33.831: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr  7 06:29:33.831: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/pods/agnhost/proxy/some/path/with/PUT
Apr  7 06:29:33.838: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr  7 06:29:33.838: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/DELETE
Apr  7 06:29:33.850: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr  7 06:29:33.850: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/GET
Apr  7 06:29:33.861: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr  7 06:29:33.861: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/HEAD
Apr  7 06:29:33.874: INFO: http.Client request:HEAD | StatusCode:200
Apr  7 06:29:33.874: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/OPTIONS
Apr  7 06:29:33.886: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr  7 06:29:33.886: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/PATCH
Apr  7 06:29:33.900: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr  7 06:29:33.900: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/POST
Apr  7 06:29:33.911: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr  7 06:29:33.911: INFO: Starting http.Client for https://10.0.0.1:443/api/v1/namespaces/proxy-8591/services/test-service/proxy/some/path/with/PUT
Apr  7 06:29:33.922: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:33.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8591" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":346,"completed":4,"skipped":50,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:33.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test env composition
Apr  7 06:29:34.052: INFO: Waiting up to 5m0s for pod "var-expansion-8effa704-a56c-450f-be65-8dd456922a50" in namespace "var-expansion-8095" to be "Succeeded or Failed"
Apr  7 06:29:34.059: INFO: Pod "var-expansion-8effa704-a56c-450f-be65-8dd456922a50": Phase="Pending", Reason="", readiness=false. Elapsed: 6.999253ms
Apr  7 06:29:36.069: INFO: Pod "var-expansion-8effa704-a56c-450f-be65-8dd456922a50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017659114s
STEP: Saw pod success
Apr  7 06:29:36.069: INFO: Pod "var-expansion-8effa704-a56c-450f-be65-8dd456922a50" satisfied condition "Succeeded or Failed"
Apr  7 06:29:36.076: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod var-expansion-8effa704-a56c-450f-be65-8dd456922a50 container dapi-container: <nil>
STEP: delete the pod
Apr  7 06:29:36.122: INFO: Waiting for pod var-expansion-8effa704-a56c-450f-be65-8dd456922a50 to disappear
Apr  7 06:29:36.129: INFO: Pod var-expansion-8effa704-a56c-450f-be65-8dd456922a50 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:36.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8095" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":346,"completed":5,"skipped":51,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:36.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-6855
[It] should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-6855
Apr  7 06:29:36.291: INFO: Found 0 stateful pods, waiting for 1
Apr  7 06:29:46.306: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Apr  7 06:29:46.354: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Apr  7 06:29:46.382: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Apr  7 06:29:46.385: INFO: Observed &StatefulSet event: ADDED
Apr  7 06:29:46.385: INFO: Found Statefulset ss in namespace statefulset-6855 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr  7 06:29:46.385: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Apr  7 06:29:46.385: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr  7 06:29:46.397: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Apr  7 06:29:46.401: INFO: Observed &StatefulSet event: ADDED
Apr  7 06:29:46.401: INFO: Observed Statefulset ss in namespace statefulset-6855 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr  7 06:29:46.401: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 06:29:46.401: INFO: Deleting all statefulset in ns statefulset-6855
Apr  7 06:29:46.411: INFO: Scaling statefulset ss to 0
Apr  7 06:29:56.456: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 06:29:56.466: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:29:56.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6855" for this suite.

• [SLOW TEST:20.375 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should validate Statefulset Status endpoints [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":346,"completed":6,"skipped":71,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:29:56.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-5019
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 06:29:56.608: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr  7 06:29:56.658: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:29:58.672: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:00.677: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:02.671: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:04.675: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:06.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:08.670: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:10.670: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:12.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:14.676: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:16.673: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:30:18.672: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr  7 06:30:18.685: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr  7 06:30:20.764: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr  7 06:30:20.764: INFO: Going to poll 10.244.0.15 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Apr  7 06:30:20.770: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.15 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5019 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:30:20.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:30:20.771: INFO: ExecWithOptions: Clientset creation
Apr  7 06:30:20.771: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-5019/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.15+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:30:21.937: INFO: Found all 1 expected endpoints: [netserver-0]
Apr  7 06:30:21.937: INFO: Going to poll 10.244.1.9 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Apr  7 06:30:21.952: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.9 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5019 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:30:21.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:30:21.952: INFO: ExecWithOptions: Clientset creation
Apr  7 06:30:21.952: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-5019/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.9+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:30:23.087: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:30:23.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5019" for this suite.

• [SLOW TEST:26.591 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":7,"skipped":97,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:30:23.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:30:23.219: INFO: Creating deployment "webserver-deployment"
Apr  7 06:30:23.230: INFO: Waiting for observed generation 1
Apr  7 06:30:25.251: INFO: Waiting for all required pods to come up
Apr  7 06:30:25.261: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  7 06:30:29.296: INFO: Waiting for deployment "webserver-deployment" to complete
Apr  7 06:30:29.311: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr  7 06:30:29.342: INFO: Updating deployment webserver-deployment
Apr  7 06:30:29.342: INFO: Waiting for observed generation 2
Apr  7 06:30:31.365: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  7 06:30:31.373: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  7 06:30:31.381: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr  7 06:30:31.404: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  7 06:30:31.404: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  7 06:30:31.416: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr  7 06:30:31.431: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr  7 06:30:31.431: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr  7 06:30:31.451: INFO: Updating deployment webserver-deployment
Apr  7 06:30:31.451: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr  7 06:30:31.466: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  7 06:30:31.473: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 06:30:31.496: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2864  e00596cf-22b0-47de-af45-02ecd44e6e1d 3615 3 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca3be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-566f96c878" is progressing.,LastUpdateTime:2022-04-07 06:30:29 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-04-07 06:30:31 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr  7 06:30:31.507: INFO: New ReplicaSet "webserver-deployment-566f96c878" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-566f96c878  deployment-2864  c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 3613 3 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment e00596cf-22b0-47de-af45-02ecd44e6e1d 0xc003ca3fc7 0xc003ca3fc8}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e00596cf-22b0-47de-af45-02ecd44e6e1d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 566f96c878,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003efe068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 06:30:31.507: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr  7 06:30:31.507: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-5d9fdcc779  deployment-2864  d3be721c-dcd2-4fe3-befd-fe920d72c2fa 3611 3 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment e00596cf-22b0-47de-af45-02ecd44e6e1d 0xc003efe0c7 0xc003efe0c8}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e00596cf-22b0-47de-af45-02ecd44e6e1d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:30:25 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003efe158 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr  7 06:30:31.524: INFO: Pod "webserver-deployment-566f96c878-5b4rj" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-5b4rj webserver-deployment-566f96c878- deployment-2864  2b8eb02c-f1ec-493c-ac9e-597f711e4334 3637 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003a8d9f0 0xc003a8d9f1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9259s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9259s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.525: INFO: Pod "webserver-deployment-566f96c878-5dfx6" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-5dfx6 webserver-deployment-566f96c878- deployment-2864  836a6f8e-00ff-45b2-b5df-1cea9c48e8ea 3534 0 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003a8db50 0xc003a8db51}] []  [{Go-http-client Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6n8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6n8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2022-04-07 06:30:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.525: INFO: Pod "webserver-deployment-566f96c878-5k6cj" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-5k6cj webserver-deployment-566f96c878- deployment-2864  b677eb74-c5fd-45eb-9a44-2e0c724c83d9 3541 0 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003a8dd20 0xc003a8dd21}] []  [{Go-http-client Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6qgdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6qgdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2022-04-07 06:30:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.525: INFO: Pod "webserver-deployment-566f96c878-7d7hs" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-7d7hs webserver-deployment-566f96c878- deployment-2864  25a37f1d-8daf-4b00-a10e-1fd18ce2766d 3622 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003a8def0 0xc003a8def1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wfcr9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wfcr9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.525: INFO: Pod "webserver-deployment-566f96c878-hj9sd" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-hj9sd webserver-deployment-566f96c878- deployment-2864  6a14127b-9938-48c2-b824-c9daeaed0464 3635 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003f42050 0xc003f42051}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5lbpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5lbpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.526: INFO: Pod "webserver-deployment-566f96c878-k7f47" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-k7f47 webserver-deployment-566f96c878- deployment-2864  8c7cd0b4-6a00-4648-b3ca-49bfb6a2d714 3579 0 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003f421b0 0xc003f421b1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjlh7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjlh7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.16,StartTime:2022-04-07 06:30:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.526: INFO: Pod "webserver-deployment-566f96c878-tkgmc" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-tkgmc webserver-deployment-566f96c878- deployment-2864  56de7ac1-eb75-4f4d-9e89-914c4d8e8d1a 3586 0 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003f423c0 0xc003f423c1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dkql2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dkql2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.17,StartTime:2022-04-07 06:30:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.526: INFO: Pod "webserver-deployment-566f96c878-zns6k" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-zns6k webserver-deployment-566f96c878- deployment-2864  973ecf64-3434-4c21-8fd4-73709c9c1e1c 3564 0 2022-04-07 06:30:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13 0xc003f425d0 0xc003f425d1}] []  [{Go-http-client Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2022-04-07 06:30:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c16cc8a5-44cf-4b0a-ac19-9ba75d7f9e13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rd8zg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rd8zg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2022-04-07 06:30:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.526: INFO: Pod "webserver-deployment-5d9fdcc779-4bt6t" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4bt6t webserver-deployment-5d9fdcc779- deployment-2864  e8698a74-190a-4555-b89b-b4a0cbe68f27 3439 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f427a0 0xc003f427a1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qqns6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qqns6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.14,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f4f038c55cb228b5e78cba6681bfd4d6a5a915da93e277db22afa2ce63c882f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.527: INFO: Pod "webserver-deployment-5d9fdcc779-4spbk" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4spbk webserver-deployment-5d9fdcc779- deployment-2864  4f724e3e-fc33-4332-9357-67e75b0db22d 3632 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f42980 0xc003f42981}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2bn4x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2bn4x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.527: INFO: Pod "webserver-deployment-5d9fdcc779-4w4bq" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4w4bq webserver-deployment-5d9fdcc779- deployment-2864  a16c8fa8-cc89-43e7-a719-78bcd9012ced 3634 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f42ab7 0xc003f42ab8}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wns8k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wns8k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.527: INFO: Pod "webserver-deployment-5d9fdcc779-5n75c" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-5n75c webserver-deployment-5d9fdcc779- deployment-2864  460fa3fe-cfdc-4d23-88ea-32d90202d25c 3468 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f42bf7 0xc003f42bf8}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mk8tt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mk8tt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.18,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7e1a84fdc8ed48c6332db18de72487301f953d3ea31694f5f8c3359df8f1f061,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.527: INFO: Pod "webserver-deployment-5d9fdcc779-778dx" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-778dx webserver-deployment-5d9fdcc779- deployment-2864  16436bf9-c542-44c3-9b45-675f5a769f7b 3473 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f42dd0 0xc003f42dd1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5bkf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5bkf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.20,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://524a0a022d2c561f0fe2e810e65127667a1b29a70041c47ece97fa72d63133e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.527: INFO: Pod "webserver-deployment-5d9fdcc779-8dbt7" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-8dbt7 webserver-deployment-5d9fdcc779- deployment-2864  256b7f64-a768-4ac9-b97b-33ce52848539 3436 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f42fb0 0xc003f42fb1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gqccc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gqccc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.15,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://62204a45dc60f674121164c7675085c9c47d9c04e1346b93d4e707e66d7b8467,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-9dvz5" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-9dvz5 webserver-deployment-5d9fdcc779- deployment-2864  102ef7db-e60b-4a79-b8e3-159fba100ca8 3631 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43190 0xc003f43191}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nn5v2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nn5v2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-b4qn2" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-b4qn2 webserver-deployment-5d9fdcc779- deployment-2864  8f97c30f-52f0-4ca3-b915-f3f2cf4c83d7 3636 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f432c7 0xc003f432c8}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5gskq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5gskq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-g7ftn" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-g7ftn webserver-deployment-5d9fdcc779- deployment-2864  bdb500e3-32f9-485b-8233-10d3940dcaaa 3449 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43420 0xc003f43421}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8h6bq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8h6bq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.12,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://df56b8014559c4197dfcf51c4d944706787f2dcd29f4b32872aa4c343fb8d7a4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-mtzt4" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-mtzt4 webserver-deployment-5d9fdcc779- deployment-2864  d6d1b328-fa94-40e1-9989-494ae3721a3c 3443 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43600 0xc003f43601}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.13\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c5htr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c5htr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.13,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e27def2af7978029552525df2d3311d7fd4cbb83d7daa5085f1ab257eaccb563,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.13,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-qj7rn" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-qj7rn webserver-deployment-5d9fdcc779- deployment-2864  588138ca-f200-461a-8c37-47d811455c28 3476 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f437e0 0xc003f437e1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xtlk6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xtlk6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.17,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://34f7eacdf72fcfe301bc66ff356b9cb2ce821c37ccf761f9efaf274ae35c153b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.528: INFO: Pod "webserver-deployment-5d9fdcc779-qrq5x" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-qrq5x webserver-deployment-5d9fdcc779- deployment-2864  f501218d-1f88-4e2b-a5f0-2a31120af07b 3627 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f439c0 0xc003f439c1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6tl8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6tl8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.529: INFO: Pod "webserver-deployment-5d9fdcc779-v26fv" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-v26fv webserver-deployment-5d9fdcc779- deployment-2864  2c35fa46-97a4-4c2c-942b-34aa0ac0301f 3618 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43b10 0xc003f43b11}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2v46q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2v46q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.529: INFO: Pod "webserver-deployment-5d9fdcc779-xknqr" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-xknqr webserver-deployment-5d9fdcc779- deployment-2864  bf2f8f13-fe23-48b7-b0e9-b3f2d9bba4b3 3624 0 2022-04-07 06:30:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43c60 0xc003f43c61}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hwq9g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hwq9g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 06:30:31.529: INFO: Pod "webserver-deployment-5d9fdcc779-zf2pn" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-zf2pn webserver-deployment-5d9fdcc779- deployment-2864  a7aa3859-e7fd-46a6-990b-a55fcc9560dc 3430 0 2022-04-07 06:30:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 d3be721c-dcd2-4fe3-befd-fe920d72c2fa 0xc003f43db0 0xc003f43db1}] []  [{kube-controller-manager Update v1 2022-04-07 06:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3be721c-dcd2-4fe3-befd-fe920d72c2fa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:30:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fh2xc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fh2xc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:30:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.11,StartTime:2022-04-07 06:30:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:30:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://683abfe8c35ee5e0a851a3053edc238ddd51d1ed02d7257cb7dd2df13983f228,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:30:31.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2864" for this suite.

• [SLOW TEST:8.444 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":346,"completed":8,"skipped":125,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:30:31.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  7 06:30:31.669: INFO: Waiting up to 5m0s for pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd" in namespace "emptydir-1703" to be "Succeeded or Failed"
Apr  7 06:30:31.677: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.22177ms
Apr  7 06:30:33.691: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02212272s
Apr  7 06:30:35.708: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039120406s
Apr  7 06:30:37.721: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051332281s
Apr  7 06:30:39.743: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.074069016s
STEP: Saw pod success
Apr  7 06:30:39.743: INFO: Pod "pod-bab51d15-3470-4315-96f0-bb33dee6e0dd" satisfied condition "Succeeded or Failed"
Apr  7 06:30:39.750: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod pod-bab51d15-3470-4315-96f0-bb33dee6e0dd container test-container: <nil>
STEP: delete the pod
Apr  7 06:30:39.787: INFO: Waiting for pod pod-bab51d15-3470-4315-96f0-bb33dee6e0dd to disappear
Apr  7 06:30:39.792: INFO: Pod pod-bab51d15-3470-4315-96f0-bb33dee6e0dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:30:39.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1703" for this suite.

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":9,"skipped":130,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:30:39.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  7 06:30:40.437: INFO: Pod name wrapped-volume-race-648a69de-16aa-4490-9322-0238859ba994: Found 0 pods out of 5
Apr  7 06:30:45.472: INFO: Pod name wrapped-volume-race-648a69de-16aa-4490-9322-0238859ba994: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-648a69de-16aa-4490-9322-0238859ba994 in namespace emptydir-wrapper-6709, will wait for the garbage collector to delete the pods
Apr  7 06:30:57.588: INFO: Deleting ReplicationController wrapped-volume-race-648a69de-16aa-4490-9322-0238859ba994 took: 12.21318ms
Apr  7 06:30:57.689: INFO: Terminating ReplicationController wrapped-volume-race-648a69de-16aa-4490-9322-0238859ba994 pods took: 100.721736ms
STEP: Creating RC which spawns configmap-volume pods
Apr  7 06:31:02.938: INFO: Pod name wrapped-volume-race-e63ddd85-9558-4aee-b847-f2b022995bd9: Found 0 pods out of 5
Apr  7 06:31:07.959: INFO: Pod name wrapped-volume-race-e63ddd85-9558-4aee-b847-f2b022995bd9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e63ddd85-9558-4aee-b847-f2b022995bd9 in namespace emptydir-wrapper-6709, will wait for the garbage collector to delete the pods
Apr  7 06:31:22.113: INFO: Deleting ReplicationController wrapped-volume-race-e63ddd85-9558-4aee-b847-f2b022995bd9 took: 13.858883ms
Apr  7 06:31:22.213: INFO: Terminating ReplicationController wrapped-volume-race-e63ddd85-9558-4aee-b847-f2b022995bd9 pods took: 100.381899ms
STEP: Creating RC which spawns configmap-volume pods
Apr  7 06:31:24.971: INFO: Pod name wrapped-volume-race-8edadbfe-7c91-483f-bfaf-1537fe7228da: Found 0 pods out of 5
Apr  7 06:31:30.009: INFO: Pod name wrapped-volume-race-8edadbfe-7c91-483f-bfaf-1537fe7228da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8edadbfe-7c91-483f-bfaf-1537fe7228da in namespace emptydir-wrapper-6709, will wait for the garbage collector to delete the pods
Apr  7 06:31:44.134: INFO: Deleting ReplicationController wrapped-volume-race-8edadbfe-7c91-483f-bfaf-1537fe7228da took: 15.839208ms
Apr  7 06:31:44.235: INFO: Terminating ReplicationController wrapped-volume-race-8edadbfe-7c91-483f-bfaf-1537fe7228da pods took: 100.228581ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:31:49.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6709" for this suite.

• [SLOW TEST:69.463 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":346,"completed":10,"skipped":172,"failed":0}
SSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:31:49.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-3c4632d0-1a90-4ca9-a04a-8e766ad3cc81 in namespace container-probe-6528
Apr  7 06:31:51.482: INFO: Started pod busybox-3c4632d0-1a90-4ca9-a04a-8e766ad3cc81 in namespace container-probe-6528
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 06:31:51.488: INFO: Initial restart count of pod busybox-3c4632d0-1a90-4ca9-a04a-8e766ad3cc81 is 0
Apr  7 06:32:41.884: INFO: Restart count of pod container-probe-6528/busybox-3c4632d0-1a90-4ca9-a04a-8e766ad3cc81 is now 1 (50.395542544s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:32:41.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6528" for this suite.

• [SLOW TEST:52.662 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":11,"skipped":177,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:32:41.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:32:42.691: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:32:45.750: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:32:45.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7520" for this suite.
STEP: Destroying namespace "webhook-7520-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":346,"completed":12,"skipped":203,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:32:45.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:32:45.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr  7 06:32:46.000: INFO: The status of Pod pod-logs-websocket-f549b2ea-8699-41b9-946e-02afd488b081 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:32:48.012: INFO: The status of Pod pod-logs-websocket-f549b2ea-8699-41b9-946e-02afd488b081 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:32:48.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-576" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":346,"completed":13,"skipped":228,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:32:48.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:32:48.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5190" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":346,"completed":14,"skipped":254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:32:48.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:00.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-664" for this suite.

• [SLOW TEST:312.199 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":346,"completed":15,"skipped":300,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:00.494: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:38:00.599: INFO: Waiting up to 5m0s for pod "busybox-user-65534-f83284db-c98a-4b50-ad85-fdb6305c0060" in namespace "security-context-test-2958" to be "Succeeded or Failed"
Apr  7 06:38:00.605: INFO: Pod "busybox-user-65534-f83284db-c98a-4b50-ad85-fdb6305c0060": Phase="Pending", Reason="", readiness=false. Elapsed: 6.309203ms
Apr  7 06:38:02.620: INFO: Pod "busybox-user-65534-f83284db-c98a-4b50-ad85-fdb6305c0060": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020951211s
Apr  7 06:38:02.620: INFO: Pod "busybox-user-65534-f83284db-c98a-4b50-ad85-fdb6305c0060" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:02.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2958" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":16,"skipped":318,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:02.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:02.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-883" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":346,"completed":17,"skipped":332,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:02.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Apr  7 06:38:02.958: INFO: Waiting up to 5m0s for pod "security-context-3b74e698-35e8-4743-b6b9-aba4621c3360" in namespace "security-context-2064" to be "Succeeded or Failed"
Apr  7 06:38:02.967: INFO: Pod "security-context-3b74e698-35e8-4743-b6b9-aba4621c3360": Phase="Pending", Reason="", readiness=false. Elapsed: 8.588349ms
Apr  7 06:38:04.980: INFO: Pod "security-context-3b74e698-35e8-4743-b6b9-aba4621c3360": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02186917s
STEP: Saw pod success
Apr  7 06:38:04.980: INFO: Pod "security-context-3b74e698-35e8-4743-b6b9-aba4621c3360" satisfied condition "Succeeded or Failed"
Apr  7 06:38:04.988: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod security-context-3b74e698-35e8-4743-b6b9-aba4621c3360 container test-container: <nil>
STEP: delete the pod
Apr  7 06:38:05.019: INFO: Waiting for pod security-context-3b74e698-35e8-4743-b6b9-aba4621c3360 to disappear
Apr  7 06:38:05.029: INFO: Pod security-context-3b74e698-35e8-4743-b6b9-aba4621c3360 no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:05.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-2064" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":18,"skipped":338,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:05.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create deployment with httpd image
Apr  7 06:38:05.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5330 create -f -'
Apr  7 06:38:05.409: INFO: stderr: ""
Apr  7 06:38:05.409: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Apr  7 06:38:05.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5330 diff -f -'
Apr  7 06:38:05.566: INFO: rc: 1
Apr  7 06:38:05.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5330 delete -f -'
Apr  7 06:38:05.652: INFO: stderr: ""
Apr  7 06:38:05.652: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:05.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5330" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":346,"completed":19,"skipped":338,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:05.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr  7 06:38:05.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr  7 06:38:18.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:38:21.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:33.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3751" for this suite.

• [SLOW TEST:27.366 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":346,"completed":20,"skipped":357,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:33.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:186
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr  7 06:38:33.214: INFO: starting watch
STEP: patching
STEP: updating
Apr  7 06:38:33.232: INFO: waiting for watch events with expected annotations
Apr  7 06:38:33.232: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:33.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-6963" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":346,"completed":21,"skipped":366,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:33.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:38:33.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:39.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8907" for this suite.

• [SLOW TEST:6.548 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":346,"completed":22,"skipped":422,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:39.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  7 06:38:42.569: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1774 pod-service-account-455ecbf7-b5b8-49c0-ab58-0ffb023b060a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  7 06:38:42.776: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1774 pod-service-account-455ecbf7-b5b8-49c0-ab58-0ffb023b060a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  7 06:38:43.038: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1774 pod-service-account-455ecbf7-b5b8-49c0-ab58-0ffb023b060a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:43.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1774" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":346,"completed":23,"skipped":437,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:43.310: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:43.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4551" for this suite.
STEP: Destroying namespace "nspatchtest-3d105b0b-840b-4120-8363-ae3a76c84a4d-5021" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":346,"completed":24,"skipped":525,"failed":0}
SSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:43.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override all
Apr  7 06:38:43.681: INFO: Waiting up to 5m0s for pod "client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62" in namespace "containers-3398" to be "Succeeded or Failed"
Apr  7 06:38:43.688: INFO: Pod "client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335605ms
Apr  7 06:38:45.705: INFO: Pod "client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023758055s
STEP: Saw pod success
Apr  7 06:38:45.705: INFO: Pod "client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62" satisfied condition "Succeeded or Failed"
Apr  7 06:38:45.712: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:38:45.754: INFO: Waiting for pod client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62 to disappear
Apr  7 06:38:45.760: INFO: Pod client-containers-ce73576d-07a8-488d-a034-dd6d8e6d7a62 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:45.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3398" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":346,"completed":25,"skipped":528,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:45.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:38:46.535: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:38:49.620: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:38:49.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2562" for this suite.
STEP: Destroying namespace "webhook-2562-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":346,"completed":26,"skipped":530,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:38:50.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-8754
Apr  7 06:38:50.244: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:38:52.254: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr  7 06:38:52.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr  7 06:38:52.488: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr  7 06:38:52.488: INFO: stdout: "iptables"
Apr  7 06:38:52.488: INFO: proxyMode: iptables
Apr  7 06:38:52.510: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr  7 06:38:52.516: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-8754
STEP: creating replication controller affinity-clusterip-timeout in namespace services-8754
I0407 06:38:52.549986      23 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-8754, replica count: 3
I0407 06:38:55.602191      23 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 06:38:55.626: INFO: Creating new exec pod
Apr  7 06:38:58.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec execpod-affinityqgz2r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Apr  7 06:38:58.916: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Apr  7 06:38:58.916: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:38:58.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec execpod-affinityqgz2r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.109.148 80'
Apr  7 06:38:59.110: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.109.148 80\nConnection to 10.0.109.148 80 port [tcp/http] succeeded!\n"
Apr  7 06:38:59.110: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:38:59.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec execpod-affinityqgz2r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.109.148:80/ ; done'
Apr  7 06:38:59.383: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n"
Apr  7 06:38:59.383: INFO: stdout: "\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz\naffinity-clusterip-timeout-5vsnz"
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Received response from host: affinity-clusterip-timeout-5vsnz
Apr  7 06:38:59.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec execpod-affinityqgz2r -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.109.148:80/'
Apr  7 06:38:59.593: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n"
Apr  7 06:38:59.593: INFO: stdout: "affinity-clusterip-timeout-5vsnz"
Apr  7 06:39:19.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8754 exec execpod-affinityqgz2r -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.109.148:80/'
Apr  7 06:39:19.797: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.109.148:80/\n"
Apr  7 06:39:19.797: INFO: stdout: "affinity-clusterip-timeout-snlqk"
Apr  7 06:39:19.797: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-8754, will wait for the garbage collector to delete the pods
Apr  7 06:39:19.893: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 11.301621ms
Apr  7 06:39:19.993: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.561114ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:21.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8754" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:31.533 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":27,"skipped":536,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:21.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:39:27.853: INFO: DNS probes using dns-7899/dns-test-68ced37d-6d88-4b38-8e27-2a26d3430879 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:27.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7899" for this suite.

• [SLOW TEST:6.220 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":346,"completed":28,"skipped":538,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:27.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating pod
Apr  7 06:39:28.023: INFO: The status of Pod pod-hostip-c66ea03d-0c95-4406-a71c-c76539797eec is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:39:30.043: INFO: The status of Pod pod-hostip-c66ea03d-0c95-4406-a71c-c76539797eec is Running (Ready = true)
Apr  7 06:39:30.059: INFO: Pod pod-hostip-c66ea03d-0c95-4406-a71c-c76539797eec has hostIP: 10.240.0.5
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:30.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5904" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":346,"completed":29,"skipped":552,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:30.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:39:30.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55" in namespace "downward-api-7356" to be "Succeeded or Failed"
Apr  7 06:39:30.302: INFO: Pod "downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.219545ms
Apr  7 06:39:32.315: INFO: Pod "downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025306525s
STEP: Saw pod success
Apr  7 06:39:32.315: INFO: Pod "downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55" satisfied condition "Succeeded or Failed"
Apr  7 06:39:32.322: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55 container client-container: <nil>
STEP: delete the pod
Apr  7 06:39:32.363: INFO: Waiting for pod downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55 to disappear
Apr  7 06:39:32.371: INFO: Pod downwardapi-volume-cfcb5ecb-be2c-46ec-86f4-7142aac0be55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:32.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7356" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":30,"skipped":558,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:32.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:39:32.507: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  7 06:39:37.518: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 06:39:37.518: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 06:39:39.607: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2949  c820784d-18ec-4b07-ba9a-353c6d3abc4a 7621 1 2022-04-07 06:39:37 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-04-07 06:39:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:39:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002924c18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-07 06:39:37 +0000 UTC,LastTransitionTime:2022-04-07 06:39:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-56cd759769" has successfully progressed.,LastUpdateTime:2022-04-07 06:39:38 +0000 UTC,LastTransitionTime:2022-04-07 06:39:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 06:39:39.614: INFO: New ReplicaSet "test-cleanup-deployment-56cd759769" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-56cd759769  deployment-2949  e9a13538-6684-46c3-b341-174f7098ef1d 7611 1 2022-04-07 06:39:37 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:56cd759769] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment c820784d-18ec-4b07-ba9a-353c6d3abc4a 0xc004070027 0xc004070028}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:39:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c820784d-18ec-4b07-ba9a-353c6d3abc4a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:39:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 56cd759769,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:56cd759769] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0040700d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  7 06:39:39.621: INFO: Pod "test-cleanup-deployment-56cd759769-s8bsr" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-56cd759769-s8bsr test-cleanup-deployment-56cd759769- deployment-2949  db2899be-d149-4a64-bd06-3566dfa78fff 7610 0 2022-04-07 06:39:37 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:56cd759769] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-56cd759769 e9a13538-6684-46c3-b341-174f7098ef1d 0xc004070437 0xc004070438}] []  [{kube-controller-manager Update v1 2022-04-07 06:39:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e9a13538-6684-46c3-b341-174f7098ef1d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:39:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.50\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvdxb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvdxb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:39:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:39:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:39:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:39:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.50,StartTime:2022-04-07 06:39:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:39:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43,ContainerID:containerd://dfbe3d2ca2bbecb4504caa619a77dbd0a4cdd12a7427b1ae3c62bc6618cee452,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:39.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2949" for this suite.

• [SLOW TEST:7.250 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":346,"completed":31,"skipped":569,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:39.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:39:39.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:40.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7459" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":346,"completed":32,"skipped":580,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:40.803: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:39:41.219: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:39:44.274: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:44.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4708" for this suite.
STEP: Destroying namespace "webhook-4708-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":346,"completed":33,"skipped":643,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:44.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr  7 06:39:44.985: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:48.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5140" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":346,"completed":34,"skipped":677,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:48.581: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:39:48.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f" in namespace "projected-563" to be "Succeeded or Failed"
Apr  7 06:39:48.707: INFO: Pod "downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.609123ms
Apr  7 06:39:50.718: INFO: Pod "downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018053554s
STEP: Saw pod success
Apr  7 06:39:50.718: INFO: Pod "downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f" satisfied condition "Succeeded or Failed"
Apr  7 06:39:50.724: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f container client-container: <nil>
STEP: delete the pod
Apr  7 06:39:50.758: INFO: Waiting for pod downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f to disappear
Apr  7 06:39:50.766: INFO: Pod downwardapi-volume-0f418cd9-4e0b-4d41-9c87-a4a24793f09f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:39:50.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-563" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":35,"skipped":710,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:39:50.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:39:52.946: INFO: DNS probes using dns-test-5d459676-92f5-4914-94ae-c23a266e5f74 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:39:55.049: INFO: File wheezy_udp@dns-test-service-3.dns-4832.svc.cluster.local from pod  dns-4832/dns-test-c18a8639-7b0d-4711-a0de-6bf3da371b6d contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  7 06:39:55.057: INFO: File jessie_udp@dns-test-service-3.dns-4832.svc.cluster.local from pod  dns-4832/dns-test-c18a8639-7b0d-4711-a0de-6bf3da371b6d contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  7 06:39:55.057: INFO: Lookups using dns-4832/dns-test-c18a8639-7b0d-4711-a0de-6bf3da371b6d failed for: [wheezy_udp@dns-test-service-3.dns-4832.svc.cluster.local jessie_udp@dns-test-service-3.dns-4832.svc.cluster.local]

Apr  7 06:40:00.080: INFO: DNS probes using dns-test-c18a8639-7b0d-4711-a0de-6bf3da371b6d succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4832.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4832.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:40:02.310: INFO: DNS probes using dns-test-757d3a05-2a76-45a4-bb84-cb72960d5518 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:02.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4832" for this suite.

• [SLOW TEST:11.598 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":346,"completed":36,"skipped":744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:02.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr  7 06:40:02.513: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 06:40:02.532: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 06:40:02.540: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000000 before test
Apr  7 06:40:02.558: INFO: azure-ip-masq-agent-vjb96 from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 06:40:02.558: INFO: cloud-node-manager-tcnjx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 06:40:02.558: INFO: coredns-748769b948-gz9rk from kube-system started at 2022-04-07 06:25:16 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container coredns ready: true, restart count 0
Apr  7 06:40:02.558: INFO: coredns-748769b948-j9bgf from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container coredns ready: true, restart count 0
Apr  7 06:40:02.558: INFO: coredns-autoscaler-6fb889cdfc-w5qm4 from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container autoscaler ready: true, restart count 0
Apr  7 06:40:02.558: INFO: csi-azuredisk-node-qmwkm from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:40:02.558: INFO: csi-azurefile-node-swhhx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:40:02.558: INFO: konnectivity-agent-76fcfc46bd-9kq4v from kube-system started at 2022-04-07 06:25:20 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 06:40:02.558: INFO: konnectivity-agent-76fcfc46bd-chsbh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 06:40:02.558: INFO: kube-proxy-spxrs from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 06:40:02.558: INFO: metrics-server-7d59848cc6-4skgh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 06:40:02.558: INFO: metrics-server-7d59848cc6-wrc2c from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 06:40:02.558: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:40:02.558: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  7 06:40:02.558: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000001 before test
Apr  7 06:40:02.575: INFO: azure-ip-masq-agent-k7wwg from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 06:40:02.575: INFO: cloud-node-manager-4xrsl from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 06:40:02.575: INFO: csi-azuredisk-node-6g62x from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:40:02.575: INFO: csi-azurefile-node-8z4x6 from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:40:02.575: INFO: kube-proxy-9vz4m from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 06:40:02.575: INFO: sonobuoy from sonobuoy started at 2022-04-07 06:29:06 +0000 UTC (1 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 06:40:02.575: INFO: sonobuoy-e2e-job-6dc4960ffa6e4d5e from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container e2e ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:40:02.575: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-c22tn from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:40:02.575: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:40:02.575: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3dbfb719-30ff-4df6-b1bf-b0777d40f0a9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3dbfb719-30ff-4df6-b1bf-b0777d40f0a9 off the node aks-nodepool1-35379194-vmss000001
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3dbfb719-30ff-4df6-b1bf-b0777d40f0a9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:06.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4736" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":346,"completed":37,"skipped":816,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:06.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  7 06:40:06.916: INFO: Waiting up to 5m0s for pod "pod-ee4464c1-a3ca-4973-95f3-17028da69fad" in namespace "emptydir-3095" to be "Succeeded or Failed"
Apr  7 06:40:06.925: INFO: Pod "pod-ee4464c1-a3ca-4973-95f3-17028da69fad": Phase="Pending", Reason="", readiness=false. Elapsed: 9.334399ms
Apr  7 06:40:08.940: INFO: Pod "pod-ee4464c1-a3ca-4973-95f3-17028da69fad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023786773s
STEP: Saw pod success
Apr  7 06:40:08.940: INFO: Pod "pod-ee4464c1-a3ca-4973-95f3-17028da69fad" satisfied condition "Succeeded or Failed"
Apr  7 06:40:08.946: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-ee4464c1-a3ca-4973-95f3-17028da69fad container test-container: <nil>
STEP: delete the pod
Apr  7 06:40:08.995: INFO: Waiting for pod pod-ee4464c1-a3ca-4973-95f3-17028da69fad to disappear
Apr  7 06:40:09.001: INFO: Pod pod-ee4464c1-a3ca-4973-95f3-17028da69fad no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:09.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3095" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":38,"skipped":819,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:09.026: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr  7 06:40:09.100: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:12.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4233" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":346,"completed":39,"skipped":835,"failed":0}
SSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:12.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr  7 06:40:12.899: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr  7 06:40:12.909: INFO: starting watch
STEP: patching
STEP: updating
Apr  7 06:40:12.940: INFO: waiting for watch events with expected annotations
Apr  7 06:40:12.940: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:13.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1897" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":346,"completed":40,"skipped":838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:13.085: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:13.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8145" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":41,"skipped":883,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:13.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  7 06:40:13.466: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8203 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 06:40:13.466: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8204 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 06:40:13.466: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8205 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  7 06:40:23.536: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8284 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 06:40:23.536: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8285 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 06:40:23.536: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7702  49618999-204a-47a7-86a8-b7dbea34a5a5 8286 0 2022-04-07 06:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-07 06:40:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:23.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7702" for this suite.

• [SLOW TEST:10.221 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":346,"completed":42,"skipped":885,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:40:23.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  7 06:40:27.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7373 --namespace=crd-publish-openapi-7373 create -f -'
Apr  7 06:40:28.687: INFO: stderr: ""
Apr  7 06:40:28.687: INFO: stdout: "e2e-test-crd-publish-openapi-2311-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr  7 06:40:28.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7373 --namespace=crd-publish-openapi-7373 delete e2e-test-crd-publish-openapi-2311-crds test-cr'
Apr  7 06:40:28.881: INFO: stderr: ""
Apr  7 06:40:28.881: INFO: stdout: "e2e-test-crd-publish-openapi-2311-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr  7 06:40:28.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7373 --namespace=crd-publish-openapi-7373 apply -f -'
Apr  7 06:40:29.038: INFO: stderr: ""
Apr  7 06:40:29.038: INFO: stdout: "e2e-test-crd-publish-openapi-2311-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr  7 06:40:29.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7373 --namespace=crd-publish-openapi-7373 delete e2e-test-crd-publish-openapi-2311-crds test-cr'
Apr  7 06:40:29.129: INFO: stderr: ""
Apr  7 06:40:29.129: INFO: stdout: "e2e-test-crd-publish-openapi-2311-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr  7 06:40:29.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7373 explain e2e-test-crd-publish-openapi-2311-crds'
Apr  7 06:40:29.749: INFO: stderr: ""
Apr  7 06:40:29.749: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2311-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:32.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7373" for this suite.

• [SLOW TEST:9.046 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":346,"completed":43,"skipped":891,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:32.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr  7 06:40:32.776: INFO: The status of Pod labelsupdate3d614018-399c-476a-b816-e37b1228e0ff is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:40:34.786: INFO: The status of Pod labelsupdate3d614018-399c-476a-b816-e37b1228e0ff is Running (Ready = true)
Apr  7 06:40:35.336: INFO: Successfully updated pod "labelsupdate3d614018-399c-476a-b816-e37b1228e0ff"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:37.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6897" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":44,"skipped":919,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:37.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  7 06:40:37.505: INFO: Waiting up to 5m0s for pod "pod-e315085e-77ec-4761-9973-e3c6d02ccc1e" in namespace "emptydir-203" to be "Succeeded or Failed"
Apr  7 06:40:37.513: INFO: Pod "pod-e315085e-77ec-4761-9973-e3c6d02ccc1e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.162422ms
Apr  7 06:40:39.530: INFO: Pod "pod-e315085e-77ec-4761-9973-e3c6d02ccc1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025135427s
STEP: Saw pod success
Apr  7 06:40:39.530: INFO: Pod "pod-e315085e-77ec-4761-9973-e3c6d02ccc1e" satisfied condition "Succeeded or Failed"
Apr  7 06:40:39.538: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-e315085e-77ec-4761-9973-e3c6d02ccc1e container test-container: <nil>
STEP: delete the pod
Apr  7 06:40:39.580: INFO: Waiting for pod pod-e315085e-77ec-4761-9973-e3c6d02ccc1e to disappear
Apr  7 06:40:39.588: INFO: Pod pod-e315085e-77ec-4761-9973-e3c6d02ccc1e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:39.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-203" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":45,"skipped":932,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:39.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's command
Apr  7 06:40:39.706: INFO: Waiting up to 5m0s for pod "var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22" in namespace "var-expansion-3410" to be "Succeeded or Failed"
Apr  7 06:40:39.733: INFO: Pod "var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22": Phase="Pending", Reason="", readiness=false. Elapsed: 27.349948ms
Apr  7 06:40:41.746: INFO: Pod "var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040274391s
STEP: Saw pod success
Apr  7 06:40:41.746: INFO: Pod "var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22" satisfied condition "Succeeded or Failed"
Apr  7 06:40:41.753: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22 container dapi-container: <nil>
STEP: delete the pod
Apr  7 06:40:41.793: INFO: Waiting for pod var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22 to disappear
Apr  7 06:40:41.800: INFO: Pod var-expansion-d81fe21e-77bf-4f15-a0df-74eedabb7b22 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:41.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3410" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":346,"completed":46,"skipped":964,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:41.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:41.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4386" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":346,"completed":47,"skipped":1017,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:42.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Apr  7 06:40:42.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:40:59.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2912" for this suite.

• [SLOW TEST:17.721 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":346,"completed":48,"skipped":1064,"failed":0}
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:40:59.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1101.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1101.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 193.5.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.5.193_udp@PTR;check="$$(dig +tcp +noall +answer +search 193.5.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.5.193_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1101.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1101.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1101.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1101.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1101.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 193.5.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.5.193_udp@PTR;check="$$(dig +tcp +noall +answer +search 193.5.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.5.193_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:41:01.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:01.960: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:01.972: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:01.981: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:02.028: INFO: Unable to read jessie_udp@dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:02.040: INFO: Unable to read jessie_tcp@dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:02.049: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:02.057: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local from pod dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184: the server could not find the requested resource (get pods dns-test-15490461-9084-4b06-aac3-7029fd011184)
Apr  7 06:41:02.089: INFO: Lookups using dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184 failed for: [wheezy_udp@dns-test-service.dns-1101.svc.cluster.local wheezy_tcp@dns-test-service.dns-1101.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local jessie_udp@dns-test-service.dns-1101.svc.cluster.local jessie_tcp@dns-test-service.dns-1101.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1101.svc.cluster.local]

Apr  7 06:41:07.246: INFO: DNS probes using dns-1101/dns-test-15490461-9084-4b06-aac3-7029fd011184 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:41:07.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1101" for this suite.

• [SLOW TEST:7.658 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":346,"completed":49,"skipped":1064,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:41:07.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:41:07.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:41:08.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4843" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":346,"completed":50,"skipped":1069,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:41:08.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Apr  7 06:41:28.422: INFO: EndpointSlice for Service endpointslice-6392/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:41:38.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6392" for this suite.

• [SLOW TEST:30.407 seconds]
[sig-network] EndpointSlice
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":346,"completed":51,"skipped":1082,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:41:38.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:41:38.613: INFO: The status of Pod pod-secrets-4f70953a-4ec2-4de3-9dde-f63da0d62ee8 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:41:40.625: INFO: The status of Pod pod-secrets-4f70953a-4ec2-4de3-9dde-f63da0d62ee8 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:41:40.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2711" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":346,"completed":52,"skipped":1096,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:41:40.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr  7 06:41:41.940: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
W0407 06:41:41.940289      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr  7 06:41:41.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4252" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":346,"completed":53,"skipped":1114,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:41:41.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-7652
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Apr  7 06:41:42.074: INFO: Found 0 stateful pods, waiting for 3
Apr  7 06:41:52.088: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 06:41:52.088: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 06:41:52.088: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Apr  7 06:41:52.160: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  7 06:42:02.239: INFO: Updating stateful set ss2
Apr  7 06:42:02.254: INFO: Waiting for Pod statefulset-7652/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Apr  7 06:42:12.345: INFO: Found 1 stateful pods, waiting for 3
Apr  7 06:42:22.363: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 06:42:22.363: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 06:42:22.363: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  7 06:42:22.413: INFO: Updating stateful set ss2
Apr  7 06:42:22.430: INFO: Waiting for Pod statefulset-7652/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Apr  7 06:42:32.486: INFO: Updating stateful set ss2
Apr  7 06:42:32.508: INFO: Waiting for StatefulSet statefulset-7652/ss2 to complete update
Apr  7 06:42:32.508: INFO: Waiting for Pod statefulset-7652/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 06:42:42.531: INFO: Deleting all statefulset in ns statefulset-7652
Apr  7 06:42:42.541: INFO: Scaling statefulset ss2 to 0
Apr  7 06:42:52.584: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 06:42:52.592: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:42:52.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7652" for this suite.

• [SLOW TEST:70.684 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":346,"completed":54,"skipped":1127,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:42:52.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:43:03.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5543" for this suite.

• [SLOW TEST:11.234 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":346,"completed":55,"skipped":1171,"failed":0}
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:43:03.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:149
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:43:04.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3088" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":346,"completed":56,"skipped":1171,"failed":0}
SSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:43:04.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:43:06.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8005" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":346,"completed":57,"skipped":1174,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:43:06.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:43:06.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09" in namespace "downward-api-9976" to be "Succeeded or Failed"
Apr  7 06:43:06.378: INFO: Pod "downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09": Phase="Pending", Reason="", readiness=false. Elapsed: 6.890541ms
Apr  7 06:43:08.400: INFO: Pod "downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028392591s
STEP: Saw pod success
Apr  7 06:43:08.400: INFO: Pod "downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09" satisfied condition "Succeeded or Failed"
Apr  7 06:43:08.410: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09 container client-container: <nil>
STEP: delete the pod
Apr  7 06:43:08.453: INFO: Waiting for pod downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09 to disappear
Apr  7 06:43:08.461: INFO: Pod downwardapi-volume-9a6eff78-252d-4889-bfb1-ece3ce673f09 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:43:08.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9976" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":346,"completed":58,"skipped":1187,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:43:08.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr  7 06:43:08.595: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 06:44:08.636: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:44:08.641: INFO: Starting informer...
STEP: Starting pods...
Apr  7 06:44:08.881: INFO: Pod1 is running on aks-nodepool1-35379194-vmss000001. Tainting Node
Apr  7 06:44:11.142: INFO: Pod2 is running on aks-nodepool1-35379194-vmss000001. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr  7 06:44:17.335: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr  7 06:44:37.407: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:37.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-3243" for this suite.

• [SLOW TEST:88.993 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":346,"completed":59,"skipped":1225,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:37.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr  7 06:44:37.581: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr  7 06:44:37.586: INFO: starting watch
STEP: patching
STEP: updating
Apr  7 06:44:37.612: INFO: waiting for watch events with expected annotations
Apr  7 06:44:37.612: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:37.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6033" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":346,"completed":60,"skipped":1275,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-9bc88274-7c37-4e01-a95d-4ea582987871
STEP: Creating a pod to test consume configMaps
Apr  7 06:44:37.816: INFO: Waiting up to 5m0s for pod "pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8" in namespace "configmap-6987" to be "Succeeded or Failed"
Apr  7 06:44:37.825: INFO: Pod "pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.515641ms
Apr  7 06:44:39.846: INFO: Pod "pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029495026s
STEP: Saw pod success
Apr  7 06:44:39.846: INFO: Pod "pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8" satisfied condition "Succeeded or Failed"
Apr  7 06:44:39.856: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:44:39.909: INFO: Waiting for pod pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8 to disappear
Apr  7 06:44:39.917: INFO: Pod pod-configmaps-41ffadf4-85b4-413b-ac62-5dd6dbe51ce8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:39.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6987" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":61,"skipped":1304,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:39.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:44:40.345: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:44:43.386: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:43.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1148" for this suite.
STEP: Destroying namespace "webhook-1148-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":346,"completed":62,"skipped":1320,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:43.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:44:43.757: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-fe7dda3f-925b-48ac-829e-c51368ec399a" in namespace "security-context-test-7987" to be "Succeeded or Failed"
Apr  7 06:44:43.771: INFO: Pod "alpine-nnp-false-fe7dda3f-925b-48ac-829e-c51368ec399a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.836237ms
Apr  7 06:44:45.786: INFO: Pod "alpine-nnp-false-fe7dda3f-925b-48ac-829e-c51368ec399a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029906693s
Apr  7 06:44:47.804: INFO: Pod "alpine-nnp-false-fe7dda3f-925b-48ac-829e-c51368ec399a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046944273s
Apr  7 06:44:47.804: INFO: Pod "alpine-nnp-false-fe7dda3f-925b-48ac-829e-c51368ec399a" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:47.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7987" for this suite.
•{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":63,"skipped":1330,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:47.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:44:48.411: INFO: Checking APIGroup: apiregistration.k8s.io
Apr  7 06:44:48.413: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr  7 06:44:48.413: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr  7 06:44:48.413: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr  7 06:44:48.413: INFO: Checking APIGroup: apps
Apr  7 06:44:48.414: INFO: PreferredVersion.GroupVersion: apps/v1
Apr  7 06:44:48.414: INFO: Versions found [{apps/v1 v1}]
Apr  7 06:44:48.414: INFO: apps/v1 matches apps/v1
Apr  7 06:44:48.414: INFO: Checking APIGroup: events.k8s.io
Apr  7 06:44:48.417: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr  7 06:44:48.417: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.417: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr  7 06:44:48.417: INFO: Checking APIGroup: authentication.k8s.io
Apr  7 06:44:48.418: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr  7 06:44:48.418: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr  7 06:44:48.418: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr  7 06:44:48.418: INFO: Checking APIGroup: authorization.k8s.io
Apr  7 06:44:48.419: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr  7 06:44:48.419: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr  7 06:44:48.419: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr  7 06:44:48.419: INFO: Checking APIGroup: autoscaling
Apr  7 06:44:48.420: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr  7 06:44:48.420: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Apr  7 06:44:48.420: INFO: autoscaling/v2 matches autoscaling/v2
Apr  7 06:44:48.420: INFO: Checking APIGroup: batch
Apr  7 06:44:48.421: INFO: PreferredVersion.GroupVersion: batch/v1
Apr  7 06:44:48.421: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Apr  7 06:44:48.421: INFO: batch/v1 matches batch/v1
Apr  7 06:44:48.421: INFO: Checking APIGroup: certificates.k8s.io
Apr  7 06:44:48.423: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr  7 06:44:48.423: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr  7 06:44:48.423: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr  7 06:44:48.423: INFO: Checking APIGroup: networking.k8s.io
Apr  7 06:44:48.424: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr  7 06:44:48.424: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr  7 06:44:48.424: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr  7 06:44:48.424: INFO: Checking APIGroup: policy
Apr  7 06:44:48.425: INFO: PreferredVersion.GroupVersion: policy/v1
Apr  7 06:44:48.425: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Apr  7 06:44:48.425: INFO: policy/v1 matches policy/v1
Apr  7 06:44:48.425: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr  7 06:44:48.426: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr  7 06:44:48.426: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr  7 06:44:48.426: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr  7 06:44:48.426: INFO: Checking APIGroup: storage.k8s.io
Apr  7 06:44:48.427: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr  7 06:44:48.427: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.427: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr  7 06:44:48.427: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr  7 06:44:48.428: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr  7 06:44:48.428: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr  7 06:44:48.428: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr  7 06:44:48.428: INFO: Checking APIGroup: apiextensions.k8s.io
Apr  7 06:44:48.429: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr  7 06:44:48.429: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr  7 06:44:48.429: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr  7 06:44:48.429: INFO: Checking APIGroup: scheduling.k8s.io
Apr  7 06:44:48.431: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr  7 06:44:48.431: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr  7 06:44:48.431: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr  7 06:44:48.431: INFO: Checking APIGroup: coordination.k8s.io
Apr  7 06:44:48.433: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr  7 06:44:48.433: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr  7 06:44:48.433: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr  7 06:44:48.433: INFO: Checking APIGroup: node.k8s.io
Apr  7 06:44:48.435: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr  7 06:44:48.435: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.435: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr  7 06:44:48.435: INFO: Checking APIGroup: discovery.k8s.io
Apr  7 06:44:48.439: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr  7 06:44:48.439: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.439: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr  7 06:44:48.439: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr  7 06:44:48.441: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr  7 06:44:48.441: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.441: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Apr  7 06:44:48.441: INFO: Checking APIGroup: snapshot.storage.k8s.io
Apr  7 06:44:48.442: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Apr  7 06:44:48.442: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.442: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Apr  7 06:44:48.442: INFO: Checking APIGroup: metrics.k8s.io
Apr  7 06:44:48.444: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Apr  7 06:44:48.444: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Apr  7 06:44:48.444: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:48.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-5154" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":346,"completed":64,"skipped":1341,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:48.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  7 06:44:48.597: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7743  b081a8c1-f466-46d7-9b16-d987c22e3188 10287 0 2022-04-07 06:44:48 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-04-07 06:44:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 06:44:48.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7743  b081a8c1-f466-46d7-9b16-d987c22e3188 10288 0 2022-04-07 06:44:48 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-04-07 06:44:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:48.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7743" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":346,"completed":65,"skipped":1355,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:48.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1331
STEP: creating the pod
Apr  7 06:44:48.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 create -f -'
Apr  7 06:44:48.929: INFO: stderr: ""
Apr  7 06:44:48.929: INFO: stdout: "pod/pause created\n"
Apr  7 06:44:48.929: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  7 06:44:48.929: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4873" to be "running and ready"
Apr  7 06:44:48.940: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.743286ms
Apr  7 06:44:50.950: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020943391s
Apr  7 06:44:52.966: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.036562443s
Apr  7 06:44:52.966: INFO: Pod "pause" satisfied condition "running and ready"
Apr  7 06:44:52.966: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  7 06:44:52.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 label pods pause testing-label=testing-label-value'
Apr  7 06:44:53.056: INFO: stderr: ""
Apr  7 06:44:53.056: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  7 06:44:53.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 get pod pause -L testing-label'
Apr  7 06:44:53.130: INFO: stderr: ""
Apr  7 06:44:53.130: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  7 06:44:53.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 label pods pause testing-label-'
Apr  7 06:44:53.224: INFO: stderr: ""
Apr  7 06:44:53.224: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  7 06:44:53.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 get pod pause -L testing-label'
Apr  7 06:44:53.298: INFO: stderr: ""
Apr  7 06:44:53.298: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1337
STEP: using delete to clean up resources
Apr  7 06:44:53.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 delete --grace-period=0 --force -f -'
Apr  7 06:44:53.391: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 06:44:53.391: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  7 06:44:53.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 get rc,svc -l name=pause --no-headers'
Apr  7 06:44:53.469: INFO: stderr: "No resources found in kubectl-4873 namespace.\n"
Apr  7 06:44:53.469: INFO: stdout: ""
Apr  7 06:44:53.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4873 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 06:44:53.541: INFO: stderr: ""
Apr  7 06:44:53.541: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:44:53.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4873" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":346,"completed":66,"skipped":1359,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:44:53.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Apr  7 06:44:53.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 create -f -'
Apr  7 06:44:53.796: INFO: stderr: ""
Apr  7 06:44:53.796: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 06:44:53.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 06:44:53.876: INFO: stderr: ""
Apr  7 06:44:53.876: INFO: stdout: "update-demo-nautilus-9fptk update-demo-nautilus-zz5w5 "
Apr  7 06:44:53.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-9fptk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:44:53.946: INFO: stderr: ""
Apr  7 06:44:53.946: INFO: stdout: ""
Apr  7 06:44:53.946: INFO: update-demo-nautilus-9fptk is created but not running
Apr  7 06:44:58.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 06:44:59.027: INFO: stderr: ""
Apr  7 06:44:59.027: INFO: stdout: "update-demo-nautilus-9fptk update-demo-nautilus-zz5w5 "
Apr  7 06:44:59.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-9fptk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:44:59.097: INFO: stderr: ""
Apr  7 06:44:59.097: INFO: stdout: "true"
Apr  7 06:44:59.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-9fptk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 06:44:59.170: INFO: stderr: ""
Apr  7 06:44:59.170: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 06:44:59.170: INFO: validating pod update-demo-nautilus-9fptk
Apr  7 06:44:59.182: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 06:44:59.182: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 06:44:59.182: INFO: update-demo-nautilus-9fptk is verified up and running
Apr  7 06:44:59.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:44:59.255: INFO: stderr: ""
Apr  7 06:44:59.255: INFO: stdout: "true"
Apr  7 06:44:59.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 06:44:59.324: INFO: stderr: ""
Apr  7 06:44:59.324: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 06:44:59.324: INFO: validating pod update-demo-nautilus-zz5w5
Apr  7 06:44:59.347: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 06:44:59.347: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 06:44:59.347: INFO: update-demo-nautilus-zz5w5 is verified up and running
STEP: scaling down the replication controller
Apr  7 06:44:59.349: INFO: scanned /root for discovery docs: <nil>
Apr  7 06:44:59.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr  7 06:45:00.456: INFO: stderr: ""
Apr  7 06:45:00.456: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 06:45:00.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 06:45:00.530: INFO: stderr: ""
Apr  7 06:45:00.530: INFO: stdout: "update-demo-nautilus-zz5w5 "
Apr  7 06:45:00.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:45:00.609: INFO: stderr: ""
Apr  7 06:45:00.609: INFO: stdout: "true"
Apr  7 06:45:00.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 06:45:00.679: INFO: stderr: ""
Apr  7 06:45:00.679: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 06:45:00.679: INFO: validating pod update-demo-nautilus-zz5w5
Apr  7 06:45:00.690: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 06:45:00.690: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 06:45:00.690: INFO: update-demo-nautilus-zz5w5 is verified up and running
STEP: scaling up the replication controller
Apr  7 06:45:00.691: INFO: scanned /root for discovery docs: <nil>
Apr  7 06:45:00.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr  7 06:45:01.809: INFO: stderr: ""
Apr  7 06:45:01.809: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 06:45:01.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 06:45:01.890: INFO: stderr: ""
Apr  7 06:45:01.890: INFO: stdout: "update-demo-nautilus-7985k update-demo-nautilus-zz5w5 "
Apr  7 06:45:01.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-7985k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:45:01.959: INFO: stderr: ""
Apr  7 06:45:01.959: INFO: stdout: ""
Apr  7 06:45:01.959: INFO: update-demo-nautilus-7985k is created but not running
Apr  7 06:45:06.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 06:45:07.122: INFO: stderr: ""
Apr  7 06:45:07.122: INFO: stdout: "update-demo-nautilus-7985k update-demo-nautilus-zz5w5 "
Apr  7 06:45:07.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-7985k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:45:07.194: INFO: stderr: ""
Apr  7 06:45:07.194: INFO: stdout: "true"
Apr  7 06:45:07.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-7985k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 06:45:07.279: INFO: stderr: ""
Apr  7 06:45:07.279: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 06:45:07.280: INFO: validating pod update-demo-nautilus-7985k
Apr  7 06:45:07.294: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 06:45:07.294: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 06:45:07.294: INFO: update-demo-nautilus-7985k is verified up and running
Apr  7 06:45:07.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 06:45:07.373: INFO: stderr: ""
Apr  7 06:45:07.373: INFO: stdout: "true"
Apr  7 06:45:07.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods update-demo-nautilus-zz5w5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 06:45:07.447: INFO: stderr: ""
Apr  7 06:45:07.447: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 06:45:07.447: INFO: validating pod update-demo-nautilus-zz5w5
Apr  7 06:45:07.458: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 06:45:07.458: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 06:45:07.458: INFO: update-demo-nautilus-zz5w5 is verified up and running
STEP: using delete to clean up resources
Apr  7 06:45:07.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 delete --grace-period=0 --force -f -'
Apr  7 06:45:07.551: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 06:45:07.551: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  7 06:45:07.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get rc,svc -l name=update-demo --no-headers'
Apr  7 06:45:07.642: INFO: stderr: "No resources found in kubectl-3555 namespace.\n"
Apr  7 06:45:07.642: INFO: stdout: ""
Apr  7 06:45:07.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-3555 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 06:45:07.726: INFO: stderr: ""
Apr  7 06:45:07.726: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:07.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3555" for this suite.

• [SLOW TEST:14.188 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should scale a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":346,"completed":67,"skipped":1361,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:07.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  7 06:45:07.856: INFO: Waiting up to 5m0s for pod "pod-517b87be-e3d0-4f6e-87bd-fb64327471f0" in namespace "emptydir-1442" to be "Succeeded or Failed"
Apr  7 06:45:07.872: INFO: Pod "pod-517b87be-e3d0-4f6e-87bd-fb64327471f0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.219135ms
Apr  7 06:45:09.887: INFO: Pod "pod-517b87be-e3d0-4f6e-87bd-fb64327471f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031423127s
STEP: Saw pod success
Apr  7 06:45:09.887: INFO: Pod "pod-517b87be-e3d0-4f6e-87bd-fb64327471f0" satisfied condition "Succeeded or Failed"
Apr  7 06:45:09.896: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-517b87be-e3d0-4f6e-87bd-fb64327471f0 container test-container: <nil>
STEP: delete the pod
Apr  7 06:45:09.957: INFO: Waiting for pod pod-517b87be-e3d0-4f6e-87bd-fb64327471f0 to disappear
Apr  7 06:45:09.967: INFO: Pod pod-517b87be-e3d0-4f6e-87bd-fb64327471f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1442" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":68,"skipped":1379,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:09.983: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:16.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8203" for this suite.

• [SLOW TEST:6.169 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":346,"completed":69,"skipped":1393,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:16.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Apr  7 06:45:16.272: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr  7 06:45:21.285: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Apr  7 06:45:21.293: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:21.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9308" for this suite.

• [SLOW TEST:5.233 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":346,"completed":70,"skipped":1434,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:21.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:45:21.498: INFO: The status of Pod server-envvars-a6bf2a49-fa78-4c41-a1be-c83269d9735b is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:45:23.524: INFO: The status of Pod server-envvars-a6bf2a49-fa78-4c41-a1be-c83269d9735b is Running (Ready = true)
Apr  7 06:45:23.578: INFO: Waiting up to 5m0s for pod "client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae" in namespace "pods-5002" to be "Succeeded or Failed"
Apr  7 06:45:23.595: INFO: Pod "client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae": Phase="Pending", Reason="", readiness=false. Elapsed: 17.204808ms
Apr  7 06:45:25.606: INFO: Pod "client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028038697s
STEP: Saw pod success
Apr  7 06:45:25.606: INFO: Pod "client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae" satisfied condition "Succeeded or Failed"
Apr  7 06:45:25.613: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae container env3cont: <nil>
STEP: delete the pod
Apr  7 06:45:25.653: INFO: Waiting for pod client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae to disappear
Apr  7 06:45:25.661: INFO: Pod client-envvars-0503d2ce-3a59-4ffe-b39b-25d14ee0aeae no longer exists
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:25.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5002" for this suite.
•{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":346,"completed":71,"skipped":1453,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:25.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7879.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7879.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7879.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7879.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:45:27.920: INFO: DNS probes using dns-7879/dns-test-263b95fc-c636-4f62-92aa-577c90885500 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:27.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7879" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":346,"completed":72,"skipped":1500,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:28.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5154" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":346,"completed":73,"skipped":1526,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:28.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-0974b081-3b23-4d0a-869b-bc1fef054c32
STEP: Creating a pod to test consume configMaps
Apr  7 06:45:28.391: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2" in namespace "projected-8934" to be "Succeeded or Failed"
Apr  7 06:45:28.401: INFO: Pod "pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.47821ms
Apr  7 06:45:30.411: INFO: Pod "pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020218408s
STEP: Saw pod success
Apr  7 06:45:30.412: INFO: Pod "pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2" satisfied condition "Succeeded or Failed"
Apr  7 06:45:30.446: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:45:30.505: INFO: Waiting for pod pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2 to disappear
Apr  7 06:45:30.512: INFO: Pod pod-projected-configmaps-9f617e3b-5132-420b-bc5f-ad7c58c3a0a2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:45:30.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8934" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":74,"skipped":1539,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:45:30.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr  7 06:45:30.659: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 06:46:30.682: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:46:30.687: INFO: Starting informer...
STEP: Starting pod...
Apr  7 06:46:30.920: INFO: Pod is running on aks-nodepool1-35379194-vmss000001. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr  7 06:46:30.948: INFO: Pod wasn't evicted. Proceeding
Apr  7 06:46:30.948: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr  7 06:47:45.980: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:47:45.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8893" for this suite.

• [SLOW TEST:135.473 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":346,"completed":75,"skipped":1558,"failed":0}
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:47:46.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-6bd7f542-f105-4a9d-ba7f-56dfcbfc6cc2
STEP: Creating a pod to test consume configMaps
Apr  7 06:47:46.149: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787" in namespace "projected-7691" to be "Succeeded or Failed"
Apr  7 06:47:46.160: INFO: Pod "pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787": Phase="Pending", Reason="", readiness=false. Elapsed: 10.653976ms
Apr  7 06:47:48.181: INFO: Pod "pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031957243s
STEP: Saw pod success
Apr  7 06:47:48.181: INFO: Pod "pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787" satisfied condition "Succeeded or Failed"
Apr  7 06:47:48.190: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:47:48.232: INFO: Waiting for pod pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787 to disappear
Apr  7 06:47:48.239: INFO: Pod pod-projected-configmaps-3f87d500-59d2-4297-b937-b4ddff561787 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:47:48.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7691" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":76,"skipped":1558,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:47:48.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  7 06:47:48.391: INFO: Waiting up to 5m0s for pod "pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13" in namespace "emptydir-94" to be "Succeeded or Failed"
Apr  7 06:47:48.399: INFO: Pod "pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13": Phase="Pending", Reason="", readiness=false. Elapsed: 8.090714ms
Apr  7 06:47:50.420: INFO: Pod "pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028842046s
STEP: Saw pod success
Apr  7 06:47:50.420: INFO: Pod "pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13" satisfied condition "Succeeded or Failed"
Apr  7 06:47:50.429: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13 container test-container: <nil>
STEP: delete the pod
Apr  7 06:47:50.470: INFO: Waiting for pod pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13 to disappear
Apr  7 06:47:50.478: INFO: Pod pod-4e5f0d7e-648d-4af2-b04a-f514c7eaeb13 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:47:50.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-94" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":77,"skipped":1560,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:47:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Apr  7 06:47:52.642: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6297 PodName:pod-sharedvolume-90cc84ed-3463-40b1-8411-5aad5a033d05 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:47:52.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:47:52.643: INFO: ExecWithOptions: Clientset creation
Apr  7 06:47:52.643: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/emptydir-6297/pods/pod-sharedvolume-90cc84ed-3463-40b1-8411-5aad5a033d05/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:47:52.786: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:47:52.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6297" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":346,"completed":78,"skipped":1576,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:47:52.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:47:53.485: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:47:56.539: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:08.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3017" for this suite.
STEP: Destroying namespace "webhook-3017-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.164 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":346,"completed":79,"skipped":1579,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:08.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:48:09.131: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9fd6bd63-69ef-47c8-a78c-46c0ba61a212", Controller:(*bool)(0xc002f3d616), BlockOwnerDeletion:(*bool)(0xc002f3d617)}}
Apr  7 06:48:09.140: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c16417ad-a49a-42fe-a8fa-9b320a88b8c6", Controller:(*bool)(0xc002f3d856), BlockOwnerDeletion:(*bool)(0xc002f3d857)}}
Apr  7 06:48:09.150: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f8b7f110-4e4e-4c5c-87b3-842e47bcd947", Controller:(*bool)(0xc002f3dabe), BlockOwnerDeletion:(*bool)(0xc002f3dabf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:14.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7940" for this suite.

• [SLOW TEST:5.241 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":346,"completed":80,"skipped":1588,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:14.219: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:48:14.637: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:48:17.704: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:17.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6141" for this suite.
STEP: Destroying namespace "webhook-6141-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":346,"completed":81,"skipped":1608,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:17.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7679
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7679
I0407 06:48:18.113537      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7679, replica count: 2
Apr  7 06:48:21.165: INFO: Creating new exec pod
I0407 06:48:21.165591      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 06:48:24.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7679 exec execpodngkb4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr  7 06:48:24.442: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr  7 06:48:24.442: INFO: stdout: "externalname-service-xz52w"
Apr  7 06:48:24.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7679 exec execpodngkb4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.246.44 80'
Apr  7 06:48:24.667: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.246.44 80\nConnection to 10.0.246.44 80 port [tcp/http] succeeded!\n"
Apr  7 06:48:24.668: INFO: stdout: ""
Apr  7 06:48:25.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7679 exec execpodngkb4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.246.44 80'
Apr  7 06:48:25.866: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.246.44 80\nConnection to 10.0.246.44 80 port [tcp/http] succeeded!\n"
Apr  7 06:48:25.866: INFO: stdout: "externalname-service-xz52w"
Apr  7 06:48:25.866: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:25.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7679" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.957 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":346,"completed":82,"skipped":1611,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:25.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr  7 06:48:26.048: INFO: The status of Pod pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:48:28.060: INFO: The status of Pod pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  7 06:48:28.602: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32"
Apr  7 06:48:28.602: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32" in namespace "pods-314" to be "terminated due to deadline exceeded"
Apr  7 06:48:28.610: INFO: Pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32": Phase="Running", Reason="", readiness=true. Elapsed: 7.138257ms
Apr  7 06:48:30.624: INFO: Pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32": Phase="Running", Reason="", readiness=true. Elapsed: 2.021900289s
Apr  7 06:48:32.638: INFO: Pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32": Phase="Failed", Reason="DeadlineExceeded", readiness=true. Elapsed: 4.03539094s
Apr  7 06:48:32.638: INFO: Pod "pod-update-activedeadlineseconds-d962e264-2cb7-431f-8f34-6cb7bc531d32" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:32.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-314" for this suite.

• [SLOW TEST:6.723 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":346,"completed":83,"skipped":1629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:32.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Starting the proxy
Apr  7 06:48:32.742: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8478 proxy --unix-socket=/tmp/kubectl-proxy-unix292127388/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:32.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8478" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":346,"completed":84,"skipped":1671,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:32.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Apr  7 06:48:32.935: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:32.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9158" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":346,"completed":85,"skipped":1732,"failed":0}
SS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:32.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override command
Apr  7 06:48:33.112: INFO: Waiting up to 5m0s for pod "client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd" in namespace "containers-3739" to be "Succeeded or Failed"
Apr  7 06:48:33.128: INFO: Pod "client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.885489ms
Apr  7 06:48:35.141: INFO: Pod "client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02951556s
STEP: Saw pod success
Apr  7 06:48:35.141: INFO: Pod "client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd" satisfied condition "Succeeded or Failed"
Apr  7 06:48:35.159: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:48:35.196: INFO: Waiting for pod client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd to disappear
Apr  7 06:48:35.204: INFO: Pod client-containers-8c7ec28b-bf97-45a9-8564-a93cd904dacd no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:35.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3739" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":346,"completed":86,"skipped":1734,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:35.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:48:35.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc" in namespace "projected-4095" to be "Succeeded or Failed"
Apr  7 06:48:35.339: INFO: Pod "downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125524ms
Apr  7 06:48:37.356: INFO: Pod "downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026012934s
STEP: Saw pod success
Apr  7 06:48:37.356: INFO: Pod "downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc" satisfied condition "Succeeded or Failed"
Apr  7 06:48:37.369: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc container client-container: <nil>
STEP: delete the pod
Apr  7 06:48:37.414: INFO: Waiting for pod downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc to disappear
Apr  7 06:48:37.432: INFO: Pod downwardapi-volume-33d725f5-ec47-4566-b097-cb420689c3dc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:37.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4095" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":87,"skipped":1742,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:37.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr  7 06:48:37.578: INFO: The status of Pod labelsupdated4680716-3052-4019-b0da-c7963f432323 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:48:39.591: INFO: The status of Pod labelsupdated4680716-3052-4019-b0da-c7963f432323 is Running (Ready = true)
Apr  7 06:48:40.136: INFO: Successfully updated pod "labelsupdated4680716-3052-4019-b0da-c7963f432323"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:42.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9521" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":88,"skipped":1777,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:42.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  7 06:48:42.357: INFO: Waiting up to 5m0s for pod "pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf" in namespace "emptydir-3616" to be "Succeeded or Failed"
Apr  7 06:48:42.365: INFO: Pod "pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.381638ms
Apr  7 06:48:44.380: INFO: Pod "pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023343332s
STEP: Saw pod success
Apr  7 06:48:44.380: INFO: Pod "pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf" satisfied condition "Succeeded or Failed"
Apr  7 06:48:44.388: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf container test-container: <nil>
STEP: delete the pod
Apr  7 06:48:44.453: INFO: Waiting for pod pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf to disappear
Apr  7 06:48:44.468: INFO: Pod pod-6ed2137c-27f9-4faa-b369-5710cab8fdaf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:44.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3616" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":89,"skipped":1806,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:44.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-198/configmap-test-cbc996b0-6cd7-4581-8c43-473c208cb31c
STEP: Creating a pod to test consume configMaps
Apr  7 06:48:44.684: INFO: Waiting up to 5m0s for pod "pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a" in namespace "configmap-198" to be "Succeeded or Failed"
Apr  7 06:48:44.708: INFO: Pod "pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 23.923737ms
Apr  7 06:48:46.723: INFO: Pod "pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039307758s
STEP: Saw pod success
Apr  7 06:48:46.723: INFO: Pod "pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a" satisfied condition "Succeeded or Failed"
Apr  7 06:48:46.730: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a container env-test: <nil>
STEP: delete the pod
Apr  7 06:48:46.763: INFO: Waiting for pod pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a to disappear
Apr  7 06:48:46.770: INFO: Pod pod-configmaps-73b7d3c9-b860-4c2a-865d-23258c400c6a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:48:46.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-198" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":90,"skipped":1830,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:48:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:48:46.899: INFO: created pod
Apr  7 06:48:46.899: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4261" to be "Succeeded or Failed"
Apr  7 06:48:46.910: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.716288ms
Apr  7 06:48:48.923: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024142683s
STEP: Saw pod success
Apr  7 06:48:48.923: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr  7 06:49:18.925: INFO: polling logs
Apr  7 06:49:18.942: INFO: Pod logs: 
2022/04/07 06:48:47 OK: Got token
2022/04/07 06:48:47 validating with in-cluster discovery
2022/04/07 06:48:47 OK: got issuer https://aksconform-levo-aks-eastus-01db32-35da8d30.hcp.eastus.azmk8s.io
2022/04/07 06:48:47 Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://aksconform-levo-aks-eastus-01db32-35da8d30.hcp.eastus.azmk8s.io", Subject:"system:serviceaccount:svcaccounts-4261:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1649314727, NotBefore:1649314127, IssuedAt:1649314127, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4261", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"dc4ab794-6762-4b84-8ea8-bcaae19b3205"}}}
2022/04/07 06:48:47 OK: Constructed OIDC provider for issuer https://aksconform-levo-aks-eastus-01db32-35da8d30.hcp.eastus.azmk8s.io
2022/04/07 06:48:47 OK: Validated signature on JWT
2022/04/07 06:48:47 OK: Got valid claims from token!
2022/04/07 06:48:47 Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://aksconform-levo-aks-eastus-01db32-35da8d30.hcp.eastus.azmk8s.io", Subject:"system:serviceaccount:svcaccounts-4261:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1649314727, NotBefore:1649314127, IssuedAt:1649314127, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4261", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"dc4ab794-6762-4b84-8ea8-bcaae19b3205"}}}

Apr  7 06:49:18.942: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:18.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4261" for this suite.

• [SLOW TEST:32.194 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":346,"completed":91,"skipped":1849,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:18.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:32.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5019" for this suite.

• [SLOW TEST:13.319 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":346,"completed":92,"skipped":1860,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:32.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-40b5d400-8054-40e3-95ad-b7cd22cf0d11
STEP: Creating a pod to test consume secrets
Apr  7 06:49:32.424: INFO: Waiting up to 5m0s for pod "pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da" in namespace "secrets-4207" to be "Succeeded or Failed"
Apr  7 06:49:32.433: INFO: Pod "pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.679755ms
Apr  7 06:49:34.446: INFO: Pod "pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021899581s
STEP: Saw pod success
Apr  7 06:49:34.446: INFO: Pod "pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da" satisfied condition "Succeeded or Failed"
Apr  7 06:49:34.453: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 06:49:34.499: INFO: Waiting for pod pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da to disappear
Apr  7 06:49:34.507: INFO: Pod pod-secrets-75234ff7-ed2c-4c16-ab60-f91308f3b0da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:34.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4207" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":93,"skipped":1883,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:34.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-12069a06-5a3e-47d0-852c-e767983386de
STEP: Creating secret with name s-test-opt-upd-a5f86d4b-4c39-4ccc-aa5f-484f3286a002
STEP: Creating the pod
Apr  7 06:49:34.671: INFO: The status of Pod pod-secrets-869a7f14-01de-4b5a-87dc-7d9381c90b51 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:49:36.688: INFO: The status of Pod pod-secrets-869a7f14-01de-4b5a-87dc-7d9381c90b51 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-12069a06-5a3e-47d0-852c-e767983386de
STEP: Updating secret s-test-opt-upd-a5f86d4b-4c39-4ccc-aa5f-484f3286a002
STEP: Creating secret with name s-test-opt-create-dbe1933f-443e-43ad-892f-085b8d1fe135
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:40.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5663" for this suite.

• [SLOW TEST:6.366 seconds]
[sig-storage] Secrets
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":94,"skipped":1900,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:40.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:52.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7956" for this suite.

• [SLOW TEST:11.409 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":346,"completed":95,"skipped":1903,"failed":0}
SSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:52.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:49:52.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr  7 06:49:52.395: INFO: The status of Pod pod-exec-websocket-1769bacb-891d-4c5b-a1be-f45c94db1e33 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:49:54.410: INFO: The status of Pod pod-exec-websocket-1769bacb-891d-4c5b-a1be-f45c94db1e33 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:54.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1606" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":346,"completed":96,"skipped":1910,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-481409fc-4830-425b-90dc-2aa19d72b2db
STEP: Creating a pod to test consume secrets
Apr  7 06:49:54.759: INFO: Waiting up to 5m0s for pod "pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72" in namespace "secrets-6396" to be "Succeeded or Failed"
Apr  7 06:49:54.768: INFO: Pod "pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885969ms
Apr  7 06:49:56.799: INFO: Pod "pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039252893s
STEP: Saw pod success
Apr  7 06:49:56.799: INFO: Pod "pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72" satisfied condition "Succeeded or Failed"
Apr  7 06:49:56.807: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 06:49:56.850: INFO: Waiting for pod pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72 to disappear
Apr  7 06:49:56.857: INFO: Pod pod-secrets-a7728b71-3ed9-4fb0-8617-ec6b5e1ffe72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:49:56.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6396" for this suite.
STEP: Destroying namespace "secret-namespace-3559" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":346,"completed":97,"skipped":1926,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:49:56.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Apr  7 06:49:56.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the sample API server.
Apr  7 06:49:57.401: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Apr  7 06:49:59.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 06:50:01.510: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 49, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 06:50:04.778: INFO: Waited 1.254401098s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Apr  7 06:50:04.925: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:05.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7721" for this suite.

• [SLOW TEST:8.571 seconds]
[sig-api-machinery] Aggregator
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":346,"completed":98,"skipped":1932,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:05.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:26.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6155" for this suite.

• [SLOW TEST:20.745 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    when starting a container that exits
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":346,"completed":99,"skipped":1941,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:26.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:26.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-2899" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":100,"skipped":1961,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:26.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating api versions
Apr  7 06:50:26.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6191 api-versions'
Apr  7 06:50:26.479: INFO: stderr: ""
Apr  7 06:50:26.479: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:26.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6191" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":346,"completed":101,"skipped":1964,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:26.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:50:27.220: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:50:30.268: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:30.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9436" for this suite.
STEP: Destroying namespace "webhook-9436-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":346,"completed":102,"skipped":1976,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:30.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:30.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5930" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":346,"completed":103,"skipped":1997,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:30.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  7 06:50:32.878: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:32.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9281" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":104,"skipped":2004,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:32.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-e5344f2c-47c9-47b5-a6bc-20246b1ec129
STEP: Creating a pod to test consume configMaps
Apr  7 06:50:33.152: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467" in namespace "projected-1822" to be "Succeeded or Failed"
Apr  7 06:50:33.161: INFO: Pod "pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467": Phase="Pending", Reason="", readiness=false. Elapsed: 9.013474ms
Apr  7 06:50:35.179: INFO: Pod "pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02667801s
STEP: Saw pod success
Apr  7 06:50:35.179: INFO: Pod "pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467" satisfied condition "Succeeded or Failed"
Apr  7 06:50:35.186: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:50:35.229: INFO: Waiting for pod pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467 to disappear
Apr  7 06:50:35.235: INFO: Pod pod-projected-configmaps-ce892d98-9b7d-43cf-b3f6-eac228134467 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:35.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1822" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":105,"skipped":2010,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:35.251: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:50:35.369: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18" in namespace "projected-6914" to be "Succeeded or Failed"
Apr  7 06:50:35.376: INFO: Pod "downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18": Phase="Pending", Reason="", readiness=false. Elapsed: 7.559383ms
Apr  7 06:50:37.388: INFO: Pod "downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019701272s
STEP: Saw pod success
Apr  7 06:50:37.388: INFO: Pod "downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18" satisfied condition "Succeeded or Failed"
Apr  7 06:50:37.396: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18 container client-container: <nil>
STEP: delete the pod
Apr  7 06:50:37.455: INFO: Waiting for pod downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18 to disappear
Apr  7 06:50:37.462: INFO: Pod downwardapi-volume-ba6c16c0-6e79-4e6d-a188-696918a20d18 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:37.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6914" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":106,"skipped":2013,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:37.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:54.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7823" for this suite.

• [SLOW TEST:17.254 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":346,"completed":107,"skipped":2014,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:54.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test service account token: 
Apr  7 06:50:54.833: INFO: Waiting up to 5m0s for pod "test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4" in namespace "svcaccounts-3545" to be "Succeeded or Failed"
Apr  7 06:50:54.841: INFO: Pod "test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.927407ms
Apr  7 06:50:56.856: INFO: Pod "test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023525856s
STEP: Saw pod success
Apr  7 06:50:56.856: INFO: Pod "test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4" satisfied condition "Succeeded or Failed"
Apr  7 06:50:56.867: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:50:56.916: INFO: Waiting for pod test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4 to disappear
Apr  7 06:50:56.925: INFO: Pod test-pod-0235c2b1-33cc-47af-9087-ea8953b954a4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:50:56.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3545" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":346,"completed":108,"skipped":2021,"failed":0}
SSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:50:56.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:50:59.074: INFO: Deleting pod "var-expansion-d9c9af75-5e67-4c63-b801-b83ebec0b454" in namespace "var-expansion-8375"
Apr  7 06:50:59.089: INFO: Wait up to 5m0s for pod "var-expansion-d9c9af75-5e67-4c63-b801-b83ebec0b454" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:01.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8375" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":346,"completed":109,"skipped":2026,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:01.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-3065
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 06:51:01.204: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr  7 06:51:01.259: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:51:03.273: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:51:05.270: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:51:07.274: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:51:09.274: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:51:11.270: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:51:13.279: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr  7 06:51:13.295: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr  7 06:51:15.391: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr  7 06:51:15.391: INFO: Going to poll 10.244.0.39 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Apr  7 06:51:15.399: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.39:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:51:15.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:51:15.400: INFO: ExecWithOptions: Clientset creation
Apr  7 06:51:15.400: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-3065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.39%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:51:15.530: INFO: Found all 1 expected endpoints: [netserver-0]
Apr  7 06:51:15.530: INFO: Going to poll 10.244.1.117 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Apr  7 06:51:15.549: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.117:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3065 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:51:15.549: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:51:15.550: INFO: ExecWithOptions: Clientset creation
Apr  7 06:51:15.550: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-3065/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.117%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:51:15.676: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:15.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3065" for this suite.

• [SLOW TEST:14.578 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":110,"skipped":2026,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:15.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:15.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-504" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":346,"completed":111,"skipped":2039,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:15.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Apr  7 06:51:16.098: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:18.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1418" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":346,"completed":112,"skipped":2099,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:18.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr  7 06:51:18.281: INFO: Waiting up to 5m0s for pod "downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f" in namespace "downward-api-6555" to be "Succeeded or Failed"
Apr  7 06:51:18.291: INFO: Pod "downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.340761ms
Apr  7 06:51:20.310: INFO: Pod "downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029189196s
STEP: Saw pod success
Apr  7 06:51:20.310: INFO: Pod "downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f" satisfied condition "Succeeded or Failed"
Apr  7 06:51:20.320: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f container dapi-container: <nil>
STEP: delete the pod
Apr  7 06:51:20.377: INFO: Waiting for pod downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f to disappear
Apr  7 06:51:20.387: INFO: Pod downward-api-a0f8a6b1-be93-488e-9b0c-491e6c84974f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:20.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6555" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":346,"completed":113,"skipped":2109,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:20.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-23b9d241-ee61-4f88-b734-50609801ab04
STEP: Creating a pod to test consume secrets
Apr  7 06:51:20.525: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4" in namespace "projected-4726" to be "Succeeded or Failed"
Apr  7 06:51:20.534: INFO: Pod "pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.128684ms
Apr  7 06:51:22.547: INFO: Pod "pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022056711s
STEP: Saw pod success
Apr  7 06:51:22.547: INFO: Pod "pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4" satisfied condition "Succeeded or Failed"
Apr  7 06:51:22.555: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 06:51:22.592: INFO: Waiting for pod pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4 to disappear
Apr  7 06:51:22.599: INFO: Pod pod-projected-secrets-d87e7a83-42d4-4a62-9014-d8dfaf4b64c4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:22.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4726" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":114,"skipped":2113,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:22.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:51:22.724: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 06:51:22.755: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:51:22.755: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:51:23.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:51:23.777: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:51:24.772: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 06:51:24.772: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  7 06:51:24.849: INFO: Wrong image for pod: daemon-set-d8jjh. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Apr  7 06:51:24.849: INFO: Wrong image for pod: daemon-set-fsz98. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Apr  7 06:51:25.869: INFO: Wrong image for pod: daemon-set-fsz98. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Apr  7 06:51:26.868: INFO: Wrong image for pod: daemon-set-fsz98. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Apr  7 06:51:27.868: INFO: Pod daemon-set-4hlrt is not available
Apr  7 06:51:27.868: INFO: Wrong image for pod: daemon-set-fsz98. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.33, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Apr  7 06:51:29.866: INFO: Pod daemon-set-hfz6k is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  7 06:51:29.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:51:29.887: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:51:30.905: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:51:30.905: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:51:31.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 06:51:31.908: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4039, will wait for the garbage collector to delete the pods
Apr  7 06:51:32.010: INFO: Deleting DaemonSet.extensions daemon-set took: 11.91926ms
Apr  7 06:51:32.111: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.119953ms
Apr  7 06:51:34.126: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:51:34.126: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 06:51:34.131: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14010"},"items":null}

Apr  7 06:51:34.145: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14010"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:34.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4039" for this suite.

• [SLOW TEST:11.576 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":346,"completed":115,"skipped":2123,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:51:34.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  7 06:51:36.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-658 --namespace=crd-publish-openapi-658 create -f -'
Apr  7 06:51:37.853: INFO: stderr: ""
Apr  7 06:51:37.853: INFO: stdout: "e2e-test-crd-publish-openapi-1817-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr  7 06:51:37.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-658 --namespace=crd-publish-openapi-658 delete e2e-test-crd-publish-openapi-1817-crds test-cr'
Apr  7 06:51:38.083: INFO: stderr: ""
Apr  7 06:51:38.083: INFO: stdout: "e2e-test-crd-publish-openapi-1817-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr  7 06:51:38.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-658 --namespace=crd-publish-openapi-658 apply -f -'
Apr  7 06:51:38.261: INFO: stderr: ""
Apr  7 06:51:38.261: INFO: stdout: "e2e-test-crd-publish-openapi-1817-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr  7 06:51:38.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-658 --namespace=crd-publish-openapi-658 delete e2e-test-crd-publish-openapi-1817-crds test-cr'
Apr  7 06:51:38.347: INFO: stderr: ""
Apr  7 06:51:38.347: INFO: stdout: "e2e-test-crd-publish-openapi-1817-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr  7 06:51:38.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-658 explain e2e-test-crd-publish-openapi-1817-crds'
Apr  7 06:51:38.485: INFO: stderr: ""
Apr  7 06:51:38.485: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1817-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:41.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-658" for this suite.

• [SLOW TEST:7.098 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":346,"completed":116,"skipped":2130,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:41.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr  7 06:51:41.423: INFO: The status of Pod annotationupdatef9ec6762-b575-4689-a10d-03477d10f5b2 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:51:43.438: INFO: The status of Pod annotationupdatef9ec6762-b575-4689-a10d-03477d10f5b2 is Running (Ready = true)
Apr  7 06:51:43.990: INFO: Successfully updated pod "annotationupdatef9ec6762-b575-4689-a10d-03477d10f5b2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:51:48.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6656" for this suite.

• [SLOW TEST:6.802 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":117,"skipped":2157,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:51:48.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-downwardapi-zcs4
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 06:51:48.243: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zcs4" in namespace "subpath-1548" to be "Succeeded or Failed"
Apr  7 06:51:48.253: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.542508ms
Apr  7 06:51:50.263: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 2.020120945s
Apr  7 06:51:52.277: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 4.033616369s
Apr  7 06:51:54.293: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 6.04961944s
Apr  7 06:51:56.315: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 8.071789008s
Apr  7 06:51:58.328: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 10.0849514s
Apr  7 06:52:00.343: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 12.099480579s
Apr  7 06:52:02.357: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 14.113560663s
Apr  7 06:52:04.373: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 16.129955432s
Apr  7 06:52:06.388: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 18.144530785s
Apr  7 06:52:08.405: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Running", Reason="", readiness=true. Elapsed: 20.161564595s
Apr  7 06:52:10.427: INFO: Pod "pod-subpath-test-downwardapi-zcs4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.183609272s
STEP: Saw pod success
Apr  7 06:52:10.427: INFO: Pod "pod-subpath-test-downwardapi-zcs4" satisfied condition "Succeeded or Failed"
Apr  7 06:52:10.436: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-subpath-test-downwardapi-zcs4 container test-container-subpath-downwardapi-zcs4: <nil>
STEP: delete the pod
Apr  7 06:52:10.478: INFO: Waiting for pod pod-subpath-test-downwardapi-zcs4 to disappear
Apr  7 06:52:10.487: INFO: Pod pod-subpath-test-downwardapi-zcs4 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zcs4
Apr  7 06:52:10.487: INFO: Deleting pod "pod-subpath-test-downwardapi-zcs4" in namespace "subpath-1548"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:10.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1548" for this suite.

• [SLOW TEST:22.417 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":118,"skipped":2164,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:10.510: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:52:11.125: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:52:14.173: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr  7 06:52:16.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=webhook-4609 attach --namespace=webhook-4609 to-be-attached-pod -i -c=container1'
Apr  7 06:52:16.385: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:16.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4609" for this suite.
STEP: Destroying namespace "webhook-4609-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.004 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":346,"completed":119,"skipped":2234,"failed":0}
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:16.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-gmjzb in namespace proxy-4963
I0407 06:52:16.643207      23 runners.go:193] Created replication controller with name: proxy-service-gmjzb, namespace: proxy-4963, replica count: 1
I0407 06:52:17.694807      23 runners.go:193] proxy-service-gmjzb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0407 06:52:18.695378      23 runners.go:193] proxy-service-gmjzb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0407 06:52:19.696369      23 runners.go:193] proxy-service-gmjzb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 06:52:19.705: INFO: setup took 3.108302982s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  7 06:52:19.724: INFO: (0) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 18.13496ms)
Apr  7 06:52:19.724: INFO: (0) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 18.067856ms)
Apr  7 06:52:19.724: INFO: (0) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 18.821503ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 19.183127ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 19.136823ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 19.229229ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 19.455644ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 19.598053ms)
Apr  7 06:52:19.725: INFO: (0) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 19.575552ms)
Apr  7 06:52:19.727: INFO: (0) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 21.157353ms)
Apr  7 06:52:19.727: INFO: (0) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 21.411069ms)
Apr  7 06:52:19.730: INFO: (0) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 24.667478ms)
Apr  7 06:52:19.730: INFO: (0) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 24.444463ms)
Apr  7 06:52:19.730: INFO: (0) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 24.451863ms)
Apr  7 06:52:19.731: INFO: (0) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 24.881891ms)
Apr  7 06:52:19.731: INFO: (0) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 25.064103ms)
Apr  7 06:52:19.751: INFO: (1) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 19.782765ms)
Apr  7 06:52:19.752: INFO: (1) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 20.992142ms)
Apr  7 06:52:19.752: INFO: (1) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 20.985542ms)
Apr  7 06:52:19.752: INFO: (1) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 21.485474ms)
Apr  7 06:52:19.753: INFO: (1) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 21.500074ms)
Apr  7 06:52:19.753: INFO: (1) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 22.308927ms)
Apr  7 06:52:19.753: INFO: (1) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 22.555343ms)
Apr  7 06:52:19.753: INFO: (1) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 22.288725ms)
Apr  7 06:52:19.754: INFO: (1) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 22.733054ms)
Apr  7 06:52:19.755: INFO: (1) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 24.373859ms)
Apr  7 06:52:19.759: INFO: (1) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 27.920386ms)
Apr  7 06:52:19.762: INFO: (1) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 31.239898ms)
Apr  7 06:52:19.763: INFO: (1) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 31.885939ms)
Apr  7 06:52:19.782: INFO: (1) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 51.29298ms)
Apr  7 06:52:19.782: INFO: (1) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 51.449991ms)
Apr  7 06:52:19.782: INFO: (1) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 51.422688ms)
Apr  7 06:52:19.795: INFO: (2) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 12.378091ms)
Apr  7 06:52:19.796: INFO: (2) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 13.949492ms)
Apr  7 06:52:19.797: INFO: (2) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 14.505328ms)
Apr  7 06:52:19.797: INFO: (2) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 14.914454ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 16.849178ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 16.934583ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 16.919982ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 17.03549ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 16.904981ms)
Apr  7 06:52:19.800: INFO: (2) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 16.951885ms)
Apr  7 06:52:19.803: INFO: (2) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 19.962977ms)
Apr  7 06:52:19.804: INFO: (2) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 21.754091ms)
Apr  7 06:52:19.804: INFO: (2) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 21.72819ms)
Apr  7 06:52:19.806: INFO: (2) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 23.537606ms)
Apr  7 06:52:19.806: INFO: (2) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 23.572108ms)
Apr  7 06:52:19.806: INFO: (2) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 23.712917ms)
Apr  7 06:52:19.818: INFO: (3) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 11.184815ms)
Apr  7 06:52:19.819: INFO: (3) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 12.434795ms)
Apr  7 06:52:19.819: INFO: (3) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 12.723314ms)
Apr  7 06:52:19.819: INFO: (3) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 12.144777ms)
Apr  7 06:52:19.821: INFO: (3) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 14.55023ms)
Apr  7 06:52:19.821: INFO: (3) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 14.346518ms)
Apr  7 06:52:19.822: INFO: (3) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 15.244975ms)
Apr  7 06:52:19.822: INFO: (3) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 15.651801ms)
Apr  7 06:52:19.822: INFO: (3) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 14.895952ms)
Apr  7 06:52:19.822: INFO: (3) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 14.953656ms)
Apr  7 06:52:19.822: INFO: (3) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 15.521792ms)
Apr  7 06:52:19.825: INFO: (3) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 18.29147ms)
Apr  7 06:52:19.825: INFO: (3) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 18.250067ms)
Apr  7 06:52:19.826: INFO: (3) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 20.056083ms)
Apr  7 06:52:19.827: INFO: (3) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 20.031681ms)
Apr  7 06:52:19.827: INFO: (3) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 20.086885ms)
Apr  7 06:52:19.838: INFO: (4) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 10.693184ms)
Apr  7 06:52:19.840: INFO: (4) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 12.361991ms)
Apr  7 06:52:19.840: INFO: (4) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 12.461197ms)
Apr  7 06:52:19.842: INFO: (4) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 14.469625ms)
Apr  7 06:52:19.842: INFO: (4) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 14.678639ms)
Apr  7 06:52:19.842: INFO: (4) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 14.100801ms)
Apr  7 06:52:19.842: INFO: (4) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 14.764344ms)
Apr  7 06:52:19.843: INFO: (4) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 16.269441ms)
Apr  7 06:52:19.843: INFO: (4) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 16.25194ms)
Apr  7 06:52:19.843: INFO: (4) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 15.894416ms)
Apr  7 06:52:19.845: INFO: (4) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 17.83044ms)
Apr  7 06:52:19.851: INFO: (4) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 24.217649ms)
Apr  7 06:52:19.851: INFO: (4) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 23.938831ms)
Apr  7 06:52:19.854: INFO: (4) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 26.742611ms)
Apr  7 06:52:19.854: INFO: (4) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 26.815115ms)
Apr  7 06:52:19.854: INFO: (4) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 26.386088ms)
Apr  7 06:52:19.868: INFO: (5) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 13.344553ms)
Apr  7 06:52:19.868: INFO: (5) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 13.407357ms)
Apr  7 06:52:19.873: INFO: (5) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 18.944212ms)
Apr  7 06:52:19.873: INFO: (5) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 18.92631ms)
Apr  7 06:52:19.873: INFO: (5) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 19.201228ms)
Apr  7 06:52:19.873: INFO: (5) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 18.959313ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 28.820943ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 28.867746ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 29.047357ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 29.051058ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 29.105661ms)
Apr  7 06:52:19.883: INFO: (5) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 29.130663ms)
Apr  7 06:52:19.884: INFO: (5) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 29.352677ms)
Apr  7 06:52:19.885: INFO: (5) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 31.000083ms)
Apr  7 06:52:19.885: INFO: (5) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 31.112689ms)
Apr  7 06:52:19.885: INFO: (5) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 31.078488ms)
Apr  7 06:52:19.896: INFO: (6) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 10.857495ms)
Apr  7 06:52:19.899: INFO: (6) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 13.216046ms)
Apr  7 06:52:19.899: INFO: (6) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 13.373055ms)
Apr  7 06:52:19.899: INFO: (6) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 13.667874ms)
Apr  7 06:52:19.899: INFO: (6) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 13.568167ms)
Apr  7 06:52:19.899: INFO: (6) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 13.635773ms)
Apr  7 06:52:19.900: INFO: (6) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 14.728941ms)
Apr  7 06:52:19.900: INFO: (6) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 14.84955ms)
Apr  7 06:52:19.900: INFO: (6) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 14.716341ms)
Apr  7 06:52:19.900: INFO: (6) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 14.85055ms)
Apr  7 06:52:19.903: INFO: (6) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 17.007487ms)
Apr  7 06:52:19.907: INFO: (6) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 21.386067ms)
Apr  7 06:52:19.907: INFO: (6) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 21.41827ms)
Apr  7 06:52:19.908: INFO: (6) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 22.082112ms)
Apr  7 06:52:19.908: INFO: (6) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 22.133815ms)
Apr  7 06:52:19.908: INFO: (6) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 22.070911ms)
Apr  7 06:52:19.918: INFO: (7) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 10.332561ms)
Apr  7 06:52:19.945: INFO: (7) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 37.497898ms)
Apr  7 06:52:19.946: INFO: (7) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 37.648707ms)
Apr  7 06:52:19.946: INFO: (7) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 38.360653ms)
Apr  7 06:52:19.947: INFO: (7) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 39.169705ms)
Apr  7 06:52:19.947: INFO: (7) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 39.170105ms)
Apr  7 06:52:19.947: INFO: (7) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 39.258511ms)
Apr  7 06:52:19.947: INFO: (7) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 39.124703ms)
Apr  7 06:52:19.947: INFO: (7) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 39.25341ms)
Apr  7 06:52:19.948: INFO: (7) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 39.866749ms)
Apr  7 06:52:19.949: INFO: (7) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 40.82181ms)
Apr  7 06:52:19.949: INFO: (7) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 41.010223ms)
Apr  7 06:52:19.982: INFO: (7) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 74.025734ms)
Apr  7 06:52:19.983: INFO: (7) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 75.609035ms)
Apr  7 06:52:19.983: INFO: (7) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 75.570732ms)
Apr  7 06:52:19.984: INFO: (7) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 76.578597ms)
Apr  7 06:52:20.012: INFO: (8) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 26.89102ms)
Apr  7 06:52:20.012: INFO: (8) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 26.935622ms)
Apr  7 06:52:20.013: INFO: (8) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 28.275208ms)
Apr  7 06:52:20.013: INFO: (8) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 28.286809ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 28.804242ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 29.275872ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 29.183266ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 28.884647ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 28.995254ms)
Apr  7 06:52:20.014: INFO: (8) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 29.517488ms)
Apr  7 06:52:20.026: INFO: (8) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 40.893115ms)
Apr  7 06:52:20.026: INFO: (8) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 41.090328ms)
Apr  7 06:52:20.026: INFO: (8) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 40.859913ms)
Apr  7 06:52:20.026: INFO: (8) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 41.832275ms)
Apr  7 06:52:20.027: INFO: (8) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 42.094092ms)
Apr  7 06:52:20.027: INFO: (8) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 42.070791ms)
Apr  7 06:52:20.038: INFO: (9) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 11.000303ms)
Apr  7 06:52:20.053: INFO: (9) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 25.676942ms)
Apr  7 06:52:20.053: INFO: (9) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 25.925458ms)
Apr  7 06:52:20.053: INFO: (9) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 25.708445ms)
Apr  7 06:52:20.053: INFO: (9) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 25.665041ms)
Apr  7 06:52:20.056: INFO: (9) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 28.829544ms)
Apr  7 06:52:20.056: INFO: (9) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 28.953351ms)
Apr  7 06:52:20.082: INFO: (9) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 54.862309ms)
Apr  7 06:52:20.082: INFO: (9) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 55.36084ms)
Apr  7 06:52:20.082: INFO: (9) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 55.233332ms)
Apr  7 06:52:20.082: INFO: (9) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 55.318238ms)
Apr  7 06:52:20.084: INFO: (9) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 57.285764ms)
Apr  7 06:52:20.084: INFO: (9) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 57.381869ms)
Apr  7 06:52:20.086: INFO: (9) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 59.275691ms)
Apr  7 06:52:20.086: INFO: (9) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 59.159684ms)
Apr  7 06:52:20.088: INFO: (9) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 60.588775ms)
Apr  7 06:52:20.101: INFO: (10) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 13.235347ms)
Apr  7 06:52:20.117: INFO: (10) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 29.364778ms)
Apr  7 06:52:20.117: INFO: (10) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 29.08926ms)
Apr  7 06:52:20.117: INFO: (10) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 29.261772ms)
Apr  7 06:52:20.124: INFO: (10) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 36.146711ms)
Apr  7 06:52:20.125: INFO: (10) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 37.234481ms)
Apr  7 06:52:20.132: INFO: (10) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 43.687194ms)
Apr  7 06:52:20.132: INFO: (10) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 43.968912ms)
Apr  7 06:52:20.132: INFO: (10) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 43.7811ms)
Apr  7 06:52:20.136: INFO: (10) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 47.581743ms)
Apr  7 06:52:20.137: INFO: (10) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 49.518167ms)
Apr  7 06:52:20.141: INFO: (10) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 53.430316ms)
Apr  7 06:52:20.141: INFO: (10) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 53.442517ms)
Apr  7 06:52:20.142: INFO: (10) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 54.021955ms)
Apr  7 06:52:20.143: INFO: (10) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 54.749801ms)
Apr  7 06:52:20.143: INFO: (10) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 54.675496ms)
Apr  7 06:52:20.152: INFO: (11) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 9.298594ms)
Apr  7 06:52:20.179: INFO: (11) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 36.536037ms)
Apr  7 06:52:20.179: INFO: (11) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 36.405928ms)
Apr  7 06:52:20.179: INFO: (11) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 36.27962ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 37.641107ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 37.706211ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 37.592804ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 37.610805ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 37.811318ms)
Apr  7 06:52:20.181: INFO: (11) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 38.240746ms)
Apr  7 06:52:20.186: INFO: (11) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 43.446479ms)
Apr  7 06:52:20.189: INFO: (11) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 46.710487ms)
Apr  7 06:52:20.190: INFO: (11) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 46.708987ms)
Apr  7 06:52:20.190: INFO: (11) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 46.729389ms)
Apr  7 06:52:20.191: INFO: (11) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 48.020671ms)
Apr  7 06:52:20.191: INFO: (11) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 48.172881ms)
Apr  7 06:52:20.209: INFO: (12) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 17.462517ms)
Apr  7 06:52:20.209: INFO: (12) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 17.436515ms)
Apr  7 06:52:20.209: INFO: (12) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 17.583624ms)
Apr  7 06:52:20.209: INFO: (12) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 17.746235ms)
Apr  7 06:52:20.209: INFO: (12) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 17.781737ms)
Apr  7 06:52:20.210: INFO: (12) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 18.353173ms)
Apr  7 06:52:20.210: INFO: (12) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 18.387276ms)
Apr  7 06:52:20.210: INFO: (12) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 18.587289ms)
Apr  7 06:52:20.210: INFO: (12) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 18.910109ms)
Apr  7 06:52:20.210: INFO: (12) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 19.015716ms)
Apr  7 06:52:20.215: INFO: (12) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 23.884327ms)
Apr  7 06:52:20.215: INFO: (12) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 23.820223ms)
Apr  7 06:52:20.215: INFO: (12) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 23.897028ms)
Apr  7 06:52:20.216: INFO: (12) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 24.628475ms)
Apr  7 06:52:20.216: INFO: (12) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 24.981598ms)
Apr  7 06:52:20.217: INFO: (12) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 25.194311ms)
Apr  7 06:52:20.250: INFO: (13) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 32.672489ms)
Apr  7 06:52:20.250: INFO: (13) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 33.087716ms)
Apr  7 06:52:20.250: INFO: (13) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 33.298829ms)
Apr  7 06:52:20.250: INFO: (13) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 33.498342ms)
Apr  7 06:52:20.251: INFO: (13) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 33.634751ms)
Apr  7 06:52:20.251: INFO: (13) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 33.889267ms)
Apr  7 06:52:20.252: INFO: (13) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 35.434566ms)
Apr  7 06:52:20.253: INFO: (13) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 36.620242ms)
Apr  7 06:52:20.253: INFO: (13) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 36.577839ms)
Apr  7 06:52:20.254: INFO: (13) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 37.21448ms)
Apr  7 06:52:20.255: INFO: (13) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 37.938326ms)
Apr  7 06:52:20.260: INFO: (13) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 43.424377ms)
Apr  7 06:52:20.269: INFO: (13) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 52.22934ms)
Apr  7 06:52:20.270: INFO: (13) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 53.179601ms)
Apr  7 06:52:20.270: INFO: (13) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 53.183001ms)
Apr  7 06:52:20.270: INFO: (13) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 53.203103ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 28.877447ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 28.872546ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 28.967553ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 28.876947ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 28.853345ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 28.872346ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 28.827444ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 28.842644ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 28.950852ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 28.91795ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 28.886247ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 29.113562ms)
Apr  7 06:52:20.299: INFO: (14) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 29.028056ms)
Apr  7 06:52:20.301: INFO: (14) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 30.871574ms)
Apr  7 06:52:20.301: INFO: (14) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 31.210396ms)
Apr  7 06:52:20.301: INFO: (14) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 31.141391ms)
Apr  7 06:52:20.322: INFO: (15) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 20.858634ms)
Apr  7 06:52:20.328: INFO: (15) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 26.087668ms)
Apr  7 06:52:20.328: INFO: (15) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 26.020564ms)
Apr  7 06:52:20.328: INFO: (15) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 26.668105ms)
Apr  7 06:52:20.328: INFO: (15) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 26.705908ms)
Apr  7 06:52:20.329: INFO: (15) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 27.807878ms)
Apr  7 06:52:20.330: INFO: (15) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 28.191003ms)
Apr  7 06:52:20.330: INFO: (15) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 28.258208ms)
Apr  7 06:52:20.330: INFO: (15) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 28.328511ms)
Apr  7 06:52:20.330: INFO: (15) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 28.469121ms)
Apr  7 06:52:20.341: INFO: (15) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 39.708539ms)
Apr  7 06:52:20.347: INFO: (15) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 45.456607ms)
Apr  7 06:52:20.347: INFO: (15) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 45.354ms)
Apr  7 06:52:20.347: INFO: (15) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 45.463808ms)
Apr  7 06:52:20.348: INFO: (15) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 46.222656ms)
Apr  7 06:52:20.348: INFO: (15) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 46.199954ms)
Apr  7 06:52:20.361: INFO: (16) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 13.202245ms)
Apr  7 06:52:20.374: INFO: (16) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 24.869091ms)
Apr  7 06:52:20.375: INFO: (16) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 26.247679ms)
Apr  7 06:52:20.375: INFO: (16) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 26.650504ms)
Apr  7 06:52:20.375: INFO: (16) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 26.522096ms)
Apr  7 06:52:20.380: INFO: (16) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 32.047049ms)
Apr  7 06:52:20.381: INFO: (16) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 32.878303ms)
Apr  7 06:52:20.381: INFO: (16) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 32.20696ms)
Apr  7 06:52:20.381: INFO: (16) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 32.499878ms)
Apr  7 06:52:20.381: INFO: (16) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 32.909304ms)
Apr  7 06:52:20.384: INFO: (16) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 35.859893ms)
Apr  7 06:52:20.388: INFO: (16) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 40.079563ms)
Apr  7 06:52:20.389: INFO: (16) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 40.202971ms)
Apr  7 06:52:20.390: INFO: (16) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 41.300941ms)
Apr  7 06:52:20.390: INFO: (16) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 41.714368ms)
Apr  7 06:52:20.390: INFO: (16) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 41.793673ms)
Apr  7 06:52:20.399: INFO: (17) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 8.995276ms)
Apr  7 06:52:20.408: INFO: (17) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 17.186899ms)
Apr  7 06:52:20.408: INFO: (17) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 17.263004ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 20.805031ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 21.431271ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 21.088749ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 21.513076ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 21.138652ms)
Apr  7 06:52:20.412: INFO: (17) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 21.237758ms)
Apr  7 06:52:20.418: INFO: (17) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 27.009728ms)
Apr  7 06:52:20.421: INFO: (17) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 29.822407ms)
Apr  7 06:52:20.431: INFO: (17) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 40.284576ms)
Apr  7 06:52:20.431: INFO: (17) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 40.276876ms)
Apr  7 06:52:20.432: INFO: (17) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 41.152231ms)
Apr  7 06:52:20.432: INFO: (17) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 41.277839ms)
Apr  7 06:52:20.432: INFO: (17) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 41.194034ms)
Apr  7 06:52:20.445: INFO: (18) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 12.174179ms)
Apr  7 06:52:20.453: INFO: (18) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 20.036881ms)
Apr  7 06:52:20.453: INFO: (18) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 20.3257ms)
Apr  7 06:52:20.453: INFO: (18) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 20.306298ms)
Apr  7 06:52:20.454: INFO: (18) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 21.622883ms)
Apr  7 06:52:20.454: INFO: (18) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 21.869198ms)
Apr  7 06:52:20.455: INFO: (18) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 22.087913ms)
Apr  7 06:52:20.455: INFO: (18) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 22.223321ms)
Apr  7 06:52:20.455: INFO: (18) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 22.354929ms)
Apr  7 06:52:20.455: INFO: (18) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 22.52014ms)
Apr  7 06:52:20.470: INFO: (18) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 37.658808ms)
Apr  7 06:52:20.470: INFO: (18) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 37.795217ms)
Apr  7 06:52:20.471: INFO: (18) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 38.356653ms)
Apr  7 06:52:20.471: INFO: (18) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 38.420457ms)
Apr  7 06:52:20.474: INFO: (18) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 41.614261ms)
Apr  7 06:52:20.477: INFO: (18) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 43.995614ms)
Apr  7 06:52:20.501: INFO: (19) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 23.815823ms)
Apr  7 06:52:20.501: INFO: (19) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:460/proxy/: tls baz (200; 23.75992ms)
Apr  7 06:52:20.501: INFO: (19) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:462/proxy/: tls qux (200; 24.849689ms)
Apr  7 06:52:20.501: INFO: (19) /api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/https:proxy-service-gmjzb-6gkb7:443/proxy/tlsrewritem... (200; 24.504367ms)
Apr  7 06:52:20.502: INFO: (19) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname2/proxy/: bar (200; 25.070203ms)
Apr  7 06:52:20.502: INFO: (19) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 24.771885ms)
Apr  7 06:52:20.502: INFO: (19) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7/proxy/rewriteme">test</a> (200; 25.284017ms)
Apr  7 06:52:20.502: INFO: (19) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:160/proxy/: foo (200; 25.444927ms)
Apr  7 06:52:20.503: INFO: (19) /api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">test<... (200; 25.967761ms)
Apr  7 06:52:20.503: INFO: (19) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:1080/proxy/rewriteme">... (200; 26.138072ms)
Apr  7 06:52:20.503: INFO: (19) /api/v1/namespaces/proxy-4963/pods/http:proxy-service-gmjzb-6gkb7:162/proxy/: bar (200; 26.670105ms)
Apr  7 06:52:20.505: INFO: (19) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname2/proxy/: bar (200; 27.713872ms)
Apr  7 06:52:20.508: INFO: (19) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname2/proxy/: tls qux (200; 31.195595ms)
Apr  7 06:52:20.509: INFO: (19) /api/v1/namespaces/proxy-4963/services/https:proxy-service-gmjzb:tlsportname1/proxy/: tls baz (200; 31.89324ms)
Apr  7 06:52:20.509: INFO: (19) /api/v1/namespaces/proxy-4963/services/http:proxy-service-gmjzb:portname1/proxy/: foo (200; 32.197759ms)
Apr  7 06:52:20.510: INFO: (19) /api/v1/namespaces/proxy-4963/services/proxy-service-gmjzb:portname1/proxy/: foo (200; 33.167621ms)
STEP: deleting ReplicationController proxy-service-gmjzb in namespace proxy-4963, will wait for the garbage collector to delete the pods
Apr  7 06:52:20.580: INFO: Deleting ReplicationController proxy-service-gmjzb took: 11.799755ms
Apr  7 06:52:20.681: INFO: Terminating ReplicationController proxy-service-gmjzb pods took: 100.811146ms
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:21.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4963" for this suite.

• [SLOW TEST:5.292 seconds]
[sig-network] Proxy
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":346,"completed":120,"skipped":2240,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:21.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating cluster-info
Apr  7 06:52:21.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6902 cluster-info'
Apr  7 06:52:21.962: INFO: stderr: ""
Apr  7 06:52:21.962: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:21.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6902" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":346,"completed":121,"skipped":2287,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:21.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:52:22.066: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr  7 06:52:23.139: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:24.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8802" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":346,"completed":122,"skipped":2301,"failed":0}
SSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:24.180: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Apr  7 06:52:24.311: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Apr  7 06:52:24.348: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:24.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8758" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":346,"completed":123,"skipped":2306,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:24.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-9095
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:52:24.531: INFO: Found 0 stateful pods, waiting for 1
Apr  7 06:52:34.545: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Apr  7 06:52:34.644: INFO: Found 1 stateful pods, waiting for 2
Apr  7 06:52:44.662: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 06:52:44.662: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 06:52:44.722: INFO: Deleting all statefulset in ns statefulset-9095
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:44.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9095" for this suite.

• [SLOW TEST:20.344 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should list, patch and delete a collection of StatefulSets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":346,"completed":124,"skipped":2324,"failed":0}
S
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:44.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:157
[It] should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating server pod server in namespace prestop-8958
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8958
STEP: Deleting pre-stop pod
Apr  7 06:52:53.972: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:52:54.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8958" for this suite.

• [SLOW TEST:9.278 seconds]
[sig-node] PreStop
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":346,"completed":125,"skipped":2325,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:52:54.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:52:54.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Creating first CR 
Apr  7 06:52:56.787: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:52:56Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:52:56Z]] name:name1 resourceVersion:14844 uid:6c397433-4e4a-469f-b471-87c398b445fd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr  7 06:53:06.803: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:53:06Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:53:06Z]] name:name2 resourceVersion:14898 uid:14fc81cc-dc54-481e-82e4-7226a431881f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr  7 06:53:16.815: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:52:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:53:16Z]] name:name1 resourceVersion:14936 uid:6c397433-4e4a-469f-b471-87c398b445fd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr  7 06:53:26.835: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:53:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:53:26Z]] name:name2 resourceVersion:14978 uid:14fc81cc-dc54-481e-82e4-7226a431881f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr  7 06:53:36.860: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:52:56Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:53:16Z]] name:name1 resourceVersion:15016 uid:6c397433-4e4a-469f-b471-87c398b445fd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr  7 06:53:46.878: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-07T06:53:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-07T06:53:26Z]] name:name2 resourceVersion:15052 uid:14fc81cc-dc54-481e-82e4-7226a431881f] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:53:57.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4959" for this suite.

• [SLOW TEST:63.392 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":346,"completed":126,"skipped":2341,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:53:57.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:53:57.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0" in namespace "downward-api-8082" to be "Succeeded or Failed"
Apr  7 06:53:57.565: INFO: Pod "downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.067044ms
Apr  7 06:53:59.587: INFO: Pod "downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032306156s
STEP: Saw pod success
Apr  7 06:53:59.587: INFO: Pod "downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0" satisfied condition "Succeeded or Failed"
Apr  7 06:53:59.599: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0 container client-container: <nil>
STEP: delete the pod
Apr  7 06:53:59.651: INFO: Waiting for pod downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0 to disappear
Apr  7 06:53:59.658: INFO: Pod downwardapi-volume-8e980327-d25c-49bd-8c29-bea1883c1bb0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:53:59.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8082" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":127,"skipped":2343,"failed":0}
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:53:59.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr  7 06:53:59.774: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 06:54:59.807: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Apr  7 06:54:59.872: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr  7 06:54:59.885: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr  7 06:54:59.925: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr  7 06:54:59.942: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:55:14.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4078" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:74.575 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":346,"completed":128,"skipped":2353,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:55:14.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-8191
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 06:55:14.362: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr  7 06:55:14.435: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:55:16.450: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:18.453: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:20.447: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:22.445: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:24.452: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:26.455: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:28.450: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:30.457: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:32.447: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 06:55:34.451: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr  7 06:55:34.466: INFO: The status of Pod netserver-1 is Running (Ready = false)
Apr  7 06:55:36.477: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr  7 06:55:38.533: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr  7 06:55:38.533: INFO: Breadth first check of 10.244.0.50 on host 10.240.0.4...
Apr  7 06:55:38.542: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.137:9080/dial?request=hostname&protocol=http&host=10.244.0.50&port=8083&tries=1'] Namespace:pod-network-test-8191 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:55:38.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:55:38.543: INFO: ExecWithOptions: Clientset creation
Apr  7 06:55:38.543: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-8191/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.137%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.50%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:55:38.704: INFO: Waiting for responses: map[]
Apr  7 06:55:38.704: INFO: reached 10.244.0.50 after 0/1 tries
Apr  7 06:55:38.704: INFO: Breadth first check of 10.244.1.136 on host 10.240.0.5...
Apr  7 06:55:38.734: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.137:9080/dial?request=hostname&protocol=http&host=10.244.1.136&port=8083&tries=1'] Namespace:pod-network-test-8191 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 06:55:38.734: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 06:55:38.734: INFO: ExecWithOptions: Clientset creation
Apr  7 06:55:38.734: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-8191/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.137%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.136%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Apr  7 06:55:38.858: INFO: Waiting for responses: map[]
Apr  7 06:55:38.858: INFO: reached 10.244.1.136 after 0/1 tries
Apr  7 06:55:38.858: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:55:38.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8191" for this suite.

• [SLOW TEST:24.632 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":346,"completed":129,"skipped":2383,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:55:38.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8512
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8512
STEP: creating replication controller externalsvc in namespace services-8512
I0407 06:55:39.036916      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8512, replica count: 2
I0407 06:55:42.088425      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr  7 06:55:42.142: INFO: Creating new exec pod
Apr  7 06:55:44.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-8512 exec execpodc9q5z -- /bin/sh -x -c nslookup nodeport-service.services-8512.svc.cluster.local'
Apr  7 06:55:44.442: INFO: stderr: "+ nslookup nodeport-service.services-8512.svc.cluster.local\n"
Apr  7 06:55:44.442: INFO: stdout: "Server:\t\t10.0.0.10\nAddress:\t10.0.0.10#53\n\nnodeport-service.services-8512.svc.cluster.local\tcanonical name = externalsvc.services-8512.svc.cluster.local.\nName:\texternalsvc.services-8512.svc.cluster.local\nAddress: 10.0.234.125\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8512, will wait for the garbage collector to delete the pods
Apr  7 06:55:44.513: INFO: Deleting ReplicationController externalsvc took: 13.031034ms
Apr  7 06:55:44.614: INFO: Terminating ReplicationController externalsvc pods took: 100.971166ms
Apr  7 06:55:46.752: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:55:46.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8512" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.924 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":346,"completed":130,"skipped":2404,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:55:46.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap that has name configmap-test-emptyKey-499799f2-8daa-488d-8a57-ea012908870e
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:55:46.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3636" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":346,"completed":131,"skipped":2449,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:55:46.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Apr  7 06:55:47.017: INFO: Waiting up to 5m0s for pod "security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f" in namespace "security-context-3215" to be "Succeeded or Failed"
Apr  7 06:55:47.025: INFO: Pod "security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.543582ms
Apr  7 06:55:49.041: INFO: Pod "security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023477456s
STEP: Saw pod success
Apr  7 06:55:49.041: INFO: Pod "security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f" satisfied condition "Succeeded or Failed"
Apr  7 06:55:49.050: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f container test-container: <nil>
STEP: delete the pod
Apr  7 06:55:49.092: INFO: Waiting for pod security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f to disappear
Apr  7 06:55:49.099: INFO: Pod security-context-ead3bc10-3c2d-4fe9-b98c-55cb4720962f no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:55:49.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3215" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":132,"skipped":2487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:55:49.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Apr  7 06:55:59.999: INFO: 66 pods remaining
Apr  7 06:55:59.999: INFO: 66 pods has nil DeletionTimestamp
Apr  7 06:55:59.999: INFO: 
STEP: Gathering metrics
Apr  7 06:56:05.007: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr  7 06:56:05.007: INFO: Deleting pod "simpletest-rc-to-be-deleted-26vnc" in namespace "gc-3669"
W0407 06:56:05.007522      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr  7 06:56:05.029: INFO: Deleting pod "simpletest-rc-to-be-deleted-2d8f4" in namespace "gc-3669"
Apr  7 06:56:05.049: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hvrb" in namespace "gc-3669"
Apr  7 06:56:05.069: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s4d5" in namespace "gc-3669"
Apr  7 06:56:05.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-44mmj" in namespace "gc-3669"
Apr  7 06:56:05.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-489zz" in namespace "gc-3669"
Apr  7 06:56:05.137: INFO: Deleting pod "simpletest-rc-to-be-deleted-4f7rr" in namespace "gc-3669"
Apr  7 06:56:05.158: INFO: Deleting pod "simpletest-rc-to-be-deleted-4mk2z" in namespace "gc-3669"
Apr  7 06:56:05.189: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qhx5" in namespace "gc-3669"
Apr  7 06:56:05.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tbbf" in namespace "gc-3669"
Apr  7 06:56:05.262: INFO: Deleting pod "simpletest-rc-to-be-deleted-5w8kv" in namespace "gc-3669"
Apr  7 06:56:05.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dfk5" in namespace "gc-3669"
Apr  7 06:56:05.307: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hzx8" in namespace "gc-3669"
Apr  7 06:56:05.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-6m7cb" in namespace "gc-3669"
Apr  7 06:56:05.392: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tnr2" in namespace "gc-3669"
Apr  7 06:56:05.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kvbm" in namespace "gc-3669"
Apr  7 06:56:05.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pttz" in namespace "gc-3669"
Apr  7 06:56:05.476: INFO: Deleting pod "simpletest-rc-to-be-deleted-8575p" in namespace "gc-3669"
Apr  7 06:56:05.516: INFO: Deleting pod "simpletest-rc-to-be-deleted-85r5r" in namespace "gc-3669"
Apr  7 06:56:05.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-8v8g8" in namespace "gc-3669"
Apr  7 06:56:05.572: INFO: Deleting pod "simpletest-rc-to-be-deleted-8w9g5" in namespace "gc-3669"
Apr  7 06:56:05.606: INFO: Deleting pod "simpletest-rc-to-be-deleted-9r779" in namespace "gc-3669"
Apr  7 06:56:05.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rk2q" in namespace "gc-3669"
Apr  7 06:56:05.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zdxf" in namespace "gc-3669"
Apr  7 06:56:05.689: INFO: Deleting pod "simpletest-rc-to-be-deleted-bmgwk" in namespace "gc-3669"
Apr  7 06:56:05.722: INFO: Deleting pod "simpletest-rc-to-be-deleted-bn6r5" in namespace "gc-3669"
Apr  7 06:56:05.745: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqlsh" in namespace "gc-3669"
Apr  7 06:56:05.776: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxtqk" in namespace "gc-3669"
Apr  7 06:56:05.805: INFO: Deleting pod "simpletest-rc-to-be-deleted-bzf2b" in namespace "gc-3669"
Apr  7 06:56:05.846: INFO: Deleting pod "simpletest-rc-to-be-deleted-c84hl" in namespace "gc-3669"
Apr  7 06:56:05.870: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8pfn" in namespace "gc-3669"
Apr  7 06:56:05.912: INFO: Deleting pod "simpletest-rc-to-be-deleted-cc74t" in namespace "gc-3669"
Apr  7 06:56:05.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-cl4mz" in namespace "gc-3669"
Apr  7 06:56:05.961: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbf9g" in namespace "gc-3669"
Apr  7 06:56:05.983: INFO: Deleting pod "simpletest-rc-to-be-deleted-dfkv2" in namespace "gc-3669"
Apr  7 06:56:06.003: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzrpw" in namespace "gc-3669"
Apr  7 06:56:06.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-fc9fk" in namespace "gc-3669"
Apr  7 06:56:06.076: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkzdz" in namespace "gc-3669"
Apr  7 06:56:06.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftp6v" in namespace "gc-3669"
Apr  7 06:56:06.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzf28" in namespace "gc-3669"
Apr  7 06:56:06.165: INFO: Deleting pod "simpletest-rc-to-be-deleted-gznb6" in namespace "gc-3669"
Apr  7 06:56:06.196: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6wf9" in namespace "gc-3669"
Apr  7 06:56:06.228: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc7lj" in namespace "gc-3669"
Apr  7 06:56:06.249: INFO: Deleting pod "simpletest-rc-to-be-deleted-hs8b4" in namespace "gc-3669"
Apr  7 06:56:06.283: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsszj" in namespace "gc-3669"
Apr  7 06:56:06.306: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4mr2" in namespace "gc-3669"
Apr  7 06:56:06.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-jdkhm" in namespace "gc-3669"
Apr  7 06:56:06.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-jj79k" in namespace "gc-3669"
Apr  7 06:56:06.380: INFO: Deleting pod "simpletest-rc-to-be-deleted-jl2hj" in namespace "gc-3669"
Apr  7 06:56:06.401: INFO: Deleting pod "simpletest-rc-to-be-deleted-jwqvx" in namespace "gc-3669"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:56:06.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3669" for this suite.

• [SLOW TEST:17.339 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":346,"completed":133,"skipped":2509,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:56:06.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Apr  7 06:56:06.581: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.581: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.611: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.611: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.642: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.642: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.674: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:06.674: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr  7 06:56:12.917: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr  7 06:56:12.917: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr  7 06:56:14.113: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Apr  7 06:56:14.132: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 0
Apr  7 06:56:14.133: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:14.134: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:14.134: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.134: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.137: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.137: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.162: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.162: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.193: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.193: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:14.208: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:14.208: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:14.242: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:14.242: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:16.170: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:16.171: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:16.201: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
STEP: listing Deployments
Apr  7 06:56:16.215: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Apr  7 06:56:16.232: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Apr  7 06:56:16.241: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:16.254: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:16.279: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:16.299: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:16.309: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:17.266: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:17.934: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:17.996: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:18.022: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr  7 06:56:19.239: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Apr  7 06:56:19.297: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:19.297: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:19.297: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:19.297: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:19.297: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 1
Apr  7 06:56:19.298: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:19.298: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 3
Apr  7 06:56:19.298: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:19.298: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 2
Apr  7 06:56:19.298: INFO: observed Deployment test-deployment in namespace deployment-4563 with ReadyReplicas 3
STEP: deleting the Deployment
Apr  7 06:56:19.312: INFO: observed event type MODIFIED
Apr  7 06:56:19.312: INFO: observed event type MODIFIED
Apr  7 06:56:19.312: INFO: observed event type MODIFIED
Apr  7 06:56:19.312: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
Apr  7 06:56:19.313: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 06:56:19.318: INFO: Log out all the ReplicaSets if there is no deployment created
Apr  7 06:56:19.326: INFO: ReplicaSet "test-deployment-5ddd8b47d8":
&ReplicaSet{ObjectMeta:{test-deployment-5ddd8b47d8  deployment-4563  789c5b1d-a380-4a17-abc8-a3b0dbed1171 17344 4 2022-04-07 06:56:14 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 428abcc8-05b1-467d-aad1-7f26f7443d2f 0xc0031b3e77 0xc0031b3e78}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:56:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"428abcc8-05b1-467d-aad1-7f26f7443d2f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:56:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5ddd8b47d8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.6 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031b3f00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr  7 06:56:19.335: INFO: pod: "test-deployment-5ddd8b47d8-nd752":
&Pod{ObjectMeta:{test-deployment-5ddd8b47d8-nd752 test-deployment-5ddd8b47d8- deployment-4563  c8404a5e-397b-4456-800f-3827cae2942a 17341 0 2022-04-07 06:56:16 +0000 UTC 2022-04-07 06:56:20 +0000 UTC 0xc005528388 map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5ddd8b47d8 789c5b1d-a380-4a17-abc8-a3b0dbed1171 0xc0055283b7 0xc0055283b8}] []  [{kube-controller-manager Update v1 2022-04-07 06:56:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"789c5b1d-a380-4a17-abc8-a3b0dbed1171\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:56:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.97\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zqxsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.6,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zqxsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.97,StartTime:2022-04-07 06:56:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:56:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.6,ImageID:k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db,ContainerID:containerd://2257682d4f25a4652c9a0bfce0f88700544afbdecda828fb5b4b53db97fa1c81,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr  7 06:56:19.335: INFO: ReplicaSet "test-deployment-6cdc5bc678":
&ReplicaSet{ObjectMeta:{test-deployment-6cdc5bc678  deployment-4563  0bc5ebfe-5f02-41c3-b519-e2b4ab217607 17257 3 2022-04-07 06:56:06 +0000 UTC <nil> <nil> map[pod-template-hash:6cdc5bc678 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 428abcc8-05b1-467d-aad1-7f26f7443d2f 0xc0031b3f67 0xc0031b3f68}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:56:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"428abcc8-05b1-467d-aad1-7f26f7443d2f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:56:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6cdc5bc678,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6cdc5bc678 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031b3ff0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr  7 06:56:19.343: INFO: ReplicaSet "test-deployment-854fdc678":
&ReplicaSet{ObjectMeta:{test-deployment-854fdc678  deployment-4563  5cc6eb78-3cb0-498f-bdb5-232d73010565 17337 2 2022-04-07 06:56:16 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 428abcc8-05b1-467d-aad1-7f26f7443d2f 0xc005528057 0xc005528058}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:56:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"428abcc8-05b1-467d-aad1-7f26f7443d2f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:56:17 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 854fdc678,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0055280e0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr  7 06:56:19.360: INFO: pod: "test-deployment-854fdc678-mlkxq":
&Pod{ObjectMeta:{test-deployment-854fdc678-mlkxq test-deployment-854fdc678- deployment-4563  1f64180e-b2b5-4f4d-9aa7-f65aa0eeb858 17311 0 2022-04-07 06:56:16 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 5cc6eb78-3cb0-498f-bdb5-232d73010565 0xc005c491a7 0xc005c491a8}] []  [{kube-controller-manager Update v1 2022-04-07 06:56:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cc6eb78-3cb0-498f-bdb5-232d73010565\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:56:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.190\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7q6h7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7q6h7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.190,StartTime:2022-04-07 06:56:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:56:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4253ae6e4a46dadb03b136065ae53eaa537510f7dcc1aa6a41b50496d8f5af5a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr  7 06:56:19.360: INFO: pod: "test-deployment-854fdc678-nppnc":
&Pod{ObjectMeta:{test-deployment-854fdc678-nppnc test-deployment-854fdc678- deployment-4563  6d893ca5-9c60-4508-882b-78cd8b676804 17336 0 2022-04-07 06:56:17 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 5cc6eb78-3cb0-498f-bdb5-232d73010565 0xc005c49397 0xc005c49398}] []  [{kube-controller-manager Update v1 2022-04-07 06:56:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cc6eb78-3cb0-498f-bdb5-232d73010565\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:56:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59cbd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59cbd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:56:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.0.98,StartTime:2022-04-07 06:56:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:56:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://958531bd97559f4a1975a9b8d85ea9589a6d16a3d3e15a64bdc1c9b1ee3af370,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.98,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:56:19.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4563" for this suite.

• [SLOW TEST:12.924 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":346,"completed":134,"skipped":2574,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:56:19.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:56:19.494: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db" in namespace "projected-8361" to be "Succeeded or Failed"
Apr  7 06:56:19.504: INFO: Pod "downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db": Phase="Pending", Reason="", readiness=false. Elapsed: 9.678019ms
Apr  7 06:56:21.515: INFO: Pod "downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021185956s
STEP: Saw pod success
Apr  7 06:56:21.515: INFO: Pod "downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db" satisfied condition "Succeeded or Failed"
Apr  7 06:56:21.522: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db container client-container: <nil>
STEP: delete the pod
Apr  7 06:56:21.566: INFO: Waiting for pod downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db to disappear
Apr  7 06:56:21.573: INFO: Pod downwardapi-volume-08748e7d-2d29-42ef-99af-b1031274e0db no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:56:21.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8361" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":135,"skipped":2619,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:56:21.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-65acdf1c-f37c-40c2-937a-b15fb0780ecb
STEP: Creating a pod to test consume configMaps
Apr  7 06:56:21.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8" in namespace "configmap-6758" to be "Succeeded or Failed"
Apr  7 06:56:21.711: INFO: Pod "pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.837285ms
Apr  7 06:56:23.723: INFO: Pod "pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025714046s
STEP: Saw pod success
Apr  7 06:56:23.723: INFO: Pod "pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8" satisfied condition "Succeeded or Failed"
Apr  7 06:56:23.732: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:56:23.772: INFO: Waiting for pod pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8 to disappear
Apr  7 06:56:23.781: INFO: Pod pod-configmaps-b749dcca-0ada-4d06-8a33-ef0142d5bad8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:56:23.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6758" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":136,"skipped":2642,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:56:23.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:56:24.441: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:56:27.501: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:56:27.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6848-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:56:30.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1810" for this suite.
STEP: Destroying namespace "webhook-1810-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.178 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":346,"completed":137,"skipped":2658,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:56:30.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr  7 06:57:11.156: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr  7 06:57:11.156: INFO: Deleting pod "simpletest.rc-27c87" in namespace "gc-1427"
W0407 06:57:11.155961      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr  7 06:57:11.185: INFO: Deleting pod "simpletest.rc-2cx66" in namespace "gc-1427"
Apr  7 06:57:11.207: INFO: Deleting pod "simpletest.rc-2dhlf" in namespace "gc-1427"
Apr  7 06:57:11.232: INFO: Deleting pod "simpletest.rc-2jr9g" in namespace "gc-1427"
Apr  7 06:57:11.259: INFO: Deleting pod "simpletest.rc-2vs5f" in namespace "gc-1427"
Apr  7 06:57:11.290: INFO: Deleting pod "simpletest.rc-2xdxt" in namespace "gc-1427"
Apr  7 06:57:11.313: INFO: Deleting pod "simpletest.rc-44455" in namespace "gc-1427"
Apr  7 06:57:11.340: INFO: Deleting pod "simpletest.rc-4942s" in namespace "gc-1427"
Apr  7 06:57:11.369: INFO: Deleting pod "simpletest.rc-4x752" in namespace "gc-1427"
Apr  7 06:57:11.396: INFO: Deleting pod "simpletest.rc-52w4x" in namespace "gc-1427"
Apr  7 06:57:11.416: INFO: Deleting pod "simpletest.rc-56f54" in namespace "gc-1427"
Apr  7 06:57:11.440: INFO: Deleting pod "simpletest.rc-57n8p" in namespace "gc-1427"
Apr  7 06:57:11.464: INFO: Deleting pod "simpletest.rc-5gxsb" in namespace "gc-1427"
Apr  7 06:57:11.489: INFO: Deleting pod "simpletest.rc-65n5z" in namespace "gc-1427"
Apr  7 06:57:11.510: INFO: Deleting pod "simpletest.rc-6l8j8" in namespace "gc-1427"
Apr  7 06:57:11.536: INFO: Deleting pod "simpletest.rc-6t7nj" in namespace "gc-1427"
Apr  7 06:57:11.567: INFO: Deleting pod "simpletest.rc-6wxjd" in namespace "gc-1427"
Apr  7 06:57:11.593: INFO: Deleting pod "simpletest.rc-7krt8" in namespace "gc-1427"
Apr  7 06:57:11.623: INFO: Deleting pod "simpletest.rc-7mqpt" in namespace "gc-1427"
Apr  7 06:57:11.653: INFO: Deleting pod "simpletest.rc-7sg96" in namespace "gc-1427"
Apr  7 06:57:11.674: INFO: Deleting pod "simpletest.rc-7wlfk" in namespace "gc-1427"
Apr  7 06:57:11.704: INFO: Deleting pod "simpletest.rc-7z6rh" in namespace "gc-1427"
Apr  7 06:57:11.725: INFO: Deleting pod "simpletest.rc-8hjnr" in namespace "gc-1427"
Apr  7 06:57:11.754: INFO: Deleting pod "simpletest.rc-8qh5h" in namespace "gc-1427"
Apr  7 06:57:11.779: INFO: Deleting pod "simpletest.rc-99mg2" in namespace "gc-1427"
Apr  7 06:57:11.810: INFO: Deleting pod "simpletest.rc-b6j4s" in namespace "gc-1427"
Apr  7 06:57:11.838: INFO: Deleting pod "simpletest.rc-bbfq9" in namespace "gc-1427"
Apr  7 06:57:11.866: INFO: Deleting pod "simpletest.rc-bl6v4" in namespace "gc-1427"
Apr  7 06:57:11.897: INFO: Deleting pod "simpletest.rc-bmcfr" in namespace "gc-1427"
Apr  7 06:57:11.928: INFO: Deleting pod "simpletest.rc-cnvf9" in namespace "gc-1427"
Apr  7 06:57:11.960: INFO: Deleting pod "simpletest.rc-cp6g8" in namespace "gc-1427"
Apr  7 06:57:12.007: INFO: Deleting pod "simpletest.rc-ctssq" in namespace "gc-1427"
Apr  7 06:57:12.033: INFO: Deleting pod "simpletest.rc-czq8v" in namespace "gc-1427"
Apr  7 06:57:12.058: INFO: Deleting pod "simpletest.rc-dg4df" in namespace "gc-1427"
Apr  7 06:57:12.078: INFO: Deleting pod "simpletest.rc-dhhkz" in namespace "gc-1427"
Apr  7 06:57:12.111: INFO: Deleting pod "simpletest.rc-dqr78" in namespace "gc-1427"
Apr  7 06:57:12.132: INFO: Deleting pod "simpletest.rc-dv8qg" in namespace "gc-1427"
Apr  7 06:57:12.161: INFO: Deleting pod "simpletest.rc-dz5ns" in namespace "gc-1427"
Apr  7 06:57:12.188: INFO: Deleting pod "simpletest.rc-flrxf" in namespace "gc-1427"
Apr  7 06:57:12.208: INFO: Deleting pod "simpletest.rc-fn42r" in namespace "gc-1427"
Apr  7 06:57:12.236: INFO: Deleting pod "simpletest.rc-fs4x6" in namespace "gc-1427"
Apr  7 06:57:12.263: INFO: Deleting pod "simpletest.rc-gd8hz" in namespace "gc-1427"
Apr  7 06:57:12.288: INFO: Deleting pod "simpletest.rc-gplpc" in namespace "gc-1427"
Apr  7 06:57:12.313: INFO: Deleting pod "simpletest.rc-gxjxq" in namespace "gc-1427"
Apr  7 06:57:12.344: INFO: Deleting pod "simpletest.rc-hghzb" in namespace "gc-1427"
Apr  7 06:57:12.369: INFO: Deleting pod "simpletest.rc-ht7g5" in namespace "gc-1427"
Apr  7 06:57:12.398: INFO: Deleting pod "simpletest.rc-hw2gr" in namespace "gc-1427"
Apr  7 06:57:12.418: INFO: Deleting pod "simpletest.rc-j6gz9" in namespace "gc-1427"
Apr  7 06:57:12.454: INFO: Deleting pod "simpletest.rc-j6r87" in namespace "gc-1427"
Apr  7 06:57:12.484: INFO: Deleting pod "simpletest.rc-j6sg2" in namespace "gc-1427"
Apr  7 06:57:12.517: INFO: Deleting pod "simpletest.rc-jb6jz" in namespace "gc-1427"
Apr  7 06:57:12.537: INFO: Deleting pod "simpletest.rc-jfrqr" in namespace "gc-1427"
Apr  7 06:57:12.565: INFO: Deleting pod "simpletest.rc-jxx7d" in namespace "gc-1427"
Apr  7 06:57:12.605: INFO: Deleting pod "simpletest.rc-k7jrd" in namespace "gc-1427"
Apr  7 06:57:12.632: INFO: Deleting pod "simpletest.rc-kdj88" in namespace "gc-1427"
Apr  7 06:57:12.656: INFO: Deleting pod "simpletest.rc-ldzbn" in namespace "gc-1427"
Apr  7 06:57:12.694: INFO: Deleting pod "simpletest.rc-lxjfh" in namespace "gc-1427"
Apr  7 06:57:12.716: INFO: Deleting pod "simpletest.rc-m4sdf" in namespace "gc-1427"
Apr  7 06:57:12.743: INFO: Deleting pod "simpletest.rc-m6tjt" in namespace "gc-1427"
Apr  7 06:57:12.764: INFO: Deleting pod "simpletest.rc-m84fs" in namespace "gc-1427"
Apr  7 06:57:12.795: INFO: Deleting pod "simpletest.rc-md8tz" in namespace "gc-1427"
Apr  7 06:57:12.817: INFO: Deleting pod "simpletest.rc-mh4jh" in namespace "gc-1427"
Apr  7 06:57:12.847: INFO: Deleting pod "simpletest.rc-n2hpb" in namespace "gc-1427"
Apr  7 06:57:12.876: INFO: Deleting pod "simpletest.rc-nf6ct" in namespace "gc-1427"
Apr  7 06:57:12.909: INFO: Deleting pod "simpletest.rc-nhv4k" in namespace "gc-1427"
Apr  7 06:57:12.932: INFO: Deleting pod "simpletest.rc-njthk" in namespace "gc-1427"
Apr  7 06:57:12.963: INFO: Deleting pod "simpletest.rc-nl5p8" in namespace "gc-1427"
Apr  7 06:57:12.998: INFO: Deleting pod "simpletest.rc-ntngw" in namespace "gc-1427"
Apr  7 06:57:13.019: INFO: Deleting pod "simpletest.rc-nv465" in namespace "gc-1427"
Apr  7 06:57:13.041: INFO: Deleting pod "simpletest.rc-nxvbq" in namespace "gc-1427"
Apr  7 06:57:13.087: INFO: Deleting pod "simpletest.rc-phn92" in namespace "gc-1427"
Apr  7 06:57:13.143: INFO: Deleting pod "simpletest.rc-ptxwg" in namespace "gc-1427"
Apr  7 06:57:13.177: INFO: Deleting pod "simpletest.rc-q9pzr" in namespace "gc-1427"
Apr  7 06:57:13.206: INFO: Deleting pod "simpletest.rc-qf99b" in namespace "gc-1427"
Apr  7 06:57:13.261: INFO: Deleting pod "simpletest.rc-qg87b" in namespace "gc-1427"
Apr  7 06:57:13.293: INFO: Deleting pod "simpletest.rc-qj545" in namespace "gc-1427"
Apr  7 06:57:13.319: INFO: Deleting pod "simpletest.rc-qmfp4" in namespace "gc-1427"
Apr  7 06:57:13.355: INFO: Deleting pod "simpletest.rc-rbfb8" in namespace "gc-1427"
Apr  7 06:57:13.382: INFO: Deleting pod "simpletest.rc-rfdx8" in namespace "gc-1427"
Apr  7 06:57:13.413: INFO: Deleting pod "simpletest.rc-rw2p6" in namespace "gc-1427"
Apr  7 06:57:13.432: INFO: Deleting pod "simpletest.rc-rwwvs" in namespace "gc-1427"
Apr  7 06:57:13.461: INFO: Deleting pod "simpletest.rc-s49cr" in namespace "gc-1427"
Apr  7 06:57:13.481: INFO: Deleting pod "simpletest.rc-s7lh5" in namespace "gc-1427"
Apr  7 06:57:13.501: INFO: Deleting pod "simpletest.rc-s8zmx" in namespace "gc-1427"
Apr  7 06:57:13.521: INFO: Deleting pod "simpletest.rc-s9qzp" in namespace "gc-1427"
Apr  7 06:57:13.540: INFO: Deleting pod "simpletest.rc-sc2ch" in namespace "gc-1427"
Apr  7 06:57:13.561: INFO: Deleting pod "simpletest.rc-sdxn4" in namespace "gc-1427"
Apr  7 06:57:13.580: INFO: Deleting pod "simpletest.rc-smm6q" in namespace "gc-1427"
Apr  7 06:57:13.616: INFO: Deleting pod "simpletest.rc-ssjqt" in namespace "gc-1427"
Apr  7 06:57:13.640: INFO: Deleting pod "simpletest.rc-t2249" in namespace "gc-1427"
Apr  7 06:57:13.675: INFO: Deleting pod "simpletest.rc-w4brb" in namespace "gc-1427"
Apr  7 06:57:13.695: INFO: Deleting pod "simpletest.rc-wdxn8" in namespace "gc-1427"
Apr  7 06:57:13.725: INFO: Deleting pod "simpletest.rc-wg75q" in namespace "gc-1427"
Apr  7 06:57:13.755: INFO: Deleting pod "simpletest.rc-whhqn" in namespace "gc-1427"
Apr  7 06:57:13.780: INFO: Deleting pod "simpletest.rc-wjgc6" in namespace "gc-1427"
Apr  7 06:57:13.805: INFO: Deleting pod "simpletest.rc-wsqsx" in namespace "gc-1427"
Apr  7 06:57:13.825: INFO: Deleting pod "simpletest.rc-wvhzd" in namespace "gc-1427"
Apr  7 06:57:13.846: INFO: Deleting pod "simpletest.rc-xpfm8" in namespace "gc-1427"
Apr  7 06:57:13.874: INFO: Deleting pod "simpletest.rc-z6xhh" in namespace "gc-1427"
Apr  7 06:57:13.897: INFO: Deleting pod "simpletest.rc-zt8j6" in namespace "gc-1427"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1427" for this suite.

• [SLOW TEST:42.988 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":346,"completed":138,"skipped":2667,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:13.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:14.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2716" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":346,"completed":139,"skipped":2678,"failed":0}
SS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:14.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:57:14.324: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1" in namespace "security-context-test-6740" to be "Succeeded or Failed"
Apr  7 06:57:14.332: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.724995ms
Apr  7 06:57:16.344: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019681857s
Apr  7 06:57:18.359: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035198848s
Apr  7 06:57:20.384: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.059893926s
Apr  7 06:57:22.407: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083009802s
Apr  7 06:57:24.423: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.098822732s
Apr  7 06:57:24.423: INFO: Pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1" satisfied condition "Succeeded or Failed"
Apr  7 06:57:24.438: INFO: Got logs for pod "busybox-privileged-false-e5b3b465-7b1d-423d-ae53-c6a384ae5aa1": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:24.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6740" for this suite.

• [SLOW TEST:10.243 seconds]
[sig-node] Security Context
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:232
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":140,"skipped":2680,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:24.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
STEP: creating an pod
Apr  7 06:57:24.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr  7 06:57:24.629: INFO: stderr: ""
Apr  7 06:57:24.629: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for log generator to start.
Apr  7 06:57:24.629: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr  7 06:57:24.629: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1798" to be "running and ready, or succeeded"
Apr  7 06:57:24.638: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.623453ms
Apr  7 06:57:26.651: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.022081533s
Apr  7 06:57:26.651: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr  7 06:57:26.651: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr  7 06:57:26.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator'
Apr  7 06:57:26.739: INFO: stderr: ""
Apr  7 06:57:26.739: INFO: stdout: "I0407 06:57:25.192542       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/5jj 292\nI0407 06:57:25.392775       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/hzj 271\nI0407 06:57:25.593180       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/hrl6 444\nI0407 06:57:25.793593       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/x6k 317\nI0407 06:57:25.992927       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/2z6l 223\nI0407 06:57:26.193362       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/btm 320\nI0407 06:57:26.392724       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/rqv 397\nI0407 06:57:26.593143       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/sjzw 448\n"
STEP: limiting log lines
Apr  7 06:57:26.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator --tail=1'
Apr  7 06:57:26.824: INFO: stderr: ""
Apr  7 06:57:26.824: INFO: stdout: "I0407 06:57:26.793451       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/zkzh 431\n"
Apr  7 06:57:26.824: INFO: got output "I0407 06:57:26.793451       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/zkzh 431\n"
STEP: limiting log bytes
Apr  7 06:57:26.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator --limit-bytes=1'
Apr  7 06:57:26.913: INFO: stderr: ""
Apr  7 06:57:26.913: INFO: stdout: "I"
Apr  7 06:57:26.913: INFO: got output "I"
STEP: exposing timestamps
Apr  7 06:57:26.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator --tail=1 --timestamps'
Apr  7 06:57:27.004: INFO: stderr: ""
Apr  7 06:57:27.004: INFO: stdout: "2022-04-07T06:57:26.992834037Z I0407 06:57:26.992699       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/wgr9 222\n"
Apr  7 06:57:27.004: INFO: got output "2022-04-07T06:57:26.992834037Z I0407 06:57:26.992699       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/wgr9 222\n"
STEP: restricting to a time range
Apr  7 06:57:29.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator --since=1s'
Apr  7 06:57:29.602: INFO: stderr: ""
Apr  7 06:57:29.602: INFO: stdout: "I0407 06:57:28.793198       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/hcj 238\nI0407 06:57:28.993626       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/fz5v 497\nI0407 06:57:29.193058       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/szxh 519\nI0407 06:57:29.393444       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/d22h 599\nI0407 06:57:29.592791       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/5k8 310\n"
Apr  7 06:57:29.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 logs logs-generator logs-generator --since=24h'
Apr  7 06:57:29.706: INFO: stderr: ""
Apr  7 06:57:29.706: INFO: stdout: "I0407 06:57:25.192542       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/5jj 292\nI0407 06:57:25.392775       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/hzj 271\nI0407 06:57:25.593180       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/hrl6 444\nI0407 06:57:25.793593       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/x6k 317\nI0407 06:57:25.992927       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/2z6l 223\nI0407 06:57:26.193362       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/btm 320\nI0407 06:57:26.392724       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/rqv 397\nI0407 06:57:26.593143       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/sjzw 448\nI0407 06:57:26.793451       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/zkzh 431\nI0407 06:57:26.992699       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/wgr9 222\nI0407 06:57:27.193035       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/pn9 307\nI0407 06:57:27.393425       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/cxb 339\nI0407 06:57:27.592777       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/xps5 337\nI0407 06:57:27.793224       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/8rb 366\nI0407 06:57:27.993549       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/p2nv 216\nI0407 06:57:28.193060       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/xp4z 257\nI0407 06:57:28.393508       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/7pvm 532\nI0407 06:57:28.592864       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/tb2 246\nI0407 06:57:28.793198       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/hcj 238\nI0407 06:57:28.993626       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/fz5v 497\nI0407 06:57:29.193058       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/szxh 519\nI0407 06:57:29.393444       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/d22h 599\nI0407 06:57:29.592791       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/5k8 310\n"
[AfterEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
Apr  7 06:57:29.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-1798 delete pod logs-generator'
Apr  7 06:57:30.974: INFO: stderr: ""
Apr  7 06:57:30.974: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:30.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1798" for this suite.

• [SLOW TEST:6.541 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1406
    should be able to retrieve and filter logs  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":346,"completed":141,"skipped":2696,"failed":0}
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:30.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  7 06:57:31.106: INFO: Waiting up to 5m0s for pod "pod-fb4580df-0d62-4d67-9441-2ca023262e9b" in namespace "emptydir-283" to be "Succeeded or Failed"
Apr  7 06:57:31.123: INFO: Pod "pod-fb4580df-0d62-4d67-9441-2ca023262e9b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.341111ms
Apr  7 06:57:33.138: INFO: Pod "pod-fb4580df-0d62-4d67-9441-2ca023262e9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032429664s
STEP: Saw pod success
Apr  7 06:57:33.138: INFO: Pod "pod-fb4580df-0d62-4d67-9441-2ca023262e9b" satisfied condition "Succeeded or Failed"
Apr  7 06:57:33.147: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-fb4580df-0d62-4d67-9441-2ca023262e9b container test-container: <nil>
STEP: delete the pod
Apr  7 06:57:33.190: INFO: Waiting for pod pod-fb4580df-0d62-4d67-9441-2ca023262e9b to disappear
Apr  7 06:57:33.198: INFO: Pod pod-fb4580df-0d62-4d67-9441-2ca023262e9b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:33.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-283" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":142,"skipped":2696,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:33.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:57:33.775: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:57:36.820: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:57:36.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9252-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:40.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7422" for this suite.
STEP: Destroying namespace "webhook-7422-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.183 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":346,"completed":143,"skipped":2715,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:40.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-deac75e0-8999-42d1-b002-3909228fbb03
STEP: Creating a pod to test consume configMaps
Apr  7 06:57:40.509: INFO: Waiting up to 5m0s for pod "pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53" in namespace "configmap-3991" to be "Succeeded or Failed"
Apr  7 06:57:40.515: INFO: Pod "pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.674427ms
Apr  7 06:57:42.528: INFO: Pod "pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019395822s
STEP: Saw pod success
Apr  7 06:57:42.528: INFO: Pod "pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53" satisfied condition "Succeeded or Failed"
Apr  7 06:57:42.536: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:57:42.570: INFO: Waiting for pod pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53 to disappear
Apr  7 06:57:42.577: INFO: Pod pod-configmaps-81da6b9e-6ae8-4e78-a054-523e85417f53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:42.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3991" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":144,"skipped":2719,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:42.590: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-900.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-900.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-900.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-900.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 06:57:44.794: INFO: DNS probes using dns-900/dns-test-80a1c276-9916-463f-bce1-a7b6cbcaf574 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:44.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-900" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":346,"completed":145,"skipped":2724,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:44.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 06:57:45.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:57:45.016: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:57:46.041: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:57:46.041: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:57:47.033: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 06:57:47.033: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status
Apr  7 06:57:47.044: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Apr  7 06:57:47.059: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Apr  7 06:57:47.062: INFO: Observed &DaemonSet event: ADDED
Apr  7 06:57:47.062: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.062: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.062: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.062: INFO: Found daemon set daemon-set in namespace daemonsets-8218 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr  7 06:57:47.062: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Apr  7 06:57:47.074: INFO: Observed &DaemonSet event: ADDED
Apr  7 06:57:47.074: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.074: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.074: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.074: INFO: Observed daemon set daemon-set in namespace daemonsets-8218 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr  7 06:57:47.075: INFO: Observed &DaemonSet event: MODIFIED
Apr  7 06:57:47.075: INFO: Found daemon set daemon-set in namespace daemonsets-8218 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr  7 06:57:47.075: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8218, will wait for the garbage collector to delete the pods
Apr  7 06:57:47.143: INFO: Deleting DaemonSet.extensions daemon-set took: 9.337997ms
Apr  7 06:57:47.244: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.861651ms
Apr  7 06:57:49.370: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:57:49.370: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 06:57:49.375: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19566"},"items":null}

Apr  7 06:57:49.383: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19566"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8218" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":346,"completed":146,"skipped":2733,"failed":0}
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:49.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Apr  7 06:57:49.581: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:57:51.593: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr  7 06:57:51.620: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:57:53.632: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  7 06:57:53.675: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  7 06:57:53.682: INFO: Pod pod-with-poststart-http-hook still exists
Apr  7 06:57:55.683: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  7 06:57:55.692: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:57:55.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4340" for this suite.

• [SLOW TEST:6.291 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":346,"completed":147,"skipped":2734,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:57:55.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Apr  7 06:57:55.821: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:57:57.837: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr  7 06:57:57.867: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:57:59.880: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Apr  7 06:57:59.904: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 06:57:59.912: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 06:58:01.912: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 06:58:01.923: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  7 06:58:03.912: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  7 06:58:03.924: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:03.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2279" for this suite.

• [SLOW TEST:8.247 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":346,"completed":148,"skipped":2747,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:03.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-a15b2ea8-2caa-454b-bd7b-ee6b407c0f6e
STEP: Creating a pod to test consume configMaps
Apr  7 06:58:04.076: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2" in namespace "projected-7471" to be "Succeeded or Failed"
Apr  7 06:58:04.083: INFO: Pod "pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.359471ms
Apr  7 06:58:06.093: INFO: Pod "pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016894066s
STEP: Saw pod success
Apr  7 06:58:06.093: INFO: Pod "pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2" satisfied condition "Succeeded or Failed"
Apr  7 06:58:06.100: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 06:58:06.166: INFO: Waiting for pod pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2 to disappear
Apr  7 06:58:06.173: INFO: Pod pod-projected-configmaps-c69f820e-4053-4916-a4f6-2d11fc2670a2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:06.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7471" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":149,"skipped":2755,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:06.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-4411a4c9-43e4-4bf2-ae5b-5dfddb541a50
STEP: Creating a pod to test consume secrets
Apr  7 06:58:06.285: INFO: Waiting up to 5m0s for pod "pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb" in namespace "secrets-8015" to be "Succeeded or Failed"
Apr  7 06:58:06.294: INFO: Pod "pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.22519ms
Apr  7 06:58:08.312: INFO: Pod "pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027012212s
STEP: Saw pod success
Apr  7 06:58:08.312: INFO: Pod "pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb" satisfied condition "Succeeded or Failed"
Apr  7 06:58:08.320: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 06:58:08.355: INFO: Waiting for pod pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb to disappear
Apr  7 06:58:08.363: INFO: Pod pod-secrets-e477afaa-c471-4dac-ab03-dead5f5310cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:08.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8015" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":150,"skipped":2769,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:08.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:58:08.482: INFO: The status of Pod busybox-scheduling-3deba50d-021e-4a5c-9c86-e8e83b19ebd7 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:58:10.500: INFO: The status of Pod busybox-scheduling-3deba50d-021e-4a5c-9c86-e8e83b19ebd7 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7969" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":346,"completed":151,"skipped":2786,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:10.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:58:10.660: INFO: Create a RollingUpdate DaemonSet
Apr  7 06:58:10.666: INFO: Check that daemon pods launch on every node of the cluster
Apr  7 06:58:10.679: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:58:10.679: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 06:58:11.706: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:58:11.706: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:58:12.697: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 06:58:12.697: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Apr  7 06:58:12.697: INFO: Update the DaemonSet to trigger a rollout
Apr  7 06:58:12.712: INFO: Updating DaemonSet daemon-set
Apr  7 06:58:14.745: INFO: Roll back the DaemonSet before rollout is complete
Apr  7 06:58:14.760: INFO: Updating DaemonSet daemon-set
Apr  7 06:58:14.760: INFO: Make sure DaemonSet rollback is complete
Apr  7 06:58:14.768: INFO: Wrong image for pod: daemon-set-7tnph. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr  7 06:58:14.768: INFO: Pod daemon-set-7tnph is not available
Apr  7 06:58:16.788: INFO: Pod daemon-set-zbq7j is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-766, will wait for the garbage collector to delete the pods
Apr  7 06:58:16.872: INFO: Deleting DaemonSet.extensions daemon-set took: 9.529509ms
Apr  7 06:58:16.972: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.421724ms
Apr  7 06:58:18.485: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:58:18.485: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 06:58:18.498: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19977"},"items":null}

Apr  7 06:58:18.506: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19977"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:18.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-766" for this suite.

• [SLOW TEST:7.997 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":346,"completed":152,"skipped":2805,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:18.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  7 06:58:18.667: INFO: Waiting up to 5m0s for pod "pod-ff36c693-fcca-4908-adc4-03946276986a" in namespace "emptydir-9269" to be "Succeeded or Failed"
Apr  7 06:58:18.676: INFO: Pod "pod-ff36c693-fcca-4908-adc4-03946276986a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.642152ms
Apr  7 06:58:20.691: INFO: Pod "pod-ff36c693-fcca-4908-adc4-03946276986a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023130189s
STEP: Saw pod success
Apr  7 06:58:20.691: INFO: Pod "pod-ff36c693-fcca-4908-adc4-03946276986a" satisfied condition "Succeeded or Failed"
Apr  7 06:58:20.698: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-ff36c693-fcca-4908-adc4-03946276986a container test-container: <nil>
STEP: delete the pod
Apr  7 06:58:20.744: INFO: Waiting for pod pod-ff36c693-fcca-4908-adc4-03946276986a to disappear
Apr  7 06:58:20.753: INFO: Pod pod-ff36c693-fcca-4908-adc4-03946276986a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:20.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9269" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":153,"skipped":2816,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:20.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  7 06:58:20.883: INFO: Waiting up to 5m0s for pod "pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c" in namespace "emptydir-1775" to be "Succeeded or Failed"
Apr  7 06:58:20.890: INFO: Pod "pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.266565ms
Apr  7 06:58:22.902: INFO: Pod "pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019258642s
STEP: Saw pod success
Apr  7 06:58:22.902: INFO: Pod "pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c" satisfied condition "Succeeded or Failed"
Apr  7 06:58:22.910: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c container test-container: <nil>
STEP: delete the pod
Apr  7 06:58:22.968: INFO: Waiting for pod pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c to disappear
Apr  7 06:58:22.977: INFO: Pod pod-563d6f1e-4c5e-4db9-b906-10c48a7e8a4c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:22.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1775" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":154,"skipped":2842,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:22.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  7 06:58:25.144: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:25.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6339" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":155,"skipped":2874,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:25.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 06:58:25.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9" in namespace "downward-api-555" to be "Succeeded or Failed"
Apr  7 06:58:25.308: INFO: Pod "downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021341ms
Apr  7 06:58:27.322: INFO: Pod "downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024257703s
STEP: Saw pod success
Apr  7 06:58:27.322: INFO: Pod "downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9" satisfied condition "Succeeded or Failed"
Apr  7 06:58:27.330: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9 container client-container: <nil>
STEP: delete the pod
Apr  7 06:58:27.367: INFO: Waiting for pod downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9 to disappear
Apr  7 06:58:27.374: INFO: Pod downwardapi-volume-544196dc-a8ff-4073-9a1f-41090e1b10f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:27.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-555" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":156,"skipped":2875,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:27.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-5d45c407-d5f7-4872-99b0-be0a6f623f70
STEP: Creating a pod to test consume secrets
Apr  7 06:58:27.509: INFO: Waiting up to 5m0s for pod "pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da" in namespace "secrets-3008" to be "Succeeded or Failed"
Apr  7 06:58:27.516: INFO: Pod "pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.136257ms
Apr  7 06:58:29.527: INFO: Pod "pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018685962s
STEP: Saw pod success
Apr  7 06:58:29.527: INFO: Pod "pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da" satisfied condition "Succeeded or Failed"
Apr  7 06:58:29.536: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 06:58:29.590: INFO: Waiting for pod pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da to disappear
Apr  7 06:58:29.599: INFO: Pod pod-secrets-389cbea1-e5dc-438c-95b8-f49bf3c8b4da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:29.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3008" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":157,"skipped":2893,"failed":0}

------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:29.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pod templates
Apr  7 06:58:29.709: INFO: created test-podtemplate-1
Apr  7 06:58:29.723: INFO: created test-podtemplate-2
Apr  7 06:58:29.732: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Apr  7 06:58:29.742: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Apr  7 06:58:29.794: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:29.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9248" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":346,"completed":158,"skipped":2893,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:29.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:58:29.918: INFO: Got root ca configmap in namespace "svcaccounts-8595"
Apr  7 06:58:29.932: INFO: Deleted root ca configmap in namespace "svcaccounts-8595"
STEP: waiting for a new root ca configmap created
Apr  7 06:58:30.454: INFO: Recreated root ca configmap in namespace "svcaccounts-8595"
Apr  7 06:58:30.464: INFO: Updated root ca configmap in namespace "svcaccounts-8595"
STEP: waiting for the root ca configmap reconciled
Apr  7 06:58:30.975: INFO: Reconciled root ca configmap in namespace "svcaccounts-8595"
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:30.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8595" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":346,"completed":159,"skipped":2900,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:30.991: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 06:58:31.758: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 06:58:34.804: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:35.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3089" for this suite.
STEP: Destroying namespace "webhook-3089-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":346,"completed":160,"skipped":2910,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:35.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-projected-8vjg
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 06:58:35.231: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8vjg" in namespace "subpath-9486" to be "Succeeded or Failed"
Apr  7 06:58:35.243: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Pending", Reason="", readiness=false. Elapsed: 11.796155ms
Apr  7 06:58:37.262: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.030540352s
Apr  7 06:58:39.281: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.049387855s
Apr  7 06:58:41.296: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.064289606s
Apr  7 06:58:43.310: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.078843349s
Apr  7 06:58:45.323: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.091987276s
Apr  7 06:58:47.338: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.106159169s
Apr  7 06:58:49.368: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.136466099s
Apr  7 06:58:51.380: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.14811965s
Apr  7 06:58:53.399: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.167697455s
Apr  7 06:58:55.412: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.180106198s
Apr  7 06:58:57.421: INFO: Pod "pod-subpath-test-projected-8vjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.189325636s
STEP: Saw pod success
Apr  7 06:58:57.421: INFO: Pod "pod-subpath-test-projected-8vjg" satisfied condition "Succeeded or Failed"
Apr  7 06:58:57.428: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-subpath-test-projected-8vjg container test-container-subpath-projected-8vjg: <nil>
STEP: delete the pod
Apr  7 06:58:57.465: INFO: Waiting for pod pod-subpath-test-projected-8vjg to disappear
Apr  7 06:58:57.476: INFO: Pod pod-subpath-test-projected-8vjg no longer exists
STEP: Deleting pod pod-subpath-test-projected-8vjg
Apr  7 06:58:57.476: INFO: Deleting pod "pod-subpath-test-projected-8vjg" in namespace "subpath-9486"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:57.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9486" for this suite.

• [SLOW TEST:22.390 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":161,"skipped":2917,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:57.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:58:59.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-7353" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":162,"skipped":2931,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:58:59.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-7398
Apr  7 06:58:59.793: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:59:01.803: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr  7 06:59:01.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr  7 06:59:02.038: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr  7 06:59:02.038: INFO: stdout: "iptables"
Apr  7 06:59:02.038: INFO: proxyMode: iptables
Apr  7 06:59:02.075: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr  7 06:59:02.084: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-7398
STEP: creating replication controller affinity-nodeport-timeout in namespace services-7398
I0407 06:59:02.174377      23 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7398, replica count: 3
I0407 06:59:05.226641      23 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 06:59:05.250: INFO: Creating new exec pod
Apr  7 06:59:08.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Apr  7 06:59:08.512: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Apr  7 06:59:08.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:59:08.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.110.205 80'
Apr  7 06:59:08.720: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.110.205 80\nConnection to 10.0.110.205 80 port [tcp/http] succeeded!\n"
Apr  7 06:59:08.720: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:59:08.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.4 30548'
Apr  7 06:59:08.939: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.4 30548\nConnection to 10.240.0.4 30548 port [tcp/*] succeeded!\n"
Apr  7 06:59:08.939: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:59:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.5 30548'
Apr  7 06:59:09.139: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.5 30548\nConnection to 10.240.0.5 30548 port [tcp/*] succeeded!\n"
Apr  7 06:59:09.139: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 06:59:09.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.240.0.4:30548/ ; done'
Apr  7 06:59:09.451: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n"
Apr  7 06:59:09.451: INFO: stdout: "\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w\naffinity-nodeport-timeout-d9k4w"
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Received response from host: affinity-nodeport-timeout-d9k4w
Apr  7 06:59:09.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.240.0.4:30548/'
Apr  7 06:59:09.681: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n"
Apr  7 06:59:09.681: INFO: stdout: "affinity-nodeport-timeout-d9k4w"
Apr  7 06:59:29.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-7398 exec execpod-affinitypwvkb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.240.0.4:30548/'
Apr  7 06:59:29.925: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.240.0.4:30548/\n"
Apr  7 06:59:29.925: INFO: stdout: "affinity-nodeport-timeout-6c2cx"
Apr  7 06:59:29.925: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7398, will wait for the garbage collector to delete the pods
Apr  7 06:59:30.019: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 9.953338ms
Apr  7 06:59:30.121: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 101.996232ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:59:32.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7398" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:32.915 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":163,"skipped":2939,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:59:32.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr  7 06:59:32.668: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 06:59:32.683: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 06:59:32.688: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000000 before test
Apr  7 06:59:32.703: INFO: azure-ip-masq-agent-vjb96 from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 06:59:32.703: INFO: cloud-node-manager-tcnjx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 06:59:32.703: INFO: coredns-748769b948-gz9rk from kube-system started at 2022-04-07 06:25:16 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container coredns ready: true, restart count 0
Apr  7 06:59:32.703: INFO: coredns-748769b948-j9bgf from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container coredns ready: true, restart count 0
Apr  7 06:59:32.703: INFO: coredns-autoscaler-6fb889cdfc-w5qm4 from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container autoscaler ready: true, restart count 0
Apr  7 06:59:32.703: INFO: csi-azuredisk-node-qmwkm from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:59:32.703: INFO: csi-azurefile-node-swhhx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:59:32.703: INFO: konnectivity-agent-76fcfc46bd-9kq4v from kube-system started at 2022-04-07 06:25:20 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 06:59:32.703: INFO: konnectivity-agent-76fcfc46bd-chsbh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 06:59:32.703: INFO: kube-proxy-spxrs from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 06:59:32.703: INFO: metrics-server-7d59848cc6-4skgh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 06:59:32.703: INFO: metrics-server-7d59848cc6-wrc2c from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 06:59:32.703: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:59:32.703: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  7 06:59:32.703: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000001 before test
Apr  7 06:59:32.714: INFO: azure-ip-masq-agent-k7wwg from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 06:59:32.714: INFO: cloud-node-manager-4xrsl from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 06:59:32.714: INFO: csi-azuredisk-node-6g62x from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:59:32.714: INFO: csi-azurefile-node-8z4x6 from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 06:59:32.714: INFO: kube-proxy-9vz4m from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 06:59:32.714: INFO: sonobuoy from sonobuoy started at 2022-04-07 06:29:06 +0000 UTC (1 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 06:59:32.714: INFO: sonobuoy-e2e-job-6dc4960ffa6e4d5e from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container e2e ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:59:32.714: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-c22tn from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 06:59:32.714: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 06:59:32.714: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: verifying the node has the label node aks-nodepool1-35379194-vmss000000
STEP: verifying the node has the label node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod azure-ip-masq-agent-k7wwg requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod azure-ip-masq-agent-vjb96 requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod cloud-node-manager-4xrsl requesting resource cpu=50m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod cloud-node-manager-tcnjx requesting resource cpu=50m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod coredns-748769b948-gz9rk requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod coredns-748769b948-j9bgf requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod coredns-autoscaler-6fb889cdfc-w5qm4 requesting resource cpu=20m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod csi-azuredisk-node-6g62x requesting resource cpu=30m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod csi-azuredisk-node-qmwkm requesting resource cpu=30m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod csi-azurefile-node-8z4x6 requesting resource cpu=30m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod csi-azurefile-node-swhhx requesting resource cpu=30m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod konnectivity-agent-76fcfc46bd-9kq4v requesting resource cpu=20m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod konnectivity-agent-76fcfc46bd-chsbh requesting resource cpu=20m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod kube-proxy-9vz4m requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod kube-proxy-spxrs requesting resource cpu=100m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod metrics-server-7d59848cc6-4skgh requesting resource cpu=44m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod metrics-server-7d59848cc6-wrc2c requesting resource cpu=44m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod sonobuoy requesting resource cpu=0m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod sonobuoy-e2e-job-6dc4960ffa6e4d5e requesting resource cpu=0m on Node aks-nodepool1-35379194-vmss000001
Apr  7 06:59:32.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l requesting resource cpu=0m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-c22tn requesting resource cpu=0m on Node aks-nodepool1-35379194-vmss000001
STEP: Starting Pods to consume most of the cluster CPU.
Apr  7 06:59:32.807: INFO: Creating a pod which consumes cpu=2241m on Node aks-nodepool1-35379194-vmss000000
Apr  7 06:59:32.827: INFO: Creating a pod which consumes cpu=2485m on Node aks-nodepool1-35379194-vmss000001
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a.16e38b0c26f8f386], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6162/filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a to aks-nodepool1-35379194-vmss000000]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a.16e38b0c42fea168], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a.16e38b0c43ff2123], Reason = [Created], Message = [Created container filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a.16e38b0c48b038da], Reason = [Started], Message = [Started container filler-pod-7dc3160c-9922-4e59-af26-a51ed255197a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867.16e38b0c2796da4e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6162/filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867 to aks-nodepool1-35379194-vmss000001]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867.16e38b0c43fe2fb4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867.16e38b0c44f87a1f], Reason = [Created], Message = [Created container filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867.16e38b0c49027007], Reason = [Started], Message = [Started container filler-pod-eebe5dbd-3438-4d01-a25d-d6362b157867]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16e38b0ca17541f2], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node aks-nodepool1-35379194-vmss000000
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-nodepool1-35379194-vmss000001
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:59:36.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6162" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":346,"completed":164,"skipped":2980,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:59:36.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:59:36.128: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  7 06:59:36.142: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:36.142: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Apr  7 06:59:36.182: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:36.182: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:59:37.256: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:37.256: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:59:38.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:59:38.193: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  7 06:59:38.234: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:59:38.234: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr  7 06:59:39.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:39.244: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  7 06:59:39.263: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:39.263: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:59:40.275: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:40.275: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:59:41.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:41.273: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 06:59:42.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 06:59:42.273: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5406, will wait for the garbage collector to delete the pods
Apr  7 06:59:42.349: INFO: Deleting DaemonSet.extensions daemon-set took: 11.036806ms
Apr  7 06:59:42.450: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.45983ms
Apr  7 06:59:44.563: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 06:59:44.563: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 06:59:44.568: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20925"},"items":null}

Apr  7 06:59:44.576: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20925"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:59:44.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5406" for this suite.

• [SLOW TEST:8.616 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":346,"completed":165,"skipped":3009,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:59:44.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr  7 06:59:44.773: INFO: The status of Pod annotationupdate42564202-d6e6-48dd-be04-570408d16ed8 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 06:59:46.801: INFO: The status of Pod annotationupdate42564202-d6e6-48dd-be04-570408d16ed8 is Running (Ready = true)
Apr  7 06:59:47.352: INFO: Successfully updated pod "annotationupdate42564202-d6e6-48dd-be04-570408d16ed8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 06:59:49.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-908" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":166,"skipped":3011,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 06:59:49.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 06:59:49.540: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  7 06:59:54.560: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 06:59:54.560: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  7 06:59:56.575: INFO: Creating deployment "test-rollover-deployment"
Apr  7 06:59:56.591: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  7 06:59:58.607: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  7 06:59:58.619: INFO: Ensure that both replica sets have 1 created replica
Apr  7 06:59:58.633: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  7 06:59:58.647: INFO: Updating deployment test-rollover-deployment
Apr  7 06:59:58.647: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  7 07:00:00.669: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  7 07:00:00.683: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  7 07:00:00.697: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 07:00:00.697: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 07:00:02.718: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 07:00:02.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 07:00:04.720: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 07:00:04.721: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 07:00:06.715: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 07:00:06.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 07:00:08.718: INFO: all replica sets need to contain the pod-template-hash label
Apr  7 07:00:08.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 6, 59, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 6, 59, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-668b7f667d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  7 07:00:10.713: INFO: 
Apr  7 07:00:10.713: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 07:00:10.732: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5553  d310fd40-1d42-4bfb-9f43-a0c4513ea2f8 21149 2 2022-04-07 06:59:56 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-07 06:59:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002ec7258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-07 06:59:56 +0000 UTC,LastTransitionTime:2022-04-07 06:59:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-668b7f667d" has successfully progressed.,LastUpdateTime:2022-04-07 07:00:09 +0000 UTC,LastTransitionTime:2022-04-07 06:59:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 07:00:10.741: INFO: New ReplicaSet "test-rollover-deployment-668b7f667d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-668b7f667d  deployment-5553  3bc2dccf-4f4a-43e5-aee6-d100963dd47a 21139 2 2022-04-07 06:59:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d310fd40-1d42-4bfb-9f43-a0c4513ea2f8 0xc002ec7757 0xc002ec7758}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:59:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d310fd40-1d42-4bfb-9f43-a0c4513ea2f8\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 668b7f667d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002ec7808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:00:10.741: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  7 07:00:10.741: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5553  2c965a6d-b236-41ac-ad3b-d0ac1b4b028e 21148 2 2022-04-07 06:59:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d310fd40-1d42-4bfb-9f43-a0c4513ea2f8 0xc002ec7627 0xc002ec7628}] []  [{e2e.test Update apps/v1 2022-04-07 06:59:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d310fd40-1d42-4bfb-9f43-a0c4513ea2f8\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:09 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002ec76e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:00:10.741: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-784bc44b77  deployment-5553  51b61bae-bb9a-436b-a9a0-f7611ed1a868 21086 2 2022-04-07 06:59:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d310fd40-1d42-4bfb-9f43-a0c4513ea2f8 0xc002ec7877 0xc002ec7878}] []  [{kube-controller-manager Update apps/v1 2022-04-07 06:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d310fd40-1d42-4bfb-9f43-a0c4513ea2f8\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 06:59:58 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 784bc44b77,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002ec7928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:00:10.751: INFO: Pod "test-rollover-deployment-668b7f667d-dbbvb" is available:
&Pod{ObjectMeta:{test-rollover-deployment-668b7f667d-dbbvb test-rollover-deployment-668b7f667d- deployment-5553  f0c2a7f0-589c-4822-9aa1-e670008d78ab 21097 0 2022-04-07 06:59:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:668b7f667d] map[] [{apps/v1 ReplicaSet test-rollover-deployment-668b7f667d 3bc2dccf-4f4a-43e5-aee6-d100963dd47a 0xc002ec7e77 0xc002ec7e78}] []  [{kube-controller-manager Update v1 2022-04-07 06:59:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3bc2dccf-4f4a-43e5-aee6-d100963dd47a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 06:59:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9nhk4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9nhk4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:59:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:59:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:59:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 06:59:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.23,StartTime:2022-04-07 06:59:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 06:59:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43,ContainerID:containerd://991567b335b17190da235f943df01960287482ebad3c10c43472482c4d64a38d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:10.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5553" for this suite.

• [SLOW TEST:21.348 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":346,"completed":167,"skipped":3040,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:10.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-153
STEP: creating service affinity-nodeport-transition in namespace services-153
STEP: creating replication controller affinity-nodeport-transition in namespace services-153
I0407 07:00:10.898802      23 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-153, replica count: 3
I0407 07:00:13.950627      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:00:13.980: INFO: Creating new exec pod
Apr  7 07:00:17.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr  7 07:00:17.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr  7 07:00:17.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:00:17.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.24.71 80'
Apr  7 07:00:17.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.24.71 80\nConnection to 10.0.24.71 80 port [tcp/http] succeeded!\n"
Apr  7 07:00:17.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:00:17.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.4 30641'
Apr  7 07:00:17.659: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.4 30641\nConnection to 10.240.0.4 30641 port [tcp/*] succeeded!\n"
Apr  7 07:00:17.659: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:00:17.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.5 30641'
Apr  7 07:00:17.883: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.5 30641\nConnection to 10.240.0.5 30641 port [tcp/*] succeeded!\n"
Apr  7 07:00:17.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:00:17.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.240.0.4:30641/ ; done'
Apr  7 07:00:18.180: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n"
Apr  7 07:00:18.180: INFO: stdout: "\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-t22rm\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-t22rm\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-t22rm\naffinity-nodeport-transition-lsmtg\naffinity-nodeport-transition-t22rm\naffinity-nodeport-transition-t22rm\naffinity-nodeport-transition-lsmtg"
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-t22rm
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-t22rm
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-t22rm
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-t22rm
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-t22rm
Apr  7 07:00:18.180: INFO: Received response from host: affinity-nodeport-transition-lsmtg
Apr  7 07:00:18.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-153 exec execpod-affinitygtxkw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.240.0.4:30641/ ; done'
Apr  7 07:00:18.506: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:30641/\n"
Apr  7 07:00:18.506: INFO: stdout: "\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2\naffinity-nodeport-transition-8rcp2"
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Received response from host: affinity-nodeport-transition-8rcp2
Apr  7 07:00:18.506: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-153, will wait for the garbage collector to delete the pods
Apr  7 07:00:18.598: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.061243ms
Apr  7 07:00:18.699: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.39032ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:20.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-153" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:10.118 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":168,"skipped":3096,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:20.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:00:20.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 create -f -'
Apr  7 07:00:21.897: INFO: stderr: ""
Apr  7 07:00:21.898: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr  7 07:00:21.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 create -f -'
Apr  7 07:00:22.055: INFO: stderr: ""
Apr  7 07:00:22.055: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr  7 07:00:23.072: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:00:23.072: INFO: Found 1 / 1
Apr  7 07:00:23.072: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  7 07:00:23.079: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:00:23.079: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 07:00:23.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 describe pod agnhost-primary-mngrm'
Apr  7 07:00:23.189: INFO: stderr: ""
Apr  7 07:00:23.189: INFO: stdout: "Name:         agnhost-primary-mngrm\nNamespace:    kubectl-6854\nPriority:     0\nNode:         aks-nodepool1-35379194-vmss000001/10.240.0.5\nStart Time:   Thu, 07 Apr 2022 07:00:21 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.1.26\nIPs:\n  IP:           10.244.1.26\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://b7729c6e87f9dbb8f3d37a0a244bdb4221080f82073ea603ca5b768df1375baa\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.33\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 07 Apr 2022 07:00:22 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tprfl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-tprfl:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-6854/agnhost-primary-mngrm to aks-nodepool1-35379194-vmss000001\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.33\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Apr  7 07:00:23.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 describe rc agnhost-primary'
Apr  7 07:00:23.291: INFO: stderr: ""
Apr  7 07:00:23.291: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6854\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.33\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-mngrm\n"
Apr  7 07:00:23.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 describe service agnhost-primary'
Apr  7 07:00:23.404: INFO: stderr: ""
Apr  7 07:00:23.404: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6854\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.0.140.64\nIPs:               10.0.140.64\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.1.26:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  7 07:00:23.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 describe node aks-nodepool1-35379194-vmss000000'
Apr  7 07:00:23.550: INFO: stderr: ""
Apr  7 07:00:23.550: INFO: stdout: "Name:               aks-nodepool1-35379194-vmss000000\nRoles:              agent\nLabels:             agentpool=nodepool1\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS3_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eastus\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/agentpool=nodepool1\n                    kubernetes.azure.com/cluster=MC_levo-aks-eastus_aksconformance-123_eastus\n                    kubernetes.azure.com/mode=system\n                    kubernetes.azure.com/node-image-version=AKSUbuntu-1804gen2containerd-2022.03.23\n                    kubernetes.azure.com/os-sku=Ubuntu\n                    kubernetes.azure.com/role=agent\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=aks-nodepool1-35379194-vmss000000\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    node.kubernetes.io/instance-type=Standard_DS3_v2\n                    topology.disk.csi.azure.com/zone=\n                    topology.kubernetes.io/region=eastus\n                    topology.kubernetes.io/zone=0\nAnnotations:        csi.volume.kubernetes.io/nodeid:\n                      {\"disk.csi.azure.com\":\"aks-nodepool1-35379194-vmss000000\",\"file.csi.azure.com\":\"aks-nodepool1-35379194-vmss000000\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 07 Apr 2022 06:24:27 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  aks-nodepool1-35379194-vmss000000\n  AcquireTime:     <unset>\n  RenewTime:       Thu, 07 Apr 2022 07:00:16 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ReadonlyFilesystem            False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  ContainerRuntimeProblem       False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   ContainerRuntimeIsUp            container runtime service is up\n  TerminateScheduled            False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:33:40 +0000   NoTerminateScheduled            VM has no scheduled Terminate event\n  KernelDeadlock                False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  FreezeScheduled               False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:33:43 +0000   NoFreezeScheduled               VM has no scheduled Freeze event\n  FrequentKubeletRestart        False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentUnregisterNetDevice   False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  KubeletProblem                False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   KubeletIsUp                     kubelet service is up\n  PreemptScheduled              False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:33:37 +0000   NoPreemptScheduled              VM has no scheduled Preempt event\n  FilesystemCorruptionProblem   False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   FilesystemIsOK                  Filesystem is healthy\n  FrequentDockerRestart         False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   NoFrequentDockerRestart         docker is functioning properly\n  RedeployScheduled             False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:33:41 +0000   NoRedeployScheduled             VM has no scheduled Redeploy event\n  FrequentContainerdRestart     False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:32:27 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  RebootScheduled               False   Thu, 07 Apr 2022 06:58:47 +0000   Thu, 07 Apr 2022 06:33:42 +0000   NoRebootScheduled               VM has no scheduled Reboot event\n  NetworkUnavailable            False   Thu, 07 Apr 2022 06:25:10 +0000   Thu, 07 Apr 2022 06:25:10 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Thu, 07 Apr 2022 07:00:12 +0000   Thu, 07 Apr 2022 06:24:27 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Thu, 07 Apr 2022 07:00:12 +0000   Thu, 07 Apr 2022 06:24:27 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Thu, 07 Apr 2022 07:00:12 +0000   Thu, 07 Apr 2022 06:24:27 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Thu, 07 Apr 2022 07:00:12 +0000   Thu, 07 Apr 2022 06:24:38 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.240.0.4\n  Hostname:    aks-nodepool1-35379194-vmss000000\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      129900528Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 14328912Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    3860m\n  ephemeral-storage:      119716326407\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 11044944Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 c64ac917d8ac4f39a822a328e0e9c4c1\n  System UUID:                f5a64b15-ad9c-4dbd-b869-1c6d10750d79\n  Boot ID:                    6277e3eb-89c9-4d0c-87ee-bd397a19738c\n  Kernel Version:             5.4.0-1073-azure\n  OS Image:                   Ubuntu 18.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.9+azure-3\n  Kubelet Version:            v1.23.3\n  Kube-Proxy Version:         v1.23.3\nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nProviderID:                   azure:///subscriptions/01db32b1-e169-43b0-a791-de0e1ca5d8cd/resourceGroups/mc_levo-aks-eastus_aksconformance-123_eastus/providers/Microsoft.Compute/virtualMachineScaleSets/aks-nodepool1-35379194-vmss/virtualMachines/0\nNon-terminated Pods:          (13 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 azure-ip-masq-agent-vjb96                                  100m (2%)     500m (12%)  50Mi (0%)        250Mi (2%)     35m\n  kube-system                 cloud-node-manager-tcnjx                                   50m (1%)      2 (51%)     50Mi (0%)        512Mi (4%)     35m\n  kube-system                 coredns-748769b948-gz9rk                                   100m (2%)     3 (77%)     70Mi (0%)        500Mi (4%)     35m\n  kube-system                 coredns-748769b948-j9bgf                                   100m (2%)     3 (77%)     70Mi (0%)        500Mi (4%)     38m\n  kube-system                 coredns-autoscaler-6fb889cdfc-w5qm4                        20m (0%)      200m (5%)   10Mi (0%)        500Mi (4%)     38m\n  kube-system                 csi-azuredisk-node-qmwkm                                   30m (0%)      0 (0%)      60Mi (0%)        400Mi (3%)     35m\n  kube-system                 csi-azurefile-node-swhhx                                   30m (0%)      0 (0%)      60Mi (0%)        500Mi (4%)     35m\n  kube-system                 konnectivity-agent-76fcfc46bd-9kq4v                        20m (0%)      100m (2%)   20Mi (0%)        128Mi (1%)     35m\n  kube-system                 konnectivity-agent-76fcfc46bd-chsbh                        20m (0%)      100m (2%)   20Mi (0%)        128Mi (1%)     37m\n  kube-system                 kube-proxy-spxrs                                           100m (2%)     0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                 metrics-server-7d59848cc6-4skgh                            44m (1%)      1 (25%)     55Mi (0%)        2000Mi (18%)   38m\n  kube-system                 metrics-server-7d59848cc6-wrc2c                            44m (1%)      1 (25%)     55Mi (0%)        2000Mi (18%)   38m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l    0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    658m (17%)  10900m (282%)\n  memory                 520Mi (4%)  7418Mi (68%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type     Reason                                            Age                From                                           Message\n  ----     ------                                            ----               ----                                           -------\n  Warning  listen tcp4 :30641: bind: address already in use  12s                kube-proxy                                     can't open port \"nodePort for services-153/affinity-nodeport-transition\" (:30641/tcp4), skipping it\n  Warning  listen tcp4 :30548: bind: address already in use  81s                kube-proxy                                     can't open port \"nodePort for services-7398/affinity-nodeport-timeout\" (:30548/tcp4), skipping it\n  Warning  listen tcp4 :30070: bind: address already in use  4m44s              kube-proxy                                     can't open port \"nodePort for services-8512/nodeport-service\" (:30070/tcp4), skipping it\n  Warning  listen tcp4 :31490: bind: address already in use  10m                kube-proxy                                     can't open port \"nodePort for resourcequota-7956/test-service-np\" (:31490/tcp4), skipping it\n  Normal   Starting                                          35m                kube-proxy                                     \n  Normal   NodeHasSufficientPID                              35m (x2 over 35m)  kubelet                                        Node aks-nodepool1-35379194-vmss000000 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced                           35m                kubelet                                        Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity                               35m                kubelet                                        invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory                           35m (x2 over 35m)  kubelet                                        Node aks-nodepool1-35379194-vmss000000 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure                             35m (x2 over 35m)  kubelet                                        Node aks-nodepool1-35379194-vmss000000 status is now: NodeHasNoDiskPressure\n  Normal   Starting                                          35m                kubelet                                        Starting kubelet.\n  Normal   NodeReady                                         35m                kubelet                                        Node aks-nodepool1-35379194-vmss000000 status is now: NodeReady\n  Normal   NoTerminateScheduled                              26m                custom-scheduledevents-plugin-monitor          Node condition TerminateScheduled is now: Unknown, reason: NoTerminateScheduled\n  Normal   NoPreemptScheduled                                26m                custom-scheduledevents-preempt-plugin-monitor  Node condition PreemptScheduled is now: False, reason: NoPreemptScheduled\n  Normal   NoPreemptScheduled                                26m                custom-scheduledevents-preempt-plugin-monitor  Node condition PreemptScheduled is now: Unknown, reason: NoPreemptScheduled\n  Normal   NoRedeployScheduled                               26m                custom-scheduledevents-plugin-monitor          Node condition RedeployScheduled is now: Unknown, reason: NoRedeployScheduled\n  Normal   NoRebootScheduled                                 26m                custom-scheduledevents-plugin-monitor          Node condition RebootScheduled is now: Unknown, reason: NoRebootScheduled\n  Normal   NoFreezeScheduled                                 26m                custom-scheduledevents-plugin-monitor          Node condition FreezeScheduled is now: Unknown, reason: NoFreezeScheduled\n  Normal   NoTerminateScheduled                              26m                custom-scheduledevents-plugin-monitor          Node condition TerminateScheduled is now: False, reason: NoTerminateScheduled\n  Normal   NoRedeployScheduled                               26m                custom-scheduledevents-plugin-monitor          Node condition RedeployScheduled is now: False, reason: NoRedeployScheduled\n  Normal   NoRebootScheduled                                 26m                custom-scheduledevents-plugin-monitor          Node condition RebootScheduled is now: False, reason: NoRebootScheduled\n  Normal   NoFreezeScheduled                                 26m                custom-scheduledevents-plugin-monitor          Node condition FreezeScheduled is now: False, reason: NoFreezeScheduled\n"
Apr  7 07:00:23.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-6854 describe namespace kubectl-6854'
Apr  7 07:00:23.650: INFO: stderr: ""
Apr  7 07:00:23.650: INFO: stdout: "Name:         kubectl-6854\nLabels:       e2e-framework=kubectl\n              e2e-run=f7f4912d-3f9a-4bad-b707-d31154960389\n              kubernetes.io/metadata.name=kubectl-6854\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:23.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6854" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":346,"completed":169,"skipped":3097,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:23.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:26.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6656" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":346,"completed":170,"skipped":3113,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:26.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
Apr  7 07:00:26.684: INFO: Creating simple deployment test-deployment-xppwq
Apr  7 07:00:26.708: INFO: deployment "test-deployment-xppwq" doesn't have the required revision set
STEP: Getting /status
Apr  7 07:00:28.747: INFO: Deployment test-deployment-xppwq has Conditions: [{Available True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xppwq-764bc7c4b7" has successfully progressed.}]
STEP: updating Deployment Status
Apr  7 07:00:28.762: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 7, 0, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 7, 0, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.April, 7, 7, 0, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.April, 7, 7, 0, 26, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-xppwq-764bc7c4b7\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Apr  7 07:00:28.764: INFO: Observed &Deployment event: ADDED
Apr  7 07:00:28.764: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xppwq-764bc7c4b7"}
Apr  7 07:00:28.764: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.764: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xppwq-764bc7c4b7"}
Apr  7 07:00:28.764: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr  7 07:00:28.765: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-xppwq-764bc7c4b7" is progressing.}
Apr  7 07:00:28.765: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xppwq-764bc7c4b7" has successfully progressed.}
Apr  7 07:00:28.765: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr  7 07:00:28.765: INFO: Observed Deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xppwq-764bc7c4b7" has successfully progressed.}
Apr  7 07:00:28.765: INFO: Found Deployment test-deployment-xppwq in namespace deployment-6266 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr  7 07:00:28.765: INFO: Deployment test-deployment-xppwq has an updated status
STEP: patching the Statefulset Status
Apr  7 07:00:28.765: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr  7 07:00:28.772: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Apr  7 07:00:28.774: INFO: Observed &Deployment event: ADDED
Apr  7 07:00:28.774: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xppwq-764bc7c4b7"}
Apr  7 07:00:28.774: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xppwq-764bc7c4b7"}
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr  7 07:00:28.775: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:26 +0000 UTC 2022-04-07 07:00:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-xppwq-764bc7c4b7" is progressing.}
Apr  7 07:00:28.775: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr  7 07:00:28.775: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xppwq-764bc7c4b7" has successfully progressed.}
Apr  7 07:00:28.775: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.776: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr  7 07:00:28.776: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-07 07:00:27 +0000 UTC 2022-04-07 07:00:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xppwq-764bc7c4b7" has successfully progressed.}
Apr  7 07:00:28.776: INFO: Observed deployment test-deployment-xppwq in namespace deployment-6266 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr  7 07:00:28.776: INFO: Observed &Deployment event: MODIFIED
Apr  7 07:00:28.776: INFO: Found deployment test-deployment-xppwq in namespace deployment-6266 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr  7 07:00:28.776: INFO: Deployment test-deployment-xppwq has a patched status
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 07:00:28.780: INFO: Deployment "test-deployment-xppwq":
&Deployment{ObjectMeta:{test-deployment-xppwq  deployment-6266  6fa6473c-e46e-4ccc-bab3-1118b4c4b1e7 21554 1 2022-04-07 07:00:26 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-04-07 07:00:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2022-04-07 07:00:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051de338 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 07:00:28.788: INFO: New ReplicaSet "test-deployment-xppwq-764bc7c4b7" of Deployment "test-deployment-xppwq":
&ReplicaSet{ObjectMeta:{test-deployment-xppwq-764bc7c4b7  deployment-6266  f2c6e36d-156f-47f4-9336-e7f1bbcebf60 21544 1 2022-04-07 07:00:26 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-xppwq 6fa6473c-e46e-4ccc-bab3-1118b4c4b1e7 0xc0051de6e0 0xc0051de6e1}] []  [{kube-controller-manager Update apps/v1 2022-04-07 07:00:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6fa6473c-e46e-4ccc-bab3-1118b4c4b1e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:00:27 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 764bc7c4b7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051de788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:00:28.804: INFO: Pod "test-deployment-xppwq-764bc7c4b7-cpzhx" is available:
&Pod{ObjectMeta:{test-deployment-xppwq-764bc7c4b7-cpzhx test-deployment-xppwq-764bc7c4b7- deployment-6266  357f8ec1-001b-415e-818a-67e87689664c 21543 0 2022-04-07 07:00:26 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [{apps/v1 ReplicaSet test-deployment-xppwq-764bc7c4b7 f2c6e36d-156f-47f4-9336-e7f1bbcebf60 0xc0051deb10 0xc0051deb11}] []  [{kube-controller-manager Update v1 2022-04-07 07:00:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2c6e36d-156f-47f4-9336-e7f1bbcebf60\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 07:00:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8fjlr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fjlr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:00:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:00:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:00:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.27,StartTime:2022-04-07 07:00:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 07:00:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ebd3d14029524a31ff82d6ac1373e44e727d3ad9fe6b15d6914cfd87b7b79cb8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:28.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6266" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":346,"completed":171,"skipped":3117,"failed":0}
SSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:28.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr  7 07:00:28.932: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr  7 07:00:28.937: INFO: starting watch
STEP: patching
STEP: updating
Apr  7 07:00:28.956: INFO: waiting for watch events with expected annotations
Apr  7 07:00:28.956: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:29.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-6834" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":346,"completed":172,"skipped":3122,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:29.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:00:29.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728" in namespace "downward-api-8799" to be "Succeeded or Failed"
Apr  7 07:00:29.185: INFO: Pod "downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728": Phase="Pending", Reason="", readiness=false. Elapsed: 8.43314ms
Apr  7 07:00:31.202: INFO: Pod "downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025277461s
STEP: Saw pod success
Apr  7 07:00:31.202: INFO: Pod "downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728" satisfied condition "Succeeded or Failed"
Apr  7 07:00:31.209: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728 container client-container: <nil>
STEP: delete the pod
Apr  7 07:00:31.245: INFO: Waiting for pod downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728 to disappear
Apr  7 07:00:31.252: INFO: Pod downwardapi-volume-80dd286e-e9ce-478b-93bf-7062416e2728 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:31.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8799" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":173,"skipped":3128,"failed":0}
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:31.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Apr  7 07:00:31.392: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:00:33.405: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr  7 07:00:33.436: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:00:35.447: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Apr  7 07:00:35.477: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 07:00:35.484: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 07:00:37.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 07:00:37.504: INFO: Pod pod-with-prestop-http-hook still exists
Apr  7 07:00:39.485: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  7 07:00:39.500: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:39.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8494" for this suite.

• [SLOW TEST:8.295 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":346,"completed":174,"skipped":3130,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:39.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4083" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":175,"skipped":3146,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:39.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Apr  7 07:00:41.909: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:48.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7452" for this suite.

• [SLOW TEST:8.478 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":346,"completed":176,"skipped":3147,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:48.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-2380f339-86d5-4387-83e8-67fc38d1a8ce
STEP: Creating configMap with name cm-test-opt-upd-cd02a9d2-f690-4037-b111-a596ce99632e
STEP: Creating the pod
Apr  7 07:00:48.401: INFO: The status of Pod pod-configmaps-64ef331e-bcff-4494-9209-8679cbb76665 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:00:50.420: INFO: The status of Pod pod-configmaps-64ef331e-bcff-4494-9209-8679cbb76665 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-2380f339-86d5-4387-83e8-67fc38d1a8ce
STEP: Updating configmap cm-test-opt-upd-cd02a9d2-f690-4037-b111-a596ce99632e
STEP: Creating configMap with name cm-test-opt-create-2e76f831-80b6-4e13-a84f-2f763859448e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:52.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4140" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":177,"skipped":3167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:52.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-406a07e8-2b50-4452-9d9d-dc0eb217b667
STEP: Creating a pod to test consume configMaps
Apr  7 07:00:52.713: INFO: Waiting up to 5m0s for pod "pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496" in namespace "configmap-793" to be "Succeeded or Failed"
Apr  7 07:00:52.722: INFO: Pod "pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496": Phase="Pending", Reason="", readiness=false. Elapsed: 8.675057ms
Apr  7 07:00:54.735: INFO: Pod "pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021935719s
STEP: Saw pod success
Apr  7 07:00:54.735: INFO: Pod "pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496" satisfied condition "Succeeded or Failed"
Apr  7 07:00:54.744: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:00:54.793: INFO: Waiting for pod pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496 to disappear
Apr  7 07:00:54.802: INFO: Pod pod-configmaps-452683aa-b9b4-4bfc-9a8e-2043bb56a496 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:00:54.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-793" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":178,"skipped":3203,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:00:54.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 07:00:54.984: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 07:00:54.984: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 07:00:56.010: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 07:00:56.010: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  7 07:00:56.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:00:56.051: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:00:57.070: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:00:57.070: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:00:58.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 07:00:58.068: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8575, will wait for the garbage collector to delete the pods
Apr  7 07:00:58.159: INFO: Deleting DaemonSet.extensions daemon-set took: 12.568205ms
Apr  7 07:00:58.260: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.005069ms
Apr  7 07:01:00.774: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 07:01:00.774: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 07:01:00.779: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22122"},"items":null}

Apr  7 07:01:00.788: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22122"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:00.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8575" for this suite.

• [SLOW TEST:6.000 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":346,"completed":179,"skipped":3231,"failed":0}
SS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:00.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Apr  7 07:01:00.923: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  7 07:01:05.937: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Apr  7 07:01:05.944: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Apr  7 07:01:05.964: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Apr  7 07:01:05.966: INFO: Observed &ReplicaSet event: ADDED
Apr  7 07:01:05.967: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.967: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.967: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.967: INFO: Found replicaset test-rs in namespace replicaset-9119 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr  7 07:01:05.967: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Apr  7 07:01:05.967: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr  7 07:01:05.978: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Apr  7 07:01:05.980: INFO: Observed &ReplicaSet event: ADDED
Apr  7 07:01:05.980: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.980: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.980: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.980: INFO: Observed replicaset test-rs in namespace replicaset-9119 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr  7 07:01:05.980: INFO: Observed &ReplicaSet event: MODIFIED
Apr  7 07:01:05.980: INFO: Found replicaset test-rs in namespace replicaset-9119 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr  7 07:01:05.980: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:05.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9119" for this suite.

• [SLOW TEST:5.178 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":346,"completed":180,"skipped":3233,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:05.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Service
STEP: watching for the Service to be added
Apr  7 07:01:06.128: INFO: Found Service test-service-xwws6 in namespace services-6481 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr  7 07:01:06.128: INFO: Service test-service-xwws6 created
STEP: Getting /status
Apr  7 07:01:06.135: INFO: Service test-service-xwws6 has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Apr  7 07:01:06.145: INFO: observed Service test-service-xwws6 in namespace services-6481 with annotations: map[] & LoadBalancer: {[]}
Apr  7 07:01:06.145: INFO: Found Service test-service-xwws6 in namespace services-6481 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr  7 07:01:06.145: INFO: Service test-service-xwws6 has service status patched
STEP: updating the ServiceStatus
Apr  7 07:01:06.161: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Apr  7 07:01:06.163: INFO: Observed Service test-service-xwws6 in namespace services-6481 with annotations: map[] & Conditions: {[]}
Apr  7 07:01:06.163: INFO: Observed event: &Service{ObjectMeta:{test-service-xwws6  services-6481  5029914d-2629-40aa-86a1-ef59799586b3 22176 0 2022-04-07 07:01:06 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-04-07 07:01:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-04-07 07:01:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.0.86.205,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.0.86.205],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr  7 07:01:06.163: INFO: Found Service test-service-xwws6 in namespace services-6481 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr  7 07:01:06.163: INFO: Service test-service-xwws6 has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Apr  7 07:01:06.178: INFO: observed Service test-service-xwws6 in namespace services-6481 with labels: map[test-service-static:true]
Apr  7 07:01:06.178: INFO: observed Service test-service-xwws6 in namespace services-6481 with labels: map[test-service-static:true]
Apr  7 07:01:06.178: INFO: observed Service test-service-xwws6 in namespace services-6481 with labels: map[test-service-static:true]
Apr  7 07:01:06.178: INFO: Found Service test-service-xwws6 in namespace services-6481 with labels: map[test-service:patched test-service-static:true]
Apr  7 07:01:06.178: INFO: Service test-service-xwws6 patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Apr  7 07:01:06.210: INFO: Observed event: ADDED
Apr  7 07:01:06.210: INFO: Observed event: MODIFIED
Apr  7 07:01:06.210: INFO: Observed event: MODIFIED
Apr  7 07:01:06.210: INFO: Observed event: MODIFIED
Apr  7 07:01:06.210: INFO: Found Service test-service-xwws6 in namespace services-6481 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr  7 07:01:06.210: INFO: Service test-service-xwws6 deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:06.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6481" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":346,"completed":181,"skipped":3264,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:06.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr  7 07:01:06.301: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:08.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9023" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":346,"completed":182,"skipped":3277,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:08.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:08.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2955" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":346,"completed":183,"skipped":3284,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:08.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-5287
STEP: creating service affinity-nodeport in namespace services-5287
STEP: creating replication controller affinity-nodeport in namespace services-5287
I0407 07:01:08.990468      23 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5287, replica count: 3
I0407 07:01:12.041813      23 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:01:12.064: INFO: Creating new exec pod
Apr  7 07:01:15.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5287 exec execpod-affinityb2mv6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr  7 07:01:15.326: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr  7 07:01:15.326: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:01:15.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5287 exec execpod-affinityb2mv6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.233.190 80'
Apr  7 07:01:15.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.233.190 80\nConnection to 10.0.233.190 80 port [tcp/http] succeeded!\n"
Apr  7 07:01:15.538: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:01:15.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5287 exec execpod-affinityb2mv6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.4 31963'
Apr  7 07:01:15.745: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.4 31963\nConnection to 10.240.0.4 31963 port [tcp/*] succeeded!\n"
Apr  7 07:01:15.745: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:01:15.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5287 exec execpod-affinityb2mv6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.5 31963'
Apr  7 07:01:15.953: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.5 31963\nConnection to 10.240.0.5 31963 port [tcp/*] succeeded!\n"
Apr  7 07:01:15.953: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:01:15.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5287 exec execpod-affinityb2mv6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.240.0.4:31963/ ; done'
Apr  7 07:01:16.247: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.240.0.4:31963/\n"
Apr  7 07:01:16.247: INFO: stdout: "\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g\naffinity-nodeport-7856g"
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Received response from host: affinity-nodeport-7856g
Apr  7 07:01:16.247: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5287, will wait for the garbage collector to delete the pods
Apr  7 07:01:16.337: INFO: Deleting ReplicationController affinity-nodeport took: 9.645418ms
Apr  7 07:01:16.438: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.16058ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:18.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5287" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.350 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":184,"skipped":3383,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:18.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:46.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8648" for this suite.

• [SLOW TEST:28.222 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":346,"completed":185,"skipped":3396,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:46.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:01:46.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:49.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3087" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":346,"completed":186,"skipped":3404,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:49.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr  7 07:01:52.585: INFO: Successfully updated pod "adopt-release-9r4jd"
STEP: Checking that the Job readopts the Pod
Apr  7 07:01:52.585: INFO: Waiting up to 15m0s for pod "adopt-release-9r4jd" in namespace "job-8774" to be "adopted"
Apr  7 07:01:52.591: INFO: Pod "adopt-release-9r4jd": Phase="Running", Reason="", readiness=true. Elapsed: 6.746431ms
Apr  7 07:01:54.607: INFO: Pod "adopt-release-9r4jd": Phase="Running", Reason="", readiness=true. Elapsed: 2.021844398s
Apr  7 07:01:54.607: INFO: Pod "adopt-release-9r4jd" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr  7 07:01:55.132: INFO: Successfully updated pod "adopt-release-9r4jd"
STEP: Checking that the Job releases the Pod
Apr  7 07:01:55.132: INFO: Waiting up to 15m0s for pod "adopt-release-9r4jd" in namespace "job-8774" to be "released"
Apr  7 07:01:55.139: INFO: Pod "adopt-release-9r4jd": Phase="Running", Reason="", readiness=true. Elapsed: 7.378572ms
Apr  7 07:01:57.152: INFO: Pod "adopt-release-9r4jd": Phase="Running", Reason="", readiness=true. Elapsed: 2.020003358s
Apr  7 07:01:57.152: INFO: Pod "adopt-release-9r4jd" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:01:57.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8774" for this suite.

• [SLOW TEST:7.239 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":346,"completed":187,"skipped":3437,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:01:57.170: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Apr  7 07:02:03.375: INFO: 80 pods remaining
Apr  7 07:02:03.375: INFO: 80 pods has nil DeletionTimestamp
Apr  7 07:02:03.375: INFO: 
Apr  7 07:02:04.393: INFO: 70 pods remaining
Apr  7 07:02:04.393: INFO: 69 pods has nil DeletionTimestamp
Apr  7 07:02:04.393: INFO: 
Apr  7 07:02:05.361: INFO: 60 pods remaining
Apr  7 07:02:05.361: INFO: 60 pods has nil DeletionTimestamp
Apr  7 07:02:05.361: INFO: 
Apr  7 07:02:06.359: INFO: 40 pods remaining
Apr  7 07:02:06.359: INFO: 40 pods has nil DeletionTimestamp
Apr  7 07:02:06.359: INFO: 
Apr  7 07:02:07.357: INFO: 31 pods remaining
Apr  7 07:02:07.357: INFO: 30 pods has nil DeletionTimestamp
Apr  7 07:02:07.357: INFO: 
Apr  7 07:02:08.353: INFO: 20 pods remaining
Apr  7 07:02:08.353: INFO: 20 pods has nil DeletionTimestamp
Apr  7 07:02:08.353: INFO: 
STEP: Gathering metrics
Apr  7 07:02:09.413: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0407 07:02:09.413726      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:09.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5231" for this suite.

• [SLOW TEST:12.262 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":346,"completed":188,"skipped":3558,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:09.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-b6c77201-b052-4872-b65f-b21b166b15ac
STEP: Creating a pod to test consume secrets
Apr  7 07:02:09.585: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2" in namespace "projected-827" to be "Succeeded or Failed"
Apr  7 07:02:09.594: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.747659ms
Apr  7 07:02:11.604: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018948439s
Apr  7 07:02:13.617: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031973342s
Apr  7 07:02:15.649: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064121669s
Apr  7 07:02:17.660: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.074861726s
Apr  7 07:02:19.673: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.08764514s
Apr  7 07:02:21.686: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.100477395s
Apr  7 07:02:23.705: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.119515534s
STEP: Saw pod success
Apr  7 07:02:23.705: INFO: Pod "pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2" satisfied condition "Succeeded or Failed"
Apr  7 07:02:23.717: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:02:23.765: INFO: Waiting for pod pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2 to disappear
Apr  7 07:02:23.773: INFO: Pod pod-projected-secrets-5e883f9f-307a-496f-af0d-8546c062e3f2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:23.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-827" for this suite.

• [SLOW TEST:14.356 seconds]
[sig-storage] Projected secret
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":189,"skipped":3620,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:23.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Apr  7 07:02:23.900: INFO: observed Pod pod-test in namespace pods-9305 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr  7 07:02:23.906: INFO: observed Pod pod-test in namespace pods-9305 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC  }]
Apr  7 07:02:23.925: INFO: observed Pod pod-test in namespace pods-9305 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC  }]
Apr  7 07:02:25.404: INFO: Found Pod pod-test in namespace pods-9305 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:02:23 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
Apr  7 07:02:25.426: INFO: observed event type ADDED
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Apr  7 07:02:25.476: INFO: observed event type ADDED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:25.476: INFO: observed event type MODIFIED
Apr  7 07:02:27.409: INFO: observed event type MODIFIED
Apr  7 07:02:28.414: INFO: observed event type MODIFIED
Apr  7 07:02:28.429: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:28.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9305" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":346,"completed":190,"skipped":3674,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:28.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:44.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9840" for this suite.

• [SLOW TEST:16.392 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":346,"completed":191,"skipped":3675,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:44.849: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1537
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Apr  7 07:02:44.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-785 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Apr  7 07:02:45.165: INFO: stderr: ""
Apr  7 07:02:45.165: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1541
Apr  7 07:02:45.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-785 delete pods e2e-test-httpd-pod'
Apr  7 07:02:47.492: INFO: stderr: ""
Apr  7 07:02:47.492: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:47.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-785" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":346,"completed":192,"skipped":3707,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:47.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-82fe2c0a-f6a9-4e11-8e3e-c39b100f3e44
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:49.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2576" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":193,"skipped":3721,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:49.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:49.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7949" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":346,"completed":194,"skipped":3768,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:49.873: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr  7 07:02:49.991: INFO: Waiting up to 5m0s for pod "downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2" in namespace "downward-api-7451" to be "Succeeded or Failed"
Apr  7 07:02:50.003: INFO: Pod "downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.500799ms
Apr  7 07:02:52.020: INFO: Pod "downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028961643s
STEP: Saw pod success
Apr  7 07:02:52.020: INFO: Pod "downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2" satisfied condition "Succeeded or Failed"
Apr  7 07:02:52.030: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2 container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:02:52.077: INFO: Waiting for pod downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2 to disappear
Apr  7 07:02:52.085: INFO: Pod downward-api-49988b14-ac7d-4d3a-943e-51c4e0977ca2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:52.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7451" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":346,"completed":195,"skipped":3787,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:52.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:02:52.244: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8" in namespace "projected-5552" to be "Succeeded or Failed"
Apr  7 07:02:52.252: INFO: Pod "downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.610931ms
Apr  7 07:02:54.266: INFO: Pod "downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021902759s
STEP: Saw pod success
Apr  7 07:02:54.266: INFO: Pod "downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8" satisfied condition "Succeeded or Failed"
Apr  7 07:02:54.273: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8 container client-container: <nil>
STEP: delete the pod
Apr  7 07:02:54.324: INFO: Waiting for pod downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8 to disappear
Apr  7 07:02:54.331: INFO: Pod downwardapi-volume-4dfd0675-1196-48c7-888f-71b641f605c8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:54.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5552" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":196,"skipped":3795,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:54.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:02:56.503: INFO: Deleting pod "var-expansion-572249f6-bfa2-4493-bf87-046f6a059093" in namespace "var-expansion-3176"
Apr  7 07:02:56.525: INFO: Wait up to 5m0s for pod "var-expansion-572249f6-bfa2-4493-bf87-046f6a059093" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:02:58.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3176" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":346,"completed":197,"skipped":3834,"failed":0}
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:02:58.566: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-8949/configmap-test-132c28c0-4545-4147-9099-fda7812885ae
STEP: Creating a pod to test consume configMaps
Apr  7 07:02:58.685: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72" in namespace "configmap-8949" to be "Succeeded or Failed"
Apr  7 07:02:58.695: INFO: Pod "pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72": Phase="Pending", Reason="", readiness=false. Elapsed: 9.53235ms
Apr  7 07:03:00.711: INFO: Pod "pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026033282s
STEP: Saw pod success
Apr  7 07:03:00.712: INFO: Pod "pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72" satisfied condition "Succeeded or Failed"
Apr  7 07:03:00.720: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72 container env-test: <nil>
STEP: delete the pod
Apr  7 07:03:00.765: INFO: Waiting for pod pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72 to disappear
Apr  7 07:03:00.772: INFO: Pod pod-configmaps-d7ba9cbd-4fd1-40ed-beea-f18db5faac72 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:03:00.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8949" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":346,"completed":198,"skipped":3838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:03:00.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:03:00.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9302" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":346,"completed":199,"skipped":3885,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:03:00.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-7cd448ba-537b-452e-a3a6-bae09fdb05fa
STEP: Creating a pod to test consume secrets
Apr  7 07:03:01.000: INFO: Waiting up to 5m0s for pod "pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243" in namespace "secrets-7104" to be "Succeeded or Failed"
Apr  7 07:03:01.009: INFO: Pod "pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243": Phase="Pending", Reason="", readiness=false. Elapsed: 8.425486ms
Apr  7 07:03:03.026: INFO: Pod "pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026109187s
STEP: Saw pod success
Apr  7 07:03:03.026: INFO: Pod "pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243" satisfied condition "Succeeded or Failed"
Apr  7 07:03:03.039: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:03:03.136: INFO: Waiting for pod pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243 to disappear
Apr  7 07:03:03.145: INFO: Pod pod-secrets-24576976-a45a-4edd-b73b-bbcbb4f0c243 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:03:03.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7104" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":200,"skipped":3902,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:03:03.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-c0c38c69-5f6e-4f5a-8278-49cd12070e6b
STEP: Creating the pod
Apr  7 07:03:03.345: INFO: The status of Pod pod-configmaps-8c412b26-50e9-49b4-85aa-42428f935eda is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:03:05.375: INFO: The status of Pod pod-configmaps-8c412b26-50e9-49b4-85aa-42428f935eda is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-c0c38c69-5f6e-4f5a-8278-49cd12070e6b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:03:07.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5472" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":201,"skipped":3912,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:03:07.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with configMap that has name projected-configmap-test-upd-798b3391-3d24-40dc-864c-db86d366de8f
STEP: Creating the pod
Apr  7 07:03:07.616: INFO: The status of Pod pod-projected-configmaps-bdd16e21-df11-42ea-a750-9a560d6fca09 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:03:09.629: INFO: The status of Pod pod-projected-configmaps-bdd16e21-df11-42ea-a750-9a560d6fca09 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-798b3391-3d24-40dc-864c-db86d366de8f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:04:26.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6889" for this suite.

• [SLOW TEST:79.014 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":202,"skipped":3916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:04:26.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:04:26.612: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b" in namespace "projected-6819" to be "Succeeded or Failed"
Apr  7 07:04:26.622: INFO: Pod "downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.4041ms
Apr  7 07:04:28.633: INFO: Pod "downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020816751s
STEP: Saw pod success
Apr  7 07:04:28.633: INFO: Pod "downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b" satisfied condition "Succeeded or Failed"
Apr  7 07:04:28.641: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b container client-container: <nil>
STEP: delete the pod
Apr  7 07:04:28.686: INFO: Waiting for pod downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b to disappear
Apr  7 07:04:28.693: INFO: Pod downwardapi-volume-0e9f8c09-e382-48df-ac0b-09785896470b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:04:28.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6819" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":203,"skipped":3959,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:04:28.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:04:28.824: INFO: The status of Pod busybox-host-aliasesd001a34d-52ab-480e-aeff-71041f721b84 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:04:30.840: INFO: The status of Pod busybox-host-aliasesd001a34d-52ab-480e-aeff-71041f721b84 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:04:30.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6014" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":204,"skipped":3969,"failed":0}
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:04:30.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr  7 07:04:31.006: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 07:05:31.068: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:05:31.073: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:488
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Apr  7 07:05:33.269: INFO: found a healthy node: aks-nodepool1-35379194-vmss000001
[It] runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:05:43.433: INFO: pods created so far: [1 1 1]
Apr  7 07:05:43.433: INFO: length of pods created so far: 3
Apr  7 07:05:45.460: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:05:52.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9983" for this suite.
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:462
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:05:52.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4351" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:81.721 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:451
    runs ReplicaSets to verify preemption running path [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":346,"completed":205,"skipped":3979,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:05:52.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:05:52.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-2985
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:05:56.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-9393" for this suite.
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:05:56.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2985" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":346,"completed":206,"skipped":3987,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:05:57.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr  7 07:05:57.127: INFO: The status of Pod pod-update-1b9ed7ad-cbfc-4b47-a23c-78f8d4781b69 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:05:59.136: INFO: The status of Pod pod-update-1b9ed7ad-cbfc-4b47-a23c-78f8d4781b69 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  7 07:05:59.681: INFO: Successfully updated pod "pod-update-1b9ed7ad-cbfc-4b47-a23c-78f8d4781b69"
STEP: verifying the updated pod is in kubernetes
Apr  7 07:05:59.703: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:05:59.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2666" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":346,"completed":207,"skipped":4006,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:05:59.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:06:00.461: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:06:03.512: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr  7 07:06:03.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:06:03.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2708" for this suite.
STEP: Destroying namespace "webhook-2708-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":346,"completed":208,"skipped":4022,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:06:03.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr  7 07:06:03.835: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 07:06:03.846: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 07:06:03.852: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000000 before test
Apr  7 07:06:03.876: INFO: azure-ip-masq-agent-vjb96 from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 07:06:03.876: INFO: cloud-node-manager-tcnjx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 07:06:03.876: INFO: coredns-748769b948-gz9rk from kube-system started at 2022-04-07 06:25:16 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container coredns ready: true, restart count 0
Apr  7 07:06:03.876: INFO: coredns-748769b948-j9bgf from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container coredns ready: true, restart count 0
Apr  7 07:06:03.876: INFO: coredns-autoscaler-6fb889cdfc-w5qm4 from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container autoscaler ready: true, restart count 0
Apr  7 07:06:03.876: INFO: csi-azuredisk-node-qmwkm from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:06:03.876: INFO: csi-azurefile-node-swhhx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:06:03.876: INFO: konnectivity-agent-76fcfc46bd-9kq4v from kube-system started at 2022-04-07 06:25:20 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 07:06:03.876: INFO: konnectivity-agent-76fcfc46bd-chsbh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 07:06:03.876: INFO: kube-proxy-spxrs from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 07:06:03.876: INFO: metrics-server-7d59848cc6-4skgh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 07:06:03.876: INFO: metrics-server-7d59848cc6-wrc2c from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 07:06:03.876: INFO: pod-update-1b9ed7ad-cbfc-4b47-a23c-78f8d4781b69 from pods-2666 started at 2022-04-07 07:05:57 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container nginx ready: true, restart count 0
Apr  7 07:06:03.876: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:06:03.876: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  7 07:06:03.876: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000001 before test
Apr  7 07:06:03.888: INFO: azure-ip-masq-agent-k7wwg from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 07:06:03.888: INFO: cloud-node-manager-4xrsl from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 07:06:03.888: INFO: csi-azuredisk-node-6g62x from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:06:03.888: INFO: csi-azurefile-node-8z4x6 from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:06:03.888: INFO: kube-proxy-9vz4m from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 07:06:03.888: INFO: sonobuoy from sonobuoy started at 2022-04-07 06:29:06 +0000 UTC (1 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 07:06:03.888: INFO: sonobuoy-e2e-job-6dc4960ffa6e4d5e from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container e2e ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:06:03.888: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-c22tn from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:06:03.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:06:03.888: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ecc32de0-1c9f-4d41-8427-d8b71f00d669 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.240.0.5 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-ecc32de0-1c9f-4d41-8427-d8b71f00d669 off the node aks-nodepool1-35379194-vmss000001
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ecc32de0-1c9f-4d41-8427-d8b71f00d669
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:11:08.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4854" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:304.491 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":346,"completed":209,"skipped":4029,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:11:08.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-865bc3f4-4185-4aa9-b73c-3e9ea0cb4027
STEP: Creating a pod to test consume configMaps
Apr  7 07:11:08.305: INFO: Waiting up to 5m0s for pod "pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894" in namespace "configmap-2596" to be "Succeeded or Failed"
Apr  7 07:11:08.312: INFO: Pod "pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894": Phase="Pending", Reason="", readiness=false. Elapsed: 7.275065ms
Apr  7 07:11:10.332: INFO: Pod "pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026710378s
STEP: Saw pod success
Apr  7 07:11:10.332: INFO: Pod "pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894" satisfied condition "Succeeded or Failed"
Apr  7 07:11:10.340: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:11:10.378: INFO: Waiting for pod pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894 to disappear
Apr  7 07:11:10.385: INFO: Pod pod-configmaps-95fa0939-b70a-47b3-ab52-5cd497c96894 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:11:10.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2596" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":210,"skipped":4030,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:11:10.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a collection of services
Apr  7 07:11:10.501: INFO: Creating e2e-svc-a-q87fk
Apr  7 07:11:10.527: INFO: Creating e2e-svc-b-bw4mg
Apr  7 07:11:10.551: INFO: Creating e2e-svc-c-x9m9x
STEP: deleting service collection
Apr  7 07:11:10.661: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:11:10.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3740" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":346,"completed":211,"skipped":4033,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:11:10.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:11:10.774: INFO: Creating simple deployment test-new-deployment
Apr  7 07:11:10.795: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 07:11:12.884: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-9948  a33d2fcc-e9e1-4e24-b401-338a0bde4951 26590 3 2022-04-07 07:11:10 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-04-07 07:11:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:11:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005424d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-07 07:11:11 +0000 UTC,LastTransitionTime:2022-04-07 07:11:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-5d9fdcc779" has successfully progressed.,LastUpdateTime:2022-04-07 07:11:11 +0000 UTC,LastTransitionTime:2022-04-07 07:11:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 07:11:12.896: INFO: New ReplicaSet "test-new-deployment-5d9fdcc779" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-5d9fdcc779  deployment-9948  0999a13d-aac7-4495-a86c-bb3ed2865621 26591 2 2022-04-07 07:11:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment a33d2fcc-e9e1-4e24-b401-338a0bde4951 0xc00514b9e7 0xc00514b9e8}] []  [{kube-controller-manager Update apps/v1 2022-04-07 07:11:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a33d2fcc-e9e1-4e24-b401-338a0bde4951\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:11:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00514bb88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:11:12.907: INFO: Pod "test-new-deployment-5d9fdcc779-l8hz7" is not available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-l8hz7 test-new-deployment-5d9fdcc779- deployment-9948  8ae401b2-bbeb-48fb-bca3-b977ebeff5a5 26594 0 2022-04-07 07:11:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 0999a13d-aac7-4495-a86c-bb3ed2865621 0xc0054e83e7 0xc0054e83e8}] []  [{kube-controller-manager Update v1 2022-04-07 07:11:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0999a13d-aac7-4495-a86c-bb3ed2865621\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9dk5g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9dk5g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:11:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 07:11:12.907: INFO: Pod "test-new-deployment-5d9fdcc779-tgqxx" is available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-tgqxx test-new-deployment-5d9fdcc779- deployment-9948  c282f5fb-2977-45f0-9abd-08d0b3eca32b 26582 0 2022-04-07 07:11:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 0999a13d-aac7-4495-a86c-bb3ed2865621 0xc0054e8540 0xc0054e8541}] []  [{kube-controller-manager Update v1 2022-04-07 07:11:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0999a13d-aac7-4495-a86c-bb3ed2865621\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 07:11:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.99\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rxjmj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rxjmj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:11:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:11:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:11:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:11:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.99,StartTime:2022-04-07 07:11:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 07:11:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://090ae6eda9cbc6e7677be4e2bf10f761c7090f90b59eaffa0de84e9181bd237d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:11:12.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9948" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":346,"completed":212,"skipped":4040,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:11:12.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-3534
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3534
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3534
Apr  7 07:11:13.077: INFO: Found 0 stateful pods, waiting for 1
Apr  7 07:11:23.088: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  7 07:11:23.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:11:23.330: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:11:23.330: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:11:23.330: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:11:23.339: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  7 07:11:33.368: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:11:33.368: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:11:33.409: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999996s
Apr  7 07:11:34.422: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99192372s
Apr  7 07:11:35.448: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978645309s
Apr  7 07:11:36.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.953098014s
Apr  7 07:11:37.472: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.94041204s
Apr  7 07:11:38.487: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.929436476s
Apr  7 07:11:39.502: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.914030433s
Apr  7 07:11:40.520: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.898747203s
Apr  7 07:11:41.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.88042208s
Apr  7 07:11:42.545: INFO: Verifying statefulset ss doesn't scale past 1 for another 867.088274ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3534
Apr  7 07:11:43.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:11:43.764: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:11:43.764: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:11:43.764: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:11:43.779: INFO: Found 1 stateful pods, waiting for 3
Apr  7 07:11:53.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:11:53.791: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:11:53.791: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  7 07:11:53.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:11:54.004: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:11:54.004: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:11:54.004: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:11:54.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:11:54.201: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:11:54.201: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:11:54.201: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:11:54.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:11:54.414: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:11:54.414: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:11:54.414: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:11:54.414: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:11:54.431: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  7 07:12:04.456: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:12:04.456: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:12:04.456: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:12:04.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999998s
Apr  7 07:12:05.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990726473s
Apr  7 07:12:06.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977656803s
Apr  7 07:12:07.521: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965379084s
Apr  7 07:12:08.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.953121466s
Apr  7 07:12:09.555: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939675372s
Apr  7 07:12:10.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919199229s
Apr  7 07:12:11.578: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.906582391s
Apr  7 07:12:12.602: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.896219898s
Apr  7 07:12:13.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 872.725661ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3534
Apr  7 07:12:14.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:12:14.868: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:12:14.868: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:12:14.868: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:12:14.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:12:15.059: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:12:15.060: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:12:15.060: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:12:15.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3534 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:12:15.270: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:12:15.270: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:12:15.270: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:12:15.270: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 07:12:25.318: INFO: Deleting all statefulset in ns statefulset-3534
Apr  7 07:12:25.342: INFO: Scaling statefulset ss to 0
Apr  7 07:12:25.391: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:12:25.401: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:12:25.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3534" for this suite.

• [SLOW TEST:72.532 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":346,"completed":213,"skipped":4061,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:12:25.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:12:28.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-910" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":346,"completed":214,"skipped":4104,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:12:28.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Apr  7 07:12:28.397: INFO: namespace kubectl-5326
Apr  7 07:12:28.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5326 create -f -'
Apr  7 07:12:28.562: INFO: stderr: ""
Apr  7 07:12:28.562: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr  7 07:12:29.572: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:12:29.572: INFO: Found 0 / 1
Apr  7 07:12:30.573: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:12:30.573: INFO: Found 1 / 1
Apr  7 07:12:30.573: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  7 07:12:30.582: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:12:30.582: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 07:12:30.582: INFO: wait on agnhost-primary startup in kubectl-5326 
Apr  7 07:12:30.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5326 logs agnhost-primary-wb77g agnhost-primary'
Apr  7 07:12:30.675: INFO: stderr: ""
Apr  7 07:12:30.675: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr  7 07:12:30.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5326 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr  7 07:12:30.810: INFO: stderr: ""
Apr  7 07:12:30.810: INFO: stdout: "service/rm2 exposed\n"
Apr  7 07:12:30.824: INFO: Service rm2 in namespace kubectl-5326 found.
STEP: exposing service
Apr  7 07:12:32.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5326 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr  7 07:12:32.960: INFO: stderr: ""
Apr  7 07:12:32.960: INFO: stdout: "service/rm3 exposed\n"
Apr  7 07:12:32.971: INFO: Service rm3 in namespace kubectl-5326 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:12:34.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5326" for this suite.

• [SLOW TEST:6.710 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
    should create services for rc  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":346,"completed":215,"skipped":4119,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:12:35.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:14:01.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6303" for this suite.

• [SLOW TEST:86.179 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":346,"completed":216,"skipped":4135,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:14:01.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Request ServerVersion
STEP: Confirm major version
Apr  7 07:14:01.277: INFO: Major version: 1
STEP: Confirm minor version
Apr  7 07:14:01.277: INFO: cleanMinorVersion: 23
Apr  7 07:14:01.277: INFO: Minor version: 23
[AfterEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:14:01.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7880" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":346,"completed":217,"skipped":4192,"failed":0}

------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:14:01.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3157, will wait for the garbage collector to delete the pods
Apr  7 07:14:03.577: INFO: Deleting Job.batch foo took: 22.537044ms
Apr  7 07:14:03.678: INFO: Terminating Job.batch foo pods took: 101.147781ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:14:35.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3157" for this suite.

• [SLOW TEST:34.398 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":346,"completed":218,"skipped":4192,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:14:35.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-4221
STEP: creating service affinity-clusterip in namespace services-4221
STEP: creating replication controller affinity-clusterip in namespace services-4221
I0407 07:14:35.841934      23 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-4221, replica count: 3
I0407 07:14:38.893782      23 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:14:38.925: INFO: Creating new exec pod
Apr  7 07:14:41.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4221 exec execpod-affinityc47qd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr  7 07:14:42.228: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr  7 07:14:42.228: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:14:42.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4221 exec execpod-affinityc47qd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.110.4 80'
Apr  7 07:14:42.410: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.110.4 80\nConnection to 10.0.110.4 80 port [tcp/http] succeeded!\n"
Apr  7 07:14:42.410: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:14:42.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4221 exec execpod-affinityc47qd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.110.4:80/ ; done'
Apr  7 07:14:42.705: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.110.4:80/\n"
Apr  7 07:14:42.705: INFO: stdout: "\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf\naffinity-clusterip-nk7pf"
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Received response from host: affinity-clusterip-nk7pf
Apr  7 07:14:42.705: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-4221, will wait for the garbage collector to delete the pods
Apr  7 07:14:42.795: INFO: Deleting ReplicationController affinity-clusterip took: 10.243556ms
Apr  7 07:14:42.896: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.006268ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:14:44.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4221" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.059 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":219,"skipped":4216,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:14:44.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Apr  7 07:14:44.895: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:14:46.912: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  7 07:14:47.965: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:14:49.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4243" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":346,"completed":220,"skipped":4225,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:14:49.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr  7 07:14:49.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:14:51.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:15:03.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-354" for this suite.

• [SLOW TEST:14.455 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":346,"completed":221,"skipped":4250,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:15:03.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:15:03.592: INFO: Creating ReplicaSet my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201
Apr  7 07:15:03.610: INFO: Pod name my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201: Found 0 pods out of 1
Apr  7 07:15:08.624: INFO: Pod name my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201: Found 1 pods out of 1
Apr  7 07:15:08.624: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201" is running
Apr  7 07:15:08.631: INFO: Pod "my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201-dwx9t" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:15:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:15:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:15:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:15:03 +0000 UTC Reason: Message:}])
Apr  7 07:15:08.631: INFO: Trying to dial the pod
Apr  7 07:15:13.679: INFO: Controller my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201: Got expected result from replica 1 [my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201-dwx9t]: "my-hostname-basic-d0b7b45f-bf1e-4158-a175-f0755ab51201-dwx9t", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:15:13.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7949" for this suite.

• [SLOW TEST:10.237 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":222,"skipped":4260,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:15:13.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr  7 07:15:13.824: INFO: PodSpec: initContainers in spec.initContainers
Apr  7 07:15:55.840: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c7e3c62e-bc24-4bb6-bbbb-f412fb7a100d", GenerateName:"", Namespace:"init-container-9819", SelfLink:"", UID:"a600b46a-e33b-4e30-bf56-1f3aaf1138de", ResourceVersion:"28492", Generation:0, CreationTimestamp:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"824423250"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539b350), Subresource:""}, v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.April, 7, 7, 15, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00539b380), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xn2z9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003363b40), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xn2z9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xn2z9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.6", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xn2z9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00530d500), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-nodepool1-35379194-vmss000001", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0031ca7e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00530d580)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00530d5a0)}, v1.Toleration{Key:"node.kubernetes.io/memory-pressure", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00530d5bc), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00530d5c0), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00420ef30), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.5", PodIP:"10.244.1.113", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.113"}}, StartTime:time.Date(2022, time.April, 7, 7, 15, 13, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0031ca8c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0031ca930)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://8359ff0202219b5c395e59293fc4e284cc0db65cff16f4b76b03a2e7a0c6ee2f", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003363bc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003363ba0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.6", ImageID:"", ContainerID:"", Started:(*bool)(0xc00530d66f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:15:55.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9819" for this suite.

• [SLOW TEST:42.170 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":346,"completed":223,"skipped":4289,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:15:55.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-1836
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  7 07:15:55.975: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr  7 07:15:56.027: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:15:58.043: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 07:16:00.046: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 07:16:02.038: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 07:16:04.040: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 07:16:06.042: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr  7 07:16:08.046: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr  7 07:16:08.062: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr  7 07:16:10.193: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Apr  7 07:16:10.193: INFO: Breadth first check of 10.244.0.215 on host 10.240.0.4...
Apr  7 07:16:10.204: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.115:9080/dial?request=hostname&protocol=udp&host=10.244.0.215&port=8081&tries=1'] Namespace:pod-network-test-1836 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:16:10.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:16:10.205: INFO: ExecWithOptions: Clientset creation
Apr  7 07:16:10.205: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-1836/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.115%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.215%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:16:10.335: INFO: Waiting for responses: map[]
Apr  7 07:16:10.335: INFO: reached 10.244.0.215 after 0/1 tries
Apr  7 07:16:10.335: INFO: Breadth first check of 10.244.1.114 on host 10.240.0.5...
Apr  7 07:16:10.343: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.115:9080/dial?request=hostname&protocol=udp&host=10.244.1.114&port=8081&tries=1'] Namespace:pod-network-test-1836 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:16:10.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:16:10.344: INFO: ExecWithOptions: Clientset creation
Apr  7 07:16:10.344: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/pod-network-test-1836/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.115%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.114%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:16:10.469: INFO: Waiting for responses: map[]
Apr  7 07:16:10.469: INFO: reached 10.244.1.114 after 0/1 tries
Apr  7 07:16:10.469: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:16:10.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1836" for this suite.

• [SLOW TEST:14.619 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":346,"completed":224,"skipped":4368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:16:10.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption is created
Apr  7 07:16:10.629: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:16:12.644: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:16:13.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1485" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":346,"completed":225,"skipped":4424,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:16:13.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-a7d7b44f-7769-4e5e-9372-276617036584
STEP: Creating a pod to test consume configMaps
Apr  7 07:16:13.925: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6" in namespace "projected-7206" to be "Succeeded or Failed"
Apr  7 07:16:13.938: INFO: Pod "pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.583904ms
Apr  7 07:16:15.951: INFO: Pod "pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025954627s
STEP: Saw pod success
Apr  7 07:16:15.951: INFO: Pod "pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6" satisfied condition "Succeeded or Failed"
Apr  7 07:16:15.959: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:16:15.998: INFO: Waiting for pod pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6 to disappear
Apr  7 07:16:16.005: INFO: Pod pod-projected-configmaps-0e64e0ba-a465-4f00-961a-e9361051c2b6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:16:16.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7206" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":226,"skipped":4440,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:16:16.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting the proxy server
Apr  7 07:16:16.208: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-2007 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:16:16.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2007" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":346,"completed":227,"skipped":4442,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:16:16.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-8102
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating stateful set ss in namespace statefulset-8102
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8102
Apr  7 07:16:16.395: INFO: Found 0 stateful pods, waiting for 1
Apr  7 07:16:26.414: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  7 07:16:26.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:16:26.670: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:16:26.670: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:16:26.670: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:16:26.679: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  7 07:16:36.690: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:16:36.690: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:16:36.734: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Apr  7 07:16:36.734: INFO: ss-0  aks-nodepool1-35379194-vmss000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:16 +0000 UTC  }]
Apr  7 07:16:36.734: INFO: 
Apr  7 07:16:36.734: INFO: StatefulSet ss has not reached scale 3, at 1
Apr  7 07:16:37.745: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993300411s
Apr  7 07:16:38.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981249881s
Apr  7 07:16:39.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967411937s
Apr  7 07:16:40.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955981746s
Apr  7 07:16:41.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945028386s
Apr  7 07:16:42.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.93413623s
Apr  7 07:16:43.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.919759355s
Apr  7 07:16:44.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.90825137s
Apr  7 07:16:45.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 897.696546ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8102
Apr  7 07:16:46.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:16:47.057: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:16:47.057: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:16:47.057: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:16:47.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:16:47.277: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  7 07:16:47.277: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:16:47.277: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:16:47.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:16:47.504: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  7 07:16:47.504: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:16:47.504: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  7 07:16:47.520: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:16:47.520: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:16:47.520: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  7 07:16:47.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:16:47.739: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:16:47.739: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:16:47.739: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:16:47.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:16:47.943: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:16:47.943: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:16:47.943: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:16:47.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-8102 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:16:48.163: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:16:48.163: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:16:48.163: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:16:48.163: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:16:48.175: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr  7 07:16:58.198: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:16:58.198: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:16:58.198: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  7 07:16:58.230: INFO: POD   NODE                               PHASE    GRACE  CONDITIONS
Apr  7 07:16:58.230: INFO: ss-0  aks-nodepool1-35379194-vmss000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:16 +0000 UTC  }]
Apr  7 07:16:58.230: INFO: ss-1  aks-nodepool1-35379194-vmss000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:36 +0000 UTC  }]
Apr  7 07:16:58.230: INFO: ss-2  aks-nodepool1-35379194-vmss000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-07 07:16:36 +0000 UTC  }]
Apr  7 07:16:58.230: INFO: 
Apr  7 07:16:58.230: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  7 07:16:59.240: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.991382722s
Apr  7 07:17:00.252: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.980984388s
Apr  7 07:17:01.263: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.969001238s
Apr  7 07:17:02.275: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.958276269s
Apr  7 07:17:03.299: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.94569408s
Apr  7 07:17:04.312: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.921631458s
Apr  7 07:17:05.323: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.908713648s
Apr  7 07:17:06.334: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.897840269s
Apr  7 07:17:07.345: INFO: Verifying statefulset ss doesn't scale past 0 for another 887.217206ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8102
Apr  7 07:17:08.359: INFO: Scaling statefulset ss to 0
Apr  7 07:17:08.386: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 07:17:08.392: INFO: Deleting all statefulset in ns statefulset-8102
Apr  7 07:17:08.400: INFO: Scaling statefulset ss to 0
Apr  7 07:17:08.424: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:17:08.450: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:08.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8102" for this suite.

• [SLOW TEST:52.223 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":346,"completed":228,"skipped":4460,"failed":0}
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:08.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:17:08.596: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  7 07:17:08.615: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  7 07:17:13.631: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  7 07:17:13.631: INFO: Creating deployment "test-rolling-update-deployment"
Apr  7 07:17:13.647: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  7 07:17:13.669: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  7 07:17:15.692: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  7 07:17:15.702: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 07:17:15.727: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9469  287f8114-01b6-427f-82fd-a283b46526ee 29191 1 2022-04-07 07:17:13 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-04-07 07:17:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:17:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fbcb48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-07 07:17:13 +0000 UTC,LastTransitionTime:2022-04-07 07:17:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-796dbc4547" has successfully progressed.,LastUpdateTime:2022-04-07 07:17:15 +0000 UTC,LastTransitionTime:2022-04-07 07:17:13 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  7 07:17:15.736: INFO: New ReplicaSet "test-rolling-update-deployment-796dbc4547" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-796dbc4547  deployment-9469  93e34591-01f9-49f1-9d87-7326cf44b648 29180 1 2022-04-07 07:17:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 287f8114-01b6-427f-82fd-a283b46526ee 0xc00410f917 0xc00410f918}] []  [{kube-controller-manager Update apps/v1 2022-04-07 07:17:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"287f8114-01b6-427f-82fd-a283b46526ee\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:17:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 796dbc4547,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00410f9c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:17:15.736: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  7 07:17:15.736: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9469  9645afd3-dda7-4391-8fee-12a2cfcfb1ee 29190 2 2022-04-07 07:17:08 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 287f8114-01b6-427f-82fd-a283b46526ee 0xc00410f7e7 0xc00410f7e8}] []  [{e2e.test Update apps/v1 2022-04-07 07:17:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:17:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"287f8114-01b6-427f-82fd-a283b46526ee\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:17:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00410f8a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:17:15.745: INFO: Pod "test-rolling-update-deployment-796dbc4547-59hgb" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-796dbc4547-59hgb test-rolling-update-deployment-796dbc4547- deployment-9469  7ac7b532-0c2b-4761-a9b5-072770ddca0c 29178 0 2022-04-07 07:17:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:796dbc4547] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-796dbc4547 93e34591-01f9-49f1-9d87-7326cf44b648 0xc00410fe27 0xc00410fe28}] []  [{kube-controller-manager Update v1 2022-04-07 07:17:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93e34591-01f9-49f1-9d87-7326cf44b648\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-04-07 07:17:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.120\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nbv5s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nbv5s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:17:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:17:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:17:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:17:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.120,StartTime:2022-04-07 07:17:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-07 07:17:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:5b3a9f1c71c09c00649d8374224642ff7029ce91a721ec9132e6ed45fa73fd43,ContainerID:containerd://cde229ecbd3859136550c1555362caa1c97886edc9038da3139ec049ef9146d5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.120,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:15.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9469" for this suite.

• [SLOW TEST:7.271 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":229,"skipped":4463,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:15.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:30.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-814" for this suite.
STEP: Destroying namespace "nsdeletetest-2688" for this suite.
Apr  7 07:17:30.222: INFO: Namespace nsdeletetest-2688 was already deleted
STEP: Destroying namespace "nsdeletetest-2131" for this suite.

• [SLOW TEST:14.454 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":346,"completed":230,"skipped":4536,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:30.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr  7 07:17:30.364: INFO: Waiting up to 5m0s for pod "downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606" in namespace "downward-api-9503" to be "Succeeded or Failed"
Apr  7 07:17:30.373: INFO: Pod "downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606": Phase="Pending", Reason="", readiness=false. Elapsed: 8.758058ms
Apr  7 07:17:32.387: INFO: Pod "downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023329795s
STEP: Saw pod success
Apr  7 07:17:32.387: INFO: Pod "downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606" satisfied condition "Succeeded or Failed"
Apr  7 07:17:32.407: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606 container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:17:32.447: INFO: Waiting for pod downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606 to disappear
Apr  7 07:17:32.456: INFO: Pod downward-api-8ab609db-63ef-42bb-9914-459ee2fe5606 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:32.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9503" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":346,"completed":231,"skipped":4554,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:32.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5437
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5437
STEP: creating replication controller externalsvc in namespace services-5437
I0407 07:17:32.656558      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5437, replica count: 2
I0407 07:17:35.707802      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr  7 07:17:35.764: INFO: Creating new exec pod
Apr  7 07:17:37.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-5437 exec execpodkwjvm -- /bin/sh -x -c nslookup clusterip-service.services-5437.svc.cluster.local'
Apr  7 07:17:38.037: INFO: stderr: "+ nslookup clusterip-service.services-5437.svc.cluster.local\n"
Apr  7 07:17:38.037: INFO: stdout: "Server:\t\t10.0.0.10\nAddress:\t10.0.0.10#53\n\nclusterip-service.services-5437.svc.cluster.local\tcanonical name = externalsvc.services-5437.svc.cluster.local.\nName:\texternalsvc.services-5437.svc.cluster.local\nAddress: 10.0.105.29\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5437, will wait for the garbage collector to delete the pods
Apr  7 07:17:38.109: INFO: Deleting ReplicationController externalsvc took: 12.863321ms
Apr  7 07:17:38.210: INFO: Terminating ReplicationController externalsvc pods took: 101.103553ms
Apr  7 07:17:40.357: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:40.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5437" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.911 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":346,"completed":232,"skipped":4568,"failed":0}
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:40.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:17:46.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4541" for this suite.
STEP: Destroying namespace "nsdeletetest-2915" for this suite.
Apr  7 07:17:46.771: INFO: Namespace nsdeletetest-2915 was already deleted
STEP: Destroying namespace "nsdeletetest-2262" for this suite.

• [SLOW TEST:6.376 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":346,"completed":233,"skipped":4571,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:17:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-1c0ecb08-e430-4449-a33c-6539458460b6 in namespace container-probe-8963
Apr  7 07:17:48.907: INFO: Started pod busybox-1c0ecb08-e430-4449-a33c-6539458460b6 in namespace container-probe-8963
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 07:17:48.916: INFO: Initial restart count of pod busybox-1c0ecb08-e430-4449-a33c-6539458460b6 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:21:50.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8963" for this suite.

• [SLOW TEST:244.003 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":234,"skipped":4592,"failed":0}
SSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:21:50.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:21:57.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-678" for this suite.

• [SLOW TEST:6.247 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":346,"completed":235,"skipped":4599,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:21:57.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:21:57.108: INFO: Creating deployment "test-recreate-deployment"
Apr  7 07:21:57.117: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  7 07:21:57.131: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  7 07:21:59.157: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  7 07:21:59.166: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  7 07:21:59.191: INFO: Updating deployment test-recreate-deployment
Apr  7 07:21:59.191: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr  7 07:21:59.324: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6345  833d0a6f-95fe-441c-83cd-8dc96f1839f7 30595 2 2022-04-07 07:21:57 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d53198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-04-07 07:21:59 +0000 UTC,LastTransitionTime:2022-04-07 07:21:59 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5b99bd5487" is progressing.,LastUpdateTime:2022-04-07 07:21:59 +0000 UTC,LastTransitionTime:2022-04-07 07:21:57 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr  7 07:21:59.334: INFO: New ReplicaSet "test-recreate-deployment-5b99bd5487" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5b99bd5487  deployment-6345  ba13f621-3191-408b-b5e5-d49acd8eb05b 30593 1 2022-04-07 07:21:59 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 833d0a6f-95fe-441c-83cd-8dc96f1839f7 0xc004bef327 0xc004bef328}] []  [{kube-controller-manager Update apps/v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"833d0a6f-95fe-441c-83cd-8dc96f1839f7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5b99bd5487,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bef3c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:21:59.334: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  7 07:21:59.334: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d659f7dc9  deployment-6345  cdff0a14-cbfe-4e3c-9729-9f8ca0a79c9f 30584 2 2022-04-07 07:21:57 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d659f7dc9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 833d0a6f-95fe-441c-83cd-8dc96f1839f7 0xc004bef437 0xc004bef438}] []  [{kube-controller-manager Update apps/v1 2022-04-07 07:21:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"833d0a6f-95fe-441c-83cd-8dc96f1839f7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d659f7dc9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d659f7dc9] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.33 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004bef4f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  7 07:21:59.340: INFO: Pod "test-recreate-deployment-5b99bd5487-fdq9h" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5b99bd5487-fdq9h test-recreate-deployment-5b99bd5487- deployment-6345  f5c1841e-c246-4c71-84d1-02dc6443b5d4 30596 0 2022-04-07 07:21:59 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5b99bd5487 ba13f621-3191-408b-b5e5-d49acd8eb05b 0xc004bef977 0xc004bef978}] []  [{Go-http-client Update v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {kube-controller-manager Update v1 2022-04-07 07:21:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba13f621-3191-408b-b5e5-d49acd8eb05b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9q2n5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9q2n5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-35379194-vmss000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:21:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:21:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:21:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-07 07:21:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2022-04-07 07:21:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:21:59.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6345" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":236,"skipped":4613,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:21:59.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-t69h
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 07:21:59.540: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t69h" in namespace "subpath-9404" to be "Succeeded or Failed"
Apr  7 07:21:59.547: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Pending", Reason="", readiness=false. Elapsed: 7.681799ms
Apr  7 07:22:01.557: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 2.017680273s
Apr  7 07:22:03.572: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 4.032107836s
Apr  7 07:22:05.586: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 6.046766466s
Apr  7 07:22:07.600: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 8.06077259s
Apr  7 07:22:09.615: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 10.075384652s
Apr  7 07:22:11.626: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 12.086249374s
Apr  7 07:22:13.638: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 14.098442907s
Apr  7 07:22:15.652: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 16.11278547s
Apr  7 07:22:17.665: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 18.125548932s
Apr  7 07:22:19.682: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Running", Reason="", readiness=true. Elapsed: 20.142325951s
Apr  7 07:22:21.691: INFO: Pod "pod-subpath-test-configmap-t69h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.150889062s
STEP: Saw pod success
Apr  7 07:22:21.691: INFO: Pod "pod-subpath-test-configmap-t69h" satisfied condition "Succeeded or Failed"
Apr  7 07:22:21.699: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-subpath-test-configmap-t69h container test-container-subpath-configmap-t69h: <nil>
STEP: delete the pod
Apr  7 07:22:21.741: INFO: Waiting for pod pod-subpath-test-configmap-t69h to disappear
Apr  7 07:22:21.747: INFO: Pod pod-subpath-test-configmap-t69h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t69h
Apr  7 07:22:21.747: INFO: Deleting pod "pod-subpath-test-configmap-t69h" in namespace "subpath-9404"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:22:21.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9404" for this suite.

• [SLOW TEST:22.415 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]","total":346,"completed":237,"skipped":4664,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:22:21.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-secret-m865
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 07:22:21.924: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-m865" in namespace "subpath-2280" to be "Succeeded or Failed"
Apr  7 07:22:21.931: INFO: Pod "pod-subpath-test-secret-m865": Phase="Pending", Reason="", readiness=false. Elapsed: 7.526383ms
Apr  7 07:22:23.944: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 2.020188061s
Apr  7 07:22:25.958: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 4.034645454s
Apr  7 07:22:27.970: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 6.045906242s
Apr  7 07:22:29.984: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 8.059748165s
Apr  7 07:22:31.996: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 10.072343508s
Apr  7 07:22:34.014: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 12.090668019s
Apr  7 07:22:36.030: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 14.105973866s
Apr  7 07:22:38.042: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 16.118535967s
Apr  7 07:22:40.056: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 18.131866817s
Apr  7 07:22:42.066: INFO: Pod "pod-subpath-test-secret-m865": Phase="Running", Reason="", readiness=true. Elapsed: 20.142212674s
Apr  7 07:22:44.084: INFO: Pod "pod-subpath-test-secret-m865": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.160239175s
STEP: Saw pod success
Apr  7 07:22:44.084: INFO: Pod "pod-subpath-test-secret-m865" satisfied condition "Succeeded or Failed"
Apr  7 07:22:44.101: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-subpath-test-secret-m865 container test-container-subpath-secret-m865: <nil>
STEP: delete the pod
Apr  7 07:22:44.185: INFO: Waiting for pod pod-subpath-test-secret-m865 to disappear
Apr  7 07:22:44.193: INFO: Pod pod-subpath-test-secret-m865 no longer exists
STEP: Deleting pod pod-subpath-test-secret-m865
Apr  7 07:22:44.193: INFO: Deleting pod "pod-subpath-test-secret-m865" in namespace "subpath-2280"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:22:44.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2280" for this suite.

• [SLOW TEST:22.464 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":238,"skipped":4687,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:22:44.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  7 07:22:44.373: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30857 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:44.373: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30857 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  7 07:22:44.408: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30858 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:44.408: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30858 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  7 07:22:44.429: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30859 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:44.429: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30859 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  7 07:22:44.444: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30861 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:44.444: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-134  24979c0b-700e-4ac9-aa43-7ec747dd9931 30861 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  7 07:22:44.453: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-134  28623b2d-994d-4daf-8226-c759a8a3e430 30862 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:44.453: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-134  28623b2d-994d-4daf-8226-c759a8a3e430 30862 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  7 07:22:54.499: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-134  28623b2d-994d-4daf-8226-c759a8a3e430 30915 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:22:54.499: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-134  28623b2d-994d-4daf-8226-c759a8a3e430 30915 0 2022-04-07 07:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-07 07:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:23:04.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-134" for this suite.

• [SLOW TEST:20.278 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":346,"completed":239,"skipped":4700,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:23:04.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-2868
STEP: creating service affinity-clusterip-transition in namespace services-2868
STEP: creating replication controller affinity-clusterip-transition in namespace services-2868
I0407 07:23:04.676435      23 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2868, replica count: 3
I0407 07:23:07.728547      23 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:23:07.751: INFO: Creating new exec pod
Apr  7 07:23:10.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2868 exec execpod-affinityvqj9x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr  7 07:23:10.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr  7 07:23:10.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:23:10.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2868 exec execpod-affinityvqj9x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.183.61 80'
Apr  7 07:23:11.204: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.183.61 80\nConnection to 10.0.183.61 80 port [tcp/http] succeeded!\n"
Apr  7 07:23:11.204: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:23:11.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2868 exec execpod-affinityvqj9x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.183.61:80/ ; done'
Apr  7 07:23:11.493: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n"
Apr  7 07:23:11.493: INFO: stdout: "\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-r24x5\naffinity-clusterip-transition-5bgtt\naffinity-clusterip-transition-z9tb5"
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-r24x5
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-5bgtt
Apr  7 07:23:11.493: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2868 exec execpod-affinityvqj9x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.183.61:80/ ; done'
Apr  7 07:23:11.786: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.183.61:80/\n"
Apr  7 07:23:11.786: INFO: stdout: "\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5\naffinity-clusterip-transition-z9tb5"
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Received response from host: affinity-clusterip-transition-z9tb5
Apr  7 07:23:11.787: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2868, will wait for the garbage collector to delete the pods
Apr  7 07:23:11.919: INFO: Deleting ReplicationController affinity-clusterip-transition took: 40.128077ms
Apr  7 07:23:12.019: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.483755ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:23:14.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2868" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.892 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":240,"skipped":4707,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:23:14.422: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:23:15.335: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:23:18.416: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:23:18.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:23:21.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-40" for this suite.
STEP: Destroying namespace "webhook-40-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.455 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":346,"completed":241,"skipped":4720,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:23:21.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 in namespace container-probe-8942
Apr  7 07:23:24.034: INFO: Started pod liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 in namespace container-probe-8942
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 07:23:24.044: INFO: Initial restart count of pod liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is 0
Apr  7 07:23:44.229: INFO: Restart count of pod container-probe-8942/liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is now 1 (20.185458443s elapsed)
Apr  7 07:24:04.388: INFO: Restart count of pod container-probe-8942/liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is now 2 (40.344279517s elapsed)
Apr  7 07:24:22.509: INFO: Restart count of pod container-probe-8942/liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is now 3 (58.465313175s elapsed)
Apr  7 07:24:42.709: INFO: Restart count of pod container-probe-8942/liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is now 4 (1m18.665169496s elapsed)
Apr  7 07:25:47.146: INFO: Restart count of pod container-probe-8942/liveness-dc6e3081-cb5a-4b5f-9ffd-d6f65460cf86 is now 5 (2m23.102036771s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:25:47.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8942" for this suite.

• [SLOW TEST:145.312 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":346,"completed":242,"skipped":4730,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:25:47.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Apr  7 07:25:47.305: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:25:49.321: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr  7 07:25:49.348: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:25:51.356: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  7 07:25:51.395: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 07:25:51.402: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 07:25:53.402: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 07:25:53.414: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  7 07:25:55.402: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  7 07:25:55.415: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:25:55.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4208" for this suite.

• [SLOW TEST:8.250 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":346,"completed":243,"skipped":4751,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:25:55.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8502 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8502;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8502 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8502;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8502.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8502.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8502.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8502.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8502.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8502.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8502.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8502.svc;check="$$(dig +notcp +noall +answer +search 218.188.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.188.218_udp@PTR;check="$$(dig +tcp +noall +answer +search 218.188.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.188.218_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8502 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8502;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8502 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8502;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8502.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8502.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8502.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8502.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8502.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8502.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8502.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8502.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8502.svc;check="$$(dig +notcp +noall +answer +search 218.188.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.188.218_udp@PTR;check="$$(dig +tcp +noall +answer +search 218.188.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.188.218_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 07:25:57.630: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.639: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.647: INFO: Unable to read wheezy_udp@dns-test-service.dns-8502 from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.658: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8502 from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.667: INFO: Unable to read wheezy_udp@dns-test-service.dns-8502.svc from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.681: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8502.svc from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.751: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.759: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.767: INFO: Unable to read jessie_udp@dns-test-service.dns-8502 from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.775: INFO: Unable to read jessie_tcp@dns-test-service.dns-8502 from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.784: INFO: Unable to read jessie_udp@dns-test-service.dns-8502.svc from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.792: INFO: Unable to read jessie_tcp@dns-test-service.dns-8502.svc from pod dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af: the server could not find the requested resource (get pods dns-test-d92aee48-505b-48f5-9a77-27106a2c96af)
Apr  7 07:25:57.843: INFO: Lookups using dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8502 wheezy_tcp@dns-test-service.dns-8502 wheezy_udp@dns-test-service.dns-8502.svc wheezy_tcp@dns-test-service.dns-8502.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8502 jessie_tcp@dns-test-service.dns-8502 jessie_udp@dns-test-service.dns-8502.svc jessie_tcp@dns-test-service.dns-8502.svc]

Apr  7 07:26:03.123: INFO: DNS probes using dns-8502/dns-test-d92aee48-505b-48f5-9a77-27106a2c96af succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:03.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8502" for this suite.

• [SLOW TEST:7.854 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":346,"completed":244,"skipped":4765,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:03.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:26:03.395: INFO: The status of Pod busybox-readonly-fsf436a0fe-7f31-4960-b35a-4eea2831988b is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:26:05.411: INFO: The status of Pod busybox-readonly-fsf436a0fe-7f31-4960-b35a-4eea2831988b is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:05.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9084" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":245,"skipped":4785,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4895.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4895.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4895.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4895.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  7 07:26:07.625: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.634: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.646: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.654: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.669: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.680: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.691: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.700: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4895.svc.cluster.local from pod dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf: the server could not find the requested resource (get pods dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf)
Apr  7 07:26:07.700: INFO: Lookups using dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4895.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4895.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4895.svc.cluster.local jessie_udp@dns-test-service-2.dns-4895.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4895.svc.cluster.local]

Apr  7 07:26:12.772: INFO: DNS probes using dns-4895/dns-test-824c6cc0-d8e1-48d7-9251-34d8561cebcf succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:12.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4895" for this suite.

• [SLOW TEST:7.396 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":346,"completed":246,"skipped":4788,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:12.855: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:26:13.465: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:26:16.531: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:26:16.540: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:19.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4637" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.953 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":346,"completed":247,"skipped":4824,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:19.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:26:19.912: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d" in namespace "downward-api-4056" to be "Succeeded or Failed"
Apr  7 07:26:19.919: INFO: Pod "downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217401ms
Apr  7 07:26:21.929: INFO: Pod "downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016322523s
STEP: Saw pod success
Apr  7 07:26:21.929: INFO: Pod "downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d" satisfied condition "Succeeded or Failed"
Apr  7 07:26:21.935: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d container client-container: <nil>
STEP: delete the pod
Apr  7 07:26:21.984: INFO: Waiting for pod downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d to disappear
Apr  7 07:26:21.990: INFO: Pod downwardapi-volume-58b3524d-0490-49c6-8b48-0e165b3c9b4d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:21.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4056" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":248,"skipped":4869,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:22.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:29.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8149" for this suite.

• [SLOW TEST:7.142 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":346,"completed":249,"skipped":4916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:29.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-projected-all-test-volume-7c3793d7-00de-48c6-8558-cd7b0e2ba5ba
STEP: Creating secret with name secret-projected-all-test-volume-c972b0fd-7fdc-4a2b-a2c0-2e755c6a674a
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  7 07:26:29.275: INFO: Waiting up to 5m0s for pod "projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76" in namespace "projected-7060" to be "Succeeded or Failed"
Apr  7 07:26:29.282: INFO: Pod "projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76": Phase="Pending", Reason="", readiness=false. Elapsed: 6.633928ms
Apr  7 07:26:31.297: INFO: Pod "projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021033592s
STEP: Saw pod success
Apr  7 07:26:31.297: INFO: Pod "projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76" satisfied condition "Succeeded or Failed"
Apr  7 07:26:31.304: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  7 07:26:31.340: INFO: Waiting for pod projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76 to disappear
Apr  7 07:26:31.347: INFO: Pod projected-volume-abcf4a31-ba1c-4461-9db8-729ab33a8f76 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:26:31.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7060" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":346,"completed":250,"skipped":4966,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:26:31.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr  7 07:26:31.480: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 07:27:31.536: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Apr  7 07:27:31.611: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr  7 07:27:31.627: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr  7 07:27:31.669: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr  7 07:27:31.685: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:27:45.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7691" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:74.551 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":346,"completed":251,"skipped":4969,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:27:45.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  7 07:27:46.004: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:27:50.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9863" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":346,"completed":252,"skipped":4982,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:27:50.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  7 07:27:50.316: INFO: Waiting up to 5m0s for pod "pod-8ca33635-0e97-4975-86df-1cad08a56477" in namespace "emptydir-6781" to be "Succeeded or Failed"
Apr  7 07:27:50.328: INFO: Pod "pod-8ca33635-0e97-4975-86df-1cad08a56477": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918068ms
Apr  7 07:27:52.338: INFO: Pod "pod-8ca33635-0e97-4975-86df-1cad08a56477": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021723498s
STEP: Saw pod success
Apr  7 07:27:52.338: INFO: Pod "pod-8ca33635-0e97-4975-86df-1cad08a56477" satisfied condition "Succeeded or Failed"
Apr  7 07:27:52.344: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-8ca33635-0e97-4975-86df-1cad08a56477 container test-container: <nil>
STEP: delete the pod
Apr  7 07:27:52.375: INFO: Waiting for pod pod-8ca33635-0e97-4975-86df-1cad08a56477 to disappear
Apr  7 07:27:52.381: INFO: Pod pod-8ca33635-0e97-4975-86df-1cad08a56477 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:27:52.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6781" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":253,"skipped":4998,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:27:52.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pods
Apr  7 07:27:52.493: INFO: created test-pod-1
Apr  7 07:27:54.512: INFO: running and ready test-pod-1
Apr  7 07:27:54.523: INFO: created test-pod-2
Apr  7 07:27:56.538: INFO: running and ready test-pod-2
Apr  7 07:27:56.549: INFO: created test-pod-3
Apr  7 07:27:58.569: INFO: running and ready test-pod-3
STEP: waiting for all 3 pods to be located
STEP: waiting for all pods to be deleted
Apr  7 07:27:58.624: INFO: Pod quantity 3 is different from expected quantity 0
Apr  7 07:27:59.634: INFO: Pod quantity 1 is different from expected quantity 0
Apr  7 07:28:00.634: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:01.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8947" for this suite.

• [SLOW TEST:9.255 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":346,"completed":254,"skipped":5024,"failed":0}
SSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:01.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/hostport.go:47
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Apr  7 07:28:01.787: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:28:03.800: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.240.0.5 on the node which pod1 resides and expect scheduled
Apr  7 07:28:03.819: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:28:05.834: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.240.0.5 but use UDP protocol on the node which pod2 resides
Apr  7 07:28:05.851: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:28:07.860: INFO: The status of Pod pod3 is Running (Ready = true)
Apr  7 07:28:07.877: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:28:09.891: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Apr  7 07:28:09.897: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.240.0.5 http://127.0.0.1:54323/hostname] Namespace:hostport-4980 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:28:09.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:28:09.898: INFO: ExecWithOptions: Clientset creation
Apr  7 07:28:09.898: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/hostport-4980/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.240.0.5+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.240.0.5, port: 54323
Apr  7 07:28:10.055: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.240.0.5:54323/hostname] Namespace:hostport-4980 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:28:10.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:28:10.056: INFO: ExecWithOptions: Clientset creation
Apr  7 07:28:10.056: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/hostport-4980/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.240.0.5%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.240.0.5, port: 54323 UDP
Apr  7 07:28:10.198: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.240.0.5 54323] Namespace:hostport-4980 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:28:10.198: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:28:10.199: INFO: ExecWithOptions: Clientset creation
Apr  7 07:28:10.199: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/hostport-4980/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+10.240.0.5+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
[AfterEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:15.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-4980" for this suite.

• [SLOW TEST:13.707 seconds]
[sig-network] HostPort
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":346,"completed":255,"skipped":5032,"failed":0}
SSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:15.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name secret-emptykey-test-294cc87e-36d5-42a6-818a-8aab670f2160
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:15.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-312" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":346,"completed":256,"skipped":5037,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:15.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr  7 07:28:15.637: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4209  b5afcb27-e4cb-40c5-88f7-e6096af2c50a 33030 0 2022-04-07 07:28:15 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-04-07 07:28:15 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47g56,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.33,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47g56,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  7 07:28:15.644: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:28:17.652: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr  7 07:28:17.653: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4209 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:28:17.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:28:17.653: INFO: ExecWithOptions: Clientset creation
Apr  7 07:28:17.653: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/dns-4209/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
STEP: Verifying customized DNS server is configured on pod...
Apr  7 07:28:17.815: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4209 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:28:17.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:28:17.816: INFO: ExecWithOptions: Clientset creation
Apr  7 07:28:17.816: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/dns-4209/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:28:17.962: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:17.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4209" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":346,"completed":257,"skipped":5067,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:18.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  7 07:28:18.107: INFO: Waiting up to 5m0s for pod "pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7" in namespace "emptydir-2320" to be "Succeeded or Failed"
Apr  7 07:28:18.115: INFO: Pod "pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.653593ms
Apr  7 07:28:20.127: INFO: Pod "pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020066769s
STEP: Saw pod success
Apr  7 07:28:20.127: INFO: Pod "pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7" satisfied condition "Succeeded or Failed"
Apr  7 07:28:20.134: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7 container test-container: <nil>
STEP: delete the pod
Apr  7 07:28:20.177: INFO: Waiting for pod pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7 to disappear
Apr  7 07:28:20.183: INFO: Pod pod-e4a3baa9-14c9-4233-ac4f-ea626d0975d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:20.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2320" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":258,"skipped":5100,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:20.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Apr  7 07:28:20.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-302 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr  7 07:28:20.476: INFO: stderr: ""
Apr  7 07:28:20.476: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Apr  7 07:28:20.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-302 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr  7 07:28:20.648: INFO: stderr: ""
Apr  7 07:28:20.648: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Apr  7 07:28:20.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-302 delete pods e2e-test-httpd-pod'
Apr  7 07:28:22.900: INFO: stderr: ""
Apr  7 07:28:22.900: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:22.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-302" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":346,"completed":259,"skipped":5123,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:22.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr  7 07:28:23.617: INFO: starting watch
STEP: patching
STEP: updating
Apr  7 07:28:23.643: INFO: waiting for watch events with expected annotations
Apr  7 07:28:23.643: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:23.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-8031" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":346,"completed":260,"skipped":5141,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:23.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-1d9bdfd3-0c41-4875-9f43-56f4c11943c9
STEP: Creating a pod to test consume secrets
Apr  7 07:28:23.925: INFO: Waiting up to 5m0s for pod "pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1" in namespace "secrets-2409" to be "Succeeded or Failed"
Apr  7 07:28:23.931: INFO: Pod "pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029589ms
Apr  7 07:28:25.943: INFO: Pod "pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018303562s
STEP: Saw pod success
Apr  7 07:28:25.943: INFO: Pod "pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1" satisfied condition "Succeeded or Failed"
Apr  7 07:28:25.951: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1 container secret-env-test: <nil>
STEP: delete the pod
Apr  7 07:28:25.988: INFO: Waiting for pod pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1 to disappear
Apr  7 07:28:25.993: INFO: Pod pod-secrets-c365f63b-10b7-432b-a21d-3213704aaae1 no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:28:25.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2409" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":346,"completed":261,"skipped":5150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:28:26.015: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod with failed condition
STEP: updating the pod
Apr  7 07:30:26.668: INFO: Successfully updated pod "var-expansion-db6fa756-36e6-4c19-9566-1cc84fdd9703"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Apr  7 07:30:28.685: INFO: Deleting pod "var-expansion-db6fa756-36e6-4c19-9566-1cc84fdd9703" in namespace "var-expansion-8181"
Apr  7 07:30:28.699: INFO: Wait up to 5m0s for pod "var-expansion-db6fa756-36e6-4c19-9566-1cc84fdd9703" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:00.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8181" for this suite.

• [SLOW TEST:154.743 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":346,"completed":262,"skipped":5179,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:00.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr  7 07:31:00.866: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  7 07:31:00.883: INFO: Waiting for terminating namespaces to be deleted...
Apr  7 07:31:00.895: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000000 before test
Apr  7 07:31:00.911: INFO: azure-ip-masq-agent-vjb96 from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 07:31:00.911: INFO: cloud-node-manager-tcnjx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 07:31:00.911: INFO: coredns-748769b948-gz9rk from kube-system started at 2022-04-07 06:25:16 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container coredns ready: true, restart count 0
Apr  7 07:31:00.911: INFO: coredns-748769b948-j9bgf from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container coredns ready: true, restart count 0
Apr  7 07:31:00.911: INFO: coredns-autoscaler-6fb889cdfc-w5qm4 from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container autoscaler ready: true, restart count 0
Apr  7 07:31:00.911: INFO: csi-azuredisk-node-qmwkm from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:31:00.911: INFO: csi-azurefile-node-swhhx from kube-system started at 2022-04-07 06:24:28 +0000 UTC (3 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:31:00.911: INFO: konnectivity-agent-76fcfc46bd-9kq4v from kube-system started at 2022-04-07 06:25:20 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 07:31:00.911: INFO: konnectivity-agent-76fcfc46bd-chsbh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr  7 07:31:00.911: INFO: kube-proxy-spxrs from kube-system started at 2022-04-07 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 07:31:00.911: INFO: metrics-server-7d59848cc6-4skgh from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 07:31:00.911: INFO: metrics-server-7d59848cc6-wrc2c from kube-system started at 2022-04-07 06:25:10 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container metrics-server ready: true, restart count 1
Apr  7 07:31:00.911: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-bqh8l from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:31:00.911: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  7 07:31:00.911: INFO: 
Logging pods the apiserver thinks is on node aks-nodepool1-35379194-vmss000001 before test
Apr  7 07:31:00.922: INFO: azure-ip-masq-agent-k7wwg from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
Apr  7 07:31:00.922: INFO: cloud-node-manager-4xrsl from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container cloud-node-manager ready: true, restart count 0
Apr  7 07:31:00.922: INFO: csi-azuredisk-node-6g62x from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container azuredisk ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:31:00.922: INFO: csi-azurefile-node-8z4x6 from kube-system started at 2022-04-07 06:27:53 +0000 UTC (3 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container azurefile ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container liveness-probe ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr  7 07:31:00.922: INFO: kube-proxy-9vz4m from kube-system started at 2022-04-07 06:27:53 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  7 07:31:00.922: INFO: sonobuoy from sonobuoy started at 2022-04-07 06:29:06 +0000 UTC (1 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  7 07:31:00.922: INFO: sonobuoy-e2e-job-6dc4960ffa6e4d5e from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container e2e ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:31:00.922: INFO: sonobuoy-systemd-logs-daemon-set-85f74cf1f85247b7-c22tn from sonobuoy started at 2022-04-07 06:29:08 +0000 UTC (2 container statuses recorded)
Apr  7 07:31:00.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  7 07:31:00.922: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16e38cc3c2b4e549], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:01.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2570" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":346,"completed":263,"skipped":5202,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:02.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:31:02.568: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:31:05.633: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:31:05.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5361-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:08.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5107" for this suite.
STEP: Destroying namespace "webhook-5107-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.965 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":346,"completed":264,"skipped":5204,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:08.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:31:09.107: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b" in namespace "projected-784" to be "Succeeded or Failed"
Apr  7 07:31:09.114: INFO: Pod "downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.647428ms
Apr  7 07:31:11.127: INFO: Pod "downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019974129s
STEP: Saw pod success
Apr  7 07:31:11.127: INFO: Pod "downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b" satisfied condition "Succeeded or Failed"
Apr  7 07:31:11.136: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b container client-container: <nil>
STEP: delete the pod
Apr  7 07:31:11.182: INFO: Waiting for pod downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b to disappear
Apr  7 07:31:11.189: INFO: Pod downwardapi-volume-8a627f22-73d9-4c48-a60e-ee01b29fbc1b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:11.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-784" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":265,"skipped":5234,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:11.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Apr  7 07:31:11.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:28.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8556" for this suite.

• [SLOW TEST:17.720 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":346,"completed":266,"skipped":5239,"failed":0}
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:28.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replication controller my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc
Apr  7 07:31:29.053: INFO: Pod name my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc: Found 0 pods out of 1
Apr  7 07:31:34.068: INFO: Pod name my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc: Found 1 pods out of 1
Apr  7 07:31:34.068: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc" are running
Apr  7 07:31:34.076: INFO: Pod "my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc-jtg5x" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:31:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:31:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:31:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-07 07:31:29 +0000 UTC Reason: Message:}])
Apr  7 07:31:34.076: INFO: Trying to dial the pod
Apr  7 07:31:39.124: INFO: Controller my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc: Got expected result from replica 1 [my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc-jtg5x]: "my-hostname-basic-49e9a705-073c-47d8-b0f1-d7d645e2b1bc-jtg5x", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:39.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-424" for this suite.

• [SLOW TEST:10.213 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":267,"skipped":5241,"failed":0}
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:39.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-2430
[It] should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-2430
Apr  7 07:31:39.280: INFO: Found 0 stateful pods, waiting for 1
Apr  7 07:31:49.298: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 07:31:49.395: INFO: Deleting all statefulset in ns statefulset-2430
Apr  7 07:31:49.404: INFO: Scaling statefulset ss to 0
Apr  7 07:31:59.476: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:31:59.484: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:31:59.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2430" for this suite.

• [SLOW TEST:20.393 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should have a working scale subresource [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":346,"completed":268,"skipped":5241,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:31:59.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service nodeport-test with type=NodePort in namespace services-1903
STEP: creating replication controller nodeport-test in namespace services-1903
I0407 07:31:59.665187      23 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1903, replica count: 2
Apr  7 07:32:02.716: INFO: Creating new exec pod
I0407 07:32:02.716164      23 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:32:05.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-1903 exec execpoddhtfh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr  7 07:32:06.005: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr  7 07:32:06.005: INFO: stdout: "nodeport-test-f4j74"
Apr  7 07:32:06.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-1903 exec execpoddhtfh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.6.153 80'
Apr  7 07:32:06.216: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.6.153 80\nConnection to 10.0.6.153 80 port [tcp/http] succeeded!\n"
Apr  7 07:32:06.216: INFO: stdout: "nodeport-test-6sk75"
Apr  7 07:32:06.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-1903 exec execpoddhtfh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.4 32106'
Apr  7 07:32:06.443: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.4 32106\nConnection to 10.240.0.4 32106 port [tcp/*] succeeded!\n"
Apr  7 07:32:06.443: INFO: stdout: "nodeport-test-6sk75"
Apr  7 07:32:06.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-1903 exec execpoddhtfh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.5 32106'
Apr  7 07:32:06.666: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.5 32106\nConnection to 10.240.0.5 32106 port [tcp/*] succeeded!\n"
Apr  7 07:32:06.666: INFO: stdout: "nodeport-test-6sk75"
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:06.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1903" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.149 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":346,"completed":269,"skipped":5249,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:06.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:32:06.793: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-3297d2c9-2fa0-42c9-b53b-bf742ddae355" in namespace "security-context-test-9375" to be "Succeeded or Failed"
Apr  7 07:32:06.800: INFO: Pod "busybox-readonly-false-3297d2c9-2fa0-42c9-b53b-bf742ddae355": Phase="Pending", Reason="", readiness=false. Elapsed: 6.891445ms
Apr  7 07:32:08.815: INFO: Pod "busybox-readonly-false-3297d2c9-2fa0-42c9-b53b-bf742ddae355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022470092s
Apr  7 07:32:08.815: INFO: Pod "busybox-readonly-false-3297d2c9-2fa0-42c9-b53b-bf742ddae355" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:08.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9375" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":346,"completed":270,"skipped":5284,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:08.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr  7 07:32:10.055: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:10.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0407 07:32:10.055770      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
STEP: Destroying namespace "gc-9833" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":346,"completed":271,"skipped":5289,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:10.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service multi-endpoint-test in namespace services-2963
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2963 to expose endpoints map[]
Apr  7 07:32:10.205: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Apr  7 07:32:11.225: INFO: successfully validated that service multi-endpoint-test in namespace services-2963 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2963
Apr  7 07:32:11.251: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:32:13.269: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2963 to expose endpoints map[pod1:[100]]
Apr  7 07:32:13.301: INFO: successfully validated that service multi-endpoint-test in namespace services-2963 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-2963
Apr  7 07:32:13.325: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:32:15.345: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2963 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  7 07:32:15.397: INFO: successfully validated that service multi-endpoint-test in namespace services-2963 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Apr  7 07:32:15.397: INFO: Creating new exec pod
Apr  7 07:32:18.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2963 exec execpod5ptn7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr  7 07:32:18.646: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr  7 07:32:18.646: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:32:18.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2963 exec execpod5ptn7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.112.129 80'
Apr  7 07:32:18.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.112.129 80\nConnection to 10.0.112.129 80 port [tcp/http] succeeded!\n"
Apr  7 07:32:18.861: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:32:18.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2963 exec execpod5ptn7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr  7 07:32:19.063: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr  7 07:32:19.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:32:19.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-2963 exec execpod5ptn7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.112.129 81'
Apr  7 07:32:19.385: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.112.129 81\nConnection to 10.0.112.129 81 port [tcp/*] succeeded!\n"
Apr  7 07:32:19.385: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2963
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2963 to expose endpoints map[pod2:[101]]
Apr  7 07:32:20.442: INFO: successfully validated that service multi-endpoint-test in namespace services-2963 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-2963
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2963 to expose endpoints map[]
Apr  7 07:32:21.484: INFO: successfully validated that service multi-endpoint-test in namespace services-2963 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:21.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2963" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:11.464 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":346,"completed":272,"skipped":5300,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:21.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-4e3a7113-405b-4d46-9a2b-4f8e69cce61e
STEP: Creating a pod to test consume configMaps
Apr  7 07:32:21.657: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4" in namespace "configmap-8412" to be "Succeeded or Failed"
Apr  7 07:32:21.665: INFO: Pod "pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.414342ms
Apr  7 07:32:23.695: INFO: Pod "pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038228901s
STEP: Saw pod success
Apr  7 07:32:23.695: INFO: Pod "pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4" satisfied condition "Succeeded or Failed"
Apr  7 07:32:23.702: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 07:32:23.781: INFO: Waiting for pod pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4 to disappear
Apr  7 07:32:23.789: INFO: Pod pod-configmaps-c7543d84-f75b-49b5-91cd-e4cd379442e4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:23.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8412" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":273,"skipped":5305,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:23.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Apr  7 07:32:23.941: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:32:25.953: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Apr  7 07:32:25.976: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:32:27.989: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  7 07:32:27.995: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:27.995: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:27.996: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:27.996: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.122: INFO: Exec stderr: ""
Apr  7 07:32:28.122: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.123: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.123: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.263: INFO: Exec stderr: ""
Apr  7 07:32:28.263: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.264: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.264: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.399: INFO: Exec stderr: ""
Apr  7 07:32:28.399: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.400: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.400: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.529: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  7 07:32:28.529: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.529: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.529: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.640: INFO: Exec stderr: ""
Apr  7 07:32:28.640: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.641: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.641: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.750: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  7 07:32:28.750: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.751: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.751: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:28.893: INFO: Exec stderr: ""
Apr  7 07:32:28.893: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:28.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:28.893: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:28.893: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:29.003: INFO: Exec stderr: ""
Apr  7 07:32:29.003: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:29.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:29.003: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:29.003: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:29.171: INFO: Exec stderr: ""
Apr  7 07:32:29.171: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9428 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:32:29.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:32:29.172: INFO: ExecWithOptions: Clientset creation
Apr  7 07:32:29.172: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9428/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Apr  7 07:32:29.279: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:29.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9428" for this suite.

• [SLOW TEST:5.492 seconds]
[sig-node] KubeletManagedEtcHosts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":274,"skipped":5346,"failed":0}
SSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:29.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
Apr  7 07:32:29.442: INFO: created test-event-1
Apr  7 07:32:29.449: INFO: created test-event-2
Apr  7 07:32:29.457: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Apr  7 07:32:29.466: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Apr  7 07:32:29.508: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:29.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6167" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":346,"completed":275,"skipped":5353,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:29.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr  7 07:32:29.637: INFO: Waiting up to 5m0s for pod "downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40" in namespace "downward-api-2552" to be "Succeeded or Failed"
Apr  7 07:32:29.645: INFO: Pod "downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40": Phase="Pending", Reason="", readiness=false. Elapsed: 8.305235ms
Apr  7 07:32:31.658: INFO: Pod "downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02081203s
STEP: Saw pod success
Apr  7 07:32:31.658: INFO: Pod "downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40" satisfied condition "Succeeded or Failed"
Apr  7 07:32:31.664: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40 container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:32:31.701: INFO: Waiting for pod downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40 to disappear
Apr  7 07:32:31.707: INFO: Pod downward-api-88672ec2-fde5-4708-8ad9-fb3251735f40 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:31.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2552" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":346,"completed":276,"skipped":5360,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:31.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Apr  7 07:32:31.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-2909 create -f -'
Apr  7 07:32:31.991: INFO: stderr: ""
Apr  7 07:32:31.991: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr  7 07:32:33.005: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:32:33.005: INFO: Found 0 / 1
Apr  7 07:32:34.002: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:32:34.002: INFO: Found 1 / 1
Apr  7 07:32:34.002: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  7 07:32:34.009: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:32:34.009: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  7 07:32:34.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-2909 patch pod agnhost-primary-6ngq5 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  7 07:32:34.115: INFO: stderr: ""
Apr  7 07:32:34.115: INFO: stdout: "pod/agnhost-primary-6ngq5 patched\n"
STEP: checking annotations
Apr  7 07:32:34.122: INFO: Selector matched 1 pods for map[app:agnhost]
Apr  7 07:32:34.122: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:34.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2909" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":346,"completed":277,"skipped":5391,"failed":0}
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:34.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:34.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-70" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":346,"completed":278,"skipped":5398,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:34.328: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:32:34.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4547
I0407 07:32:34.483468      23 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4547, replica count: 1
I0407 07:32:35.534477      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0407 07:32:36.535119      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:32:36.657: INFO: Created: latency-svc-4lm9f
Apr  7 07:32:36.669: INFO: Got endpoints: latency-svc-4lm9f [33.894782ms]
Apr  7 07:32:36.689: INFO: Created: latency-svc-qvrd5
Apr  7 07:32:36.695: INFO: Got endpoints: latency-svc-qvrd5 [26.042477ms]
Apr  7 07:32:36.700: INFO: Created: latency-svc-glb78
Apr  7 07:32:36.709: INFO: Got endpoints: latency-svc-glb78 [39.352734ms]
Apr  7 07:32:36.722: INFO: Created: latency-svc-9dxbx
Apr  7 07:32:36.729: INFO: Got endpoints: latency-svc-9dxbx [59.62684ms]
Apr  7 07:32:36.741: INFO: Created: latency-svc-hw7dc
Apr  7 07:32:36.754: INFO: Got endpoints: latency-svc-hw7dc [84.616349ms]
Apr  7 07:32:36.761: INFO: Created: latency-svc-t25bs
Apr  7 07:32:36.775: INFO: Got endpoints: latency-svc-t25bs [105.563097ms]
Apr  7 07:32:36.782: INFO: Created: latency-svc-mc8v6
Apr  7 07:32:36.798: INFO: Got endpoints: latency-svc-mc8v6 [128.496675ms]
Apr  7 07:32:36.798: INFO: Created: latency-svc-9zlgj
Apr  7 07:32:36.811: INFO: Created: latency-svc-n6vf5
Apr  7 07:32:36.814: INFO: Got endpoints: latency-svc-9zlgj [144.128681ms]
Apr  7 07:32:36.823: INFO: Created: latency-svc-8bt9n
Apr  7 07:32:36.846: INFO: Got endpoints: latency-svc-n6vf5 [176.120041ms]
Apr  7 07:32:36.846: INFO: Got endpoints: latency-svc-8bt9n [176.114441ms]
Apr  7 07:32:36.851: INFO: Created: latency-svc-rk58n
Apr  7 07:32:36.857: INFO: Got endpoints: latency-svc-rk58n [187.576179ms]
Apr  7 07:32:36.867: INFO: Created: latency-svc-8jgn4
Apr  7 07:32:36.874: INFO: Got endpoints: latency-svc-8jgn4 [204.731186ms]
Apr  7 07:32:36.876: INFO: Created: latency-svc-95d4x
Apr  7 07:32:36.882: INFO: Got endpoints: latency-svc-95d4x [212.280773ms]
Apr  7 07:32:36.890: INFO: Created: latency-svc-xjq25
Apr  7 07:32:36.896: INFO: Got endpoints: latency-svc-xjq25 [226.421687ms]
Apr  7 07:32:36.903: INFO: Created: latency-svc-sdnx4
Apr  7 07:32:36.908: INFO: Created: latency-svc-nxjkg
Apr  7 07:32:36.911: INFO: Got endpoints: latency-svc-sdnx4 [240.888321ms]
Apr  7 07:32:36.919: INFO: Got endpoints: latency-svc-nxjkg [249.744893ms]
Apr  7 07:32:36.944: INFO: Created: latency-svc-b7h7m
Apr  7 07:32:36.953: INFO: Created: latency-svc-925mh
Apr  7 07:32:36.953: INFO: Created: latency-svc-mhhgt
Apr  7 07:32:36.959: INFO: Got endpoints: latency-svc-925mh [263.600993ms]
Apr  7 07:32:36.960: INFO: Got endpoints: latency-svc-b7h7m [251.937842ms]
Apr  7 07:32:36.964: INFO: Got endpoints: latency-svc-mhhgt [235.072957ms]
Apr  7 07:32:36.964: INFO: Created: latency-svc-lrgd9
Apr  7 07:32:36.970: INFO: Got endpoints: latency-svc-lrgd9 [216.317551ms]
Apr  7 07:32:36.976: INFO: Created: latency-svc-kbs96
Apr  7 07:32:36.983: INFO: Got endpoints: latency-svc-kbs96 [207.831606ms]
Apr  7 07:32:36.989: INFO: Created: latency-svc-5dmgs
Apr  7 07:32:36.997: INFO: Got endpoints: latency-svc-5dmgs [199.551376ms]
Apr  7 07:32:37.007: INFO: Created: latency-svc-qldz8
Apr  7 07:32:37.018: INFO: Got endpoints: latency-svc-qldz8 [204.537901ms]
Apr  7 07:32:37.022: INFO: Created: latency-svc-pz2bm
Apr  7 07:32:37.028: INFO: Got endpoints: latency-svc-pz2bm [182.086858ms]
Apr  7 07:32:37.035: INFO: Created: latency-svc-g6t47
Apr  7 07:32:37.045: INFO: Got endpoints: latency-svc-g6t47 [198.981649ms]
Apr  7 07:32:37.046: INFO: Created: latency-svc-9vvvq
Apr  7 07:32:37.052: INFO: Got endpoints: latency-svc-9vvvq [195.323514ms]
Apr  7 07:32:37.053: INFO: Created: latency-svc-j8dwk
Apr  7 07:32:37.064: INFO: Got endpoints: latency-svc-j8dwk [189.869763ms]
Apr  7 07:32:37.068: INFO: Created: latency-svc-8jlz4
Apr  7 07:32:37.077: INFO: Got endpoints: latency-svc-8jlz4 [195.221209ms]
Apr  7 07:32:37.079: INFO: Created: latency-svc-g64nb
Apr  7 07:32:37.085: INFO: Got endpoints: latency-svc-g64nb [189.249024ms]
Apr  7 07:32:37.090: INFO: Created: latency-svc-tgh8q
Apr  7 07:32:37.098: INFO: Got endpoints: latency-svc-tgh8q [187.095984ms]
Apr  7 07:32:37.103: INFO: Created: latency-svc-dc7sn
Apr  7 07:32:37.110: INFO: Got endpoints: latency-svc-dc7sn [190.402098ms]
Apr  7 07:32:37.121: INFO: Created: latency-svc-vv9w8
Apr  7 07:32:37.128: INFO: Got endpoints: latency-svc-vv9w8 [168.504083ms]
Apr  7 07:32:37.138: INFO: Created: latency-svc-pffn5
Apr  7 07:32:37.145: INFO: Got endpoints: latency-svc-pffn5 [184.69903ms]
Apr  7 07:32:37.146: INFO: Created: latency-svc-8snbk
Apr  7 07:32:37.154: INFO: Got endpoints: latency-svc-8snbk [190.208885ms]
Apr  7 07:32:37.163: INFO: Created: latency-svc-9rbjd
Apr  7 07:32:37.174: INFO: Got endpoints: latency-svc-9rbjd [203.471142ms]
Apr  7 07:32:37.182: INFO: Created: latency-svc-rkpg4
Apr  7 07:32:37.189: INFO: Got endpoints: latency-svc-rkpg4 [206.684049ms]
Apr  7 07:32:37.200: INFO: Created: latency-svc-8r58g
Apr  7 07:32:37.208: INFO: Created: latency-svc-bnsvl
Apr  7 07:32:37.208: INFO: Got endpoints: latency-svc-8r58g [211.092834ms]
Apr  7 07:32:37.215: INFO: Got endpoints: latency-svc-bnsvl [196.31748ms]
Apr  7 07:32:37.223: INFO: Created: latency-svc-5ssj4
Apr  7 07:32:37.235: INFO: Got endpoints: latency-svc-5ssj4 [207.215084ms]
Apr  7 07:32:37.239: INFO: Created: latency-svc-gnvjc
Apr  7 07:32:37.251: INFO: Created: latency-svc-295zt
Apr  7 07:32:37.251: INFO: Got endpoints: latency-svc-gnvjc [205.834595ms]
Apr  7 07:32:37.262: INFO: Got endpoints: latency-svc-295zt [209.147309ms]
Apr  7 07:32:37.266: INFO: Created: latency-svc-mqmn7
Apr  7 07:32:37.273: INFO: Got endpoints: latency-svc-mqmn7 [209.117607ms]
Apr  7 07:32:37.277: INFO: Created: latency-svc-2xt77
Apr  7 07:32:37.287: INFO: Created: latency-svc-xxzhh
Apr  7 07:32:37.307: INFO: Created: latency-svc-zbv69
Apr  7 07:32:37.315: INFO: Got endpoints: latency-svc-2xt77 [237.586146ms]
Apr  7 07:32:37.342: INFO: Created: latency-svc-qh4k5
Apr  7 07:32:37.347: INFO: Created: latency-svc-shfft
Apr  7 07:32:37.373: INFO: Got endpoints: latency-svc-xxzhh [287.306157ms]
Apr  7 07:32:37.373: INFO: Created: latency-svc-4qnbx
Apr  7 07:32:37.389: INFO: Created: latency-svc-lskhm
Apr  7 07:32:37.404: INFO: Created: latency-svc-n6k9l
Apr  7 07:32:37.414: INFO: Got endpoints: latency-svc-zbv69 [316.087016ms]
Apr  7 07:32:37.418: INFO: Created: latency-svc-k29qp
Apr  7 07:32:37.428: INFO: Created: latency-svc-mkghz
Apr  7 07:32:37.437: INFO: Created: latency-svc-f2tr8
Apr  7 07:32:37.447: INFO: Created: latency-svc-6kzlc
Apr  7 07:32:37.457: INFO: Created: latency-svc-476k2
Apr  7 07:32:37.464: INFO: Got endpoints: latency-svc-qh4k5 [353.934861ms]
Apr  7 07:32:37.469: INFO: Created: latency-svc-5k8cz
Apr  7 07:32:37.481: INFO: Created: latency-svc-4v58g
Apr  7 07:32:37.493: INFO: Created: latency-svc-nh2mh
Apr  7 07:32:37.509: INFO: Created: latency-svc-zhj4l
Apr  7 07:32:37.514: INFO: Got endpoints: latency-svc-shfft [385.896025ms]
Apr  7 07:32:37.519: INFO: Created: latency-svc-blct4
Apr  7 07:32:37.530: INFO: Created: latency-svc-xhmqc
Apr  7 07:32:37.540: INFO: Created: latency-svc-m8lmj
Apr  7 07:32:37.566: INFO: Got endpoints: latency-svc-4qnbx [420.453557ms]
Apr  7 07:32:37.589: INFO: Created: latency-svc-hrgml
Apr  7 07:32:37.617: INFO: Got endpoints: latency-svc-lskhm [462.236856ms]
Apr  7 07:32:37.637: INFO: Created: latency-svc-wqhzz
Apr  7 07:32:37.666: INFO: Got endpoints: latency-svc-n6k9l [491.847168ms]
Apr  7 07:32:37.694: INFO: Created: latency-svc-625hc
Apr  7 07:32:37.716: INFO: Got endpoints: latency-svc-k29qp [526.85263ms]
Apr  7 07:32:37.736: INFO: Created: latency-svc-66rtp
Apr  7 07:32:37.774: INFO: Got endpoints: latency-svc-mkghz [565.915753ms]
Apr  7 07:32:37.796: INFO: Created: latency-svc-f4c6h
Apr  7 07:32:37.819: INFO: Got endpoints: latency-svc-f2tr8 [604.331533ms]
Apr  7 07:32:37.842: INFO: Created: latency-svc-pmdcc
Apr  7 07:32:37.867: INFO: Got endpoints: latency-svc-6kzlc [632.238036ms]
Apr  7 07:32:37.889: INFO: Created: latency-svc-n5pkc
Apr  7 07:32:37.917: INFO: Got endpoints: latency-svc-476k2 [666.83207ms]
Apr  7 07:32:37.948: INFO: Created: latency-svc-f4s4z
Apr  7 07:32:37.965: INFO: Got endpoints: latency-svc-5k8cz [703.51814ms]
Apr  7 07:32:37.991: INFO: Created: latency-svc-896xl
Apr  7 07:32:38.016: INFO: Got endpoints: latency-svc-4v58g [742.956288ms]
Apr  7 07:32:38.036: INFO: Created: latency-svc-nlwxm
Apr  7 07:32:38.065: INFO: Got endpoints: latency-svc-nh2mh [750.368466ms]
Apr  7 07:32:38.088: INFO: Created: latency-svc-l475q
Apr  7 07:32:38.116: INFO: Got endpoints: latency-svc-zhj4l [743.124298ms]
Apr  7 07:32:38.137: INFO: Created: latency-svc-g9bwr
Apr  7 07:32:38.169: INFO: Got endpoints: latency-svc-blct4 [755.406491ms]
Apr  7 07:32:38.189: INFO: Created: latency-svc-wp9vd
Apr  7 07:32:38.215: INFO: Got endpoints: latency-svc-xhmqc [751.235322ms]
Apr  7 07:32:38.236: INFO: Created: latency-svc-wc5j9
Apr  7 07:32:38.265: INFO: Got endpoints: latency-svc-m8lmj [751.355729ms]
Apr  7 07:32:38.287: INFO: Created: latency-svc-cbh6p
Apr  7 07:32:38.316: INFO: Got endpoints: latency-svc-hrgml [750.715188ms]
Apr  7 07:32:38.346: INFO: Created: latency-svc-7nzhh
Apr  7 07:32:38.366: INFO: Got endpoints: latency-svc-wqhzz [749.180289ms]
Apr  7 07:32:38.386: INFO: Created: latency-svc-klr4s
Apr  7 07:32:38.416: INFO: Got endpoints: latency-svc-625hc [750.679787ms]
Apr  7 07:32:38.448: INFO: Created: latency-svc-wmsrb
Apr  7 07:32:38.466: INFO: Got endpoints: latency-svc-66rtp [749.541013ms]
Apr  7 07:32:38.493: INFO: Created: latency-svc-t4s82
Apr  7 07:32:38.515: INFO: Got endpoints: latency-svc-f4c6h [741.029663ms]
Apr  7 07:32:38.548: INFO: Created: latency-svc-npvjg
Apr  7 07:32:38.568: INFO: Got endpoints: latency-svc-pmdcc [749.04898ms]
Apr  7 07:32:38.589: INFO: Created: latency-svc-csw9x
Apr  7 07:32:38.624: INFO: Got endpoints: latency-svc-n5pkc [756.583368ms]
Apr  7 07:32:38.649: INFO: Created: latency-svc-hfwcp
Apr  7 07:32:38.670: INFO: Got endpoints: latency-svc-f4s4z [752.064575ms]
Apr  7 07:32:38.692: INFO: Created: latency-svc-dtt29
Apr  7 07:32:38.716: INFO: Got endpoints: latency-svc-896xl [750.440771ms]
Apr  7 07:32:38.738: INFO: Created: latency-svc-rjp92
Apr  7 07:32:38.766: INFO: Got endpoints: latency-svc-nlwxm [749.3458ms]
Apr  7 07:32:38.787: INFO: Created: latency-svc-5zkbh
Apr  7 07:32:38.818: INFO: Got endpoints: latency-svc-l475q [752.336694ms]
Apr  7 07:32:38.839: INFO: Created: latency-svc-lspc8
Apr  7 07:32:38.868: INFO: Got endpoints: latency-svc-g9bwr [751.892964ms]
Apr  7 07:32:38.891: INFO: Created: latency-svc-m64mf
Apr  7 07:32:38.917: INFO: Got endpoints: latency-svc-wp9vd [747.901007ms]
Apr  7 07:32:38.949: INFO: Created: latency-svc-7lk9c
Apr  7 07:32:38.965: INFO: Got endpoints: latency-svc-wc5j9 [749.459608ms]
Apr  7 07:32:38.987: INFO: Created: latency-svc-vnq8q
Apr  7 07:32:39.017: INFO: Got endpoints: latency-svc-cbh6p [751.908665ms]
Apr  7 07:32:39.040: INFO: Created: latency-svc-rnc8w
Apr  7 07:32:39.066: INFO: Got endpoints: latency-svc-7nzhh [749.367501ms]
Apr  7 07:32:39.097: INFO: Created: latency-svc-scjzq
Apr  7 07:32:39.116: INFO: Got endpoints: latency-svc-klr4s [749.837532ms]
Apr  7 07:32:39.143: INFO: Created: latency-svc-gsd2v
Apr  7 07:32:39.170: INFO: Got endpoints: latency-svc-wmsrb [753.05944ms]
Apr  7 07:32:39.193: INFO: Created: latency-svc-f2vkz
Apr  7 07:32:39.215: INFO: Got endpoints: latency-svc-t4s82 [749.3397ms]
Apr  7 07:32:39.247: INFO: Created: latency-svc-mvxzm
Apr  7 07:32:39.264: INFO: Got endpoints: latency-svc-npvjg [748.895271ms]
Apr  7 07:32:39.290: INFO: Created: latency-svc-2fwvx
Apr  7 07:32:39.318: INFO: Got endpoints: latency-svc-csw9x [749.50201ms]
Apr  7 07:32:39.365: INFO: Created: latency-svc-7zdt6
Apr  7 07:32:39.380: INFO: Got endpoints: latency-svc-hfwcp [755.914324ms]
Apr  7 07:32:39.417: INFO: Got endpoints: latency-svc-dtt29 [747.007749ms]
Apr  7 07:32:39.418: INFO: Created: latency-svc-2lmcs
Apr  7 07:32:39.441: INFO: Created: latency-svc-hfdr5
Apr  7 07:32:39.470: INFO: Got endpoints: latency-svc-rjp92 [754.60164ms]
Apr  7 07:32:39.502: INFO: Created: latency-svc-bbv42
Apr  7 07:32:39.515: INFO: Got endpoints: latency-svc-5zkbh [749.377402ms]
Apr  7 07:32:39.552: INFO: Created: latency-svc-cldxv
Apr  7 07:32:39.566: INFO: Got endpoints: latency-svc-lspc8 [748.327334ms]
Apr  7 07:32:39.585: INFO: Created: latency-svc-28kdm
Apr  7 07:32:39.616: INFO: Got endpoints: latency-svc-m64mf [748.076618ms]
Apr  7 07:32:39.665: INFO: Created: latency-svc-pb652
Apr  7 07:32:39.675: INFO: Got endpoints: latency-svc-7lk9c [758.186771ms]
Apr  7 07:32:39.756: INFO: Created: latency-svc-zs45v
Apr  7 07:32:39.760: INFO: Got endpoints: latency-svc-vnq8q [795.067153ms]
Apr  7 07:32:39.766: INFO: Got endpoints: latency-svc-rnc8w [748.759362ms]
Apr  7 07:32:39.785: INFO: Created: latency-svc-dmj5r
Apr  7 07:32:39.825: INFO: Created: latency-svc-t6kgt
Apr  7 07:32:39.856: INFO: Got endpoints: latency-svc-scjzq [789.867817ms]
Apr  7 07:32:39.867: INFO: Got endpoints: latency-svc-gsd2v [750.848797ms]
Apr  7 07:32:39.914: INFO: Created: latency-svc-j9xpq
Apr  7 07:32:39.916: INFO: Got endpoints: latency-svc-f2vkz [746.277402ms]
Apr  7 07:32:39.939: INFO: Created: latency-svc-lg4vx
Apr  7 07:32:39.950: INFO: Created: latency-svc-bj7nh
Apr  7 07:32:39.977: INFO: Got endpoints: latency-svc-mvxzm [761.926012ms]
Apr  7 07:32:40.007: INFO: Created: latency-svc-zvj7z
Apr  7 07:32:40.016: INFO: Got endpoints: latency-svc-2fwvx [751.35353ms]
Apr  7 07:32:40.050: INFO: Created: latency-svc-nvt7p
Apr  7 07:32:40.070: INFO: Got endpoints: latency-svc-7zdt6 [752.424098ms]
Apr  7 07:32:40.104: INFO: Created: latency-svc-z6sc4
Apr  7 07:32:40.115: INFO: Got endpoints: latency-svc-2lmcs [735.271891ms]
Apr  7 07:32:40.140: INFO: Created: latency-svc-gg2kc
Apr  7 07:32:40.167: INFO: Got endpoints: latency-svc-hfdr5 [750.622383ms]
Apr  7 07:32:40.201: INFO: Created: latency-svc-gfk5p
Apr  7 07:32:40.216: INFO: Got endpoints: latency-svc-bbv42 [745.976683ms]
Apr  7 07:32:40.237: INFO: Created: latency-svc-cwp8d
Apr  7 07:32:40.269: INFO: Got endpoints: latency-svc-cldxv [753.462065ms]
Apr  7 07:32:40.295: INFO: Created: latency-svc-gt8cs
Apr  7 07:32:40.319: INFO: Got endpoints: latency-svc-28kdm [753.335957ms]
Apr  7 07:32:40.342: INFO: Created: latency-svc-7zpwv
Apr  7 07:32:40.367: INFO: Got endpoints: latency-svc-pb652 [750.494474ms]
Apr  7 07:32:40.389: INFO: Created: latency-svc-t95cs
Apr  7 07:32:40.418: INFO: Got endpoints: latency-svc-zs45v [742.281244ms]
Apr  7 07:32:40.440: INFO: Created: latency-svc-xvz52
Apr  7 07:32:40.465: INFO: Got endpoints: latency-svc-dmj5r [705.264252ms]
Apr  7 07:32:40.486: INFO: Created: latency-svc-7g6ct
Apr  7 07:32:40.516: INFO: Got endpoints: latency-svc-t6kgt [750.319463ms]
Apr  7 07:32:40.561: INFO: Created: latency-svc-cwdkl
Apr  7 07:32:40.566: INFO: Got endpoints: latency-svc-j9xpq [710.570795ms]
Apr  7 07:32:40.597: INFO: Created: latency-svc-fgtlm
Apr  7 07:32:40.616: INFO: Got endpoints: latency-svc-lg4vx [749.596616ms]
Apr  7 07:32:40.639: INFO: Created: latency-svc-w2546
Apr  7 07:32:40.674: INFO: Got endpoints: latency-svc-bj7nh [757.900453ms]
Apr  7 07:32:40.696: INFO: Created: latency-svc-6r88r
Apr  7 07:32:40.715: INFO: Got endpoints: latency-svc-zvj7z [737.201516ms]
Apr  7 07:32:40.740: INFO: Created: latency-svc-8c2wn
Apr  7 07:32:40.766: INFO: Got endpoints: latency-svc-nvt7p [750.314763ms]
Apr  7 07:32:40.794: INFO: Created: latency-svc-69rr2
Apr  7 07:32:40.815: INFO: Got endpoints: latency-svc-z6sc4 [745.378544ms]
Apr  7 07:32:40.840: INFO: Created: latency-svc-hd4dd
Apr  7 07:32:40.870: INFO: Got endpoints: latency-svc-gg2kc [754.391825ms]
Apr  7 07:32:40.893: INFO: Created: latency-svc-7b449
Apr  7 07:32:40.915: INFO: Got endpoints: latency-svc-gfk5p [748.037816ms]
Apr  7 07:32:40.934: INFO: Created: latency-svc-pp4zc
Apr  7 07:32:40.969: INFO: Got endpoints: latency-svc-cwp8d [753.147745ms]
Apr  7 07:32:40.991: INFO: Created: latency-svc-pwrn7
Apr  7 07:32:41.015: INFO: Got endpoints: latency-svc-gt8cs [746.625524ms]
Apr  7 07:32:41.035: INFO: Created: latency-svc-t2zg2
Apr  7 07:32:41.066: INFO: Got endpoints: latency-svc-7zpwv [746.996849ms]
Apr  7 07:32:41.089: INFO: Created: latency-svc-4kfj7
Apr  7 07:32:41.123: INFO: Got endpoints: latency-svc-t95cs [755.963027ms]
Apr  7 07:32:41.153: INFO: Created: latency-svc-chmdr
Apr  7 07:32:41.167: INFO: Got endpoints: latency-svc-xvz52 [749.341899ms]
Apr  7 07:32:41.191: INFO: Created: latency-svc-gxk5v
Apr  7 07:32:41.216: INFO: Got endpoints: latency-svc-7g6ct [750.75289ms]
Apr  7 07:32:41.235: INFO: Created: latency-svc-bvk72
Apr  7 07:32:41.267: INFO: Got endpoints: latency-svc-cwdkl [750.467573ms]
Apr  7 07:32:41.286: INFO: Created: latency-svc-nc6jn
Apr  7 07:32:41.315: INFO: Got endpoints: latency-svc-fgtlm [748.833466ms]
Apr  7 07:32:41.338: INFO: Created: latency-svc-b97ct
Apr  7 07:32:41.366: INFO: Got endpoints: latency-svc-w2546 [749.458007ms]
Apr  7 07:32:41.414: INFO: Created: latency-svc-vfwpj
Apr  7 07:32:41.416: INFO: Got endpoints: latency-svc-6r88r [742.282544ms]
Apr  7 07:32:41.446: INFO: Created: latency-svc-k2xkv
Apr  7 07:32:41.481: INFO: Got endpoints: latency-svc-8c2wn [766.044478ms]
Apr  7 07:32:41.503: INFO: Created: latency-svc-r4src
Apr  7 07:32:41.526: INFO: Got endpoints: latency-svc-69rr2 [759.671666ms]
Apr  7 07:32:41.551: INFO: Created: latency-svc-vfsgz
Apr  7 07:32:41.565: INFO: Got endpoints: latency-svc-hd4dd [749.225192ms]
Apr  7 07:32:41.592: INFO: Created: latency-svc-ng8fl
Apr  7 07:32:41.616: INFO: Got endpoints: latency-svc-7b449 [746.118591ms]
Apr  7 07:32:41.635: INFO: Created: latency-svc-x4qvn
Apr  7 07:32:41.666: INFO: Got endpoints: latency-svc-pp4zc [751.099413ms]
Apr  7 07:32:41.708: INFO: Created: latency-svc-7ckz8
Apr  7 07:32:41.718: INFO: Got endpoints: latency-svc-pwrn7 [748.062817ms]
Apr  7 07:32:41.737: INFO: Created: latency-svc-j96p4
Apr  7 07:32:41.766: INFO: Got endpoints: latency-svc-t2zg2 [750.683687ms]
Apr  7 07:32:41.793: INFO: Created: latency-svc-s72l6
Apr  7 07:32:41.833: INFO: Got endpoints: latency-svc-4kfj7 [766.257292ms]
Apr  7 07:32:41.854: INFO: Created: latency-svc-4fvrj
Apr  7 07:32:41.865: INFO: Got endpoints: latency-svc-chmdr [742.858481ms]
Apr  7 07:32:41.886: INFO: Created: latency-svc-bxhtb
Apr  7 07:32:41.922: INFO: Got endpoints: latency-svc-gxk5v [755.259682ms]
Apr  7 07:32:41.946: INFO: Created: latency-svc-lwqlf
Apr  7 07:32:41.965: INFO: Got endpoints: latency-svc-bvk72 [749.559314ms]
Apr  7 07:32:41.985: INFO: Created: latency-svc-d22cr
Apr  7 07:32:42.017: INFO: Got endpoints: latency-svc-nc6jn [750.389068ms]
Apr  7 07:32:42.049: INFO: Created: latency-svc-97t88
Apr  7 07:32:42.067: INFO: Got endpoints: latency-svc-b97ct [751.467537ms]
Apr  7 07:32:42.101: INFO: Created: latency-svc-64kbj
Apr  7 07:32:42.116: INFO: Got endpoints: latency-svc-vfwpj [749.841232ms]
Apr  7 07:32:42.164: INFO: Created: latency-svc-tskvg
Apr  7 07:32:42.164: INFO: Got endpoints: latency-svc-k2xkv [748.26493ms]
Apr  7 07:32:42.207: INFO: Created: latency-svc-cfmsb
Apr  7 07:32:42.215: INFO: Got endpoints: latency-svc-r4src [734.773359ms]
Apr  7 07:32:42.235: INFO: Created: latency-svc-q79kt
Apr  7 07:32:42.267: INFO: Got endpoints: latency-svc-vfsgz [740.758945ms]
Apr  7 07:32:42.286: INFO: Created: latency-svc-fpv7v
Apr  7 07:32:42.315: INFO: Got endpoints: latency-svc-ng8fl [750.279361ms]
Apr  7 07:32:42.345: INFO: Created: latency-svc-6lxb9
Apr  7 07:32:42.369: INFO: Got endpoints: latency-svc-x4qvn [753.427464ms]
Apr  7 07:32:42.407: INFO: Created: latency-svc-j4sfw
Apr  7 07:32:42.415: INFO: Got endpoints: latency-svc-7ckz8 [748.829766ms]
Apr  7 07:32:42.450: INFO: Created: latency-svc-5pwns
Apr  7 07:32:42.466: INFO: Got endpoints: latency-svc-j96p4 [748.406439ms]
Apr  7 07:32:42.491: INFO: Created: latency-svc-pzhh6
Apr  7 07:32:42.517: INFO: Got endpoints: latency-svc-s72l6 [751.044309ms]
Apr  7 07:32:42.544: INFO: Created: latency-svc-hx9ts
Apr  7 07:32:42.565: INFO: Got endpoints: latency-svc-4fvrj [732.082785ms]
Apr  7 07:32:42.593: INFO: Created: latency-svc-tbwdt
Apr  7 07:32:42.617: INFO: Got endpoints: latency-svc-bxhtb [751.982071ms]
Apr  7 07:32:42.638: INFO: Created: latency-svc-8jb46
Apr  7 07:32:42.665: INFO: Got endpoints: latency-svc-lwqlf [742.629466ms]
Apr  7 07:32:42.692: INFO: Created: latency-svc-qwmb9
Apr  7 07:32:42.714: INFO: Got endpoints: latency-svc-d22cr [748.472444ms]
Apr  7 07:32:42.735: INFO: Created: latency-svc-5gq6v
Apr  7 07:32:42.769: INFO: Got endpoints: latency-svc-97t88 [751.635248ms]
Apr  7 07:32:42.791: INFO: Created: latency-svc-z77mw
Apr  7 07:32:42.816: INFO: Got endpoints: latency-svc-64kbj [749.088083ms]
Apr  7 07:32:42.839: INFO: Created: latency-svc-q2zq4
Apr  7 07:32:42.865: INFO: Got endpoints: latency-svc-tskvg [748.947674ms]
Apr  7 07:32:42.896: INFO: Created: latency-svc-5p5fb
Apr  7 07:32:42.914: INFO: Got endpoints: latency-svc-cfmsb [749.947639ms]
Apr  7 07:32:42.934: INFO: Created: latency-svc-8lgtb
Apr  7 07:32:42.965: INFO: Got endpoints: latency-svc-q79kt [749.573914ms]
Apr  7 07:32:42.987: INFO: Created: latency-svc-74zbr
Apr  7 07:32:43.018: INFO: Got endpoints: latency-svc-fpv7v [751.678151ms]
Apr  7 07:32:43.039: INFO: Created: latency-svc-v85kc
Apr  7 07:32:43.069: INFO: Got endpoints: latency-svc-6lxb9 [753.566273ms]
Apr  7 07:32:43.090: INFO: Created: latency-svc-95pr2
Apr  7 07:32:43.115: INFO: Got endpoints: latency-svc-j4sfw [745.626459ms]
Apr  7 07:32:43.139: INFO: Created: latency-svc-9ddxw
Apr  7 07:32:43.165: INFO: Got endpoints: latency-svc-5pwns [749.385803ms]
Apr  7 07:32:43.186: INFO: Created: latency-svc-6fqgh
Apr  7 07:32:43.219: INFO: Got endpoints: latency-svc-pzhh6 [753.332257ms]
Apr  7 07:32:43.265: INFO: Got endpoints: latency-svc-hx9ts [747.498381ms]
Apr  7 07:32:43.277: INFO: Created: latency-svc-ktv64
Apr  7 07:32:43.300: INFO: Created: latency-svc-swqgc
Apr  7 07:32:43.315: INFO: Got endpoints: latency-svc-tbwdt [750.218656ms]
Apr  7 07:32:43.335: INFO: Created: latency-svc-78hkp
Apr  7 07:32:43.366: INFO: Got endpoints: latency-svc-8jb46 [748.854268ms]
Apr  7 07:32:43.390: INFO: Created: latency-svc-f92hz
Apr  7 07:32:43.416: INFO: Got endpoints: latency-svc-qwmb9 [751.071412ms]
Apr  7 07:32:43.440: INFO: Created: latency-svc-v9n89
Apr  7 07:32:43.465: INFO: Got endpoints: latency-svc-5gq6v [751.301926ms]
Apr  7 07:32:43.491: INFO: Created: latency-svc-x45df
Apr  7 07:32:43.515: INFO: Got endpoints: latency-svc-z77mw [746.464113ms]
Apr  7 07:32:43.542: INFO: Created: latency-svc-5d5fj
Apr  7 07:32:43.567: INFO: Got endpoints: latency-svc-q2zq4 [750.598081ms]
Apr  7 07:32:43.590: INFO: Created: latency-svc-pfm5w
Apr  7 07:32:43.625: INFO: Got endpoints: latency-svc-5p5fb [760.350611ms]
Apr  7 07:32:43.647: INFO: Created: latency-svc-d2tsw
Apr  7 07:32:43.665: INFO: Got endpoints: latency-svc-8lgtb [750.73549ms]
Apr  7 07:32:43.703: INFO: Created: latency-svc-wq7ff
Apr  7 07:32:43.719: INFO: Got endpoints: latency-svc-74zbr [753.451165ms]
Apr  7 07:32:43.741: INFO: Created: latency-svc-wh8zf
Apr  7 07:32:43.766: INFO: Got endpoints: latency-svc-v85kc [747.893806ms]
Apr  7 07:32:43.793: INFO: Created: latency-svc-t4pj6
Apr  7 07:32:43.816: INFO: Got endpoints: latency-svc-95pr2 [747.658791ms]
Apr  7 07:32:43.838: INFO: Created: latency-svc-hh7bh
Apr  7 07:32:43.865: INFO: Got endpoints: latency-svc-9ddxw [749.488609ms]
Apr  7 07:32:43.886: INFO: Created: latency-svc-tzc8v
Apr  7 07:32:43.924: INFO: Got endpoints: latency-svc-6fqgh [758.838713ms]
Apr  7 07:32:43.952: INFO: Created: latency-svc-7wq6x
Apr  7 07:32:43.967: INFO: Got endpoints: latency-svc-ktv64 [748.030015ms]
Apr  7 07:32:43.994: INFO: Created: latency-svc-4zbnh
Apr  7 07:32:44.014: INFO: Got endpoints: latency-svc-swqgc [749.676521ms]
Apr  7 07:32:44.039: INFO: Created: latency-svc-jhdmr
Apr  7 07:32:44.075: INFO: Got endpoints: latency-svc-78hkp [760.119396ms]
Apr  7 07:32:44.097: INFO: Created: latency-svc-n2npw
Apr  7 07:32:44.115: INFO: Got endpoints: latency-svc-f92hz [748.589351ms]
Apr  7 07:32:44.145: INFO: Created: latency-svc-4jsnw
Apr  7 07:32:44.165: INFO: Got endpoints: latency-svc-v9n89 [749.054781ms]
Apr  7 07:32:44.197: INFO: Created: latency-svc-f5m8g
Apr  7 07:32:44.217: INFO: Got endpoints: latency-svc-x45df [751.481638ms]
Apr  7 07:32:44.237: INFO: Created: latency-svc-zplc5
Apr  7 07:32:44.267: INFO: Got endpoints: latency-svc-5d5fj [751.52234ms]
Apr  7 07:32:44.306: INFO: Created: latency-svc-sdgwx
Apr  7 07:32:44.314: INFO: Got endpoints: latency-svc-pfm5w [747.681493ms]
Apr  7 07:32:44.334: INFO: Created: latency-svc-cjz62
Apr  7 07:32:44.366: INFO: Got endpoints: latency-svc-d2tsw [740.923256ms]
Apr  7 07:32:44.408: INFO: Created: latency-svc-55xtn
Apr  7 07:32:44.416: INFO: Got endpoints: latency-svc-wq7ff [750.380966ms]
Apr  7 07:32:44.438: INFO: Created: latency-svc-5gmmv
Apr  7 07:32:44.464: INFO: Got endpoints: latency-svc-wh8zf [745.800371ms]
Apr  7 07:32:44.484: INFO: Created: latency-svc-hpcxc
Apr  7 07:32:44.515: INFO: Got endpoints: latency-svc-t4pj6 [748.633454ms]
Apr  7 07:32:44.566: INFO: Got endpoints: latency-svc-hh7bh [749.157488ms]
Apr  7 07:32:44.618: INFO: Got endpoints: latency-svc-tzc8v [753.37106ms]
Apr  7 07:32:44.675: INFO: Got endpoints: latency-svc-7wq6x [750.878799ms]
Apr  7 07:32:44.715: INFO: Got endpoints: latency-svc-4zbnh [747.698394ms]
Apr  7 07:32:44.766: INFO: Got endpoints: latency-svc-jhdmr [751.664149ms]
Apr  7 07:32:44.816: INFO: Got endpoints: latency-svc-n2npw [740.761445ms]
Apr  7 07:32:44.867: INFO: Got endpoints: latency-svc-4jsnw [751.552743ms]
Apr  7 07:32:44.916: INFO: Got endpoints: latency-svc-f5m8g [750.148847ms]
Apr  7 07:32:44.967: INFO: Got endpoints: latency-svc-zplc5 [749.81452ms]
Apr  7 07:32:45.018: INFO: Got endpoints: latency-svc-sdgwx [751.315812ms]
Apr  7 07:32:45.067: INFO: Got endpoints: latency-svc-cjz62 [752.567386ms]
Apr  7 07:32:45.115: INFO: Got endpoints: latency-svc-55xtn [749.257868ms]
Apr  7 07:32:45.167: INFO: Got endpoints: latency-svc-5gmmv [751.690318ms]
Apr  7 07:32:45.214: INFO: Got endpoints: latency-svc-hpcxc [749.649582ms]
Apr  7 07:32:45.214: INFO: Latencies: [26.042477ms 39.352734ms 59.62684ms 84.616349ms 105.563097ms 128.496675ms 144.128681ms 168.504083ms 176.114441ms 176.120041ms 182.086858ms 184.69903ms 187.095984ms 187.576179ms 189.249024ms 189.869763ms 190.208885ms 190.402098ms 195.221209ms 195.323514ms 196.31748ms 198.981649ms 199.551376ms 203.471142ms 204.537901ms 204.731186ms 205.834595ms 206.684049ms 207.215084ms 207.831606ms 209.117607ms 209.147309ms 211.092834ms 212.280773ms 216.317551ms 226.421687ms 235.072957ms 237.586146ms 240.888321ms 249.744893ms 251.937842ms 263.600993ms 287.306157ms 316.087016ms 353.934861ms 385.896025ms 420.453557ms 462.236856ms 491.847168ms 526.85263ms 565.915753ms 604.331533ms 632.238036ms 666.83207ms 703.51814ms 705.264252ms 710.570795ms 732.082785ms 734.773359ms 735.271891ms 737.201516ms 740.758945ms 740.761445ms 740.923256ms 741.029663ms 742.281244ms 742.282544ms 742.629466ms 742.858481ms 742.956288ms 743.124298ms 745.378544ms 745.626459ms 745.800371ms 745.976683ms 746.118591ms 746.277402ms 746.464113ms 746.625524ms 746.996849ms 747.007749ms 747.498381ms 747.658791ms 747.681493ms 747.698394ms 747.893806ms 747.901007ms 748.030015ms 748.037816ms 748.062817ms 748.076618ms 748.26493ms 748.327334ms 748.406439ms 748.472444ms 748.589351ms 748.633454ms 748.759362ms 748.829766ms 748.833466ms 748.854268ms 748.895271ms 748.947674ms 749.04898ms 749.054781ms 749.088083ms 749.157488ms 749.180289ms 749.225192ms 749.257868ms 749.3397ms 749.341899ms 749.3458ms 749.367501ms 749.377402ms 749.385803ms 749.458007ms 749.459608ms 749.488609ms 749.50201ms 749.541013ms 749.559314ms 749.573914ms 749.596616ms 749.649582ms 749.676521ms 749.81452ms 749.837532ms 749.841232ms 749.947639ms 750.148847ms 750.218656ms 750.279361ms 750.314763ms 750.319463ms 750.368466ms 750.380966ms 750.389068ms 750.440771ms 750.467573ms 750.494474ms 750.598081ms 750.622383ms 750.679787ms 750.683687ms 750.715188ms 750.73549ms 750.75289ms 750.848797ms 750.878799ms 751.044309ms 751.071412ms 751.099413ms 751.235322ms 751.301926ms 751.315812ms 751.35353ms 751.355729ms 751.467537ms 751.481638ms 751.52234ms 751.552743ms 751.635248ms 751.664149ms 751.678151ms 751.690318ms 751.892964ms 751.908665ms 751.982071ms 752.064575ms 752.336694ms 752.424098ms 752.567386ms 753.05944ms 753.147745ms 753.332257ms 753.335957ms 753.37106ms 753.427464ms 753.451165ms 753.462065ms 753.566273ms 754.391825ms 754.60164ms 755.259682ms 755.406491ms 755.914324ms 755.963027ms 756.583368ms 757.900453ms 758.186771ms 758.838713ms 759.671666ms 760.119396ms 760.350611ms 761.926012ms 766.044478ms 766.257292ms 789.867817ms 795.067153ms]
Apr  7 07:32:45.214: INFO: 50 %ile: 748.854268ms
Apr  7 07:32:45.214: INFO: 90 %ile: 753.462065ms
Apr  7 07:32:45.214: INFO: 99 %ile: 789.867817ms
Apr  7 07:32:45.214: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:45.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4547" for this suite.

• [SLOW TEST:10.917 seconds]
[sig-network] Service endpoints latency
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":346,"completed":279,"skipped":5406,"failed":0}
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:45.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  7 07:32:46.379: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:46.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2389" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":280,"skipped":5410,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:46.438: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's args
Apr  7 07:32:46.545: INFO: Waiting up to 5m0s for pod "var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a" in namespace "var-expansion-7252" to be "Succeeded or Failed"
Apr  7 07:32:46.553: INFO: Pod "var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.397677ms
Apr  7 07:32:48.567: INFO: Pod "var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021779858s
STEP: Saw pod success
Apr  7 07:32:48.567: INFO: Pod "var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a" satisfied condition "Succeeded or Failed"
Apr  7 07:32:48.574: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:32:48.630: INFO: Waiting for pod var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a to disappear
Apr  7 07:32:48.638: INFO: Pod var-expansion-eaeafbb0-e6ae-44cf-b34b-b0260f05000a no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:48.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7252" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":346,"completed":281,"skipped":5450,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:48.674: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 07:32:48.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 07:32:48.818: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 07:32:49.842: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:32:49.842: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:32:50.850: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 07:32:50.850: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
Apr  7 07:32:50.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36007"},"items":null}

Apr  7 07:32:50.965: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36009"},"items":[{"metadata":{"name":"daemon-set-v5qkp","generateName":"daemon-set-","namespace":"daemonsets-7938","uid":"74d53ec4-cd32-4c62-8b0e-1fd93d3b4a89","resourceVersion":"36008","creationTimestamp":"2022-04-07T07:32:48Z","deletionTimestamp":"2022-04-07T07:33:20Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d362cb16-b58a-42cd-a410-aacc39540673","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-04-07T07:32:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d362cb16-b58a-42cd-a410-aacc39540673\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-04-07T07:32:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.168\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mfqm7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mfqm7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"aks-nodepool1-35379194-vmss000001","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["aks-nodepool1-35379194-vmss000001"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:48Z"}],"hostIP":"10.240.0.5","podIP":"10.244.1.168","podIPs":[{"ip":"10.244.1.168"}],"startTime":"2022-04-07T07:32:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-04-07T07:32:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://d364591a40449a7a1c3a710ba8e894c01e4d62817d6002d32d40759ef4fc68b6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wh6gm","generateName":"daemon-set-","namespace":"daemonsets-7938","uid":"b4640eaf-4160-4519-8574-b2343a54e5fc","resourceVersion":"36007","creationTimestamp":"2022-04-07T07:32:48Z","deletionTimestamp":"2022-04-07T07:33:20Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"d362cb16-b58a-42cd-a410-aacc39540673","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-04-07T07:32:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d362cb16-b58a-42cd-a410-aacc39540673\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-04-07T07:32:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-dc2nf","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-dc2nf","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"aks-nodepool1-35379194-vmss000000","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["aks-nodepool1-35379194-vmss000000"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:49Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:49Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-07T07:32:48Z"}],"hostIP":"10.240.0.4","podIP":"10.244.0.233","podIPs":[{"ip":"10.244.0.233"}],"startTime":"2022-04-07T07:32:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-04-07T07:32:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b822e25d00cf83d1dd3540508465f155b14918ccca6091c0a4d4c45e1053ba8e","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:32:50.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7938" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":346,"completed":282,"skipped":5453,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:32:51.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating all guestbook components
Apr  7 07:32:51.103: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr  7 07:32:51.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:51.279: INFO: stderr: ""
Apr  7 07:32:51.279: INFO: stdout: "service/agnhost-replica created\n"
Apr  7 07:32:51.279: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr  7 07:32:51.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:51.448: INFO: stderr: ""
Apr  7 07:32:51.448: INFO: stdout: "service/agnhost-primary created\n"
Apr  7 07:32:51.448: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  7 07:32:51.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:51.629: INFO: stderr: ""
Apr  7 07:32:51.629: INFO: stdout: "service/frontend created\n"
Apr  7 07:32:51.629: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr  7 07:32:51.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:51.802: INFO: stderr: ""
Apr  7 07:32:51.802: INFO: stdout: "deployment.apps/frontend created\n"
Apr  7 07:32:51.802: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  7 07:32:51.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:52.033: INFO: stderr: ""
Apr  7 07:32:52.033: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr  7 07:32:52.033: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.33
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  7 07:32:52.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 create -f -'
Apr  7 07:32:52.185: INFO: stderr: ""
Apr  7 07:32:52.185: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Apr  7 07:32:52.185: INFO: Waiting for all frontend pods to be Running.
Apr  7 07:32:57.236: INFO: Waiting for frontend to serve content.
Apr  7 07:32:57.242: INFO: Failed to get response from guestbook. err: the server could not find the requested resource (get services frontend), response: k8s 

v1StatusY

   Failureservices "frontend" not found"NotFound*
frontend services( 2 0� " 
Apr  7 07:33:02.270: INFO: Trying to add a new entry to the guestbook.
Apr  7 07:33:02.292: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  7 07:33:02.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:02.465: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:02.465: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 07:33:02.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:02.592: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:02.593: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 07:33:02.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:02.732: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:02.732: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 07:33:02.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:02.834: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:02.834: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 07:33:02.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:02.922: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:02.922: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Apr  7 07:33:02.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-8806 delete --grace-period=0 --force -f -'
Apr  7 07:33:03.011: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:33:03.011: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:33:03.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8806" for this suite.

• [SLOW TEST:12.022 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:339
    should create and stop a working application  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":346,"completed":283,"skipped":5478,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:33:03.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:33:14.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6215" for this suite.

• [SLOW TEST:11.230 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":346,"completed":284,"skipped":5491,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:33:14.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  7 07:33:14.409: INFO: Waiting up to 5m0s for pod "pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38" in namespace "emptydir-6629" to be "Succeeded or Failed"
Apr  7 07:33:14.418: INFO: Pod "pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38": Phase="Pending", Reason="", readiness=false. Elapsed: 8.638454ms
Apr  7 07:33:16.428: INFO: Pod "pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01854027s
STEP: Saw pod success
Apr  7 07:33:16.428: INFO: Pod "pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38" satisfied condition "Succeeded or Failed"
Apr  7 07:33:16.435: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38 container test-container: <nil>
STEP: delete the pod
Apr  7 07:33:16.492: INFO: Waiting for pod pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38 to disappear
Apr  7 07:33:16.502: INFO: Pod pod-8b2ff4e9-44ea-47f3-96be-f9b6135dbb38 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:33:16.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6629" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":285,"skipped":5499,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:33:16.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:33:16.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6078" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":346,"completed":286,"skipped":5502,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:33:16.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-3324
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Apr  7 07:33:16.877: INFO: Found 0 stateful pods, waiting for 3
Apr  7 07:33:26.888: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:33:26.888: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:33:26.888: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  7 07:33:26.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3324 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:33:27.136: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:33:27.136: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:33:27.136: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Apr  7 07:33:37.221: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  7 07:33:47.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3324 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:33:47.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:33:47.476: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:33:47.476: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Apr  7 07:33:57.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3324 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  7 07:33:57.747: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  7 07:33:57.747: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  7 07:33:57.747: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  7 07:34:07.819: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  7 07:34:17.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=statefulset-3324 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  7 07:34:18.095: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  7 07:34:18.095: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  7 07:34:18.095: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 07:34:28.155: INFO: Deleting all statefulset in ns statefulset-3324
Apr  7 07:34:28.163: INFO: Scaling statefulset ss2 to 0
Apr  7 07:34:38.228: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:34:38.241: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:34:38.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3324" for this suite.

• [SLOW TEST:81.552 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":346,"completed":287,"skipped":5593,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:34:38.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:34:39.013: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:34:42.070: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:34:42.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4719" for this suite.
STEP: Destroying namespace "webhook-4719-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":346,"completed":288,"skipped":5613,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:34:42.329: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-845e4f9c-b4af-4c66-8888-730ce427d67c in namespace container-probe-8006
Apr  7 07:34:44.471: INFO: Started pod liveness-845e4f9c-b4af-4c66-8888-730ce427d67c in namespace container-probe-8006
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 07:34:44.479: INFO: Initial restart count of pod liveness-845e4f9c-b4af-4c66-8888-730ce427d67c is 0
Apr  7 07:35:04.616: INFO: Restart count of pod container-probe-8006/liveness-845e4f9c-b4af-4c66-8888-730ce427d67c is now 1 (20.137501151s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:04.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8006" for this suite.

• [SLOW TEST:22.337 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":289,"skipped":5678,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:04.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:35:04.785: INFO: Endpoints addresses: [52.152.247.171] , ports: [443]
Apr  7 07:35:04.786: INFO: EndpointSlices addresses: [52.152.247.171] , ports: [443]
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:04.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9062" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":346,"completed":290,"skipped":5696,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:04.818: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:35:04.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  7 07:35:07.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7716 --namespace=crd-publish-openapi-7716 create -f -'
Apr  7 07:35:08.550: INFO: stderr: ""
Apr  7 07:35:08.550: INFO: stdout: "e2e-test-crd-publish-openapi-5791-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr  7 07:35:08.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7716 --namespace=crd-publish-openapi-7716 delete e2e-test-crd-publish-openapi-5791-crds test-cr'
Apr  7 07:35:08.779: INFO: stderr: ""
Apr  7 07:35:08.779: INFO: stdout: "e2e-test-crd-publish-openapi-5791-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr  7 07:35:08.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7716 --namespace=crd-publish-openapi-7716 apply -f -'
Apr  7 07:35:08.940: INFO: stderr: ""
Apr  7 07:35:08.940: INFO: stdout: "e2e-test-crd-publish-openapi-5791-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr  7 07:35:08.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7716 --namespace=crd-publish-openapi-7716 delete e2e-test-crd-publish-openapi-5791-crds test-cr'
Apr  7 07:35:09.033: INFO: stderr: ""
Apr  7 07:35:09.033: INFO: stdout: "e2e-test-crd-publish-openapi-5791-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr  7 07:35:09.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-7716 explain e2e-test-crd-publish-openapi-5791-crds'
Apr  7 07:35:09.679: INFO: stderr: ""
Apr  7 07:35:09.679: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5791-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:12.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7716" for this suite.

• [SLOW TEST:7.662 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":346,"completed":291,"skipped":5709,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:12.480: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service endpoint-test2 in namespace services-4329
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4329 to expose endpoints map[]
Apr  7 07:35:12.639: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Apr  7 07:35:13.659: INFO: successfully validated that service endpoint-test2 in namespace services-4329 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4329
Apr  7 07:35:13.689: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:35:15.704: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4329 to expose endpoints map[pod1:[80]]
Apr  7 07:35:15.742: INFO: successfully validated that service endpoint-test2 in namespace services-4329 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Apr  7 07:35:15.742: INFO: Creating new exec pod
Apr  7 07:35:18.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr  7 07:35:18.988: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:18.988: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:35:18.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.109.104 80'
Apr  7 07:35:19.188: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.109.104 80\nConnection to 10.0.109.104 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:19.188: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-4329
Apr  7 07:35:19.213: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:35:21.233: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4329 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  7 07:35:21.284: INFO: successfully validated that service endpoint-test2 in namespace services-4329 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Apr  7 07:35:22.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr  7 07:35:22.506: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:22.506: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:35:22.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.109.104 80'
Apr  7 07:35:22.708: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.109.104 80\nConnection to 10.0.109.104 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:22.708: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4329
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4329 to expose endpoints map[pod2:[80]]
Apr  7 07:35:22.761: INFO: successfully validated that service endpoint-test2 in namespace services-4329 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Apr  7 07:35:23.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr  7 07:35:23.978: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:23.978: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr  7 07:35:23.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4329 exec execpod2mbq6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.109.104 80'
Apr  7 07:35:24.165: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.109.104 80\nConnection to 10.0.109.104 80 port [tcp/http] succeeded!\n"
Apr  7 07:35:24.165: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-4329
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4329 to expose endpoints map[]
Apr  7 07:35:25.232: INFO: successfully validated that service endpoint-test2 in namespace services-4329 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:25.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4329" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:12.813 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":346,"completed":292,"skipped":5752,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:25.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in volume subpath
Apr  7 07:35:25.410: INFO: Waiting up to 5m0s for pod "var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc" in namespace "var-expansion-3387" to be "Succeeded or Failed"
Apr  7 07:35:25.417: INFO: Pod "var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.963248ms
Apr  7 07:35:27.429: INFO: Pod "var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018926977s
STEP: Saw pod success
Apr  7 07:35:27.429: INFO: Pod "var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc" satisfied condition "Succeeded or Failed"
Apr  7 07:35:27.438: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:35:27.498: INFO: Waiting for pod var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc to disappear
Apr  7 07:35:27.506: INFO: Pod var-expansion-757384ca-e7ad-4ad8-b898-d83bed6089dc no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:27.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3387" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":346,"completed":293,"skipped":5754,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:27.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:35:27.664: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  7 07:35:32.680: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Apr  7 07:35:32.701: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Apr  7 07:35:32.722: INFO: observed ReplicaSet test-rs in namespace replicaset-9888 with ReadyReplicas 1, AvailableReplicas 1
Apr  7 07:35:32.763: INFO: observed ReplicaSet test-rs in namespace replicaset-9888 with ReadyReplicas 1, AvailableReplicas 1
Apr  7 07:35:32.784: INFO: observed ReplicaSet test-rs in namespace replicaset-9888 with ReadyReplicas 1, AvailableReplicas 1
Apr  7 07:35:32.797: INFO: observed ReplicaSet test-rs in namespace replicaset-9888 with ReadyReplicas 1, AvailableReplicas 1
Apr  7 07:35:33.732: INFO: observed ReplicaSet test-rs in namespace replicaset-9888 with ReadyReplicas 2, AvailableReplicas 2
Apr  7 07:35:34.164: INFO: observed Replicaset test-rs in namespace replicaset-9888 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:34.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9888" for this suite.

• [SLOW TEST:6.672 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":346,"completed":294,"skipped":5755,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:34.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:35:34.295: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:35:36.306: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:38.305: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:40.307: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:42.309: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:44.310: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:46.304: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:48.310: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:50.309: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:52.309: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:54.305: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = false)
Apr  7 07:35:56.313: INFO: The status of Pod test-webserver-849e9e2c-b942-41df-8f6c-52c2b765f28c is Running (Ready = true)
Apr  7 07:35:56.325: INFO: Container started at 2022-04-07 07:35:34 +0000 UTC, pod became ready at 2022-04-07 07:35:54 +0000 UTC
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:56.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5591" for this suite.

• [SLOW TEST:22.154 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":346,"completed":295,"skipped":5834,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:56.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  7 07:35:56.481: INFO: Waiting up to 5m0s for pod "pod-f718f34c-07f9-4b26-9266-9f2cdbb39763" in namespace "emptydir-5940" to be "Succeeded or Failed"
Apr  7 07:35:56.490: INFO: Pod "pod-f718f34c-07f9-4b26-9266-9f2cdbb39763": Phase="Pending", Reason="", readiness=false. Elapsed: 9.806932ms
Apr  7 07:35:58.510: INFO: Pod "pod-f718f34c-07f9-4b26-9266-9f2cdbb39763": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029174218s
STEP: Saw pod success
Apr  7 07:35:58.510: INFO: Pod "pod-f718f34c-07f9-4b26-9266-9f2cdbb39763" satisfied condition "Succeeded or Failed"
Apr  7 07:35:58.517: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-f718f34c-07f9-4b26-9266-9f2cdbb39763 container test-container: <nil>
STEP: delete the pod
Apr  7 07:35:58.563: INFO: Waiting for pod pod-f718f34c-07f9-4b26-9266-9f2cdbb39763 to disappear
Apr  7 07:35:58.571: INFO: Pod pod-f718f34c-07f9-4b26-9266-9f2cdbb39763 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:35:58.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5940" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":296,"skipped":5834,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:35:58.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod test-webserver-ff3847b4-71e3-4470-9915-5dd41b06c4bd in namespace container-probe-9224
Apr  7 07:36:00.732: INFO: Started pod test-webserver-ff3847b4-71e3-4470-9915-5dd41b06c4bd in namespace container-probe-9224
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 07:36:00.740: INFO: Initial restart count of pod test-webserver-ff3847b4-71e3-4470-9915-5dd41b06c4bd is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:02.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9224" for this suite.

• [SLOW TEST:244.204 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":297,"skipped":5872,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:40:02.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd" in namespace "projected-8306" to be "Succeeded or Failed"
Apr  7 07:40:02.926: INFO: Pod "downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.418945ms
Apr  7 07:40:04.940: INFO: Pod "downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022292982s
STEP: Saw pod success
Apr  7 07:40:04.940: INFO: Pod "downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd" satisfied condition "Succeeded or Failed"
Apr  7 07:40:04.951: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd container client-container: <nil>
STEP: delete the pod
Apr  7 07:40:05.006: INFO: Waiting for pod downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd to disappear
Apr  7 07:40:05.013: INFO: Pod downwardapi-volume-04029f1f-5d73-4536-8abe-4051ddc2e0cd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:05.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8306" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":298,"skipped":5877,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:05.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-842e546e-4c64-4551-a494-d0aeb974dfa7
STEP: Creating a pod to test consume secrets
Apr  7 07:40:05.150: INFO: Waiting up to 5m0s for pod "pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50" in namespace "secrets-5671" to be "Succeeded or Failed"
Apr  7 07:40:05.157: INFO: Pod "pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50": Phase="Pending", Reason="", readiness=false. Elapsed: 7.533588ms
Apr  7 07:40:07.169: INFO: Pod "pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019033087s
STEP: Saw pod success
Apr  7 07:40:07.169: INFO: Pod "pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50" satisfied condition "Succeeded or Failed"
Apr  7 07:40:07.177: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:40:07.215: INFO: Waiting for pod pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50 to disappear
Apr  7 07:40:07.222: INFO: Pod pod-secrets-3227daa7-e6db-4920-8d5c-4bfb5486dd50 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:07.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5671" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":299,"skipped":5888,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:07.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-d231360d-ef53-45d3-9259-7db6770241e7
STEP: Creating a pod to test consume configMaps
Apr  7 07:40:07.349: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca" in namespace "projected-6536" to be "Succeeded or Failed"
Apr  7 07:40:07.356: INFO: Pod "pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.648391ms
Apr  7 07:40:09.377: INFO: Pod "pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028769817s
STEP: Saw pod success
Apr  7 07:40:09.378: INFO: Pod "pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca" satisfied condition "Succeeded or Failed"
Apr  7 07:40:09.386: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:40:09.449: INFO: Waiting for pod pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca to disappear
Apr  7 07:40:09.457: INFO: Pod pod-projected-configmaps-b7e86720-e5d4-41dd-a6d3-475d574862ca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:09.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6536" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":300,"skipped":5950,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:09.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:40:09.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4" in namespace "downward-api-861" to be "Succeeded or Failed"
Apr  7 07:40:09.582: INFO: Pod "downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.188962ms
Apr  7 07:40:11.594: INFO: Pod "downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019076595s
STEP: Saw pod success
Apr  7 07:40:11.594: INFO: Pod "downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4" satisfied condition "Succeeded or Failed"
Apr  7 07:40:11.601: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4 container client-container: <nil>
STEP: delete the pod
Apr  7 07:40:11.638: INFO: Waiting for pod downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4 to disappear
Apr  7 07:40:11.644: INFO: Pod downwardapi-volume-efa94401-e0b1-4b8a-b8a6-386a06754dd4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:11.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-861" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":301,"skipped":5987,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:11.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:40:11.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd" in namespace "downward-api-2832" to be "Succeeded or Failed"
Apr  7 07:40:11.783: INFO: Pod "downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.752998ms
Apr  7 07:40:13.796: INFO: Pod "downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019860863s
STEP: Saw pod success
Apr  7 07:40:13.796: INFO: Pod "downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd" satisfied condition "Succeeded or Failed"
Apr  7 07:40:13.804: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd container client-container: <nil>
STEP: delete the pod
Apr  7 07:40:13.848: INFO: Waiting for pod downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd to disappear
Apr  7 07:40:13.857: INFO: Pod downwardapi-volume-83730fb1-9b61-4dcd-8123-5131d5be9ecd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:13.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2832" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":302,"skipped":5995,"failed":0}
S
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:13.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr  7 07:40:13.990: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr  7 07:40:14.006: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr  7 07:40:14.007: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr  7 07:40:14.035: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr  7 07:40:14.035: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr  7 07:40:14.055: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr  7 07:40:14.055: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr  7 07:40:21.164: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:21.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-7216" for this suite.

• [SLOW TEST:7.319 seconds]
[sig-scheduling] LimitRange
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":346,"completed":303,"skipped":5996,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:21.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  7 07:40:21.310: INFO: Waiting up to 5m0s for pod "pod-33ea3d55-d8f3-4651-9361-736197f403fe" in namespace "emptydir-8437" to be "Succeeded or Failed"
Apr  7 07:40:21.317: INFO: Pod "pod-33ea3d55-d8f3-4651-9361-736197f403fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.753498ms
Apr  7 07:40:23.328: INFO: Pod "pod-33ea3d55-d8f3-4651-9361-736197f403fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018358178s
STEP: Saw pod success
Apr  7 07:40:23.328: INFO: Pod "pod-33ea3d55-d8f3-4651-9361-736197f403fe" satisfied condition "Succeeded or Failed"
Apr  7 07:40:23.336: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-33ea3d55-d8f3-4651-9361-736197f403fe container test-container: <nil>
STEP: delete the pod
Apr  7 07:40:23.379: INFO: Waiting for pod pod-33ea3d55-d8f3-4651-9361-736197f403fe to disappear
Apr  7 07:40:23.386: INFO: Pod pod-33ea3d55-d8f3-4651-9361-736197f403fe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:23.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8437" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":304,"skipped":6024,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr  7 07:40:23.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d" in namespace "projected-1605" to be "Succeeded or Failed"
Apr  7 07:40:23.513: INFO: Pod "downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.195261ms
Apr  7 07:40:25.527: INFO: Pod "downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02118182s
STEP: Saw pod success
Apr  7 07:40:25.527: INFO: Pod "downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d" satisfied condition "Succeeded or Failed"
Apr  7 07:40:25.535: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d container client-container: <nil>
STEP: delete the pod
Apr  7 07:40:25.579: INFO: Waiting for pod downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d to disappear
Apr  7 07:40:25.588: INFO: Pod downwardapi-volume-dfc522ea-16d5-473e-a63a-c2e2cfc0cf5d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:25.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1605" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":346,"completed":305,"skipped":6026,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:25.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-66pw
STEP: Creating a pod to test atomic-volume-subpath
Apr  7 07:40:25.727: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-66pw" in namespace "subpath-714" to be "Succeeded or Failed"
Apr  7 07:40:25.735: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Pending", Reason="", readiness=false. Elapsed: 8.397538ms
Apr  7 07:40:27.754: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 2.026981992s
Apr  7 07:40:29.773: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 4.046681797s
Apr  7 07:40:31.786: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 6.059725494s
Apr  7 07:40:33.805: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 8.077848514s
Apr  7 07:40:35.820: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 10.093512278s
Apr  7 07:40:37.834: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 12.107240489s
Apr  7 07:40:39.856: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 14.129219226s
Apr  7 07:40:41.871: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 16.144206214s
Apr  7 07:40:43.884: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 18.157774612s
Apr  7 07:40:45.900: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Running", Reason="", readiness=true. Elapsed: 20.173620672s
Apr  7 07:40:47.926: INFO: Pod "pod-subpath-test-configmap-66pw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.198926103s
STEP: Saw pod success
Apr  7 07:40:47.926: INFO: Pod "pod-subpath-test-configmap-66pw" satisfied condition "Succeeded or Failed"
Apr  7 07:40:47.936: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-subpath-test-configmap-66pw container test-container-subpath-configmap-66pw: <nil>
STEP: delete the pod
Apr  7 07:40:47.996: INFO: Waiting for pod pod-subpath-test-configmap-66pw to disappear
Apr  7 07:40:48.005: INFO: Pod pod-subpath-test-configmap-66pw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-66pw
Apr  7 07:40:48.005: INFO: Deleting pod "pod-subpath-test-configmap-66pw" in namespace "subpath-714"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:48.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-714" for this suite.

• [SLOW TEST:22.416 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":306,"skipped":6046,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:48.030: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Apr  7 07:40:48.145: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  7 07:40:53.164: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:40:53.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3435" for this suite.

• [SLOW TEST:5.193 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":346,"completed":307,"skipped":6049,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:40:53.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr  7 07:41:03.386: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0407 07:41:03.386886      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:41:03.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4554" for this suite.

• [SLOW TEST:10.181 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":346,"completed":308,"skipped":6050,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:41:03.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Apr  7 07:41:05.630: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:41:07.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8359" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":346,"completed":309,"skipped":6067,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:41:07.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  7 07:41:07.867: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 07:41:07.867: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 07:41:08.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:41:08.885: INFO: Node aks-nodepool1-35379194-vmss000000 is running 0 daemon pod, expected 1
Apr  7 07:41:09.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 07:41:09.890: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  7 07:41:09.933: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:41:09.933: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:41:10.952: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:41:10.952: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:41:11.955: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr  7 07:41:11.955: INFO: Node aks-nodepool1-35379194-vmss000001 is running 0 daemon pod, expected 1
Apr  7 07:41:12.955: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr  7 07:41:12.955: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7129, will wait for the garbage collector to delete the pods
Apr  7 07:41:13.030: INFO: Deleting DaemonSet.extensions daemon-set took: 13.629868ms
Apr  7 07:41:13.131: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.165238ms
Apr  7 07:41:15.947: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr  7 07:41:15.947: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr  7 07:41:15.952: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40516"},"items":null}

Apr  7 07:41:15.959: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40516"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:41:15.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7129" for this suite.

• [SLOW TEST:8.286 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":346,"completed":310,"skipped":6078,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:41:16.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-b8354d81-8c82-48f1-b23a-b20fe442763a
STEP: Creating a pod to test consume secrets
Apr  7 07:41:16.115: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5" in namespace "projected-1999" to be "Succeeded or Failed"
Apr  7 07:41:16.122: INFO: Pod "pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.993645ms
Apr  7 07:41:18.139: INFO: Pod "pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023930762s
STEP: Saw pod success
Apr  7 07:41:18.139: INFO: Pod "pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5" satisfied condition "Succeeded or Failed"
Apr  7 07:41:18.153: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:41:18.198: INFO: Waiting for pod pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5 to disappear
Apr  7 07:41:18.206: INFO: Pod pod-projected-secrets-2963f74b-d4cf-40aa-a019-58f4f5bae8f5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:41:18.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1999" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":311,"skipped":6091,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:41:18.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Apr  7 07:41:20.376: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9801 PodName:var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:41:20.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:41:20.377: INFO: ExecWithOptions: Clientset creation
Apr  7 07:41:20.377: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/var-expansion-9801/pods/var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: test for file in mounted path
Apr  7 07:41:20.511: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9801 PodName:var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr  7 07:41:20.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:41:20.511: INFO: ExecWithOptions: Clientset creation
Apr  7 07:41:20.511: INFO: ExecWithOptions: execute(POST https://10.0.0.1:443/api/v1/namespaces/var-expansion-9801/pods/var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: updating the annotation value
Apr  7 07:41:21.177: INFO: Successfully updated pod "var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Apr  7 07:41:21.185: INFO: Deleting pod "var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc" in namespace "var-expansion-9801"
Apr  7 07:41:21.201: INFO: Wait up to 5m0s for pod "var-expansion-26c6c35a-1b20-4070-a2d7-f6b59a7a07bc" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:41:55.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9801" for this suite.

• [SLOW TEST:37.017 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":346,"completed":312,"skipped":6147,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:41:55.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:42:55.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7505" for this suite.

• [SLOW TEST:60.174 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":346,"completed":313,"skipped":6207,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:42:55.421: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:42:55.540: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr  7 07:42:58.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 create -f -'
Apr  7 07:42:59.092: INFO: stderr: ""
Apr  7 07:42:59.092: INFO: stdout: "e2e-test-crd-publish-openapi-659-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr  7 07:42:59.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 delete e2e-test-crd-publish-openapi-659-crds test-foo'
Apr  7 07:42:59.274: INFO: stderr: ""
Apr  7 07:42:59.274: INFO: stdout: "e2e-test-crd-publish-openapi-659-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr  7 07:42:59.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 apply -f -'
Apr  7 07:42:59.440: INFO: stderr: ""
Apr  7 07:42:59.440: INFO: stdout: "e2e-test-crd-publish-openapi-659-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr  7 07:42:59.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 delete e2e-test-crd-publish-openapi-659-crds test-foo'
Apr  7 07:42:59.529: INFO: stderr: ""
Apr  7 07:42:59.529: INFO: stdout: "e2e-test-crd-publish-openapi-659-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with value outside defined enum values
Apr  7 07:42:59.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 create -f -'
Apr  7 07:42:59.665: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr  7 07:42:59.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 create -f -'
Apr  7 07:43:00.348: INFO: rc: 1
Apr  7 07:43:00.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 apply -f -'
Apr  7 07:43:00.483: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr  7 07:43:00.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 create -f -'
Apr  7 07:43:00.630: INFO: rc: 1
Apr  7 07:43:00.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 --namespace=crd-publish-openapi-3928 apply -f -'
Apr  7 07:43:00.772: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr  7 07:43:00.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 explain e2e-test-crd-publish-openapi-659-crds'
Apr  7 07:43:00.915: INFO: stderr: ""
Apr  7 07:43:00.915: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr  7 07:43:00.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 explain e2e-test-crd-publish-openapi-659-crds.metadata'
Apr  7 07:43:01.049: INFO: stderr: ""
Apr  7 07:43:01.049: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr  7 07:43:01.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 explain e2e-test-crd-publish-openapi-659-crds.spec'
Apr  7 07:43:01.188: INFO: stderr: ""
Apr  7 07:43:01.188: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr  7 07:43:01.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 explain e2e-test-crd-publish-openapi-659-crds.spec.bars'
Apr  7 07:43:01.319: INFO: stderr: ""
Apr  7 07:43:01.319: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr  7 07:43:01.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=crd-publish-openapi-3928 explain e2e-test-crd-publish-openapi-659-crds.spec.bars2'
Apr  7 07:43:01.453: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:43:04.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3928" for this suite.

• [SLOW TEST:8.997 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":346,"completed":314,"skipped":6207,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:43:04.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name projected-secret-test-0e4c997b-666e-4458-9b22-e0e0952e0f4a
STEP: Creating a pod to test consume secrets
Apr  7 07:43:04.548: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d" in namespace "projected-4118" to be "Succeeded or Failed"
Apr  7 07:43:04.557: INFO: Pod "pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.353135ms
Apr  7 07:43:06.572: INFO: Pod "pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024121452s
STEP: Saw pod success
Apr  7 07:43:06.572: INFO: Pod "pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d" satisfied condition "Succeeded or Failed"
Apr  7 07:43:06.580: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:43:06.617: INFO: Waiting for pod pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d to disappear
Apr  7 07:43:06.626: INFO: Pod pod-projected-secrets-a265517a-a087-40b8-bdba-29a0dc16921d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:43:06.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4118" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":315,"skipped":6209,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:43:06.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:43:23.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4324" for this suite.

• [SLOW TEST:16.382 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":346,"completed":316,"skipped":6210,"failed":0}
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:43:23.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  7 07:43:23.155: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7283  c8deb509-b47e-49df-b50a-1f915c8a5b03 41219 0 2022-04-07 07:43:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-07 07:43:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:43:23.155: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7283  c8deb509-b47e-49df-b50a-1f915c8a5b03 41220 0 2022-04-07 07:43:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-07 07:43:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  7 07:43:23.187: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7283  c8deb509-b47e-49df-b50a-1f915c8a5b03 41221 0 2022-04-07 07:43:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-07 07:43:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr  7 07:43:23.187: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7283  c8deb509-b47e-49df-b50a-1f915c8a5b03 41222 0 2022-04-07 07:43:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-07 07:43:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:43:23.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7283" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":346,"completed":317,"skipped":6210,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:43:23.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:45:01.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4221" for this suite.

• [SLOW TEST:98.143 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":346,"completed":318,"skipped":6237,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:45:01.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:45:05.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5151" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":346,"completed":319,"skipped":6246,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:45:05.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:45:05.961: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:45:09.015: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:45:09.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5724" for this suite.
STEP: Destroying namespace "webhook-5724-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":346,"completed":320,"skipped":6252,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:45:09.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:45:09.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6362" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":346,"completed":321,"skipped":6271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:45:09.330: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-7699
[It] Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7699
STEP: Waiting until pod test-pod will start running in namespace statefulset-7699
STEP: Creating statefulset with conflicting port in namespace statefulset-7699
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7699
Apr  7 07:45:11.623: INFO: Observed stateful pod in namespace: statefulset-7699, name: ss-0, uid: dc8487eb-c27c-4f75-9f51-46d8de3872ed, status phase: Pending. Waiting for statefulset controller to delete.
Apr  7 07:45:11.650: INFO: Observed stateful pod in namespace: statefulset-7699, name: ss-0, uid: dc8487eb-c27c-4f75-9f51-46d8de3872ed, status phase: Failed. Waiting for statefulset controller to delete.
Apr  7 07:45:11.663: INFO: Observed stateful pod in namespace: statefulset-7699, name: ss-0, uid: dc8487eb-c27c-4f75-9f51-46d8de3872ed, status phase: Failed. Waiting for statefulset controller to delete.
Apr  7 07:45:11.667: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7699
STEP: Removing pod with conflicting port in namespace statefulset-7699
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7699 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Apr  7 07:45:13.733: INFO: Deleting all statefulset in ns statefulset-7699
Apr  7 07:45:13.742: INFO: Scaling statefulset ss to 0
Apr  7 07:45:23.786: INFO: Waiting for statefulset status.replicas updated to 0
Apr  7 07:45:23.793: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:45:23.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7699" for this suite.

• [SLOW TEST:14.506 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Should recreate evicted statefulset [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":346,"completed":322,"skipped":6300,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:45:23.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr  7 07:45:23.932: INFO: Waiting up to 1m0s for all nodes to be ready
Apr  7 07:46:23.965: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:46:23.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:679
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:46:24.142: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Apr  7 07:46:24.147: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:46:24.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2009" for this suite.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:693
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:46:24.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7754" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:60.447 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:673
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":346,"completed":323,"skipped":6306,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:46:24.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:46:26.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3148" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":346,"completed":324,"skipped":6338,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:46:26.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:56
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-1aca14fe-3d42-411b-b835-0e0742e22cb9 in namespace container-probe-9616
Apr  7 07:46:28.677: INFO: Started pod liveness-1aca14fe-3d42-411b-b835-0e0742e22cb9 in namespace container-probe-9616
STEP: checking the pod's current state and verifying that restartCount is present
Apr  7 07:46:28.685: INFO: Initial restart count of pod liveness-1aca14fe-3d42-411b-b835-0e0742e22cb9 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:50:30.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9616" for this suite.

• [SLOW TEST:244.085 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":346,"completed":325,"skipped":6347,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:50:30.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-f0b1ef84-5074-465e-bb6a-ddce5f3f1482
STEP: Creating configMap with name cm-test-opt-upd-84e48592-8630-4e90-a7a2-1d9e9f510696
STEP: Creating the pod
Apr  7 07:50:30.750: INFO: The status of Pod pod-projected-configmaps-a758191b-01c8-4166-a3ab-4f97c2fc6908 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:50:32.766: INFO: The status of Pod pod-projected-configmaps-a758191b-01c8-4166-a3ab-4f97c2fc6908 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-f0b1ef84-5074-465e-bb6a-ddce5f3f1482
STEP: Updating configmap cm-test-opt-upd-84e48592-8630-4e90-a7a2-1d9e9f510696
STEP: Creating configMap with name cm-test-opt-create-5371df28-f45c-438a-a3c1-334397724270
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:51:53.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1156" for this suite.

• [SLOW TEST:83.113 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":326,"skipped":6358,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:51:53.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:51:54.349: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:51:57.389: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:51:57.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:00.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-834" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.376 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":346,"completed":327,"skipped":6367,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:01.099: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:01.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2536" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":346,"completed":328,"skipped":6377,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:01.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4082
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-4082
I0407 07:52:01.427792      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4082, replica count: 2
Apr  7 07:52:04.479: INFO: Creating new exec pod
I0407 07:52:04.479294      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  7 07:52:07.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4082 exec execpoddlvbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr  7 07:52:07.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr  7 07:52:07.744: INFO: stdout: "externalname-service-ccq9v"
Apr  7 07:52:07.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4082 exec execpoddlvbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.107.100 80'
Apr  7 07:52:07.955: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.107.100 80\nConnection to 10.0.107.100 80 port [tcp/http] succeeded!\n"
Apr  7 07:52:07.955: INFO: stdout: "externalname-service-ccq9v"
Apr  7 07:52:07.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4082 exec execpoddlvbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.4 32382'
Apr  7 07:52:08.179: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.4 32382\nConnection to 10.240.0.4 32382 port [tcp/*] succeeded!\n"
Apr  7 07:52:08.179: INFO: stdout: "externalname-service-6brbx"
Apr  7 07:52:08.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=services-4082 exec execpoddlvbr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.240.0.5 32382'
Apr  7 07:52:08.383: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.240.0.5 32382\nConnection to 10.240.0.5 32382 port [tcp/*] succeeded!\n"
Apr  7 07:52:08.383: INFO: stdout: "externalname-service-6brbx"
Apr  7 07:52:08.383: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:08.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4082" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.238 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":346,"completed":329,"skipped":6389,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:08.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  7 07:52:09.582: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  7 07:52:12.629: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:22.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9424" for this suite.
STEP: Destroying namespace "webhook-9424-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:14.503 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":346,"completed":330,"skipped":6402,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:22.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-31960cba-0b94-46de-9551-9c3ed61f3948
STEP: Creating a pod to test consume secrets
Apr  7 07:52:23.076: INFO: Waiting up to 5m0s for pod "pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469" in namespace "secrets-9676" to be "Succeeded or Failed"
Apr  7 07:52:23.083: INFO: Pod "pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469": Phase="Pending", Reason="", readiness=false. Elapsed: 7.373272ms
Apr  7 07:52:25.092: INFO: Pod "pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016310493s
STEP: Saw pod success
Apr  7 07:52:25.092: INFO: Pod "pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469" satisfied condition "Succeeded or Failed"
Apr  7 07:52:25.100: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469 container secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:52:25.141: INFO: Waiting for pod pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469 to disappear
Apr  7 07:52:25.148: INFO: Pod pod-secrets-89fb371d-3028-48b2-8ea2-b461fc9c2469 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:25.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9676" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":331,"skipped":6414,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:25.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-077ba1b5-abae-45e9-ad46-9c21671c8c56
STEP: Creating secret with name s-test-opt-upd-d77bbd37-49c9-40df-8ca9-1e4e44043936
STEP: Creating the pod
Apr  7 07:52:25.325: INFO: The status of Pod pod-projected-secrets-0dad616c-8c1b-4dfa-b9c9-0e510f54dbf1 is Pending, waiting for it to be Running (with Ready = true)
Apr  7 07:52:27.339: INFO: The status of Pod pod-projected-secrets-0dad616c-8c1b-4dfa-b9c9-0e510f54dbf1 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-077ba1b5-abae-45e9-ad46-9c21671c8c56
STEP: Updating secret s-test-opt-upd-d77bbd37-49c9-40df-8ca9-1e4e44043936
STEP: Creating secret with name s-test-opt-create-bf3635c7-bf70-4db6-9818-c25252603729
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:31.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4155" for this suite.

• [SLOW TEST:6.381 seconds]
[sig-storage] Projected secret
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":332,"skipped":6435,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:31.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr  7 07:52:31.636: INFO: Waiting up to 5m0s for pod "downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f" in namespace "downward-api-8075" to be "Succeeded or Failed"
Apr  7 07:52:31.643: INFO: Pod "downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.460478ms
Apr  7 07:52:33.657: INFO: Pod "downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020784962s
STEP: Saw pod success
Apr  7 07:52:33.657: INFO: Pod "downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f" satisfied condition "Succeeded or Failed"
Apr  7 07:52:33.664: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000000 pod downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f container dapi-container: <nil>
STEP: delete the pod
Apr  7 07:52:33.712: INFO: Waiting for pod downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f to disappear
Apr  7 07:52:33.723: INFO: Pod downward-api-45c90970-e4a7-4cd4-b437-f27abdeb860f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:52:33.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8075" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":346,"completed":333,"skipped":6443,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:52:33.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:33.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4069" for this suite.

• [SLOW TEST:300.144 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":346,"completed":334,"skipped":6455,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:33.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr  7 07:57:33.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-7446 version'
Apr  7 07:57:34.073: INFO: stderr: ""
Apr  7 07:57:34.074: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.3\", GitCommit:\"816c97ab8cff8a1c72eccca1026f7820e93e0d25\", GitTreeState:\"clean\", BuildDate:\"2022-01-25T21:25:17Z\", GoVersion:\"go1.17.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.3\", GitCommit:\"b3ebd2a377c24ca08085f6a47e2d8f8b380b8a3a\", GitTreeState:\"clean\", BuildDate:\"2022-03-10T08:01:37Z\", GoVersion:\"go1.17.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:34.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7446" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":346,"completed":335,"skipped":6470,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:34.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-4ec26eed-ae16-4349-b25b-2ededa78097e
STEP: Creating a pod to test consume secrets
Apr  7 07:57:34.197: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4" in namespace "projected-6506" to be "Succeeded or Failed"
Apr  7 07:57:34.204: INFO: Pod "pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.698292ms
Apr  7 07:57:36.217: INFO: Pod "pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020520005s
STEP: Saw pod success
Apr  7 07:57:36.217: INFO: Pod "pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4" satisfied condition "Succeeded or Failed"
Apr  7 07:57:36.225: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:57:36.277: INFO: Waiting for pod pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4 to disappear
Apr  7 07:57:36.286: INFO: Pod pod-projected-secrets-32cc48f9-0c23-4f98-9968-49847d0850a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:36.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6506" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":336,"skipped":6478,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:36.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1571
[It] should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Apr  7 07:57:36.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4668 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr  7 07:57:36.532: INFO: stderr: ""
Apr  7 07:57:36.532: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr  7 07:57:41.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4668 get pod e2e-test-httpd-pod -o json'
Apr  7 07:57:41.661: INFO: stderr: ""
Apr  7 07:57:41.661: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-04-07T07:57:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4668\",\n        \"resourceVersion\": \"45231\",\n        \"uid\": \"286b1332-53de-451e-8401-efa1407d2b0b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-qbf95\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"aks-nodepool1-35379194-vmss000001\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-qbf95\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-07T07:57:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-07T07:57:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-07T07:57:37Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-07T07:57:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://473b76c81178e010dd3314aaca17c2fc28b6a3aaf96d5b2030fc5416b4b17b24\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-04-07T07:57:37Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.240.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.220\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.220\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-04-07T07:57:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  7 07:57:41.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4668 replace -f -'
Apr  7 07:57:41.874: INFO: stderr: ""
Apr  7 07:57:41.874: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1575
Apr  7 07:57:41.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-4668 delete pods e2e-test-httpd-pod'
Apr  7 07:57:44.017: INFO: stderr: ""
Apr  7 07:57:44.018: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:44.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4668" for this suite.

• [SLOW TEST:7.736 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
    should update a single-container pod's image  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":346,"completed":337,"skipped":6492,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:44.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-51c42e4b-03af-4907-ae5f-126a5e9aa60d
STEP: Creating a pod to test consume configMaps
Apr  7 07:57:44.164: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8" in namespace "configmap-5714" to be "Succeeded or Failed"
Apr  7 07:57:44.172: INFO: Pod "pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.740396ms
Apr  7 07:57:46.187: INFO: Pod "pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022888562s
STEP: Saw pod success
Apr  7 07:57:46.187: INFO: Pod "pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8" satisfied condition "Succeeded or Failed"
Apr  7 07:57:46.195: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:57:46.230: INFO: Waiting for pod pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8 to disappear
Apr  7 07:57:46.237: INFO: Pod pod-configmaps-a8c3f260-a79b-4142-86cd-4a2a4f4160f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:46.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5714" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":338,"skipped":6498,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:46.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-15704273-e78f-4226-bdac-22ff09f3b8d4
STEP: Creating a pod to test consume secrets
Apr  7 07:57:46.373: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8" in namespace "projected-7707" to be "Succeeded or Failed"
Apr  7 07:57:46.381: INFO: Pod "pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.222363ms
Apr  7 07:57:48.391: INFO: Pod "pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017185797s
STEP: Saw pod success
Apr  7 07:57:48.391: INFO: Pod "pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8" satisfied condition "Succeeded or Failed"
Apr  7 07:57:48.398: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  7 07:57:48.440: INFO: Waiting for pod pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8 to disappear
Apr  7 07:57:48.448: INFO: Pod pod-projected-secrets-e5a4ede0-b48d-455d-b13f-a854dfb4c4a8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:48.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7707" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":339,"skipped":6551,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:48.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating secret secrets-8294/secret-test-a6844e39-0a26-43d4-92a2-b695166834e3
STEP: Creating a pod to test consume secrets
Apr  7 07:57:48.593: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd" in namespace "secrets-8294" to be "Succeeded or Failed"
Apr  7 07:57:48.602: INFO: Pod "pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.04588ms
Apr  7 07:57:50.617: INFO: Pod "pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024470564s
STEP: Saw pod success
Apr  7 07:57:50.617: INFO: Pod "pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd" satisfied condition "Succeeded or Failed"
Apr  7 07:57:50.630: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd container env-test: <nil>
STEP: delete the pod
Apr  7 07:57:50.669: INFO: Waiting for pod pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd to disappear
Apr  7 07:57:50.677: INFO: Pod pod-configmaps-3ab12bdc-627e-4471-aa84-a988dca328fd no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:57:50.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8294" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":340,"skipped":6564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:57:50.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr  7 07:57:50.773: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
Apr  7 07:57:53.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:06.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-384" for this suite.

• [SLOW TEST:15.701 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":346,"completed":341,"skipped":6589,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:58:06.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override arguments
Apr  7 07:58:06.518: INFO: Waiting up to 5m0s for pod "client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2" in namespace "containers-1792" to be "Succeeded or Failed"
Apr  7 07:58:06.526: INFO: Pod "client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.266133ms
Apr  7 07:58:08.538: INFO: Pod "client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020388797s
STEP: Saw pod success
Apr  7 07:58:08.538: INFO: Pod "client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2" satisfied condition "Succeeded or Failed"
Apr  7 07:58:08.546: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2 container agnhost-container: <nil>
STEP: delete the pod
Apr  7 07:58:08.593: INFO: Waiting for pod client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2 to disappear
Apr  7 07:58:08.601: INFO: Pod client-containers-fca76d58-7bd0-4547-9a71-e49489d9c8e2 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:08.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1792" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":346,"completed":342,"skipped":6629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:58:08.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-0b3bc51c-4284-4340-9879-5db098388216
STEP: Creating a pod to test consume configMaps
Apr  7 07:58:08.746: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784" in namespace "projected-6680" to be "Succeeded or Failed"
Apr  7 07:58:08.753: INFO: Pod "pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784": Phase="Pending", Reason="", readiness=false. Elapsed: 6.899542ms
Apr  7 07:58:10.766: INFO: Pod "pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020342252s
STEP: Saw pod success
Apr  7 07:58:10.766: INFO: Pod "pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784" satisfied condition "Succeeded or Failed"
Apr  7 07:58:10.775: INFO: Trying to get logs from node aks-nodepool1-35379194-vmss000001 pod pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  7 07:58:10.836: INFO: Waiting for pod pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784 to disappear
Apr  7 07:58:10.848: INFO: Pod pod-projected-configmaps-ba2e3c35-f862-4d8c-8056-d0bba16e7784 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:10.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6680" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":343,"skipped":6652,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:58:10.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Apr  7 07:58:10.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 create -f -'
Apr  7 07:58:11.711: INFO: stderr: ""
Apr  7 07:58:11.711: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  7 07:58:11.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 07:58:11.787: INFO: stderr: ""
Apr  7 07:58:11.787: INFO: stdout: "update-demo-nautilus-7s5b4 update-demo-nautilus-ch9w2 "
Apr  7 07:58:11.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods update-demo-nautilus-7s5b4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 07:58:11.877: INFO: stderr: ""
Apr  7 07:58:11.877: INFO: stdout: ""
Apr  7 07:58:11.877: INFO: update-demo-nautilus-7s5b4 is created but not running
Apr  7 07:58:16.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr  7 07:58:16.968: INFO: stderr: ""
Apr  7 07:58:16.968: INFO: stdout: "update-demo-nautilus-7s5b4 update-demo-nautilus-ch9w2 "
Apr  7 07:58:16.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods update-demo-nautilus-7s5b4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 07:58:17.050: INFO: stderr: ""
Apr  7 07:58:17.050: INFO: stdout: "true"
Apr  7 07:58:17.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods update-demo-nautilus-7s5b4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 07:58:17.127: INFO: stderr: ""
Apr  7 07:58:17.127: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 07:58:17.127: INFO: validating pod update-demo-nautilus-7s5b4
Apr  7 07:58:17.139: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 07:58:17.139: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 07:58:17.139: INFO: update-demo-nautilus-7s5b4 is verified up and running
Apr  7 07:58:17.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods update-demo-nautilus-ch9w2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr  7 07:58:17.208: INFO: stderr: ""
Apr  7 07:58:17.208: INFO: stdout: "true"
Apr  7 07:58:17.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods update-demo-nautilus-ch9w2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr  7 07:58:17.276: INFO: stderr: ""
Apr  7 07:58:17.276: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Apr  7 07:58:17.276: INFO: validating pod update-demo-nautilus-ch9w2
Apr  7 07:58:17.290: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  7 07:58:17.290: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  7 07:58:17.290: INFO: update-demo-nautilus-ch9w2 is verified up and running
STEP: using delete to clean up resources
Apr  7 07:58:17.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 delete --grace-period=0 --force -f -'
Apr  7 07:58:17.375: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  7 07:58:17.375: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  7 07:58:17.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get rc,svc -l name=update-demo --no-headers'
Apr  7 07:58:17.467: INFO: stderr: "No resources found in kubectl-5670 namespace.\n"
Apr  7 07:58:17.467: INFO: stdout: ""
Apr  7 07:58:17.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2045114083 --namespace=kubectl-5670 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  7 07:58:17.544: INFO: stderr: ""
Apr  7 07:58:17.544: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:17.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5670" for this suite.

• [SLOW TEST:6.685 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should create and stop a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":346,"completed":344,"skipped":6683,"failed":0}
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:58:17.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  7 07:58:19.739: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:19.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8749" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":346,"completed":345,"skipped":6685,"failed":0}
SSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr  7 07:58:19.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2045114083
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:39
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: mirroring a new custom Endpoint
Apr  7 07:58:19.929: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Apr  7 07:58:21.960: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Apr  7 07:58:23.993: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr  7 07:58:26.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-9606" for this suite.

• [SLOW TEST:6.227 seconds]
[sig-network] EndpointSliceMirroring
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":346,"completed":346,"skipped":6691,"failed":0}
SSSSSApr  7 07:58:26.020: INFO: Running AfterSuite actions on all nodes
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func18.2
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr  7 07:58:26.020: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Apr  7 07:58:26.020: INFO: Running AfterSuite actions on node 1
Apr  7 07:58:26.020: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":346,"completed":346,"skipped":6696,"failed":0}

Ran 346 of 7042 Specs in 5347.709 seconds
SUCCESS! -- 346 Passed | 0 Failed | 0 Pending | 6696 Skipped
PASS

Ginkgo ran 1 suite in 1h29m9.882994057s
Test Suite Passed
